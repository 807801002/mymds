# 精尽 Netty 面试题



以下面试题，基于网络整理，和自己编辑。具体参考的文章，会在文末给出所有的链接。

如果胖友有自己的疑问，欢迎在星球提问，我们一起整理吊吊的 Netty 面试题的大保健。

而题目的难度，艿艿尽量按照从容易到困难的顺序，逐步下去。

## BIO 是什么？

🦅 **概念**

- BIO ，全称 Block-IO ，是一种**阻塞** + **同步**的通信模式。
- 是一个比较传统的通信方式，模式简单，使用方便。但并发处理能力低，通信耗时，依赖网速。

🦅 **原理**

- 服务器通过一个 Acceptor 线程，负责监听客户端请求和为每个客户端创建一个新的线程进行链路处理。典型的**一请求一应答模式**。
- 若客户端数量增多，频繁地创建和销毁线程会给服务器打开很大的压力。后改良为用线程池的方式代替新增线程，被称为伪异步 IO 。

🦅 **示例**

- 代码参见 [bio](https://github.com/ITDragonBlog/daydayup/tree/master/Netty/socket-io/src/com/itdragon/bio) 。

🦅 **小结**

BIO 模型中，通过 Socket 和 ServerSocket 实现套接字通道的通信。阻塞，同步，建立连接耗时。

## NIO 是什么？

🦅 **概念**

- NIO ，全称 New IO ，也叫 Non-Block IO ，是一种**非阻塞** + 同步的通信模式。
- [《精尽 Netty 源码分析 —— NIO 基础（一）之简介》](http://svip.iocoder.cn/Netty/nio-1-intro/)

🦅 **原理**

- NIO 相对于 BIO 来说一大进步。客户端和服务器之间通过 Channel 通信。NIO 可以在 Channel 进行读写操作。这些 Channel 都会被注册在 Selector 多路复用器上。Selector 通过一个线程不停的轮询这些 Channel 。找出已经准备就绪的 Channel 执行 IO 操作。
- NIO 通过一个线程轮询，实现千万个客户端的请求，这就是非阻塞 NIO 的特点。
  - 缓冲区 Buffer ：它是 NIO 与 BIO 的一个重要区别。
    - BIO 是将数据直接写入或读取到流 Stream 对象中。
    - NIO 的数据操作都是在 Buffer 中进行的。Buffer 实际上是一个数组。Buffer 最常见的类型是ByteBuffer，另外还有 CharBuffer，ShortBuffer，IntBuffer，LongBuffer，FloatBuffer，DoubleBuffer。
    - [《精尽 Netty 源码分析 —— NIO 基础（三）之 Buffer》](http://svip.iocoder.cn/Netty/nio-3-buffer/)
  - 通道 Channel ：和流 Stream 不同，通道是双向的。NIO可以通过 Channel 进行数据的读、写和同时读写操作。
    - 通道分为两大类：一类是网络读写（SelectableChannel），一类是用于文件操作（FileChannel）。我们使用的是前者 SocketChannel 和 ServerSocketChannel ，都是SelectableChannel 的子类。
    - [《精尽 Netty 源码分析 —— NIO 基础（二）之 Channel》](http://svip.iocoder.cn/Netty/nio-2-channel/)
  - 多路复用器 Selector ：NIO 编程的基础。多路复用器提供选择已经就绪的任务的能力：就是 Selector 会不断地轮询注册在其上的通道（Channel），如果某个通道处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以取得就绪的Channel集合，从而进行后续的 IO 操作。
    - 服务器端只要提供一个线程负责 Selector 的轮询，就可以接入成千上万个客户端，这就是 JDK NIO 库的巨大进步。
    - [《精尽 Netty 源码分析 —— NIO 基础（四）之 Selector》](http://svip.iocoder.cn/Netty/nio-4-selector/)

🦅 **示例**

- 代码参见 [nio](https://github.com/ITDragonBlog/daydayup/tree/master/Netty/socket-io/src/com/itdragon/nio)
- [《精尽 Netty 源码分析 —— NIO 基础（五）之示例》](http://svip.iocoder.cn/Netty/nio-5-demo/)

🦅 **小结**

NIO 模型中通过 SocketChannel 和 ServerSocketChannel 实现套接字通道的通信。非阻塞，同步，避免为每个 TCP 连接创建一个线程。

🦅 **继续挖掘**

可能有胖友对非阻塞和阻塞，同步和异步的定义有点懵逼，我们再来看下 [《精尽 Netty 源码分析 —— NIO 基础（一）之简介》](http://svip.iocoder.cn/Netty/nio-1-intro/) 提到的一段话：

> 老艿艿：在一些文章中，会将 Java NIO 描述成**异步** IO ，实际是不太正确的： Java NIO 是**同步** IO ，Java AIO ( 也称为 NIO 2 )是**异步** IO。具体原因，推荐阅读文章：
>
> - [《异步和非阻塞一样吗? (内容涉及 BIO, NIO, AIO, Netty)》](https://blog.csdn.net/matthew_zhang/article/details/71328697) 。
> - [《BIO与NIO、AIO的区别(这个容易理解)》](https://blog.csdn.net/skiof007/article/details/52873421)
>
> 总结来说，在 **Unix IO 模型**的语境下：
>
> - 同步和异步的区别：数据拷贝阶段是否需要完全由操作系统处理。
> - 阻塞和非阻塞操作：是针对发起 IO 请求操作后，是否有立刻返回一个标志信息而不让请求线程等待。
>
> 因此，Java NIO 是**同步**且非阻塞的 IO 。

- 另外，胖友在瞅瞅下面这个图来理解下：![Unix 的 5 种 IO 模型](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554204497065.png)

## AIO 是什么？

> 艿艿：这个面试题，重点在于陈述我们对 BIO、NIO 的理解，对于 AIO 来说，基本理解即可。

🦅 **概念**

- AIO ，全称 Asynchronous IO ，也叫 NIO**2** ，是一种**非阻塞** + **异步**的通信模式。在 NIO 的基础上，引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。
- 原理：
- AIO 并没有采用 NIO 的多路复用器，而是使用异步通道的概念。其 read，write 方法的返回类型，都是 Future 对象。而 Future 模型是异步的，其核心思想是：**去主函数等待时间**。

🦅 **示例**

- 代码参见 [aio](https://github.com/ITDragonBlog/daydayup/tree/master/Netty/socket-io/src/com/itdragon/aio)

🦅 **小结**

AIO 模型中通过 AsynchronousSocketChannel 和 AsynchronousServerSocketChannel 实现套接字通道的通信。非阻塞，异步。

## BIO、NIO 有什么区别？

- 线程模型不同
  - BIO：一个连接一个线程，客户端有连接请求时服务器端就需要启动一个线程进行处理。所以，线程开销大。可改良为用线程池的方式代替新创建线程，被称为伪异步 IO 。
  - NIO：一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有新的 I/O 请求时，才启动一个线程进行处理。可改良为一个线程处理多个请求，基于 [多 Reactor 模型](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/)。
- BIO 是面向流( Stream )的，而 NIO 是面向缓冲区( Buffer )的。
- BIO 的各种操作是阻塞的，而 NIO 的各种操作是非阻塞的。
- BIO 的 Socket 是单向的，而 NIO 的 Channel 是双向的。

可能文字比较难记，整理出来就是下图：![BIO 对比 NIO 对比 AIO](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554204497089.png)

- 有一点要注意，虽然图中说 NIO 的性能一般，但是在绝大多数我们日常业务场景，NIO 和 AIO 的性能差距实际没这么大。在 Netty5 中，基于 AIO 改造和支持，最后发现，性能并没有想象中这么强悍，所以 Netty5 被废弃，而是继续保持 Netty4 为主版本，使用 NIO 为主。

为了胖友能更好的记住和理解 BIO、NIO、AIO 的流程，胖友可以在理解下图：![BIO、NIO、AIO 的流程图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554204497096.png)

## 什么是 Netty ？

> Netty 是一款提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。
>
> 也就是说，Netty 是一个基于 NIO 的客户、服务器端编程框架。使用 Netty 可以确保你快速和简单地开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty 相当简化和流线化了网络应用的编程开发过程，例如，TCP 和 UDP 的 socket 服务开发。
>
> （以上摘自百度百科）。

Netty 具有如下特性( 摘自《Netty in Action》 )

| 分类     | Netty的特性                                                  |
| -------- | ------------------------------------------------------------ |
| 设计     | 1. 统一的 API ，支持多种传输类型( 阻塞和非阻塞的 )  2. 简单而强大的线程模型  3. 真正的无连接数据报套接字( UDP )支持  4. 连接逻辑组件( ChannelHander 中顺序处理消息 )以及组件复用( 一个 ChannelHandel 可以被多个ChannelPipeLine 复用 ) |
| 易于使用 | 1. 详实的 Javadoc 和大量的示例集  2. 不需要超过 JDK 1.6+ 的依赖 |
| 性能     | 拥有比 Java 的核心 API 更高的吞吐量以及更低的延迟( 得益于池化和复用 )，更低的资源消耗以及最少的内存复制 |
| 健壮性   | 1. 不会因为慢速、快速或者超载的连接而导致 OutOfMemoryError  2. 消除在高速网络中 NIO 应用程序常见的不公平读 / 写比率 |
| 安全性   | 完整的 SSL/TLS 以及 StartTLs 支持，可用于受限环境下，如 Applet 和 OSGI |
| 社区驱动 | 发布快速而且频繁                                             |

## 为什么选择 Netty ？

- **使用简单**：API 使用简单，开发门槛低。
- **功能强大**：预置了多种编解码功能，支持多种主流协议。
- **定制能力强**：可以通过 ChannelHandler 对通信框架进行灵活的扩展。
- **性能高**：通过与其它业界主流的 NIO 框架对比，Netty 的综合性能最优。
- **成熟稳定**：Netty 修复了已经发现的所有 JDK NIO BUG，业务开发人员不需要再为 NIO 的 BUG 而烦恼。
- **社区活跃**：版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会被加入。
- **案例丰富**：经历了大规模的商业应用考验，质量已经得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它可以完全满足不同行业的商业应用。

实际上，这个也是我们做技术选型的一些参考点，不仅仅适用于 Netty ，也同样适用于其他技术栈。当然，😈 面试都可以酱紫回答，显得很高端。

## 为什么说 Netty 使用简单？

🦅 我们假设要搭建一个 Server 服务器，使用 **Java NIO 的步骤**如下：

1. 创建 ServerSocketChannel 。

   - 绑定监听端口，并配置为非阻塞模式。

2. 创建 Selector，将之前创建的 ServerSocketChannel 注册到 Selector 上，监听

    

   ```
   SelectionKey.OP_ACCEPT
   ```

    

   。

   - 循环执行 `Selector#select()` 方法，轮询就绪的 Channel。

3. 轮询就绪的 Channel 时，如果是处于

    

   ```
   OP_ACCEPT
   ```

    

   状态，说明是新的客户端接入，调用

    

   ```
   ServerSocketChannel#accept()
   ```

    

   方法，接收新的客户端。

   - 设置新接入的 SocketChannel 为非阻塞模式，并注册到 Selector 上，监听 `OP_READ` 。

4. 如果轮询的 Channel 状态是

    

   ```
   OP_READ
   ```

    

   ，说明有新的就绪数据包需要读取，则构造 ByteBuffer 对象，读取数据。

   - 这里，解码数据包的过程，需要我们自己编写。

> 艿艿：注意噢，上述步骤还是最简的 Java NIO 启动步骤，不包括**多 Reactor 多线程模型**噢！可能有胖友不知道什么是 Reactor 模型，在 [「什么是 Reactor 模型？」](http://svip.iocoder.cn/Netty/Interview/#) 问题中，我们会详细解释。

🦅 使用 **Netty 的步骤**如下：

1. 创建 NIO 线程组 EventLoopGroup 和 ServerBootstrap。
   - 设置 ServerBootstrap 的属性：线程组、SO_BACKLOG 选项，设置 NioServerSocketChannel 为 Channel
   - 设置业务处理 Handler 和 编解码器 Codec 。
   - 绑定端口，启动服务器程序。
2. 在业务处理 Handler 中，处理客户端发送的数据，并给出响应。

🦅 那么相比 Java NIO，使用 Netty 开发程序，都**简化了哪些步骤**呢？

1. 无需关心 `OP_ACCEPT`、`OP_READ`、`OP_WRITE` 等等 **IO 操作**，Netty 已经封装，对我们在使用是透明无感的。
2. 使用 boss 和 worker EventLoopGroup ，Netty 直接提供**多 Reactor 多线程模型**。
3. 在 Netty 中，我们看到有使用一个解码器 FixedLengthFrameDecoder，可以用于处理定长消息的问题，能够解决 **TCP 粘包拆包**问题，十分方便。如果使用 Java NIO ，需要我们自行实现解码器。

------

😈 如果胖友不知道如何使用 Java NIO 编写一个 Server ，建议自己去实现以下。
😈 如果胖友没有使用过 Netty 编写一个 Server ，建议去入门下。

## 说说业务中 Netty 的使用场景？

- 构建高性能、低时延的各种 Java 中间件，Netty 主要作为基础通信框架提供高性能、低时延的通信服务。例如：
  - RocketMQ ，分布式消息队列。
  - Dubbo ，服务调用框架。
  - Spring WebFlux ，基于响应式的 Web 框架。
  - HDFS ，分布式文件系统。
- 公有或者私有协议栈的基础通信框架，例如可以基于 Netty 构建异步、高性能的 WebSocket、Protobuf 等协议的支持。
- 各领域应用，例如大数据、游戏等，Netty 作为高性能的通信框架用于内部各模块的数据分发、传输和汇总等，实现模块之间高性能通信。

## 说说 Netty 如何实现高性能？

1. **线程模型** ：更加优雅的 Reactor 模式实现、灵活的线程模型、利用 EventLoop 等创新性的机制，可以非常高效地管理成百上千的 Channel 。

2. **内存池设计** ：使用池化的 Direct Buffer 等技术，在提高 IO 性能的同时，减少了对象的创建和销毁。并且，内吃吃的内部实现是用一颗二叉查找树，更好的管理内存分配情况。

3. **内存零拷贝** ：使用 Direct Buffer ，可以使用 Zero-Copy 机制。

   > Zero-Copy ，在操作数据时，不需要将数据 Buffer 从一个内存区域拷贝到另一个内存区域。因为少了一次内存的拷贝，因此 CPU 的效率就得到的提升。

4. **协议支持** ：提供对 Protobuf 等高性能序列化协议支持。

5. 使用更多本地代码

   。例如：

   - 直接利用 JNI 调用 Open SSL 等方式，获得比 Java 内建 SSL 引擎更好的性能。
   - 利用 JNI 提供了 Native Socket Transport ，在使用 Epoll edge-triggered 的情况下，可以有一定的性能提升。

6. 其它：

   - 利用反射等技术直接操纵 SelectionKey ，使用数组而不是 Java 容器等。
   - 实现 [FastThreadLocal](https://segmentfault.com/a/1190000012926809) 类，当请求频繁时，带来更好的性能。
   - ….

另外，推荐阅读白衣大大的两篇文章：

1. [《Netty高性能编程备忘录(上)》](http://calvin1978.blogcn.com/articles/netty-performance.html)
2. [《Netty高性能编程备忘录（下）》](http://calvin1978.blogcn.com/articles/netty-performance2.html)

> 下面三连问！
>
> Netty 是一个高性能的、高可靠的、可扩展的异步通信框架，那么高性能、高可靠、可扩展设计体现在哪里呢？

## Netty 的高性能如何体现？

> 这个问题，和 [「说说 Netty 如何实现高性能？」](http://svip.iocoder.cn/Netty/Interview/#) 问题，会有点重叠。没事，反正理解就好，也背不下来。哈哈哈哈。

性能是设计出来的，而不是测试出来的。那么，Netty 的架构设计是如何实现高性能的呢？

1. **线程模型** ：采用异步非阻塞的 I/O 类库，基于 Reactor 模式实现，解决了传统同步阻塞 I/O 模式下服务端无法平滑处理客户端线性增长的问题。

2. **堆外内存** ：TCP 接收和发送缓冲区采用直接内存代替堆内存，避免了内存复制，提升了 I/O 读取和写入性能。

3. **内存池设计** ：支持通过内存池的方式循环利用 ByteBuf，避免了频繁创建和销毁 ByteBuf 带来的性能消耗。

4. **参数配置** ：可配置的 I/O 线程数目和 TCP 参数等，为不同用户提供定制化的调优参数，满足不同的性能场景。

5. **队列优化** ：采用环形数组缓冲区，实现无锁化并发编程，代替传统的线程安全容器或锁。

6. **并发能力** ：合理使用线程安全容器、原子类等，提升系统的并发能力。

7. **降低锁竞争** ：关键资源的使用采用单线程串行化的方式，避免多线程并发访问带来的锁竞争和额外的 CPU 资源消耗问题。

8. 内存泄露检测

    

   ：通过引用计数器及时地释放不再被引用的对象，细粒度的内存管理降低了 GC 的频率，减少频繁 GC 带来的时延增大和 CPU 损耗。

   - [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（三）内存泄露检测》](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/)

## Netty 的高可靠如何体现？

1. 链路有效性检测

   ：由于长连接不需要每次发送消息都创建链路，也不需要在消息完成交互时关闭链路，因此相对于短连接性能更高。为了保证长连接的链路有效性，往往需要通过心跳机制周期性地进行链路检测。使用心跳机制的原因是，避免在系统空闲时因网络闪断而断开连接，之后又遇到海量业务冲击导致消息积压无法处理。为了解决这个问题，需要周期性地对链路进行有效性检测，一旦发现问题，可以及时关闭链路，重建 TCP 连接。为了支持心跳，Netty 提供了两种链路空闲检测机制：

   - 读空闲超时机制：连续 T 周期没有消息可读时，发送心跳消息，进行链路检测。如果连续 N 个周期没有读取到心跳消息，可以主动关闭链路，重建连接。
   - 写空闲超时机制：连续 T 周期没有消息需要发送时，发送心跳消息，进行链路检测。如果连续 N 个周期没有读取对方发回的心跳消息，可以主动关闭链路，重建连接。
   - [《精尽 Netty 源码解析 —— ChannelHandler（五）之 IdleStateHandler》](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/)

2. 内存保护机制

   ：Netty 提供多种机制对内存进行保护，包括以下几个方面：

   - 通过对象引用计数器对 ByteBuf 进行细粒度的内存申请和释放，对非法的对象引用进行检测和保护。
   - 可设置的内存容量上限，包括 ByteBuf、线程池线程数等，避免异常请求耗光内存。

3. 优雅停机

   ：优雅停机功能指的是当系统推出时，JVM 通过注册的 Shutdown Hook 拦截到退出信号量，然后执行推出操作，释放相关模块的资源占用，将缓冲区的消息处理完成或清空，将待刷新的数据持久化到磁盘和数据库中，等到资源回收和缓冲区消息处理完成之后，再退出。

   - [《精尽 Netty 源码解析 —— EventLoop（八）之 EventLoop 优雅关闭》](http://svip.iocoder.cn/Netty/EventLoop-8-EventLoop-shutdown/)

## Netty 的可扩展如何体现？

可定制、易扩展。

- **责任链模式** ：ChannelPipeline 基于责任链模式开发，便于业务逻辑的拦截、定制和扩展。
- **基于接口的开发** ：关键的类库都提供了接口或抽象类，便于用户自定义实现。
- **提供大量的工厂类** ：通过重载这些工厂类，可以按需创建出用户需要的对象。
- **提供大量系统参数** ：供用户按需设置，增强系统的场景定制性。

------

> 艿艿：说个题外话。
>
> 实际上，任何的技术的研究，我们都可以去思考，它的高性能是怎么体现的，它的可靠性是怎么体现的，它的可拓展是怎么体现的。
>
> 当然，因为很多时候有近义词，所以：
>
> - 高性能 => 高并发
> - 可靠性 => 高可用
> - 可拓展 => 高拓展
>
> 例如说，MySQL 如何实现高性能，MySQL 如何搭建高可用，😈 MySQL 如何做拓展貌似暂时没，哈哈哈哈。

## 简单介绍 Netty 的核心组件？

Netty 有如下六个核心组件：

- Bootstrap & ServerBootstrap
- Channel
- ChannelFuture
- EventLoop & EventLoopGroup
- ChannelHandler
- ChannelPipeline

详细的，请直接阅读 [《精尽 Netty 源码分析 —— Netty 简介（二）之核心组件》](http://svip.iocoder.cn/Netty/intro-2/) 一文。

## 说说 Netty 的逻辑架构？

Netty 采用了典型的**三层网络架构**进行设计和开发，其逻辑架构如下图所示：

![Netty 逻辑架构图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/7687046-44a838e8aed36503.jpg)

> 艿艿：注意，这个图是自下向上看。哈哈哈~

1. **Reactor 通信调度层**：由一系列辅助类组成，包括 Reactor 线程 NioEventLoop 及其父类，NioSocketChannel 和 NioServerSocketChannel 等等。该层的职责就是监听网络的读写和连接操作，负责将网络层的数据读到内存缓冲区，然后触发各自网络事件，例如连接创建、连接激活、读事件、写事件等。将这些事件触发到 pipeline 中，由 pipeline 管理的职责链来进行后续的处理。
2. **职责链 ChannelPipeline**：负责事件在职责链中的有序传播，以及负责动态地编排职责链。职责链可以选择监听和处理自己关心的事件，拦截处理和向后传播事件。
3. **业务逻辑编排层**：业务逻辑编排层通常有两类，一类是纯粹的业务逻辑编排，一类是应用层协议插件，用于特定协议相关的会话和链路管理。由于应用层协议栈往往是开发一次到处运行，并且变动较小，故而将应用协议到 POJO 的转变和上层业务放到不同的 ChannelHandler 中，就可以实现协议层和业务逻辑层的隔离，实现架构层面的分层隔离。

## 什么是 Reactor 模型？

直接阅读 [《精尽 Netty 源码解析 —— EventLoop（一）之 Reactor 模型》](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/) 一文。

认真仔细读，这是一个高频面试题。

## 请介绍 Netty 的线程模型？

还是阅读 [《精尽 Netty 源码解析 —— EventLoop（一）之 Reactor 模型》](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/) 一文。

认真仔细读，这真的真的真的是一个高频面试题。

## 什么是业务线程池？

🦅 **问题**

在 [「什么是 Reactor 模型？」](http://svip.iocoder.cn/Netty/Interview/#) 问题中，无论是那种类型的 Reactor 模型，都需要在 Reactor 所在的线程中，进行读写操作。那么此时就会有一个问题，如果我们读取到数据，需要进行业务逻辑处理，并且这个业务逻辑需要对数据库、缓存等等进行操作，会有什么问题呢？假设这个数据库操作需要 5 ms ，那就意味着这个 Reactor 线程在这 5 ms 无法进行注册在这个 Reactor 的 Channel 进行读写操作。也就是说，多个 Channel 的所有读写操作都变成了串行。势必，这样的效率会非常非常非常的低。

🦅 **解决**

那么怎么解决呢？创建业务线程池，将读取到的数据，提交到业务线程池中进行处理。这样，Reactor 的 Channel 就不会被阻塞，而 Channel 的所有读写操作都变成了并行了。

🦅 **案例**

如果胖友熟悉 Dubbo 框架，就会发现 [《Dubbo 用户指南 —— 线程模型》](http://dubbo.apache.org/zh-cn/docs/user/demos/thread-model.html) 。😈 认真读下，可以跟面试官吹一吹啦。

## TCP 粘包 / 拆包的原因？应该这么解决？

🦅 **概念**

TCP 是以流的方式来处理数据，所以会导致粘包 / 拆包。

- 拆包：一个完整的包可能会被 TCP 拆分成多个包进行发送。
- 粘包：也可能把小的封装成一个大的数据包发送。

🦅 **原因**

- 应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生**拆包**现象。而应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生**粘包**现象。
- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行**拆包**。
- 以太网帧的 payload（净荷）大于 MTU（默认为 1500 字节）进行 IP 分片**拆包**。
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生**粘包**。

🦅 **解决**

在 Netty 中，提供了多个 Decoder 解析类，如下：

- ① FixedLengthFrameDecoder ，基于**固定长度**消息进行粘包拆包处理的。
- ② LengthFieldBasedFrameDecoder ，基于**消息头指定消息长度**进行粘包拆包处理的。
- ③ LineBasedFrameDecoder ，基于**换行**来进行消息粘包拆包处理的。
- ④ DelimiterBasedFrameDecoder ，基于**指定消息边界方式**进行粘包拆包处理的。

实际上，上述四个 FrameDecoder 实现可以进行规整：

- ① 是 ② 的特例，**固定长度**是**消息头指定消息长度**的一种形式。
- ③ 是 ④ 的特例，**换行**是于**指定消息边界方式**的一种形式。

感兴趣的胖友，可以看看如下两篇文章：

- [《精尽 Netty 源码解析 —— Codec 之 ByteToMessageDecoder（一）Cumulator》](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/)
- [《精尽 Netty 源码解析 —— Codec 之 ByteToMessageDecoder（二）FrameDecoder》](http://svip.iocoder.cn/Netty/Codec-1-2-ByteToMessageDecoder-FrameDecoder/)

## 了解哪几种序列化协议？

🦅 **概念**

- 序列化（编码），是将对象序列化为二进制形式（字节数组），主要用于网络传输、数据持久化等。
- 反序列化（解码），则是将从网络、磁盘等读取的字节数组还原成原始对象，主要用于网络传输对象的解码，以便完成远程调用。

🦅 **选型**

在选择序列化协议的选择，主要考虑以下三个因素：

- 序列化后的**字节大小**。更少的字节数，可以减少网络带宽、磁盘的占用。
- 序列化的**性能**。对 CPU、内存资源占用情况。
- 是否支持**跨语言**。例如，异构系统的对接和开发语言切换。

🦅 **方案**

> 如果对序列化工具了解不多的胖友，可能一看有这么多优缺点会比较懵逼，可以先记得有哪些序列化工具，然后在慢慢熟悉它们的优缺点。
>
> 重点，还是知道【**选型**】的考虑点。

1. 【重点】Java 默认提供的序列化

   - 无法跨语言；序列化后的字节大小太大；序列化的性能差。

2. 【重点】XML 。

   - 优点：人机可读性好，可指定元素或特性的名称。
   - 缺点：序列化数据只包含数据本身以及类的结构，不包括类型标识和程序集信息；只能序列化公共属性和字段；不能序列化方法；文件庞大，文件格式复杂，传输占带宽。
   - 适用场景：当做配置文件存储数据，实时数据转换。

3. 【重点】JSON ，是一种轻量级的数据交换格式。

   - 优点：兼容性高、数据格式比较简单，易于读写、序列化后数据较小，可扩展性好，兼容性好。与 XML 相比，其协议比较简单，解析速度比较快。
   - 缺点：数据的描述性比 XML 差、不适合性能要求为 ms 级别的情况、额外空间开销比较大。
   - 适用场景（可替代 XML ）：跨防火墙访问、可调式性要求高、基于Restful API 请求、传输数据量相对小，实时性要求相对低（例如秒级别）的服务。

4. 【了解】Thrift ，不仅是序列化协议，还是一个 RPC 框架。

   - 优点：序列化后的体积小, 速度快、支持多种语言和丰富的数据类型、对于数据字段的增删具有较强的兼容性、支持二进制压缩编码。
   - 缺点：使用者较少、跨防火墙访问时，不安全、不具有可读性，调试代码时相对困难、不能与其他传输层协议共同使用（例如 HTTP）、无法支持向持久层直接读写数据，即不适合做数据持久化序列化协议。
   - 适用场景：分布式系统的 RPC 解决方案。

5. 【了解】Avro ，Hadoop 的一个子项目，解决了JSON的冗长和没有IDL的问题。

   - 优点：支持丰富的数据类型、简单的动态语言结合功能、具有自我描述属性、提高了数据解析速度、快速可压缩的二进制数据形式、可以实现远程过程调用 RPC、支持跨编程语言实现。
   - 缺点：对于习惯于静态类型语言的用户不直观。
   - 适用场景：在 Hadoop 中做 Hive、Pig 和 MapReduce 的持久化数据格式。

6. 【重点】Protobuf ，将数据结构以

    

   ```
   .proto
   ```

    

   文件进行描述，通过代码生成工具可以生成对应数据结构的 POJO 对象和 Protobuf 相关的方法和属性。

   - 优点：序列化后码流小，性能高、结构化数据存储格式（XML JSON等）、通过标识字段的顺序，可以实现协议的前向兼容、结构化的文档更容易管理和维护。
   - 缺点：需要依赖于工具生成代码、支持的语言相对较少，官方只支持Java 、C++、python。
   - 适用场景：对性能要求高的 RPC 调用、具有良好的跨防火墙的访问属性、适合应用层对象的持久化。

7. 其它

   - 【重点】Protostuff ，基于 Protobuf 协议，但不需要配置proto 文件，直接导包即可。

     - 目前，微博 RPC 框架 Motan 在使用它。

   - 【了解】Jboss Marshaling ，可以直接序列化 Java 类， 无须实 `java.io.Serializable` 接口。

   - 【了解】Message Pack ，一个高效的二进制序列化格式。

   - 【重点】

     Hessian

      

     ，采用二进制协议的轻量级 remoting on http 服务。

     - 目前，阿里 RPC 框架 Dubbo 的**默认**序列化协议。

   - 【重要】kryo ，是一个快速高效的Java对象图形序列化框架，主要特点是性能、高效和易用。该项目用来序列化对象到文件、数据库或者网络。

     - 目前，阿里 RPC 框架 Dubbo 的可选序列化协议。

   - 【重要】FST ，fast-serialization 是重新实现的 Java 快速对象序列化的开发包。序列化速度更快（2-10倍）、体积更小，而且兼容 JDK 原生的序列化。要求 JDK 1.7 支持。

     - 目前，阿里 RPC 框架 Dubbo 的可选序列化协议。

## Netty 的零拷贝实现？

Netty 的零拷贝实现，是体现在多方面的，主要如下：

1. 【重点】Netty 的接收和发送 ByteBuffer 采用堆外直接内存

    

   Direct Buffer

    

   。

   - 使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝；使用堆内内存会多了一次内存拷贝，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。
   - Netty 创建的 ByteBuffer 类型，由 ChannelConfig 配置。而 ChannelConfig 配置的 ByteBufAllocator 默认创建 Direct Buffer 类型。

2. CompositeByteBuf

    

   类，可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf ，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer 。

   - `#addComponents(...)` 方法，可将 header 与 body 合并为一个逻辑上的 ByteBuf 。这两个 ByteBuf 在CompositeByteBuf 内部都是单独存在的，即 CompositeByteBuf 只是逻辑上是一个整体。

3. 通过

    

   FileRegion

    

   包装的 FileChannel 。

   - `#tranferTo(...)` 方法，实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel ，避免了传统通过循环 write 方式，导致的内存拷贝问题。

4. 通过 **wrap** 方法, 我们可以将 `byte[]` 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免了拷贝操作。

## 原生的 NIO 存在 Epoll Bug 是什么？Netty 是怎么解决的？

🦅 **Java NIO Epoll BUG**

Java NIO Epoll 会导致 Selector 空轮询，最终导致 CPU 100% 。

官方声称在 JDK 1.6 版本的 update18 修复了该问题，但是直到 JDK 1.7 版本该问题仍旧存在，只不过该 BUG 发生概率降低了一些而已，它并没有得到根本性解决。

🦅 **Netty 解决方案**

对 Selector 的 select 操作周期进行**统计**，每完成一次**空**的 select 操作进行一次计数，若在某个周期内连续发生 N 次空轮询，则判断触发了 Epoll 死循环 Bug 。

> 艿艿：此处**空**的 select 操作的定义是，select 操作执行了 0 毫秒。

此时，Netty **重建** Selector 来解决。判断是否是其他线程发起的重建请求，若不是则将原 SocketChannel 从旧的 Selector 上取消注册，然后重新注册到新的 Selector 上，最后将原来的 Selector 关闭。

## 什么是 Netty 空闲检测？

在 Netty 中，提供了 IdleStateHandler 类，正如其名，空闲状态处理器，用于检测连接的读写是否处于空闲状态。如果是，则会触发 IdleStateEvent 。

IdleStateHandler 目前提供三种类型的心跳检测，通过构造方法来设置。代码如下：

```
// IdleStateHandler.java

public IdleStateHandler(
        int readerIdleTimeSeconds,
        int writerIdleTimeSeconds,
        int allIdleTimeSeconds) {
    this(readerIdleTimeSeconds, writerIdleTimeSeconds, allIdleTimeSeconds,
         TimeUnit.SECONDS);
}
```

- `readerIdleTimeSeconds` 参数：为读超时时间，即测试端一定时间内未接受到被测试端消息。
- `writerIdleTimeSeconds` 参数：为写超时时间，即测试端一定时间内向被测试端发送消息。
- `allIdleTimeSeconds` 参数：为读或写超时时间。

------

另外，我们会在网络上看到类似《IdleStateHandler 心跳机制》这样标题的文章，实际上空闲检测和心跳机制是**两件事**。

- 只是说，因为我们使用 IdleStateHandler 的目的，就是检测到连接处于空闲，通过心跳判断其是否还是**有效的连接**。
- 虽然说，TCP 协议层提供了 Keeplive 机制，但是该机制默认的心跳时间是 2 小时，依赖操作系统实现不够灵活。因而，我们才在应用层上，自己实现心跳机制。

具体的，我们来看看下面的问题 [「Netty 如何实现重连？」](http://svip.iocoder.cn/Netty/Interview/#) 。

## Netty 如何实现重连？

- 客户端，通过 IdleStateHandler 实现定时检测是否空闲，例如说 15 秒。
  - 如果空闲，则向服务端发起心跳。
  - 如果多次心跳失败，则关闭和服务端的连接，然后重新发起连接。
- 服务端，通过 IdleStateHandler 实现定时检测客户端是否空闲，例如说 90 秒。
  - 如果检测到空闲，则关闭客户端。
  - 注意，如果接收到客户端的心跳请求，要反馈一个心跳响应给客户端。通过这样的方式，使客户端知道自己心跳成功。

如下艿艿在自己的 [TaroRPC](https://github.com/YunaiV/TaroRPC) 中提供的一个示例：

- [NettyClient.java](https://github.com/YunaiV/TaroRPC/blob/master/transport/transport-netty4/src/main/java/cn/iocoder/taro/transport/netty4/NettyClient.java) 中，设置 IdleStateHandler 和 ClientHeartbeatHandler。核心代码如下：

  ```
  // NettyHandler.java
  
  .addLast("idleState", new IdleStateHandler(TaroConstants.TRANSPORT_CLIENT_IDLE, TaroConstants.TRANSPORT_CLIENT_IDLE, 0, TimeUnit.MILLISECONDS))
  .addLast("heartbeat", new ClientHeartbeatHandler())
  ```

- [NettyServer.java](https://github.com/YunaiV/TaroRPC/blob/master/transport/transport-netty4/src/main/java/cn/iocoder/taro/transport/netty4/NettyServer.java) 中，设置 IdleStateHandler 和 ServerHeartbeatHandler。核心代码如下：

  ```
  // NettyServer.java
  
  .addLast("idleState", new IdleStateHandler(0, 0, TaroConstants.TRANSPORT_SERVER_IDLE, TimeUnit.MILLISECONDS))
  .addLast("heartbeat", new ServerHeartbeatHandler())
  ```

- [ClientHeartbeatHandler.java](https://github.com/YunaiV/TaroRPC/blob/master/transport/transport-netty4/src/main/java/cn/iocoder/taro/transport/netty4/heartbeat/ClientHeartbeatHandler.java) 中，碰到空闲，则发起心跳。不过，如何重连，暂时没有实现。需要考虑，重新发起连接可能会失败的情况。具体的，可以看看 [《一起学Netty（十四）之 Netty生产级的心跳和重连机制》](https://blog.csdn.net/linuu/article/details/51509847) 文章中的，ConnectionWatchdog 的代码。

- [ServerHeartbeatHandler.java](https://github.com/YunaiV/TaroRPC/blob/6ce2af911ccec9ed5dc75c7f3ebda9c758272f3b/transport/transport-netty4/src/main/java/cn/iocoder/taro/transport/netty4/heartbeat/ServerHeartbeatHandler.java) 中，检测到客户端空闲，则直接关闭连接。

## Netty 自己实现的 ByteBuf 有什么优点？

如下是 [《Netty 实战》](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 对它的**优点总**结：

> - A01. 它可以被用户自定义的**缓冲区类型**扩展
> - A02. 通过内置的符合缓冲区类型实现了透明的**零拷贝**
> - A03. 容量可以**按需增长**
> - A04. 在读和写这两种模式之间切换不需要调用 `#flip()` 方法
> - A05. 读和写使用了**不同的索引**
> - A06. 支持方法的**链式**调用
> - A07. 支持引用计数
> - A08. 支持**池化**

- 特别是第 A04 这点，相信很多胖友都被 NIO ByteBuffer 反人类的读模式和写模式给坑哭了。在 [《精尽 Netty 源码分析 —— NIO 基础（三）之 Buffer》](http://svip.iocoder.cn/Netty/nio-3-buffer/) 中，我们也吐槽过了。😈

想要进一步深入的，可以看看 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（一）简介》](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/) 。

## Netty 为什么要实现内存管理？

🦅 **老艿艿的理解**

在 Netty 中，IO 读写必定是非常频繁的操作，而考虑到更高效的网络传输性能，Direct ByteBuffer 必然是最合适的选择。但是 Direct ByteBuffer 的申请和释放是高成本的操作，那么进行**池化**管理，多次重用是比较有效的方式。但是，不同于一般于我们常见的对象池、连接池等**池化**的案例，ByteBuffer 是有**大小**一说。又但是，申请多大的 Direct ByteBuffer 进行池化又会是一个大问题，太大会浪费内存，太小又会出现频繁的扩容和内存复制！！！所以呢，就需要有一个合适的内存管理算法，解决**高效分配内存**的同时又解决**内存碎片化**的问题。

🦅 **官方的说法**

> FROM [《Netty 学习笔记 —— Pooled buffer》](https://skyao.gitbooks.io/learning-netty/content/buffer/pooled_buffer.html)
>
> Netty 4.x 增加了 Pooled Buffer，实现了高性能的 buffer 池，分配策略则是结合了 buddy allocation 和 slab allocation 的 **jemalloc** 变种，代码在`io.netty.buffer.PoolArena` 中。
>
> 官方说提供了以下优势：
>
> - 频繁分配、释放 buffer 时减少了 GC 压力。
> - 在初始化新 buffer 时减少内存带宽消耗( 初始化时不可避免的要给buffer数组赋初始值 )。
> - 及时的释放 direct buffer 。

🦅 **hushi55 大佬的理解**

> > C/C++ 和 java 中有个围城，城里的想出来，城外的想进去！**
>
> 这个围城就是自动内存管理！
>
> **Netty 4 buffer 介绍**
>
> Netty4 带来一个与众不同的特点是其 ByteBuf 的实现，相比之下，通过维护两个独立的读写指针， 要比 `io.netty.buffer.ByteBuf` 简单不少，也会更高效一些。不过，Netty 的 ByteBuf 带给我们的最大不同，就是他不再基于传统 JVM 的 GC 模式，相反，它采用了类似于 C++ 中的 malloc/free 的机制，需要开发人员来手动管理回收与释放。从手动内存管理上升到GC，是一个历史的巨大进步， 不过，在20年后，居然有曲线的回归到了手动内存管理模式，正印证了马克思哲学观： **社会总是在螺旋式前进的，没有永远的最好。**
>
> **① GC 内存管理分析**
>
> 的确，就内存管理而言，GC带给我们的价值是不言而喻的，不仅大大的降低了程序员的心智包袱， 而且，也极大的减少了内存管理带来的 Crash 困扰，为函数式编程（大量的临时对象）、脚本语言编程带来了春天。 并且，高效的GC算法也让大部分情况下程序可以有更高的执行效率。 不过，也有很多的情况，可能是手工内存管理更为合适的。譬如：
>
> - 对于类似于业务逻辑相对简单，譬如网络路由转发型应用（很多erlang应用其实是这种类型）， 但是 QPS 非常高，比如1M级，在这种情况下，在每次处理中即便产生1K的垃圾，都会导致频繁的GC产生。 在这种模式下，erlang 的按进程回收模式，或者是 C/C++ 的手工回收机制，效率更高。
> - Cache 型应用，由于对象的存在周期太长，GC 基本上就变得没有价值。
>
> 所以，理论上，尴尬的GC实际上比较适合于处理介于这 2 者之间的情况： 对象分配的频繁程度相比数据处理的时间要少得多的，但又是相对短暂的， 典型的，对于OLTP型的服务，处理能力在 1K QPS 量级，每个请求的对象分配在 10K-50K 量级， 能够在 5-10s 的时间内进行一 次younger GC ，每次GC的时间可以控制在 10ms 水平上， 这类的应用，实在是太适合 GC 行的模式了，而且结合 Java 高效的分代 GC ，简直就是一个理想搭配。
>
> **② 影响**
>
> Netty 4 引入了手工内存的模式，我觉得这是一大创新，这种模式甚至于会延展， 应用到 Cache 应用中。实际上，结合 JVM 的诸多优秀特性，如果用 Java 来实现一个 Redis 型 Cache、 或者 In-memory SQL Engine，或者是一个 Mongo DB，我觉得相比 C/C++ 而言，都要更简单很多。 实际上，JVM 也已经提供了打通这种技术的机制，就是 Direct Memory 和 Unsafe 对象。 基于这个基础，我们可以像 C 语言一样直接操作内存。实际上，Netty4 的 ByteBuf 也是基于这个基础的。

更多详细的内容，胖友可以看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）简介》](http://svip.iocoder.cn/Netty/ByteBuf-3-1-Jemalloc-intro/) 。

## Netty 如何实心内存管理？

> 这个题目，简单了解即可，如果深入，就要去看 [《精尽 Netty 源码解析 —— Buffer》](http://svip.iocoder.cn/categories/Netty/) 相关的源码。而且，看完就忘记，比较难和复杂。
>
> 当然，看懂那一刻，乐趣无穷，哈哈哈哈。

Netty 内存管理机制，基于 [Jemalloc](http://www.cnhalo.net/2016/06/13/memory-optimize/) 算法。

- 首先会预申请一大块内存 **Arena** ，Arena 由许多 Chunk 组成，而每个 Chunk 默认由2048个page组成。
- **Chunk** 通过 **AVL** 树的形式组织 **Page** ，每个叶子节点表示一个 Page ，而中间节点表示内存区域，节点自己记录它在整个 Arena 中的偏移地址。当区域被分配出去后，中间节点上的标记位会被标记，这样就表示这个中间节点以下的所有节点都已被分配了。大于 8k 的内存分配在 **PoolChunkList** 中，而 **PoolSubpage** 用于分配小于 8k 的内存，它会把一个 page 分割成多段，进行内存分配。

## 什么是 Netty 的内存泄露检测？是如何进行实现的？

> 艿艿：这是一道比较复杂的面试题，可以挑战一下。

推荐阅读如下两篇文章：

- [《Netty 之有效规避内存泄漏》](http://calvin1978.blogcn.com/articles/netty-leak.html) 从原理层面解释。
- [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（三）内存泄露检测》](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/) 从源码层面解读。

另外，Netty 的内存泄露检测的实现，是对 WeakReference 和 ReferenceQueue 很好的学习。之前很多胖友在看了 [《Java 中的四种引用类型》](http://www.iocoder.cn/Fight/Four-reference-types-in-Java) 之后，是不太理解 Java 的四种引用的具体使用场景，这不就来了么。

# 666. 彩蛋

😈 撸完 Netty 源码之后，一段时间没去用，东西都忘了蛮多。不过因为读过源码，在看这些面试题，会发现轻松太多了。有一种，“老朋友”的感觉。妥妥的。

参考与推荐如下文章：

- itdragon [《Netty 序章之 BIO NIO AIO 演变》](https://segmentfault.com/a/1190000012976683)
- 白夜行515 [《【面试题】Netty相关》](https://blog.csdn.net/baiye_xing/article/details/76735113)
- albon [《Netty 权威指南笔记（二）：Java NIO 和 Netty 对比》](https://www.jianshu.com/p/93876f1bf6d1)
- albon [《Netty 权威指南笔记（四）：架构剖析》](https://www.jianshu.com/p/ececec069cc1)
- 狗窝 [《面试题之 Netty》](https://nizouba.com/articles/2018/11/04/1541322296629.html) 题目很不错，就是图片都挂了。

# 精尽 Netty 源码分析 —— 调试环境搭建



# 1. 依赖工具

- Maven
- Git
- JDK
- IntelliJ IDEA

# 2. 源码拉取

从官方仓库 <https://github.com/netty/netty> `Fork` 出属于自己的仓库。为什么要 `Fork` ？既然开始阅读、调试源码，我们可能会写一些注释，有了自己的仓库，可以进行自由的提交。😈

使用 `IntelliJ IDEA` 从 `Fork` 出来的仓库拉取代码。

本文使用的 Netty 版本为 `4.1.26.Final-SNAPSHOT` 。

# 3. Maven Profile

打开 IDEA 的 **Maven Projects** ，选择对应的 Profiles 。如下图所示：

![Maven Projects](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554204564486.png)

- `jdk8` ：笔者使用的 JDK 版本是 8 ，所以勾选了 `jdk8` 。如果错误的选择，可能会报如下错误：

  ```
  java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer
  ```

- `mac` ：选择对应的系统版本。😈 笔者手头没有 windows 的电脑，所以不知道该怎么选。

修改完成后，点击左上角的【刷新】按钮，进行依赖下载，耐心等待…

# 4. 解决依赖报错

在 `codec-redis` 模块中，类 FixedRedisMessagePool 会报如下类不存在的问题：

```java
import io.netty.util.collection.LongObjectHashMap;
import io.netty.util.collection.LongObjectMap;
```

- 具体如下图所示：![依赖报错](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554204564494.png)

解决方式如下：

```
cd common;
mvn clean compile;
```

- 跳转到 `common` 模块中，编译生成对应的类。为什么可以通过编译生成对应的类呢，原因参见 `common` 模块的 `src/java/templates/io/netty/util/collection` 目录下的 `.template` 文件。

在 Github 上，也有多个针对这个情况讨论的 issue ：

- [《Can not find class io.netty.util.collection.LongObjectHashMap in 4.1.8.final》](https://github.com/netty/netty/issues/7518)
- [《io.netty.util.collection.LongObjectHashMap not found at branch 4.1》](https://github.com/netty/netty/issues/5447)

# 5. example 模块

在 `example` 模块里，官网提供了多个 Netty 的使用示例。
本文以 `echo` 包下来作为示例。哈哈哈，因为最简单。

## 5.1 EchoServer

执行 `io.netty.example.echo.EchoServer` 的 `#main(args)` 方法，启动服务端。输出日志如下：

```
20:41:41.215 [nioEventLoopGroup-2-1] INFO  i.n.handler.logging.LoggingHandler - [id: 0xd0219f1c] REGISTERED
20:41:41.222 [nioEventLoopGroup-2-1] INFO  i.n.handler.logging.LoggingHandler - [id: 0xd0219f1c] BIND: 0.0.0.0/0.0.0.0:8007
20:41:41.228 [nioEventLoopGroup-2-1] INFO  i.n.handler.logging.LoggingHandler - [id: 0xd0219f1c, L:/0:0:0:0:0:0:0:0:8007] ACTIVE
```

## 5.2 EchoClient

执行 `io.netty.example.echo.EchoClientr` 的 `#main(args)` 方法，启动客户端。**不输出任何日志**。

但是，EchoServer 会新输出如下日志：

```
20:41:45.642 [nioEventLoopGroup-2-1] INFO  i.n.handler.logging.LoggingHandler - [id: 0xd0219f1c, L:/0:0:0:0:0:0:0:0:8007] READ: [id: 0x32721f32, L:/127.0.0.1:8007 - R:/127.0.0.1:50663]
20:41:45.646 [nioEventLoopGroup-2-1] INFO  i.n.handler.logging.LoggingHandler - [id: 0xd0219f1c, L:/0:0:0:0:0:0:0:0:8007] READ COMPLETE
```

# 6. 结尾

如此，我们就可以愉快的进行 Netty 调试啦。读源码，一定要多多调试源码。非常重要！！！

另外，也推荐基友 zhisheng 的文章：[《Netty系列文章（一）：Netty 源码阅读之初始环境搭建》](http://www.54tianzhisheng.cn/2017/12/08/netty-01-env/) 。

# 7. 为什么使用 Netty

如下内容，引用自我的基友闪电侠的分享

> FROM [《Netty 源码分析之服务端启动全解析》](https://www.jianshu.com/p/c5068caab217)
>
> netty 底层基于 jdk 的 NIO ，我们为什么不直接基于 jdk 的 nio 或者其他 nio 框架？下面是我总结出来的原因
>
> 1. 使用 jdk 自带的 nio 需要了解太多的概念，编程复杂
> 2. netty 底层 IO 模型随意切换，而这一切只需要做微小的改动
> 3. netty 自带的拆包解包，异常检测等机制让你从nio的繁重细节中脱离出来，让你只需要关心业务逻辑
> 4. netty 解决了 jdk 的很多包括空轮训在内的 bug
> 5. netty 底层对线程，selector 做了很多细小的优化，精心设计的 reactor 线程做到非常高效的并发处理
> 6. 自带各种协议栈让你处理任何一种通用协议都几乎不用亲自动手
> 7. netty 社区活跃，遇到问题随时邮件列表或者 issue
> 8. netty 已经历各大rpc框架，消息中间件，分布式通信中间件线上的广泛验证，健壮性无比强大

# 666. 彩蛋

笔者开始更新 Netty 源码解析系列，让我们在 2018 一起**精尽** Netty 。

# 精尽 Netty 源码分析 —— NIO 基础（一）之简介



# 1. 概述

Java NIO( New IO 或者 Non Blocking IO ) ，从 Java 1.4 版本开始引入的**非阻塞** IO ，用于替换**标准**( 有些文章也称为**传统**，或者 Blocking IO 。下文统称为 BIO ) Java IO API 的 IO API 。

> 老艿艿：在一些文章中，会将 Java NIO 描述成**异步** IO ，实际是不太正确的： Java NIO 是**同步** IO ，Java AIO ( 也称为 NIO 2 )是**异步** IO。具体原因，推荐阅读文章：
>
> - [《异步和非阻塞一样吗? (内容涉及 BIO, NIO, AIO, Netty)》](https://blog.csdn.net/matthew_zhang/article/details/71328697) 。
> - [《BIO与NIO、AIO的区别(这个容易理解)》](https://blog.csdn.net/skiof007/article/details/52873421)
>
> 总结来说，在 **Unix IO 模型**的语境下：
>
> - 同步和异步的区别：数据拷贝阶段是否需要完全由操作系统处理。
> - 阻塞和非阻塞操作：是针对发起 IO 请求操作后，是否有立刻返回一个标志信息而不让请求线程等待。
>
> 因此，Java NIO 是**同步**且非阻塞的 IO 。

# 2. 核心组件

Java NIO 由如下**三个**核心组件组成：

- Channel
- Buffer
- Selector

后续的每篇文章，我们会分享对应的一个组件。

# 3. NIO 和 BIO 的对比

NIO 和 BIO 的区别主要体现在三个方面：

| NIO                  | BIO              |
| -------------------- | ---------------- |
| 基于缓冲区( Buffer ) | 基于流( Stream ) |
| **非**阻塞 IO        | 阻塞 IO          |
| 选择器( Selector )   | 无               |

- 其中，选择器( Selector )是 NIO 能实现**非**阻塞的基础。

## 3.1 基于 Buffer 与基于 Stream

BIO 是面向字节流或者字符流的，而在 NIO 中，它摒弃了传统的 IO 流，而是引入 Channel 和 Buffer 的概念：从 Channel 中读取数据到 Buffer 中，或者将数据从 Buffer 中写到 Channel 中。

① 那么什么是**基于 Stream**呢？

在一般的 Java IO 操作中，我们以**流式**的方式，**顺序**的从一个 Stream 中读取一个或者多个字节，直至读取所有字节。因为它没有缓存区，所以我们就不能随意改变读取指针的位置。

② 那么什么是**基于 Buffer** 呢？

基于 Buffer 就显得有点不同了。我们在从 Channel 中读取数据到 Buffer 中，这样 Buffer 中就有了数据后，我们就可以对这些数据进行操作了。并且不同于一般的 Java IO 操作那样是**顺序**操作，NIO 中我们可以随意的读取任意位置的数据，这样大大增加了处理过程中的灵活性。

> 老艿艿：**写入**操作，也符合上述**读取**操作的情况。

## 3.2 阻塞与非阻塞 IO

Java IO 的各种流是**阻塞**的 IO 操作。这就意味着，当一个线程执行读或写 IO 操作时，该线程会被**阻塞**，直到有一些数据被读取，或者数据完全写入。

------

Java NIO 可以让我们**非阻塞**的使用 IO 操作。例如：

- 当一个线程执行从 Channel 执行读取 IO 操作时，当此时有数据，则读取数据并返回；当此时无数据，则直接返回**而不会阻塞当前线程**。
- 当一个线程执行向 Channel 执行写入 IO 操作时，**不需要阻塞等待它完全写入**，这个线程同时可以做别的事情。

也就是说，线程可以将非阻塞 IO 的空闲时间用于在其他 Channel 上执行 IO 操作。所以，一个单独的线程，可以管理多个 Channel 的读取和写入 IO 操作。

## 3.3 Selector

Java NIO 引入 Selector ( 选择器 )的概念，它是 Java NIO 得以实现非阻塞 IO 操作的**最最最关键**。

我们可以注册**多个** Channel 到**一个** Selector 中。而 Selector 内部的机制，就可以自动的为我们不断的执行查询( select )操作，判断这些注册的 Channel 是否有**已就绪的 IO 事件( 例如可读，可写，网络连接已完成 )**。
通过这样的机制，**一个**线程通过使用**一个** Selector ，就可以非常简单且高效的来管理**多个** Channel 了。

# 4. NIO 和 AIO 的对比

考虑到 Netty 4.1.X 版本实际并未基于 Java AIO 实现，所以我们就省略掉这块内容。那么，感兴趣的同学，可以自己 Google 下 Java NIO 和 Java AIO 的对比。

具体为什么 Netty 4.1.X 版本不支持 Java AIO 的原因，可参见 [《Netty（二）：Netty 为啥去掉支持 AIO ?》](https://juejin.im/entry/5a8ed33b6fb9a0634c26801c) 文章。

也因此，Netty 4.1.X 一般情况下，使用的是**同步非阻塞的 NIO 模型**。当然，如果真的有必要，也可以使用**同步阻塞的 BIO 模型**。

# 666. 彩蛋

参考文章如下：

- [《高并发 Java（8）：NIO 和 AIO》](http://www.importnew.com/21341.html)
- [《Java NIO 的前生今世 之一 简介》](https://segmentfault.com/a/1190000006824091)
- [《Java NIO 系列教程（十二） Java NIO 与 IO》](http://ifeve.com/java-nio-vs-io/)

# 精尽 Netty 源码分析 —— NIO 基础（二）之 Channel



# 1. 概述

在 Java NIO 中，基本上所有的 IO 操作都是从 Channel 开始。数据可以从 Channel 读取到 Buffer 中，也可以从 Buffer 写到 Channel 中。如下图所示：

![Buffer <=> Channel](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554204649783.png)

# 2. NIO Channel 对比 Java Stream

NIO Channel **类似** Java Stream ，但又有几点不同：

1. 对于**同一个** Channel ，我们可以从它读取数据，也可以向它写入数据。而对于**同一个** Stream ，通畅要么只能读，要么只能写，二选一( 有些文章也描述成“单向”，也是这个意思 )。
2. Channel 可以**非阻塞**的读写 IO 操作，而 Stream 只能**阻塞**的读写 IO 操作。
3. Channel **必须配合** Buffer 使用，总是先读取到一个 Buffer 中，又或者是向一个 Buffer 写入。也就是说，我们无法绕过 Buffer ，直接向 Channel 写入数据。

# 3. Channel 的实现

Channel 在 Java 中，作为一个**接口**，`java.nio.channels.Channel` ，定义了 IO 操作的**连接与关闭**。代码如下：

```java
public interface Channel extends Closeable {

    /**
     * 判断此通道是否处于打开状态。 
     */
    public boolean isOpen();

    /**
     *关闭此通道。
     */
    public void close() throws IOException;

}
```

Channel 有非常多的实现类，最为重要的**四个** Channel 实现类如下：

- SocketChannel ：一个客户端用来**发起** TCP 的 Channel 。
- ServerSocketChannel ：一个服务端用来**监听**新进来的连接的 TCP 的 Channel 。对于每一个新进来的连接，都会创建一个对应的 SocketChannel 。
- DatagramChannel ：通过 UDP 读写数据。
- FileChannel ：从文件中，读写数据。

> 老艿艿：因为 [《Java NIO 系列教程》](http://ifeve.com/java-nio-all/) 对上述的 Channel 解释的非常不错，我就直接引用啦。
>
> 我们在使用 Netty 时，主要使用 TCP 协议，所以胖友可以只看 [「3.2 SocketChannel」](http://svip.iocoder.cn/Netty/nio-2-channel/#) 和 [「3.1 ServerSocketChannel」](http://svip.iocoder.cn/Netty/nio-2-channel/#) 。

## 3.1 ServerSocketChannel

[《Java NIO系列教程（九） ServerSocketChannel》](http://ifeve.com/server-socket-channel/)

## 3.2 SocketChannel

[《Java NIO 系列教程（八） SocketChannel》](http://ifeve.com/socket-channel/)

## 3.3 DatagramChannel

[《Java NIO系列教程（十） Java NIO DatagramChannel》](http://ifeve.com/datagram-channel/)

## 3.4 FileChannel

[《Java NIO系列教程（七） FileChannel》](http://ifeve.com/file-channel/)

# 666. 彩蛋

参考文章如下：

- [《Java NIO 系列教程（二） Channel》](http://ifeve.com/channels/)

# 精尽 Netty 源码分析 —— NIO 基础（三）之 Buffer



# 1. 概述

一个 Buffer ，本质上是内存中的一块，我们可以将数据写入这块内存，之后从这块内存获取数据。通过将这块内存封装成 NIO Buffer 对象，并提供了一组常用的方法，方便我们对该块内存的读写。

Buffer 在 `java.nio` 包中实现，被定义成**抽象类**，从而实现一组常用的方法。整体类图如下：

![类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554205289260.png)

- 我们可以将 Buffer 理解为**一个数组的封装**，例如 IntBuffer、CharBuffer、ByteBuffer 等分别对应 `int[]`、`char[]`、`byte[]` 等。
- MappedByteBuffer 用于实现内存映射文件，不是本文关注的重点。因此，感兴趣的胖友，可以自己 Google 了解，还是蛮有趣的。

# 2. 基本属性

Buffer 中有 **4** 个非常重要的属性：`capacity`、`limit`、`position`、`mark` 。代码如下：

```java
public abstract class Buffer {

    // Invariants: mark <= position <= limit <= capacity
    private int mark = -1;
    private int position = 0;
    private int limit;
    private int capacity;

    // Used only by direct buffers
    // NOTE: hoisted here for speed in JNI GetDirectBufferAddress
    long address;

    Buffer(int mark, int pos, int lim, int cap) {       // package-private
        if (cap < 0)
            throw new IllegalArgumentException("Negative capacity: " + cap);
        this.capacity = cap;
        limit(lim);
        position(pos);
        if (mark >= 0) {
            if (mark > pos)
                throw new IllegalArgumentException("mark > position: ("
                                                   + mark + " > " + pos + ")");
            this.mark = mark;
        }
    }
    
    // ... 省略具体方法的代码
}
```

- `capacity` 属性，容量，Buffer 能容纳的数据元素的**最大值**。这一容量在 Buffer 创建时被赋值，并且**永远不能被修改**。

- Buffer 分成**写模式**和**读模式**两种情况。如下图所示：

  ![åæ¨¡å¼ v.s. è¯"æ¨¡å¼](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554206254304.png)

  - 从图中，我们可以看到，两种模式下，`position` 和 `limit` 属性分别代表不同的含义。下面，我们来分别看看。

- `position`属性，位置，初始值为 0 。

  - **写**模式下，每往 Buffer 中写入一个值，`position` 就自动加 1 ，代表下一次的写入位置。
  - **读**模式下，每从 Buffer 中读取一个值，`position` 就自动加 1 ，代表下一次的读取位置。( *和写模式类似* )

- `limit`属性，上限。

  - **写**模式下，代表最大能写入的数据上限位置，这个时候 `limit` 等于 `capacity` 。
  - **读**模式下，在 Buffer 完成所有数据写入后，通过调用 `#flip()` 方法，切换到**读**模式。此时，`limit` 等于 Buffer 中实际的数据大小。因为 Buffer 不一定被写满，所以不能使用 `capacity` 作为实际的数据大小。

- `mark`属性，标记，通过 `#mark()`方法，记录当前`position`；通过`reset()`方法，恢复`position`为标记。

  - **写**模式下，标记上一次写位置。
  - **读**模式下，标记上一次读位置。

- 从代码注释上，我们可以看到，四个属性总是遵循如下大小关系：

  ```
  mark <= position <= limit <= capacity
  ```

------

写到此处，忍不住吐槽了下，Buffer 的读模式和写模式，我认为是有一点“**糟糕**”。相信大多数人在理解的时候，都会开始一脸懵逼的状态。相比较来说，Netty 的 ByteBuf 就**优雅**的非常多，基本属性设计如下：

```
0 <= readerIndex <= writerIndex <= capacity
```

- 通过 `readerIndex` 和 `writerIndex` 两个属性，避免出现读模式和写模式的切换。

# 3. 创建 Buffer

① 每个 Buffer 实现类，都提供了 `#allocate(int capacity)` 静态方法，帮助我们快速**实例化**一个 Buffer 对象。以 ByteBuffer 举例子，代码如下：

```java
// ByteBuffer.java
public static ByteBuffer allocate(int capacity) {
    if (capacity < 0)
        throw new IllegalArgumentException();
    return new HeapByteBuffer(capacity, capacity);
}
```

- ByteBuffer 实际是个抽象类，返回的是它的**基于堆内( Non-Direct )内存**的实现类 HeapByteBuffer 的对象。

② 每个 Buffer 实现类，都提供了 `#wrap(array)` 静态方法，帮助我们将其对应的数组**包装**成一个 Buffer 对象。还是以 ByteBuffer 举例子，代码如下：

```java
// ByteBuffer.java
public static ByteBuffer wrap(byte[] array, int offset, int length){
    try {
        return new HeapByteBuffer(array, offset, length);
    } catch (IllegalArgumentException x) {
        throw new IndexOutOfBoundsException();
    }
}

public static ByteBuffer wrap(byte[] array) {
    return wrap(array, 0, array.length);
}
```

- 和 `#allocate(int capacity)` 静态方法**一样**，返回的也是 HeapByteBuffer 的对象。

③ 每个 Buffer 实现类，都提供了 `#allocateDirect(int capacity)` 静态方法，帮助我们快速**实例化**一个 Buffer 对象。以 ByteBuffer 举例子，代码如下：

```java
// ByteBuffer.java
public static ByteBuffer allocateDirect(int capacity) {
    return new DirectByteBuffer(capacity);
}
```

- 和 `#allocate(int capacity)` 静态方法**不一样**，返回的是它的**基于堆外( Direct )内存**的实现类 DirectByteBuffer 的对象。

## 3.1 关于 Direct Buffer 和 Non-Direct Buffer 的区别

> FROM [《Java NIO 的前生今世 之三 NIO Buffer 详解》](https://segmentfault.com/a/1190000006824155)
>
> **Direct Buffer:**
>
> - 所分配的内存不在 JVM 堆上, 不受 GC 的管理.(但是 Direct Buffer 的 Java 对象是由 GC 管理的, 因此当发生 GC, 对象被回收时, Direct Buffer 也会被释放)
> - 因为 Direct Buffer 不在 JVM 堆上分配, 因此 Direct Buffer 对应用程序的内存占用的影响就不那么明显(实际上还是占用了这么多内存, 但是 JVM 不好统计到非 JVM 管理的内存.)
> - 申请和释放 Direct Buffer 的开销比较大. 因此正确的使用 Direct Buffer 的方式是在初始化时申请一个 Buffer, 然后不断复用此 buffer, 在程序结束后才释放此 buffer.
> - 使用 Direct Buffer 时, 当进行一些底层的系统 IO 操作时, 效率会比较高, 因为此时 JVM 不需要拷贝 buffer 中的内存到中间临时缓冲区中.
>
> **Non-Direct Buffer:**
>
> - 直接在 JVM 堆上进行内存的分配, 本质上是 byte[] 数组的封装.
> - 因为 Non-Direct Buffer 在 JVM 堆中, 因此当进行操作系统底层 IO 操作中时, 会将此 buffer 的内存复制到中间临时缓冲区中. 因此 Non-Direct Buffer 的效率就较低.

笔者之前研究 JVM 内存时，也整理过一个脑图，感兴趣的胖友可以下载：[传送门](http://static2.iocoder.cn/Java%E5%86%85%E5%AD%98.xmind) 。

# 4. 向 Buffer 写入数据

每个 Buffer 实现类，都提供了 `#put(...)` 方法，向 Buffer 写入数据。以 ByteBuffer 举例子，代码如下：

```java
// 写入 byte
public abstract ByteBuffer put(byte b); 
public abstract ByteBuffer put(int index, byte b);
// 写入 byte 数组
public final ByteBuffer put(byte[] src) { ... }
public ByteBuffer put(byte[] src, int offset, int length) {...}
// ... 省略，还有其他 put 方法
```

对于 Buffer 来说，有一个非常重要的操作就是，我们要讲来自 Channel 的数据写入到 Buffer 中。在系统层面上，这个操作我们称为**读操作**，因为数据是从外部( 文件或者网络等 )读取到内存中。示例如下：

```java
int num = channel.read(buffer);
```

- 上述方法会返回从 Channel 中写入到 Buffer 的数据大小。对应方法的代码如下：

  ```java
  public interface ReadableByteChannel extends Channel {
  
      public int read(ByteBuffer dst) throws IOException;
      
  }
  ```

> 注意，通常在说 NIO 的读操作的时候，我们说的是从 Channel 中读数据到 Buffer 中，对应的是对 Buffer 的写入操作，初学者需要理清楚这个。

# 5. 从 Buffer 读取数据

每个 Buffer 实现类，都提供了 `#get(...)` 方法，从 Buffer 读取数据。以 ByteBuffer 举例子，代码如下：

```java
// 读取 byte
public abstract byte get();
public abstract byte get(int index);
// 读取 byte 数组
public ByteBuffer get(byte[] dst, int offset, int length) {...}
public ByteBuffer get(byte[] dst) {...}
// ... 省略，还有其他 get 方法
```

对于 Buffer 来说，还有一个非常重要的操作就是，我们要讲来向 Channel 的写入 Buffer 中的数据。在系统层面上，这个操作我们称为**写操作**，因为数据是从内存中写入到外部( 文件或者网络等 )。示例如下：

```java
int num = channel.write(buffer);
```

- 上述方法会返回向 Channel 中写入 Buffer 的数据大小。对应方法的代码如下：

  ```java
  public interface WritableByteChannel extends Channel {
  
      public int write(ByteBuffer src) throws IOException;
      
  }
  ```

# 6. rewind() v.s. flip() v.s. clear()

## 6.1 flip

如果要读取 Buffer 中的数据，需要切换模式，**从写模式切换到读模式**。对应的为 `#flip()` 方法，代码如下：

```java
public final Buffer flip() {
    limit = position; // 设置读取上限
    position = 0; // 重置 position
    mark = -1; // 清空 mark
    return this;
}
```

使用示例，代码如下：

```java
buf.put(magic);    // Prepend header
in.read(buf);      // Read data into rest of buffer
buf.flip();        // Flip buffer
channel.write(buf);    // Write header + data to channel
```

## 6.2 rewind

`#rewind()` 方法，可以**重置** `position` 的值为 0 。因此，我们可以重新**读取和写入** Buffer 了。

大多数情况下，该方法主要针对于**读模式**，所以可以翻译为“倒带”。也就是说，和我们当年的磁带倒回去是一个意思。代码如下：

```java
public final Buffer rewind() {
    position = 0; // 重置 position
    mark = -1; // 清空 mark
    return this;
}
```

- 从代码上，和 `#flip()` 相比，非常类似，除了少了第一行的 `limit = position` 的代码块。

使用示例，代码如下：

```java
channel.write(buf);    // Write remaining data
buf.rewind();      // Rewind buffer
buf.get(array);    // Copy data into array
```

## 6.3 clear

`#clear()` 方法，可以“**重置**” Buffer 的数据。因此，我们可以重新**读取和写入** Buffer 了。

大多数情况下，该方法主要针对于**写模式**。代码如下：

```java
public final Buffer clear() {
    position = 0; // 重置 position
    limit = capacity; // 恢复 limit 为 capacity
    mark = -1; // 清空 mark
    return this;
}

```

- 从源码上，我们可以看出，Buffer 的数据实际并未清理掉，所以使用时需要注意。
- 读模式下，尽量不要调用 `#clear()` 方法，因为 `limit` 可能会被错误的赋值为 `capacity` 。相比来说，调用 `#rewind()` 更合理，如果有重读的需求。

使用示例，代码如下：

```java
buf.clear();     // Prepare buffer for reading
in.read(buf);    // Read data

```

# 7. mark() 搭配 reset()

## 7.1 mark

`#mark()` 方法，保存当前的 `position` 到 `mark` 中。代码如下：

```java
public final Buffer mark() {
    mark = position;
    return this;
}

```

## 7.2 reset

`#reset()` 方法，恢复当前的 `postion` 为 `mark` 。代码如下：

```java
public final Buffer reset() {
    int m = mark;
    if (m < 0)
        throw new InvalidMarkException();
    position = m;
    return this;
}

```

# 8. 其它方法

Buffer 中还有其它方法，比较简单，所以胖友自己研究噢。代码如下：

```java
// ========== capacity ==========
public final int capacity() {
    return capacity;
}

// ========== position ==========
public final int position() {
    return position;
}

public final Buffer position(int newPosition) {
    if ((newPosition > limit) || (newPosition < 0))
        throw new IllegalArgumentException();
    position = newPosition;
    if (mark > position) mark = -1;
    return this;
}

// ========== limit ==========
public final int limit() {
    return limit;
}
    
public final Buffer limit(int newLimit) {
    if ((newLimit > capacity) || (newLimit < 0))
        throw new IllegalArgumentException();
    limit = newLimit;
    if (position > limit) position = limit;
    if (mark > limit) mark = -1;
    return this;
}

// ========== mark ==========
final int markValue() {                             // package-private
    return mark;
}

final void discardMark() {                          // package-private
    mark = -1;
}

// ========== 数组相关 ==========
public final int remaining() {
    return limit - position;
}

public final boolean hasRemaining() {
    return position < limit;
}

public abstract boolean hasArray();

public abstract Object array();

public abstract int arrayOffset();

public abstract boolean isDirect();

// ========== 下一个读 / 写 position ==========
final int nextGetIndex() {                          // package-private
    if (position >= limit)
        throw new BufferUnderflowException();
    return position++;
}

final int nextGetIndex(int nb) {                    // package-private
    if (limit - position < nb)
        throw new BufferUnderflowException();
    int p = position;
    position += nb;
    return p;
}

final int nextPutIndex() {                          // package-private
    if (position >= limit)
        throw new BufferOverflowException();
    return position++;
}

final int nextPutIndex(int nb) {                    // package-private
    if (limit - position < nb)
        throw new BufferOverflowException();
    int p = position;
    position += nb;
    return p;
}

final int checkIndex(int i) {                       // package-private
    if ((i < 0) || (i >= limit))
        throw new IndexOutOfBoundsException();
    return i;
}

final int checkIndex(int i, int nb) {               // package-private
    if ((i < 0) || (nb > limit - i))
        throw new IndexOutOfBoundsException();
    return i;
}

// ========== 其它方法 ==========
final void truncate() {                             // package-private
    mark = -1;
    position = 0;
    limit = 0;
    capacity = 0;
}

static void checkBounds(int off, int len, int size) { // package-private
    if ((off | len | (off + len) | (size - (off + len))) < 0)
        throw new IndexOutOfBoundsException();
}

```

# 666. 彩蛋

参考文章如下：

- [《Java NIO：Buffer、Channel 和 Selector》](http://www.importnew.com/28007.html)
- [《Java NIO系列教程（三） Buffer》](http://ifeve.com/buffers/)
- [《Java NIO 的前生今世 之三 NIO Buffer 详解》](https://segmentfault.com/a/1190000006824155)
- [《深入浅出NIO之Channel、Buffer》](https://www.jianshu.com/p/052035037297)
- [《NIO学习笔记——缓冲区（Buffer）详解》](https://blog.csdn.net/fuyuwei2015/article/details/73521681)

# 精尽 Netty 源码分析 —— NIO 基础（四）之 Selector



# 1. 概述

Selector ， 一般称为**选择器**。它是 Java NIO 核心组件中的一个，用于轮询一个或多个 NIO Channel 的状态是否处于可读、可写。如此，一个线程就可以管理多个 Channel ，也就说可以管理多个网络连接。也因此，Selector 也被称为**多路复用器**。

那么 Selector 是如何轮询的呢？

- 首先，需要将 Channel 注册到 Selector 中，这样 Selector 才知道哪些 Channel 是它需要管理的。
- 之后，Selector 会不断地轮询注册在其上的 Channel 。如果某个 Channel 上面发生了读或者写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作。

下图是一个 Selector 管理三个 Channel 的示例：

![Selector <=> Channel](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554346327242.png)

# 2. 优缺点

① **优点**

使用一个线程**能够**处理多个 Channel 的优点是，只需要更少的线程来处理 Channel 。事实上，可以使用一个线程处理所有的 Channel 。对于操作系统来说，线程之间上下文切换的开销很大，而且每个线程都要占用系统的一些资源( 例如 CPU、内存 )。因此，使用的线程越少越好。

② **缺点**

因为在一个线程中使用了多个 Channel ，因此会造成每个 Channel 处理效率的降低。

当然，Netty 在设计实现上，通过 n 个线程处理多个 Channel ，从而很好的解决了这样的缺点。其中，n 的指的是有限的线程数，默认情况下为 CPU * 2 。

# 3. Selector 类图

Selector 在 `java.nio` 包中，被定义成**抽象类**，整体实现类图如下：

![Selector 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554346327251.png)

- Selector 的实现不是本文的重点，感兴趣的胖友可以看看占小狼的 [《深入浅出NIO之Selector实现原理》](https://www.jianshu.com/p/0d497fe5484a) 。

# 3. 创建 Selector

通过 `#open()` 方法，我们可以创建一个 Selector 对象。代码如下：

```
Selector selector = Selector.open();
```

# 4. 注册 Chanel 到 Selector 中

为了让 Selector 能够管理 Channel ，我们需要将 Channel 注册到 Selector 中。代码如下：

```
channel.configureBlocking(false); // <1>
SelectionKey key = channel.register(selector, SelectionKey.OP_READ);
```

- **注意**，如果一个 Channel 要注册到 Selector 中，那么该 Channel 必须是**非阻塞**，所以 `<1>` 处的 `channel.configureBlocking(false);` 代码块。也因此，FileChannel 是不能够注册到 Channel 中的，因为它是**阻塞**的。

- 在 `#register(Selector selector, int interestSet)` 方法的**第二个参数**，表示一个“interest 集合”，意思是通过 Selector 监听 Channel 时，对**哪些**( 可以是多个 )事件感兴趣。可以监听四种不同类型的事件：

  - Connect ：连接完成事件( TCP 连接 )，仅适用于客户端，对应 `SelectionKey.OP_CONNECT` 。
  - Accept ：接受新连接事件，仅适用于服务端，对应 `SelectionKey.OP_ACCEPT` 。
  - Read ：读事件，适用于两端，对应 `SelectionKey.OP_READ` ，表示 Buffer 可读。
  - Write ：写时间，适用于两端，对应 `SelectionKey.OP_WRITE` ，表示 Buffer 可写。

  Channel 触发了一个事件，意思是该事件已经就绪：

- 一个 Client Channel Channel 成功连接到另一个服务器，称为“连接就绪”。

- 一个 Server Socket Channel 准备好接收新进入的连接，称为“接收就绪”。

- 一个有数据可读的 Channel ，可以说是“读就绪”。

- 一个等待写数据的 Channel ，可以说是“写就绪”。

------

因为 Selector 可以对 Channel 的**多个**事件感兴趣，所以在我们想要注册 Channel 的多个事件到 Selector 中时，可以使用**或运算** `|` 来组合多个事件。示例代码如下：

```
int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;
```

------

实际使用时，我们会有**改变** Selector 对 Channel 感兴趣的事件集合，可以通过再次调用 `#register(Selector selector, int interestSet)` 方法来进行变更。示例代码如下：

```
channel.register(selector, SelectionKey.OP_READ);
channel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);
```

- 初始时，Selector 仅对 Channel 的 `SelectionKey.OP_READ` 事件感兴趣。
- 修改后，Selector 仅对 Channel 的 `SelectionKey.OP_READ` 和 `SelectionKey.OP_WRITE)` 事件**都**感兴趣。

# 5. SelectionKey 类

上一小节, 当我们调用 Channel 的 `#register(...)` 方法，向 Selector 注册一个 Channel 后，会返回一个 SelectionKey 对象。那么 SelectionKey 是什么呢？SelectionKey 在 `java.nio.channels` 包下，被定义成一个**抽象类**，表示一个 Channel 和一个 Selector 的注册关系，包含如下内容：

- interest set ：感兴趣的事件集合。
- ready set ：就绪的事件集合。
- Channel
- Selector
- attachment ：*可选的*附加对象。

## 5.1 interest set

通过调用 `#interestOps()` 方法，返回感兴趣的事件集合。示例代码如下：

```
int interestSet = selectionKey.interestOps();

// 判断对哪些事件感兴趣
boolean isInterestedInAccept  = interestSet & SelectionKey.OP_ACCEPT != 0;
boolean isInterestedInConnect = interestSet & SelectionKey.OP_CONNECT != 0;
boolean isInterestedInRead    = interestSet & SelectionKey.OP_READ != 0;
boolean isInterestedInWrite   = interestSet & SelectionKey.OP_WRITE != 0;
```

- 其中每个事件 Key 在 SelectionKey 中枚举，通过位( bit ) 表示。代码如下：

  ```
  //  SelectionKey.java
  
  public static final int OP_READ = 1 << 0;
  public static final int OP_WRITE = 1 << 2;
  public static final int OP_CONNECT = 1 << 3;
  public static final int OP_ACCEPT = 1 << 4;
  ```

  - 所以，在上述示例的后半段的代码，可以通过与运算 `&` 来判断是否对指定事件感兴趣。

## 5.2 ready set

通过调用 `#readyOps()` 方法，返回就绪的事件集合。示例代码如下：

```
int readySet = selectionKey.readyOps();

// 判断哪些事件已就绪
selectionKey.isAcceptable();
selectionKey.isConnectable();
selectionKey.isReadable();
selectionKey.isWritable();
```

- 相比 interest set 来说，ready set 已经内置了判断事件的方法。代码如下：

  ```
  // SelectionKey.java
  public final boolean isReadable() {
      return (readyOps() & OP_READ) != 0;
  }
  public final boolean isWritable() {
      return (readyOps() & OP_WRITE) != 0;
  }
  public final boolean isConnectable() {
      return (readyOps() & OP_CONNECT) != 0;
  }
  public final boolean isAcceptable() {
      return (readyOps() & OP_ACCEPT) != 0;
  }
  ```

## 5.3 attachment

通过调用 `#attach(Object ob)` 方法，可以向 SelectionKey 添加附加对象；通过调用 `#attachment()` 方法，可以获得 SelectionKey 获得附加对象。示例代码如下：

```
selectionKey.attach(theObject);
Object attachedObj = selectionKey.attachment();
```

又获得在注册时，直接添加附加对象。示例代码如下：

```
SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);
```

# 6. 通过 Selector 选择 Channel

在 Selector 中，提供三种类型的选择( select )方法，返回当前有感兴趣事件准备就绪的 Channel **数量**：

```
// Selector.java

// 阻塞到至少有一个 Channel 在你注册的事件上就绪了。
public abstract int select() throws IOException;

// 在 `#select()` 方法的基础上，增加超时机制。
public abstract int select(long timeout) throws IOException;

// 和 `#select()` 方法不同，立即返回数量，而不阻塞。
public abstract int selectNow() throws IOException;
```

- 有一点**非常需要注意**：select 方法返回的 `int` 值，表示有多少 Channel 已经就绪。亦即，**自上次调用 select 方法后有多少 Channel 变成就绪状态**。如果调用 select 方法，因为有一个 Channel 变成就绪状态则返回了 1 ；若再次调用 select 方法，如果另一个 Channel 就绪了，它会再次返回1。如果对第一个就绪的 Channel 没有做任何操作，现在就有两个就绪的 Channel ，**但在每次 select 方法调用之间，只有一个 Channel 就绪了，所以才返回 1**。

# 7. 获取可操作的 Channel

一旦调用了 select 方法，并且返回值表明有一个或更多个 Channel 就绪了，然后可以通过调用Selector 的 `#selectedKeys()` 方法，访问“已选择键集( selected key set )”中的**就绪**Channel 。示例代码所示：

```
Set selectedKeys = selector.selectedKeys();
```

- 注意，当有**新增就绪**的 Channel ，需要先调用 select 方法，才会添加到“已选择键集( selected key set )”中。否则，我们直接调用 `#selectedKeys()` 方法，是无法获得它们对应的 SelectionKey 们。

# 8. 唤醒 Selector 选择

某个线程调用 `#select()` 方法后，发生阻塞了，即使没有通道已经就绪，也有办法让其从 `#select()` 方法返回。

- 只要让其它线程在第一个线程调用 `select()` 方法的那个 Selector 对象上，调用该 Selector 的 `#wakeup()` 方法，进行唤醒该 Selector 即可。
- 那么，阻塞在 `#select()`方法上的线程，会立马返回。

> Selector 的 `#select(long timeout)` 方法，若未超时的情况下，也可以满足上述方式。

注意，如果有其它线程调用了 `#wakeup()` 方法，但当前没有线程阻塞在 `#select()` 方法上，下个调用 `#select()` 方法的线程会立即被唤醒。😈 有点神奇。

# 9. 关闭 Selector

当我们不再使用 Selector 时，可以调用 Selector 的 `#close()` 方法，将它进行关闭。

- Selector 相关的所有 SelectionKey 都**会失效**。
- Selector 相关的所有 Channel 并**不会关闭**。

注意，此时若有线程阻塞在 `#select()` 方法上，也会被唤醒返回。

# 10. 简单 Selector 示例

如下是一个简单的 Selector 示例，创建一个 Selector ，并将一个 Channel注册到这个 Selector上( Channel 的初始化过程略去 )，然后持续轮询这个 Selector 的四种事件( 接受，连接，读，写 )是否就绪。代码如下：

> 老艿艿：本代码取自 [《Java NIO系列教程（六） Selector》](http://ifeve.com/selectors/) 提供的示例，实际生产环境下并非这样的代码。🙂 最佳的实践，我们将在 Netty 中看到。

```
// 创建 Selector
Selector selector = Selector.open();
// 注册 Channel 到 Selector 中
channel.configureBlocking(false);
SelectionKey key = channel.register(selector, SelectionKey.OP_READ);
while (true) {
      // 通过 Selector 选择 Channel 
	int readyChannels = selector.select();
	if (readyChannels == 0) {
	   continue;
	}
	// 获得可操作的 Channel
	Set selectedKeys = selector.selectedKeys();
	// 遍历 SelectionKey 数组
	Iterator<SelectionKey> keyIterator = selectedKeys.iterator();
	while (keyIterator.hasNext()) {
		SelectionKey key = keyIterator.next();
		if (key.isAcceptable()) {
			// a connection was accepted by a ServerSocketChannel.
		} else if (key.isConnectable()) {
			// a connection was established with a remote server.
		} else if (key.isReadable()) {
			// a channel is ready for reading
		} else if (key.isWritable()) {
			// a channel is ready for writing
		}
		// 移除
		keyIterator.remove(); // <1>
	}
}
```

- **注意**, 在每次迭代时, 我们都调用`keyIterator.remove()`代码块，将这个 key 从迭代器中删除。
  - 因为 `#select()` 方法仅仅是简单地将就绪的 Channel 对应的 SelectionKey 放到 selected keys 集合中。
  - 因此，如果我们从 selected keys 集合中，获取到一个 key ，但是没有将它删除，那么下一次 `#select` 时, 这个 SelectionKey 还在 selectedKeys 中.

# 666. 彩蛋

参考文章如下：

- [《Java NIO系列教程（六） Selector》](http://ifeve.com/selectors/)
- [《Java NIO之Selector（选择器）》](https://www.cnblogs.com/snailclimb/p/9086334.html)
- [《Java NIO 的前生今世 之四 NIO Selector 详解》](https://segmentfault.com/a/1190000006824196)

# 精尽 Netty 源码分析 —— NIO 基础（五）之示例



# 1. 概述

在前面的四篇文章，我们已经对 NIO 的概念已经有了一定的了解。当然，胖友也可能和我一样，已经被一堆概念烦死了。

那么本文，我们撸起袖子，就是干代码，不瞎比比了。

当然，下面更多的是提供一个 NIO 示例。真正生产级的 NIO 代码，建议胖友重新写，或者直接使用 Netty 。

代码仓库在 [example/yunai/nio](https://github.com/YunaiV/netty/tree/f7016330f1483021ef1c38e0923e1c8b7cef0d10/example/src/main/java/io/netty/example/yunai/nio) 目录下。一共 3 个类：

- NioServer ：NIO 服务端。
- NioClient ：NIO 客户端。
- CodecUtil ：消息编解码工具类。

# 2. 服务端

```java
  1: public class NioServer {
  2: 
  3:     private ServerSocketChannel serverSocketChannel;
  4:     private Selector selector;
  5: 
  6:     public NioServer() throws IOException {
  7:         // 打开 Server Socket Channel
  8:         serverSocketChannel = ServerSocketChannel.open();
  9:         // 配置为非阻塞
 10:         serverSocketChannel.configureBlocking(false);
 11:         // 绑定 Server port
 12:         serverSocketChannel.socket().bind(new InetSocketAddress(8080));
 13:         // 创建 Selector
 14:         selector = Selector.open();
 15:         // 注册 Server Socket Channel 到 Selector
 16:         serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);
 17:         System.out.println("Server 启动完成");
 18: 
 19:         handleKeys();
 20:     }
 21: 
 22:     private void handleKeys() throws IOException {
 23:         while (true) {
 24:             // 通过 Selector 选择 Channel
 25:             int selectNums = selector.select(30 * 1000L);
 26:             if (selectNums == 0) {
 27:                 continue;
 28:             }
 29:             System.out.println("选择 Channel 数量：" + selectNums);
 30: 
 31:             // 遍历可选择的 Channel 的 SelectionKey 集合
 32:             Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
 33:             while (iterator.hasNext()) {
 34:                 SelectionKey key = iterator.next();
 35:                 iterator.remove(); // 移除下面要处理的 SelectionKey
 36:                 if (!key.isValid()) { // 忽略无效的 SelectionKey
 37:                     continue;
 38:                 }
 39: 
 40:                 handleKey(key);
 41:             }
 42:         }
 43:     }
 44: 
 45:     private void handleKey(SelectionKey key) throws IOException {
 46:         // 接受连接就绪
 47:         if (key.isAcceptable()) {
 48:             handleAcceptableKey(key);
 49:         }
 50:         // 读就绪
 51:         if (key.isReadable()) {
 52:             handleReadableKey(key);
 53:         }
 54:         // 写就绪
 55:         if (key.isWritable()) {
 56:             handleWritableKey(key);
 57:         }
 58:     }
 59: 
 60:     private void handleAcceptableKey(SelectionKey key) throws IOException {
 61:         // 接受 Client Socket Channel
 62:         SocketChannel clientSocketChannel = ((ServerSocketChannel) key.channel()).accept();
 63:         // 配置为非阻塞
 64:         clientSocketChannel.configureBlocking(false);
 65:         // log
 66:         System.out.println("接受新的 Channel");
 67:         // 注册 Client Socket Channel 到 Selector
 68:         clientSocketChannel.register(selector, SelectionKey.OP_READ, new ArrayList<String>());
 69:     }
 70: 
 71:     private void handleReadableKey(SelectionKey key) throws IOException {
 72:         // Client Socket Channel
 73:         SocketChannel clientSocketChannel = (SocketChannel) key.channel();
 74:         // 读取数据
 75:         ByteBuffer readBuffer = CodecUtil.read(clientSocketChannel);
 76:         // 处理连接已经断开的情况
 77:         if (readBuffer == null) {
 78:             System.out.println("断开 Channel");
 79:             clientSocketChannel.register(selector, 0);
 80:             return;
 81:         }
 82:         // 打印数据
 83:         if (readBuffer.position() > 0) {
 84:             String content = CodecUtil.newString(readBuffer);
 85:             System.out.println("读取数据：" + content);
 86: 
 87:             // 添加到响应队列
 88:             List<String> responseQueue = (ArrayList<String>) key.attachment();
 89:             responseQueue.add("响应：" + content);
 90:             // 注册 Client Socket Channel 到 Selector
 91:             clientSocketChannel.register(selector, SelectionKey.OP_WRITE, key.attachment());
 92:         }
 93:     }
 94: 
 95:     @SuppressWarnings("Duplicates")
 96:     private void handleWritableKey(SelectionKey key) throws ClosedChannelException {
 97:         // Client Socket Channel
 98:         SocketChannel clientSocketChannel = (SocketChannel) key.channel();
 99: 
100:         // 遍历响应队列
101:         List<String> responseQueue = (ArrayList<String>) key.attachment();
102:         for (String content : responseQueue) {
103:             // 打印数据
104:             System.out.println("写入数据：" + content);
105:             // 返回
106:             CodecUtil.write(clientSocketChannel, content);
107:         }
108:         responseQueue.clear();
109: 
110:         // 注册 Client Socket Channel 到 Selector
111:         clientSocketChannel.register(selector, SelectionKey.OP_READ, responseQueue);
112:     }
113: 
114:     public static void main(String[] args) throws IOException {
115:         NioServer server = new NioServer();
116:     }
117: 
118: }
```

整块代码我们可以分成 3 部分：

- 构造方法：初始化 NIO 服务端。
- `#handleKeys()` 方法：基于 Selector 处理 IO 操作。
- `#main(String[] args)` 方法：创建 NIO 服务端。

下面，我们逐小节来分享。

## 2.1 构造方法

> 对应【第 3 至 20 行】的代码。

- `serverSocketChannel` 属性，服务端的 ServerSocketChannel ，在【第 7 至 12 行】的代码进行初始化，重点是此处启动了服务端，并监听指定端口( 此处为 8080 )。
- `selector` 属性，选择器，在【第 14 至 16 行】的代码进行初始化，重点是此处将 `serverSocketChannel` 到 `selector` 中，并对 `SelectionKey.OP_ACCEPT` 事件感兴趣。这样子，在客户端连接服务端时，我们就可以处理该 IO 事件。
- 第 19 行：调用 `#handleKeys()` 方法，基于 Selector 处理 IO 事件。

## 2.2 handleKeys

> 对应【第 22 至 43 行】的代码。

- 第 23 行：死循环。本文的示例，不考虑服务端关闭的逻辑。
- 第 24 至 29 行：调用 `Selector#select(long timeout)` 方法，每 30 秒阻塞等待有就绪的 IO 事件。此处的 30 秒为笔者随意写的，实际也可以改成其他超时时间，或者 `Selector#select()` 方法。当不存在就绪的 IO 事件，直接 `continue` ，继续下一次阻塞等待。
- 第 32 行：调用`Selector#selectedKeys()`方法，获得有就绪的 IO 事件( 也可以称为“选择的” ) Channel 对应的 SelectionKey 集合。
  - 第 33 行 至 35 行：遍历 `iterator` ，进行逐个 SelectionKey 处理。重点注意下，处理完需要进行移除，具体原因，在 [《精尽 Netty 源码分析 —— NIO 基础（四）之 Selector》「10. 简单 Selector 示例」](http://svip.iocoder.cn/Netty/nio-4-selector/#10-%E7%AE%80%E5%8D%95-Selector-%E7%A4%BA%E4%BE%8B) 有详细解析。
  - 第 36 至 38 行：在遍历的过程中，可能该 SelectionKey 已经**失效**，直接 `continue` ，不进行处理。
  - 第 40 行：调用 `#handleKey()` 方法，逐个 SelectionKey 处理。

### 2.2.1 handleKey

> 对应【第 45 至 58 行】的代码。

- 通过调用 SelectionKey 的 `#isAcceptable()`、`#isReadable()`、`#isWritable()` 方法，**分别**判断 Channel 是**接受连接**就绪，还是**读**就绪，或是**写**就绪，并调用相应的 `#handleXXXX(SelectionKey key)` 方法，处理对应的 IO 事件。
- 因为 SelectionKey 可以**同时**对**一个** Channel 的**多个**事件感兴趣，所以此处的代码都是 `if` 判断，而不是 `if else` 判断。😈 虽然，考虑到让示例更简单，本文的并未编写同时对一个 Channel 的多个事件感兴趣，后续我们会在 Netty 的源码解析中看到。
- `SelectionKey.OP_CONNECT` 使用在**客户端**中，所以此处不需要做相应的判断和处理。

### 2.2.2 handleAcceptableKey

> 对应【第 60 至 69 行】的代码。

- 第 62 行：调用 `ServerSocketChannel#accept()` 方法，获得连接的客户端的 SocketChannel 。
- 第 64 行：配置客户端的 SocketChannel 为非阻塞，否则无法使用 Selector 。
- 第 66 行：打印日志，方便调试。实际场景下，使用 Logger 而不要使用 `System.out` 进行输出。
- 第 68 行：注册客户端的 SocketChannel 到`selector`中，并对`SelectionKey.OP_READ`事件感兴趣。这样子，在客户端发送消息( 数据 )到服务端时，我们就可以处理该 IO 事件。
  - 为什么不对 `SelectionKey.OP_WRITE` 事件感兴趣呢？因为这个时候，服务端一般不会主动向客户端发送消息，所以不需要对 `SelectionKey.OP_WRITE` 事件感兴趣。
  - 细心的胖友会发现，`Channel#register(Selector selector, int ops, Object attachment)` 方法的第 3 个参数，我们注册了 SelectionKey 的 `attachment` 属性为 `new ArrayList<String>()` ，这又是为什么呢？结合下面的 `#handleReadableKey(Selection key)` 方法，我们一起解析。

### 2.2.3 handleReadableKey

> 对应【第 71 至 93 行】的代码。

- 第 73 行：调用 `SelectionKey#channel()` 方法，获得该 SelectionKey 对应的 SocketChannel ，即客户端的 SocketChannel 。

- 第 75 行：调用 `CodecUtil#read(SocketChannel channel)` 方法，读取数据。具体代码如下：

  ```
  // CodecUtil.java
  
  public static ByteBuffer read(SocketChannel channel) {
      // 注意，不考虑拆包的处理
      ByteBuffer buffer = ByteBuffer.allocate(1024);
      try {
          int count = channel.read(buffer);
          if (count == -1) {
              return null;
          }
      } catch (IOException e) {
          throw new RuntimeException(e);
      }
      return buffer;
  }
  ```

  - 考虑到示例的简单性，数据的读取，就不考虑拆包的处理。不理解的胖友，可以自己 Google 下。
  - 调用 `SocketChannel#read(ByteBuffer)` 方法，读取 Channel 的缓冲区的数据到 ByteBuffer 中。若返回的结果( `count` ) 为 -1 ，意味着客户端连接已经断开，我们直接返回 `null` 。为什么是返回 `null` 呢？下面继续见分晓。

- 第 76 至 81 行：若读取数据返回的结果为 `null` 时，意味着客户端的连接已经断开，因此取消注册 `selector` 对该客户端的 SocketChannel 的感兴趣的 IO 事件。通过调用注册方法，并且第 2 个参数 `ops` 为 0 ，可以达到取消注册的效果。😈 感兴趣的胖友，可以将这行代码进行注释，测试下效果就很容易明白了。

- 第 83 行：通过调用 `ByteBuffer#position()` 大于 0 ，来判断**实际**读取到数据。

  - 第 84 至 85 行：调用 `CodecUtil#newString(ByteBuffer)` 方法，格式化为字符串，并进行打印。代码如下：

    ```
    // CodecUtil.java
    
    public static String newString(ByteBuffer buffer) {
        buffer.flip();
        byte[] bytes = new byte[buffer.remaining()];
        System.arraycopy(buffer.array(), buffer.position(), bytes, 0, buffer.remaining());
        try {
            return new String(bytes, "UTF-8");
        } catch (UnsupportedEncodingException e) {
            throw new RuntimeException(e);
        }
    }
    ```

    - 注意，需要调用 `ByteBuffer#flip()` 方法，将 ByteBuffer 从**写**模式切换到**读**模式。

  - 第 86 行：一般在此处，我们可以进行一些业务逻辑的处理，并返回处理的相应结果。例如，我们熟悉的 Request / Response 的处理。当然，考虑到性能，我们甚至可以将逻辑的处理，丢到逻辑线程池。

    - 😈 如果不理解，木有关系，在 [《精尽 Dubbo 源码分析 —— NIO 服务器（二）之 Transport 层》「8. Dispacher」](http://svip.iocoder.cn/Dubbo/remoting-api-transport/) 中，有详细解析。
    - 🙂 考虑到示例的简洁性，所以在【第 88 至 89 行】的代码中，我们直接返回（`"响应："` + 请求内容）给客户端。

  - 第 88 行：通过调用`SelectionKey#attachment()`方法，获得我们**附加**在 SelectionKey 的响应队列(`responseQueue`)。可能有胖友会问啦，为什么不调用`SocketChannel#write(ByteBuf)`方法，直接写数据给客户端呢？虽然大多数情况下，SocketChannel 都是**可写**的，但是如果写入比较频繁，超过 SocketChannel 的缓存区大小，就会导致数据“**丢失**”，并未写给客户端。

    - 所以，此处笔者在示例中，处理的方式为添加响应数据到 `responseQueue` 中，并在【第 91 行】的代码中，注册客户端的 SocketChannel 到 `selector` 中，并对 `SelectionKey.OP_WRITE` 事件感兴趣。这样子，在 SocketChannel **写就绪**时，在 `#handleWritableKey(SelectionKey key)` 方法中，统一处理写数据给客户端。
    - 当然，还是因为是示例，所以这样的实现方式不是最优。在 Netty 中，具体的实现方式是，先尝试调用 `SocketChannel#write(ByteBuf)` 方法，写数据给客户端。若写入失败( 方法返回结果为 0 )时，再进行类似笔者的上述实现方式。牛逼！Netty ！
    - 如果不太理解分享的原因，可以再阅读如下两篇文章：
      - [《深夜对话：NIO 中 SelectionKey.OP_WRITE 你了解多少》](https://mp.weixin.qq.com/s/V4tEH1j64FHFmB8bReNI7g)
      - [《Java.nio 中 socketChannle.write() 返回 0 的简易解决方案》](https://blog.csdn.net/a34140974/article/details/48464845)

  - 第 91 行：有一点需要注意，`Channel#register(Selector selector, int ops, Object attachment)` 方法的第 3 个参数，需要继续传入响应队列( `responseQueue` )，因为每次注册生成**新**的 SelectionKey 。若不传入，下面的 `#handleWritableKey(SelectionKey key)` 方法，会获得不到响应队列( `responseQueue` )。

### 2.2.4 handleWritableKey

> 对应【第 96 至 112 行】的代码。

- 第 98 行：调用 `SelectionKey#channel()` 方法，获得该 SelectionKey 对应的 SocketChannel ，即客户端的 SocketChannel 。

- 第 101 行：通过调用 `SelectionKey#attachment()` 方法，获得我们**附加**在 SelectionKey 的响应队列( `responseQueue` )。

  - 第 102 行：遍历响应队列。

  - 第 106 行：调用 `CodeUtil#write(SocketChannel, content)` 方法，写入响应数据给客户端。代码如下：

    ```
     // CodecUtil.java
     
    public static void write(SocketChannel channel, String content) {
        // 写入 Buffer
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        try {
            buffer.put(content.getBytes("UTF-8"));
        } catch (UnsupportedEncodingException e) {
            throw new RuntimeException(e);
        }
        // 写入 Channel
        buffer.flip();
        try {
            // 注意，不考虑写入超过 Channel 缓存区上限。
            channel.write(buffer);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
    ```

    - 代码比较简单，**还是要注意**，需要调用 `ByteBuffer#flip()` 方法，将 ByteBuffer 从**写**模式切换到**读**模式。

- 第 111 行：**注意**，再结束写入后，需要**重新**注册客户端的 SocketChannel 到 `selector` 中，并对 `SelectionKey.OP_READ` 事件感兴趣。为什么呢？其实还是我们在上文中提到的，大多数情况下，SocketChannel **都是写就绪的**，如果不取消掉注册掉对 `SelectionKey.OP_READ` 事件感兴趣，就会导致反复触发无用的写事件处理。😈 感兴趣的胖友，可以将这行代码进行注释，测试下效果就很容易明白了。

## 2.3 main

> 对应【第 114 至 116 行】

- 比较简单，就是创建一个 NioServer 对象。

撸到此处，我们可以直接通过 `telnet 127.0.0.1 8080` 的方式，连接服务端，进行读写数据的测试。

# 3. 客户端

客户端的实现代码，绝大数和服务端相同，所以我们分析的相对会简略一些。不然，自己都嫌弃自己太啰嗦了。

```
  1: public class NioClient {
  2: 
  3:     private SocketChannel clientSocketChannel;
  4:     private Selector selector;
  5:     private final List<String> responseQueue = new ArrayList<String>();
  6: 
  7:     private CountDownLatch connected = new CountDownLatch(1);
  8: 
  9:     public NioClient() throws IOException, InterruptedException {
 10:         // 打开 Client Socket Channel
 11:         clientSocketChannel = SocketChannel.open();
 12:         // 配置为非阻塞
 13:         clientSocketChannel.configureBlocking(false);
 14:         // 创建 Selector
 15:         selector = Selector.open();
 16:         // 注册 Server Socket Channel 到 Selector
 17:         clientSocketChannel.register(selector, SelectionKey.OP_CONNECT);
 18:         // 连接服务器
 19:         clientSocketChannel.connect(new InetSocketAddress(8080));
 20: 
 21:         new Thread(new Runnable() {
 22:             @Override
 23:             public void run() {
 24:                 try {
 25:                     handleKeys();
 26:                 } catch (IOException e) {
 27:                     e.printStackTrace();
 28:                 }
 29:             }
 30:         }).start();
 31: 
 32:         if (connected.getCount() != 0) {
 33:             connected.await();
 34:         }
 35:         System.out.println("Client 启动完成");
 36:     }
 37: 
 38:     @SuppressWarnings("Duplicates")
 39:     private void handleKeys() throws IOException {
 40:         while (true) {
 41:             // 通过 Selector 选择 Channel
 42:             int selectNums = selector.select(30 * 1000L);
 43:             if (selectNums == 0) {
 44:                 continue;
 45:             }
 46: 
 47:             // 遍历可选择的 Channel 的 SelectionKey 集合
 48:             Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
 49:             while (iterator.hasNext()) {
 50:                 SelectionKey key = iterator.next();
 51:                 iterator.remove(); // 移除下面要处理的 SelectionKey
 52:                 if (!key.isValid()) { // 忽略无效的 SelectionKey
 53:                     continue;
 54:                 }
 55: 
 56:                 handleKey(key);
 57:             }
 58:         }
 59:     }
 60: 
 61:     private synchronized void handleKey(SelectionKey key) throws IOException {
 62:         // 接受连接就绪
 63:         if (key.isConnectable()) {
 64:             handleConnectableKey(key);
 65:         }
 66:         // 读就绪
 67:         if (key.isReadable()) {
 68:             handleReadableKey(key);
 69:         }
 70:         // 写就绪
 71:         if (key.isWritable()) {
 72:             handleWritableKey(key);
 73:         }
 74:     }
 75: 
 76:     private void handleConnectableKey(SelectionKey key) throws IOException {
 77:         // 完成连接
 78:         if (!clientSocketChannel.isConnectionPending()) {
 79:             return;
 80:         }
 81:         clientSocketChannel.finishConnect();
 82:         // log
 83:         System.out.println("接受新的 Channel");
 84:         // 注册 Client Socket Channel 到 Selector
 85:         clientSocketChannel.register(selector, SelectionKey.OP_READ, responseQueue);
 86:         // 标记为已连接
 87:         connected.countDown();
 88:     }
 89: 
 90:     @SuppressWarnings("Duplicates")
 91:     private void handleReadableKey(SelectionKey key) throws ClosedChannelException {
 92:         // Client Socket Channel
 93:         SocketChannel clientSocketChannel = (SocketChannel) key.channel();
 94:         // 读取数据
 95:         ByteBuffer readBuffer = CodecUtil.read(clientSocketChannel);
 96:         // 打印数据
 97:         if (readBuffer.position() > 0) { // 写入模式下，
 98:             String content = CodecUtil.newString(readBuffer);
 99:             System.out.println("读取数据：" + content);
100:         }
101:     }
102: 
103:     @SuppressWarnings("Duplicates")
104:     private void handleWritableKey(SelectionKey key) throws ClosedChannelException {
105:         // Client Socket Channel
106:         SocketChannel clientSocketChannel = (SocketChannel) key.channel();
107: 
108:         // 遍历响应队列
109:         List<String> responseQueue = (ArrayList<String>) key.attachment();
110:         for (String content : responseQueue) {
111:             // 打印数据
112:             System.out.println("写入数据：" + content);
113:             // 返回
114:             CodecUtil.write(clientSocketChannel, content);
115:         }
116:         responseQueue.clear();
117: 
118:         // 注册 Client Socket Channel 到 Selector
119:         clientSocketChannel.register(selector, SelectionKey.OP_READ, responseQueue);
120:     }
121: 
122:     public synchronized void send(String content) throws ClosedChannelException {
123:         // 添加到响应队列
124:         responseQueue.add(content);
125:         // 打印数据
126:         System.out.println("写入数据：" + content);
127:         // 注册 Client Socket Channel 到 Selector
128:         clientSocketChannel.register(selector, SelectionKey.OP_WRITE, responseQueue);
129:         selector.wakeup();
130:     }
131: 
132:     public static void main(String[] args) throws IOException, InterruptedException {
133:         NioClient client = new NioClient();
134:         for (int i = 0; i < 30; i++) {
135:             client.send("nihao: " + i);
136:             Thread.sleep(1000L);
137:         }
138:     }
139: 
140: }
```

整块代码我们可以分成 3 部分：

- 构造方法：初始化 NIO 客户端。
- `#handleKeys()` 方法：基于 Selector 处理 IO 操作。
- `#main(String[] args)` 方法：创建 NIO 客户端，并向服务器发送请求数据。

下面，我们逐小节来分享。

## 3.1 构造方法

> 对应【第 3 至 36 行】的代码。

- `clientSocketChannel` 属性，客户端的 SocketChannel ，在【第 9 至 13 行】和【第 19 行】的代码进行初始化，重点是此处连接了指定服务端。
- `selector` 属性，选择器，在【第 14 至 17 行】的代码进行初始化，重点是此处将 `clientSocketChannel` 到 `selector` 中，并对 `SelectionKey.OP_CONNECT` 事件感兴趣。这样子，在客户端连接服务端**成功**时，我们就可以处理该 IO 事件。
- `responseQueue` 属性，直接声明为 NioClient 的成员变量，是为了方便 `#send(String content)` 方法的实现。
- 第 21 至 30 行：调用 `#handleKeys()` 方法，基于 Selector 处理 IO 事件。比较特殊的是，我们是启动了一个**线程**进行处理。因为在后续的 `#main()` 方法中，我们需要调用发送请求数据的方法，不能直接在**主线程**，轮询处理 IO 事件。😈 机智的胖友，可能已经发现，NioServer 严格来说，也是应该这样处理。
- 第 32 至 34 行：通过 CountDownLatch 来实现阻塞等待客户端成功连接上服务端。具体的`CountDownLatch#countDown()`方法，在`#handleConnectableKey(SelectionKey key)`方法中调用。当然，除了可以使用 CountDownLatch 来实现阻塞等待，还可以通过如下方式:
  - Object 的 wait 和 notify 的方式。
  - Lock 的 await 和 notify 的方式。
  - Queue 的阻塞等待方式。
  - 😈 开心就好，皮一下很开心。

## 3.2 handleKeys

> 对应【第 38 至 59 行】的代码。

**完全**和 NioServer 中的该方法一模一样，省略。

### 3.2.1 handleKey

> 对应【第 61 至 74 行】的代码。

**大体**逻辑和 NioServer 中的该方法一模一样，差别将对 `SelectionKey.OP_WRITE` 事件的处理改成对 `SelectionKey.OP_CONNECT` 事件的处理。

### 3.3.2 handleConnectableKey

> 对应【第 76 至 88 行】的代码。

- 第 77 至 81 行：判断客户端的 SocketChannel 上是否**正在进行连接**的操作，若是，则完成连接。
- 第 83 行：打印日志。
- 第 85 行：注册客户端的 SocketChannel 到 `selector` 中，并对 `SelectionKey.OP_READ` 事件感兴趣。这样子，在客户端接收到到服务端的消息( 数据 )时，我们就可以处理该 IO 事件。
- 第 87 行：调用 `CountDownLatch#countDown()` 方法，结束 NioClient 构造方法中的【第 32 至 34 行】的阻塞等待连接完成。

### 3.3.3 handleReadableKey

> 对应【第 91 至 101 行】的代码。

**大体**逻辑和 NioServer 中的该方法一模一样，**去掉响应请求的相关逻辑**。😈 如果不去掉，就是客户端和服务端互发消息的“死循环”了。

### 3.3.4 handleWritableKey

> 对应【第 103 至 120 行】的代码。

**完全**和 NioServer 中的该方法一模一样。

## 3.3 send

> 对应【第 122 至 130 行】的代码。

客户端发送请求消息给服务端。

- 第 124 行：添加到响应队列( `responseQueue` ) 中。
- 第 126 行：打印日志。
- 第 128 行：注册客户端的 SocketChannel 到 `selector` 中，并对 `SelectionKey.OP_WRITE` 事件感兴趣。具体的原因，和 NioServer 的 `#handleReadableKey(SelectionKey key)` 方法的【第 88 行】一样。
- 第 129 行：调用`Selector#wakeup()`方法，唤醒`#handleKeys()`方法中，`Selector#select(long timeout)`方法的阻塞等待。
  - 因为，在 `Selector#select(long timeout)` 方法的实现中，是以调用**当时**，对 SocketChannel 的感兴趣的事件 。
  - 所以，在【第 128 行】的代码中，即使修改了对 SocketChannel 的感兴趣的事件，也不会结束 `Selector#select(long timeout)` 方法的阻塞等待。因此，需要进行唤醒操作。
  - 😈 感兴趣的胖友，可以将这行代码进行注释，测试下效果就很容易明白了。

## 3.4 main

> 对应【第 132 至 137 行】的代码。

- 第 133 行：创建一个 NioClient 对象。
- 第 134 至 137 行：每秒发送一次请求。考虑到代码没有处理拆包的逻辑，所以增加了间隔 1 秒的 sleep 。

# 666. 彩蛋

呼呼，凌晨 1 点。困累，写的有点着急了。简单 Review 了一遍，如果有不正确的，烦请斧正！谢谢！

推荐阅读文章如下：

- [《【NIO系列】—— Reactor 模式》](https://mp.weixin.qq.com/s/GpeaNowZKo1plaES9oxZ7g)
- [《lanux/java-demo/nio/example》](https://github.com/lanux/java-demo/tree/5b29c4b0d0056578a6eaa847e0d1efc9e42e48a4/src/main/java/com/lanux/io/nio)

# 精尽 Netty 源码分析 —— Netty 简介（一）之项目结构



# 1. 概述

本文主要分享 **Netty 的项目结构**。
希望通过本文能让胖友对 Netty 的整体项目有个简单的了解。

在拉取 Netty 项目后，我们会发现拆分了**好多** Maven 项目。是不是内心一紧，产生了恐惧感？不要方，我们就是继续怼。

![项目结构](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554205517058.png)

# 2. 代码统计

这里先分享一个小技巧。笔者在开始源码学习时，会首先了解项目的代码量。

**第一种方式**，使用 [IDEA Statistic](https://plugins.jetbrains.com/plugin/4509-statistic) 插件，统计整体代码量。

![Statistic 统计代码量](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554205517075.png)

我们可以粗略的看到，总的代码量在 251365 行。这其中还包括单元测试，示例等等代码。
所以，不慌。

**第二种方式**，使用 [Shell 脚本命令逐个 Maven 模块统计](http://blog.csdn.net/yhhwatl/article/details/52623879) 。

一般情况下，笔者使用 `find . -name "*.java"|xargs cat|grep -v -e ^$ -e ^\s*\/\/.*$|wc -l` 。这个命令只过滤了**部分注释**，所以相比 [IDEA Statistic](https://plugins.jetbrains.com/plugin/4509-statistic) 会**偏多**。

当然，考虑到准确性，胖友需要手动 `cd` 到每个 Maven 项目的 `src/main/java` 目录下，以达到排除单元测试的代码量。

![Shell 脚本统计代码量](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554205517085.png)

- 😈 偷懒了下，暂时只统计**核心**模块，未统计**拓展**模块。

# 3. 架构图

在看具体每个 Netty 的 Maven 项目之前，我们还是先来看看 Netty 的整体架构图。

![架构图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/04-1554205517303.png)

- Core

   

  ：核心部分，是底层的网络通用抽象和部分实现。

  - Extensible Event Model ：可拓展的事件模型。Netty 是基于事件模型的网络应用框架。
  - Universal Communication API ：通用的通信 API 层。Netty 定义了一套抽象的通用通信层的 API 。
  - Zero-Copy-Capable Rich Byte Buffer ：支持零拷贝特性的 Byte Buffer 实现。

- Transport Services

   

  ：传输( 通信 )服务，具体的网络传输的定义与实现。

  - Socket & Datagram ：TCP 和 UDP 的传输实现。
  - HTTP Tunnel ：HTTP 通道的传输实现。
  - In-VM Piple ：JVM 内部的传输实现。😈 理解起来有点怪，后续看具体代码，会易懂。

- **Protocol Support** ：协议支持。Netty 对于一些通用协议的编解码实现。例如：HTTP、Redis、DNS 等等。

# 4. 项目依赖图

Netty 的 Maven 项目之间**主要依赖**如下图：

![依赖图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/07.png)

- 本图省略**非主要依赖**。例如，`handler-proxy` 对 `codec` 有依赖，但是并未画出。
- 本图省略**非主要的项目**。例如，`resolver`、`testsuite`、`example` 等等。

下面，我们来详细介绍每个项目。

# 5. common

`common` 项目，该项目是一个通用的工具类项目，几乎被所有的其它项目依赖使用，它提供了一些数据类型处理工具类，并发编程以及多线程的扩展，计数器等等通用的工具类。

![common 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/05-1554205517230.png)

# 6. buffer

> 该项目实现了 Netty 架构图中的 Zero-Copy-Capable Rich Byte Buffer 。

`buffer` 项目，该项目下是 Netty 自行实现的一个 Byte Buffer 字节缓冲区。该包的实现相对于 JDK 自带的 ByteBuffer 有很多**优点**：无论是 API 的功能，使用体验，性能都要更加优秀。它提供了**一系列( 多种 )**的抽象定义以及实现，以满足不同场景下的需要。

![buffer 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/06-1554205517259.png)

# 7. transport

> 该项是核心项目，实现了 Netty 架构图中 Transport Services、Universal Communication API 和 Extensible Event Model 等多部分内容。

`transport` 项目，该项目是网络传输通道的抽象和实现。它定义通信的统一通信 API ，统一了 JDK 的 OIO、NIO ( 不包括 AIO )等多种编程接口。

![transport 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/08-1554205517345.png)

另外，它提供了多个子项目，实现不同的传输类型。例如：`transport-native-epoll`、`transport-native-kqueue`、`transport-rxtx`、`transport-udt` 和 `transport-sctp` 等等。

# 8. codec

> 该项目实现了Netty 架构图中的 Protocol Support 。

`codec` 项目，该项目是协议编解码的抽象与**部分**实现：JSON、Google Protocol、Base64、XML 等等。

![codec 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/09.png)

另外，它提供了多个子项目，实现不同协议的编解码。例如：`codec-dns`、`codec-haproxy`、`codec-http`、`codec-http2`、`codec-mqtt`、`codec-redis`、`codec-memcached`、`codec-smtp`、`codec-socks`、`codec-stomp`、`codec-xml` 等等。

# 9. handler

`handler` 项目，该项目是提供**内置的**连接通道处理器( ChannelHandler )实现类。例如：SSL 处理器、日志处理器等等。

![handler 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/10-1554205517462.png)

另外，它提供了一个子项目 `handler-proxy` ，实现对 HTTP、Socks 4、Socks 5 的代理转发。

# 10. example

`example` 项目，该项目是提供各种 Netty 使用示例，良心开源项目。

![example 项目](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/11.png)

# 11. 其它项目

Netty 中还有其它项目，考虑到不是本系列的重点，就暂时进行省略。

- `all` ：All In One 的 `pom` 声明。

- `bom` ：Netty Bill Of Materials 的缩写，不了解的胖友，可以看看 [《Maven 与Spring BOM( Bill Of Materials )简化 Spring 版本控制》](https://blog.csdn.net/fanxiaobin577328725/article/details/66974896) 。

- `microbench` ：微基准测试。

- `resolver` ：终端( Endpoint ) 的地址解析器。

- `resolver-dns`

- `tarball` ：All In One 打包工具。

- `testsuite` ：测试集。

  > 测试集( TestSuite ) ：测试集是把多个相关测试归入一个组的表达方式。在 Junit 中，如果我们没有明确的定义一个测试集，那么 Juint 会自动的提供一个测试集。一个测试集一般将同一个包的测试类归入一组。

- `testsuite-autobahhn`

- `testsuite-http2`

- `testsuite-osgi`

# 666. 彩蛋

本文基于杨武兵大佬的 [《Netty 源码分析系列 —— 概述》](https://my.oschina.net/ywbrj042/blog/856596) 进行修改。

# 精尽 Netty 源码分析 —— Netty 简介（二）之核心组件



# 1. 概述

什么是 Netty ？

> Netty 是一款提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。
>
> 也就是说，Netty 是一个基于 NIO 的客户、服务器端编程框架。使用 Netty 可以确保你快速和简单地开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty 相当简化和流线化了网络应用的编程开发过程，例如，TCP 和 UDP 的 socket 服务开发。
>
> （以上摘自百度百科）。

Netty 具有如下特性( 摘自《Netty in Action》 )

| 分类     | Netty的特性                                                  |
| -------- | ------------------------------------------------------------ |
| 设计     | 1. 统一的 API ，支持多种传输类型( 阻塞和非阻塞的 )  2. 简单而强大的线程模型  3. 真正的无连接数据报套接字( UDP )支持  4. 连接逻辑组件( ChannelHander 中顺序处理消息 )以及组件复用( 一个 ChannelHandel 可以被多个ChannelPipeLine 复用 ) |
| 易于使用 | 1. 详实的 Javadoc 和大量的示例集  2. 不需要超过 JDK 1.6+ 的依赖 |
| 性能     | 拥有比 Java 的核心 API 更高的吞吐量以及更低的延迟( 得益于池化和复用 )，更低的资源消耗以及最少的内存复制 |
| 健壮性   | 1. 不会因为慢速、快速或者超载的连接而导致 OutOfMemoryError  2. 消除在高速网络中 NIO 应用程序常见的不公平读 / 写比率 |
| 安全性   | 完整的 SSL/TLS 以及 StartTLs 支持，可用于受限环境下，如 Applet 和 OSGI |
| 社区驱动 | 发布快速而且频繁                                             |

# 2. Netty 核心组件

为了后期更好地理解和进一步深入 Netty，有必要总体认识一下 Netty 所用到的核心组件以及他们在整个 Netty 架构中是如何协调工作的。

Netty 有如下几个核心组件：

- Bootstrap & ServerBootstrap
- Channel
- ChannelFuture
- EventLoop & EventLoopGroup
- ChannelHandler
- ChannelPipeline

核心组件的高层类图如下：

![高层类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554205552568.png)

## 2.1 Bootstrap & ServerBootstrap

这 2 个类都继承了AbstractBootstrap，因此它们有很多相同的方法和职责。它们都是**启动器**，能够帮助 Netty 使用者更加方便地组装和配置 Netty ，也可以更方便地启动 Netty 应用程序。相比使用者自己从头去将 Netty 的各部分组装起来要方便得多，降低了使用者的学习和使用成本。它们是我们使用 Netty 的入口和最重要的 API ，可以通过它来连接到一个主机和端口上，也可以通过它来绑定到一个本地的端口上。总的来说，**它们两者之间相同之处要大于不同**。

> 老艿艿：Bootstrap & ServerBootstrap 对于 Netty ，就相当于 Spring Boot 是 Spring 的启动器。

它们和其它组件之间的关系是它们将 Netty 的其它组件进行组装和配置，所以它们会组合和直接或间接依赖其它的类。

Bootstrap 用于启动一个 Netty TCP 客户端，或者 UDP 的一端。

- 通常使用 `#connet(...)` 方法连接到远程的主机和端口，作为一个 Netty TCP 客户端。
- 也可以通过 `#bind(...)` 方法绑定本地的一个端口，作为 UDP 的一端。
- 仅仅需要使用**一个** EventLoopGroup 。

ServerBootstrap 往往是用于启动一个 Netty 服务端。

- 通常使用 `#bind(...)` 方法绑定本地的端口上，然后等待客户端的连接。
- 使用**两个** EventLoopGroup 对象( 当然这个对象可以引用同一个对象 )：第一个用于处理它本地 Socket **连接**的 IO 事件处理，而第二个责负责处理远程客户端的 IO 事件处理。

## 2.2 Channel

Channel 是 Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 之外，还包括了 Netty 框架相关的一些功能，如获取该 Channel 的 EventLoop 。

在传统的网络编程中，作为核心类的 Socket ，它对程序员来说并不是那么友好，直接使用其成本还是稍微高了点。而 Netty 的 Channel 则提供的一系列的 API ，它大大降低了直接与 Socket 进行操作的复杂性。而相对于原生 NIO 的 Channel，Netty 的 Channel 具有如下优势( 摘自《Netty权威指南( 第二版 )》) ：

- 在 Channel 接口层，采用 Facade 模式进行统一封装，将网络 I/O 操作、网络 I/O 相关联的其他操作封装起来，统一对外提供。
- Channel 接口的定义尽量大而全，为 SocketChannel 和 ServerSocketChannel 提供统一的视图，由不同子类实现不同的功能，公共功能在抽象父类中实现，最大程度地实现功能和接口的重用。
- 具体实现采用聚合而非包含的方式，将相关的功能类聚合在 Channel 中，由 Channel 统一负责和调度，功能实现更加灵活。

## 2.2 EventLoop && EventLoopGroup

Netty 基于**事件驱动模型**，使用不同的事件来通知我们状态的改变或者操作状态的改变。它定义了在整个连接的生命周期里当有事件发生的时候处理的核心抽象。

Channel 为Netty 网络操作抽象类，EventLoop 负责处理注册到其上的 Channel 处理 I/O 操作，两者配合参与 I/O 操作。

EventLoopGroup 是一个 EventLoop 的分组，它可以获取到一个或者多个 EventLoop 对象，因此它提供了迭代出 EventLoop 对象的方法。

下图是 Channel、EventLoop、Thread、EventLoopGroup 之间的关系( 摘自《Netty In Action》) ：

![Channel、EventLoop、Thread、EventLoopGroup](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554205552576.png)

- 一个 EventLoopGroup 包含一个或多个 EventLoop ，即 EventLoopGroup : EventLoop = `1 : n` 。
- 一个 EventLoop 在它的生命周期内，只能与一个 Thread 绑定，即 EventLoop : Thread = `1 : 1` 。
- 所有有 EventLoop 处理的 I/O 事件都将在它**专有**的 Thread 上被处理，从而保证线程安全，即 Thread : EventLoop = `1 : 1`。
- 一个 Channel 在它的生命周期内只能注册到一个 EventLoop 上，即 Channel : EventLoop = `n : 1` 。
- 一个 EventLoop 可被分配至一个或多个 Channel ，即 EventLoop : Channel = `1 : n` 。

当一个连接到达时，Netty 就会创建一个 Channel，然后从 EventLoopGroup 中分配一个 EventLoop 来给这个 Channel 绑定上，在该 Channel 的整个生命周期中都是有这个绑定的 EventLoop 来服务的。

## 2.4 ChannelFuture

Netty 为异步非阻塞，即所有的 I/O 操作都为异步的，因此，我们不能立刻得知消息是否已经被处理了。Netty 提供了 ChannelFuture 接口，通过该接口的 `#addListener(...)` 方法，注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。

## 2.5 ChannelHandler

ChannelHandler ，连接通道处理器，我们使用 Netty 中**最常用**的组件。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。

ChannelHandler 有两个核心子类 ChannelInboundHandler 和 ChannelOutboundHandler，其中 ChannelInboundHandler 用于接收、处理入站( Inbound )的数据和事件，而 ChannelOutboundHandler 则相反，用于接收、处理出站( Outbound )的数据和事件。

- ChannelInboundHandler 的实现类还包括一系列的 **Decoder** 类，对输入字节流进行解码。
- ChannelOutboundHandler 的实现类还包括一系列的 **Encoder** 类，对输入字节流进行编码。

ChannelDuplexHandler 可以**同时**用于接收、处理入站和出站的数据和时间。

ChannelHandler 还有其它的一系列的抽象实现 Adapter ，以及一些用于编解码具体协议的 ChannelHandler 实现类。

## 2.6 ChannelPipeline

ChannelPipeline 为 ChannelHandler 的**链**，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。一个数据或者事件可能会被多个 Handler 处理，在这个过程中，数据或者事件经流 ChannelPipeline ，由 ChannelHandler 处理。在这个处理过程中，一个 ChannelHandler 接收数据后处理完成后交给下一个 ChannelHandler，或者什么都不做直接交给下一个 ChannelHandler。

![ChannelPipeline](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554205552583.png)

- 当一个数据流进入 ChannelPipeline 时，它会从 ChannelPipeline 头部开始，传给第一个 ChannelInboundHandler 。当第一个处理完后再传给下一个，一直传递到管道的尾部。
- 与之相对应的是，当数据被写出时，它会从管道的尾部开始，先经过管道尾部的“最后”一个ChannelOutboundHandler ，当它处理完成后会传递给前一个 ChannelOutboundHandler 。

上图更详细的，可以是如下过程：

```
*                                                 I/O Request
*                                            via {@link Channel} or
*                                        {@link ChannelHandlerContext}
*                                                      |
*  +---------------------------------------------------+---------------+
*  |                           ChannelPipeline         |               |
*  |                                                  \|/              |
*  |    +---------------------+            +-----------+----------+    |
*  |    | Inbound Handler  N  |            | Outbound Handler  1  |    |
*  |    +----------+----------+            +-----------+----------+    |
*  |              /|\                                  |               |
*  |               |                                  \|/              |
*  |    +----------+----------+            +-----------+----------+    |
*  |    | Inbound Handler N-1 |            | Outbound Handler  2  |    |
*  |    +----------+----------+            +-----------+----------+    |
*  |              /|\                                  .               |
*  |               .                                   .               |
*  | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|
*  |        [ method call]                       [method call]         |
*  |               .                                   .               |
*  |               .                                  \|/              |
*  |    +----------+----------+            +-----------+----------+    |
*  |    | Inbound Handler  2  |            | Outbound Handler M-1 |    |
*  |    +----------+----------+            +-----------+----------+    |
*  |              /|\                                  |               |
*  |               |                                  \|/              |
*  |    +----------+----------+            +-----------+----------+    |
*  |    | Inbound Handler  1  |            | Outbound Handler  M  |    |
*  |    +----------+----------+            +-----------+----------+    |
*  |              /|\                                  |               |
*  +---------------+-----------------------------------+---------------+
*                  |                                  \|/
*  +---------------+-----------------------------------+---------------+
*  |               |                                   |               |
*  |       [ Socket.read() ]                    [ Socket.write() ]     |
*  |                                                                   |
*  |  Netty Internal I/O Threads (Transport Implementation)            |
*  +-------------------------------------------------------------------+
```

------

当 ChannelHandler 被添加到 ChannelPipeline 时，它将会被分配一个 **ChannelHandlerContext** ，它代表了 ChannelHandler 和 ChannelPipeline 之间的绑定。其中 ChannelHandler 添加到 ChannelPipeline 中，通过 ChannelInitializer 来实现，过程如下：

1. 一个 ChannelInitializer 的实现对象，被设置到了 BootStrap 或 ServerBootStrap 中。
2. 当 `ChannelInitializer#initChannel()` 方法被调用时，ChannelInitializer 将在 ChannelPipeline 中创建**一组**自定义的 ChannelHandler 对象。
3. ChannelInitializer 将它自己从 ChannelPipeline 中移除。

> ChannelInitializer 是一个特殊的 ChannelInboundHandlerAdapter 抽象类。

# 666. 彩蛋

本文整理于如下两篇文章：

- 小明哥 [《【死磕 Netty 】—— Netty的核心组件》](https://cloud.tencent.com/developer/article/1110061)
- 杨武兵 [《Netty 源码分析系列 —— 概述》](https://my.oschina.net/ywbrj042/blog/856596)
- 乒乓狂魔 [《Netty 源码分析（一）概览》](https://my.oschina.net/pingpangkuangmo/blog/734051)

😈 见谅，不擅长写理论型的内容哈。

# 精尽 Netty 源码分析 —— 启动（一）之服务端



# 1. 概述

对于所有 Netty 的新手玩家，我们**最先**使用的就是 Netty 的 Bootstrap 和 ServerBootstrap 组这两个“**启动器**”组件。它们在 `transport` 模块的 `bootstrap` 包下实现，如下图所示：

![`bootstrap` 包](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01.png)

在图中，我们可以看到三个以 Bootstrap 结尾的类，类图如下：

![Bootstrap 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02.png)

- 为什么是这样的类关系呢？因为 ServerBootstrap 和 Bootstrap **大部分**的方法和职责都是相同的。

本文仅分享 ServerBootstrap 启动 Netty 服务端的过程。下一篇文章，我们再分享 Bootstrap 分享 Netty 客户端。

# 2. ServerBootstrap 示例

下面，我们先来看一个 ServerBootstrap 的使用示例，就是我们在 [《精尽 Netty 源码分析 —— 调试环境搭建》](http://svip.iocoder.cn/Netty/build-debugging-environment/#5-1-EchoServer) 搭建的 EchoServer 示例。代码如下：

```java
public final class EchoServer {

    static final boolean SSL = System.getProperty("ssl") != null;
    static final int PORT = Integer.parseInt(System.getProperty("port", "8007"));

    public static void main(String[] args) throws Exception {
        // Configure SSL.
        // 配置 SSL
        final SslContext sslCtx;
        if (SSL) {
            SelfSignedCertificate ssc = new SelfSignedCertificate();
            sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build();
        } else {
            sslCtx = null;
        }

        // Configure the server.
        // 创建两个 EventLoopGroup 对象
        EventLoopGroup bossGroup = new NioEventLoopGroup(1); // 创建 boss 线程组 用于服务端接受客户端的连接
        EventLoopGroup workerGroup = new NioEventLoopGroup(); // 创建 worker 线程组 用于进行 SocketChannel 的数据读写
        // 创建 EchoServerHandler 对象
        final EchoServerHandler serverHandler = new EchoServerHandler();
        try {
            // 创建 ServerBootstrap 对象
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup) // 设置使用的 EventLoopGroup
             .channel(NioServerSocketChannel.class) // 设置要被实例化的为 NioServerSocketChannel 类
             .option(ChannelOption.SO_BACKLOG, 100) // 设置 NioServerSocketChannel 的可选项
             .handler(new LoggingHandler(LogLevel.INFO)) // 设置 NioServerSocketChannel 的处理器
             .childHandler(new ChannelInitializer<SocketChannel>() {
                 @Override
                 public void initChannel(SocketChannel ch) throws Exception { // 设置连入服务端的 Client 的 SocketChannel 的处理器
                     ChannelPipeline p = ch.pipeline();
                     if (sslCtx != null) {
                         p.addLast(sslCtx.newHandler(ch.alloc()));
                     }
                     //p.addLast(new LoggingHandler(LogLevel.INFO));
                     p.addLast(serverHandler);
                 }
             });

            // Start the server.
            // 绑定端口，并同步等待成功，即启动服务端
            ChannelFuture f = b.bind(PORT).sync();

            // Wait until the server socket is closed.
            // 监听服务端关闭，并阻塞等待
            f.channel().closeFuture().sync();
        } finally {
            // Shut down all event loops to terminate all threads.
            // 优雅关闭两个 EventLoopGroup 对象
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }
}
```

- 第 7 至 15 行：配置 SSL ，暂时可以忽略。
- 第 17 至 20 行：创建两个 EventLoopGroup 对象。
  - **boss** 线程组：用于服务端接受客户端的**连接**。
  - **worker** 线程组：用于进行客户端的 SocketChannel 的**数据读写**。
  - 关于为什么是**两个** EventLoopGroup 对象，我们在后续的文章，进行分享。
- 第 22 行：创建 [`io.netty.example.echo.EchoServerHandler`](https://github.com/YunaiV/netty/blob/f7016330f1483021ef1c38e0923e1c8b7cef0d10/example/src/main/java/io/netty/example/echo/EchoServerHandler.java) 对象。
- 第 24 行：创建 ServerBootstrap 对象，用于设置服务端的启动配置。
  - 第 26 行：调用 `#group(EventLoopGroup parentGroup, EventLoopGroup childGroup)` 方法，设置使用的 EventLoopGroup 。
  - 第 27 行：调用 `#channel(Class<? extends C> channelClass)` 方法，设置要被实例化的 Channel 为 NioServerSocketChannel 类。在下文中，我们会看到该 Channel 内嵌了 `java.nio.channels.ServerSocketChannel` 对象。是不是很熟悉 😈 ？
  - 第 28 行：调用 `#option(ChannelOption<T> option, T value)` 方法，设置 NioServerSocketChannel 的可选项。在 [`io.netty.channel.ChannelOption`](https://github.com/YunaiV/netty/blob/f7016330f1483021ef1c38e0923e1c8b7cef0d10/transport/src/main/java/io/netty/channel/ChannelOption.java) 类中，枚举了相关的可选项。
  - 第 29 行：调用 `#handler(ChannelHandler handler)` 方法，设置 NioServerSocketChannel 的处理器。在本示例中，使用了 `io.netty.handler.logging.LoggingHandler` 类，用于打印服务端的每个事件。详细解析，见后续文章。
  - 第 30 至 40 行：调用 `#childHandler(ChannelHandler handler)` 方法，设置连入服务端的 Client 的 SocketChannel 的处理器。在本实例中，使用 ChannelInitializer 来初始化连入服务端的 Client 的 SocketChannel 的处理器。
- 第 44 行：**先**调用 `#bind(int port)` 方法，绑定端口，**后**调用 `ChannelFuture#sync()` 方法，阻塞等待成功。这个过程，就是“**启动服务端**”。
- 第 48 行：**先**调用 `#closeFuture()` 方法，**监听**服务器关闭，**后**调用 `ChannelFuture#sync()` 方法，阻塞等待成功。😈 注意，此处不是关闭服务器，而是“**监听**”关闭。
- 第 49 至 54 行：执行到此处，说明服务端已经关闭，所以调用 `EventLoopGroup#shutdownGracefully()` 方法，分别关闭两个 EventLoopGroup 对象。

> 老艿艿的自我吐槽：😈 貌似又啰嗦了一把？？？

# 3. AbstractBootstrap

我们再一起来看看 AbstractBootstrap 的代码实现。因为 ServerBootstrap 和 Bootstrap 都实现这个类，所以和 ServerBootstrap 相关度高的方法，我们会放在 [「4. ServerBootstrap」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 中分享，而和 Bootstrap 相关度高的方法，我们会放在下一篇 Bootstrap 的文章分享。

> 老艿艿：下面我会开始分享一系列的 AbstractBootstrap 的配置方法，如果比较熟悉的胖友，可以直接跳到 [「3.13 bind」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 开始看。

## 3.1 构造方法

```java
public abstract class AbstractBootstrap<B extends AbstractBootstrap<B, C>, C extends Channel> implements Cloneable {

    /**
     * EventLoopGroup 对象
     */
    volatile EventLoopGroup group;
    /**
     * Channel 工厂，用于创建 Channel 对象。
     */
    @SuppressWarnings("deprecation")
    private volatile ChannelFactory<? extends C> channelFactory;
    /**
     * 本地地址
     */
    private volatile SocketAddress localAddress;
    /**
     * 可选项集合
     */
    private final Map<ChannelOption<?>, Object> options = new LinkedHashMap<ChannelOption<?>, Object>();
    /**
     * 属性集合
     */
    private final Map<AttributeKey<?>, Object> attrs = new LinkedHashMap<AttributeKey<?>, Object>();
    /**
     * 处理器
     */
    private volatile ChannelHandler handler;

    AbstractBootstrap() {
        // Disallow extending from a different package.
    }

    AbstractBootstrap(AbstractBootstrap<B, C> bootstrap) {
        group = bootstrap.group;
        channelFactory = bootstrap.channelFactory;
        handler = bootstrap.handler;
        localAddress = bootstrap.localAddress;
        synchronized (bootstrap.options) { // <1>
            options.putAll(bootstrap.options);
        }
        synchronized (bootstrap.attrs) { // <2>
            attrs.putAll(bootstrap.attrs);
        }
    }
    
    // ... 省略无关代码
}
```

- AbstractBootstrap 是个

  抽象类

  ，并且实现 Cloneable 接口。另外，它声明了

   

  ```
  B
  ```

   

  、

  ```
  C
  ```

   

  两个泛型：

  - `B` ：继承 AbstractBootstrap 类，用于表示**自身**的类型。
  - `C` ：继承 Channel 类，表示表示**创建**的 Channel 类型。

- 每个属性比较简单，结合下面我们要分享的每个方法，就更易懂啦。

- 在 `<1>` 和 `<2>` 两处，比较神奇的使用了 `synchronized` 修饰符。老艿艿也是疑惑了一下，但是这并难不倒我。因为传入的 `bootstrap` 参数的 `options` 和 `attrs` 属性，可能在另外的线程被修改( 例如，我们下面会看到的 `#option(hannelOption<T> option, T value)` 方法)，通过 `synchronized` 来同步，解决此问题。

## 3.2 self

`#self()` 方法，返回自己。代码如下：

```java
private B self() {
    return (B) this;
}
```

- 这里就使用到了 AbstractBootstrap 声明的 `B` 泛型。

## 3.3 group

`#group(EventLoopGroup group)` 方法，设置 EventLoopGroup 到 `group` 中。代码如下：

```java
public B group(EventLoopGroup group) {
    if (group == null) {
        throw new NullPointerException("group");
    }
    if (this.group != null) { // 不允许重复设置
        throw new IllegalStateException("group set already");
    }
    this.group = group;
    return self();
}
```

- 最终调用 `#self()` 方法，返回自己。实际上，AbstractBootstrap 整个方法的调用，基本都是[“**链式调用**”](https://en.wikipedia.org/wiki/Method_chaining#Java)。

## 3.4 channel

`#channel(Class<? extends C> channelClass)` 方法，设置要被**实例化**的 Channel 的类。代码如下：

```java
public B channel(Class<? extends C> channelClass) {
    if (channelClass == null) {
        throw new NullPointerException("channelClass");
    }
    return channelFactory(new ReflectiveChannelFactory<C>(channelClass));
}
```

- 虽然传入的 `channelClass` 参数，但是会使用 `io.netty.channel.ReflectiveChannelFactory` 进行封装。
- 调用 `#channelFactory(io.netty.channel.ChannelFactory<? extends C> channelFactory)` 方法，设置 `channelFactory` 属性。代码如下：

```java
public B channelFactory(io.netty.channel.ChannelFactory<? extends C> channelFactory) {
  return channelFactory((ChannelFactory<C>) channelFactory);
}

@Deprecated
public B channelFactory(io.netty.bootstrap.ChannelFactory<? extends C> channelFactory) {
  if (channelFactory == null) {
	  throw new NullPointerException("channelFactory");
  }
  if (this.channelFactory != null) { // 不允许重复设置
	  throw new IllegalStateException("channelFactory set already");
  }

  this.channelFactory = channelFactory;
  return self();
}
```

- 我们可以看到有两个 `#channelFactory(...)` 方法，并且第**二**个是 `@Deprecated` 的方法。从 ChannelFactory 使用的**包名**，我们就可以很容易的判断，最初 ChannelFactory 在 `bootstrap` 中，后**重构**到 `channel` 包中。

### 3.4.1 ChannelFactory

`io.netty.channel.ChannelFactory` ，Channel 工厂**接口**，用于创建 Channel 对象。代码如下：

```java
public interface ChannelFactory<T extends Channel> extends io.netty.bootstrap.ChannelFactory<T> {

    /**
     * Creates a new channel.
     *
     * 创建 Channel 对象
     *
     */
    @Override
    T newChannel();

}
```

- `#newChannel()` 方法，用于创建 Channel 对象。

### 3.4.2 ReflectiveChannelFactory

`io.netty.channel.ReflectiveChannelFactory` ，实现 ChannelFactory 接口，反射调用默认构造方法，创建 Channel 对象的工厂实现类。代码如下：

```java
public class ReflectiveChannelFactory<T extends Channel> implements ChannelFactory<T> {

    /**
     * Channel 对应的类
     */
    private final Class<? extends T> clazz;

    public ReflectiveChannelFactory(Class<? extends T> clazz) {
        if (clazz == null) {
            throw new NullPointerException("clazz");
        }
        this.clazz = clazz;
    }

    @Override
    public T newChannel() {
        try {
            // 反射调用默认构造方法，创建 Channel 对象
            return clazz.getConstructor().newInstance();
        } catch (Throwable t) {
            throw new ChannelException("Unable to create Channel from class " + clazz, t);
        }
    }

}
```

- 重点看 `clazz.getConstructor().newInstance()` 代码块。

## 3.5 localAddress

`#localAddress(...)` 方法，设置创建 Channel 的本地地址。有四个**重载**的方法，代码如下：

```java
public B localAddress(SocketAddress localAddress) {
    this.localAddress = localAddress;
    return self();
}

public B localAddress(int inetPort) {
    return localAddress(new InetSocketAddress(inetPort));
}

public B localAddress(String inetHost, int inetPort) {
    return localAddress(SocketUtils.socketAddress(inetHost, inetPort));
}

public B localAddress(InetAddress inetHost, int inetPort) {
    return localAddress(new InetSocketAddress(inetHost, inetPort));
}
```

- 一般情况下，不会调用该方法进行配置，而是调用 `#bind(...)` 方法，例如 [「2. ServerBootstrap 示例」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。

## 3.6 option

`#option(ChannelOption<T> option, T value)` 方法，设置创建 Channel 的可选项。代码如下：

```java
public <T> B option(ChannelOption<T> option, T value) {
    if (option == null) {
        throw new NullPointerException("option");
    }
    if (value == null) { // 空，意味着移除
        synchronized (options) {
            options.remove(option);
        }
    } else { // 非空，进行修改
        synchronized (options) {
            options.put(option, value);
        }
    }
    return self();
}
```

## 3.7 attr

`#attr(AttributeKey<T> key, T value)` 方法，设置创建 Channel 的属性。代码如下：

```java
public <T> B attr(AttributeKey<T> key, T value) {
    if (key == null) {
        throw new NullPointerException("key");
    }
    if (value == null) { // 空，意味着移除
        synchronized (attrs) {
            attrs.remove(key);
        }
    } else { // 非空，进行修改
        synchronized (attrs) {
            attrs.put(key, value);
        }
    }
    return self();
}
```

- 怎么理解 `attrs` 属性呢？我们可以理解成 `java.nio.channels.SelectionKey` 的 `attachment` 属性，并且类型为 Map 。

## 3.8 handler

`#handler(ChannelHandler handler)` 方法，设置创建 Channel 的处理器。代码如下：

```java
public B handler(ChannelHandler handler) {
    if (handler == null) {
        throw new NullPointerException("handler");
    }
    this.handler = handler;
    return self();
}
```

## 3.9 validate

`#validate()` 方法，校验配置是否正确。代码如下：

```java
public B validate() {
    if (group == null) {
        throw new IllegalStateException("group not set");
    }
    if (channelFactory == null) {
        throw new IllegalStateException("channel or channelFactory not set");
    }
    return self();
}
```

- 在 `#bind(...)` 方法中，绑定本地地址时，会调用该方法进行校验。

## 3.10 clone

`#clone()` **抽象**方法，克隆一个 AbstractBootstrap 对象。代码如下。

```java
/**
 * Returns a deep clone of this bootstrap which has the identical configuration.  This method is useful when making
 * multiple {@link Channel}s with similar settings.  Please note that this method does not clone the
 * {@link EventLoopGroup} deeply but shallowly, making the group a shared resource.
 */
@Override
public abstract B clone();
```

- 来自实现 Cloneable 接口，在子类中实现。这是

  深

  拷贝，即创建一个新对象，但不是所有的属性是

  深

  拷贝。可参见

   

  「3.1 构造方法」

  ：

  - **浅**拷贝属性：`group`、`channelFactory`、`handler`、`localAddress` 。
  - **深**拷贝属性：`options`、`attrs` 。

## 3.11 config

`#config()` 方法，返回当前 AbstractBootstrap 的配置对象。代码如下：

```java
public abstract AbstractBootstrapConfig<B, C> config();

```

### 3.11.1 AbstractBootstrapConfig

`io.netty.bootstrap.AbstractBootstrapConfig` ，BootstrapConfig **抽象类**。代码如下：

```java
public abstract class AbstractBootstrapConfig<B extends AbstractBootstrap<B, C>, C extends Channel> {

    protected final B bootstrap;

    protected AbstractBootstrapConfig(B bootstrap) {
        this.bootstrap = ObjectUtil.checkNotNull(bootstrap, "bootstrap");
    }
    
    public final SocketAddress localAddress() {
        return bootstrap.localAddress();
    }
    
    public final ChannelFactory<? extends C> channelFactory() {
        return bootstrap.channelFactory();
    }

    public final ChannelHandler handler() {
        return bootstrap.handler();
    }

    public final Map<ChannelOption<?>, Object> options() {
        return bootstrap.options();
    }

    public final Map<AttributeKey<?>, Object> attrs() {
        return bootstrap.attrs();
    }

    public final EventLoopGroup group() {
        return bootstrap.group();
    }
    
}

```

- `bootstrap` 属性，对应的启动类对象。在每个方法中，我们可以看到，都是直接调用 `boostrap` 属性对应的方法，读取对应的配置。

------

AbstractBootstrapConfig 的整体类图如下：![AbstractBootstrapConfig 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03.png)

- 每个 Config 类，对应一个 Bootstrap 类。
- ServerBootstrapConfig 和 BootstrapConfig 的实现代码，和 AbstractBootstrapConfig 基本一致，所以胖友自己去查看噢。

## 3.12 setChannelOptions

`#setChannelOptions(...)` **静态**方法，设置传入的 Channel 的**多个**可选项。代码如下：

```java
static void setChannelOptions(
        Channel channel, Map<ChannelOption<?>, Object> options, InternalLogger logger) {
    for (Map.Entry<ChannelOption<?>, Object> e: options.entrySet()) {
        setChannelOption(channel, e.getKey(), e.getValue(), logger);
    }
}

static void setChannelOptions(
        Channel channel, Map.Entry<ChannelOption<?>, Object>[] options, InternalLogger logger) {
    for (Map.Entry<ChannelOption<?>, Object> e: options) {
        setChannelOption(channel, e.getKey(), e.getValue(), logger);
    }
}

```

- 在两个方法的内部，**都**调用 `#setChannelOption(Channel channel, ChannelOption<?> option, Object value, InternalLogger logger)` **静态**方法，设置传入的 Channel 的**一个**可选项。代码如下：

```java
private static void setChannelOption(
	  Channel channel, ChannelOption<?> option, Object value, InternalLogger logger) {
  try {
	  if (!channel.config().setOption((ChannelOption<Object>) option, value)) {
		  logger.warn("Unknown channel option '{}' for channel '{}'", option, channel);
	  }
  } catch (Throwable t) {
	  logger.warn("Failed to set channel option '{}' with value '{}' for channel '{}'", option, value, channel, t);
  }
}

```

- 不同于 [「3.6 option」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 方法，它是设置要创建的 Channel 的可选项。而 `#setChannelOption(...)` 方法，它是设置已经创建的 Channel 的可选项。

## 3.13 bind

> 老艿艿：`#bind(...)` 方法，也可以启动 UDP 的一端，考虑到这个系列主要分享 Netty 在 NIO 相关的源码解析，所以如下所有的分享，都不考虑 UDP 的情况。

`#bind(...)` 方法，绑定端口，启动服务端。代码如下：

```java
public ChannelFuture bind() {
    // 校验服务启动需要的必要参数
    validate();
    SocketAddress localAddress = this.localAddress;
    if (localAddress == null) {
        throw new IllegalStateException("localAddress not set");
    }
    // 绑定本地地址( 包括端口 )
    return doBind(localAddress);
}

public ChannelFuture bind(int inetPort) {
    return bind(new InetSocketAddress(inetPort));
}

public ChannelFuture bind(String inetHost, int inetPort) {
    return bind(SocketUtils.socketAddress(inetHost, inetPort));
}

public ChannelFuture bind(InetAddress inetHost, int inetPort) {
    return bind(new InetSocketAddress(inetHost, inetPort));
}

public ChannelFuture bind(SocketAddress localAddress) {
    // 校验服务启动需要的必要参数
    validate();
    if (localAddress == null) {
        throw new NullPointerException("localAddress");
    }
    // 绑定本地地址( 包括端口 )
    return doBind(localAddress);
}

```

- 该方法返回的是 ChannelFuture 对象，也就是**异步**的绑定端口，启动服务端。如果需要**同步**，则需要调用 `ChannelFuture#sync()` 方法。

`#bind(...)` 方法，核心流程如下图：

![核心流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/04.png)

- 主要有 4 个步骤，下面我们来拆解代码，看看和我们在 [《精尽 Netty 源码分析 —— NIO 基础（五）之示例》](http://svip.iocoder.cn/Netty/nio-5-demo/?self) 的 NioServer 的代码，是**怎么对应**的。

### 3.13.1 doBind

`#doBind(final SocketAddress localAddress)` 方法，代码如下：

```java
private ChannelFuture doBind(final SocketAddress localAddress) {
    // 初始化并注册一个 Channel 对象，因为注册是异步的过程，所以返回一个 ChannelFuture 对象。
    final ChannelFuture regFuture = initAndRegister();
    final Channel channel = regFuture.channel();
    if (regFuture.cause() != null) { // 若发生异常，直接进行返回。
        return regFuture;
    }

    // 绑定 Channel 的端口，并注册 Channel 到 SelectionKey 中。
    if (regFuture.isDone()) { // 未
        // At this point we know that the registration was complete and successful.
        ChannelPromise promise = channel.newPromise();
        doBind0(regFuture, channel, localAddress, promise); // 绑定
        return promise;
    } else {
        // Registration future is almost always fulfilled already, but just in case it's not.
        final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel);
        regFuture.addListener(new ChannelFutureListener() {
            @Override
            public void operationComplete(ChannelFuture future) throws Exception {
                Throwable cause = future.cause();
                if (cause != null) {
                    // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an
                    // IllegalStateException once we try to access the EventLoop of the Channel.
                    promise.setFailure(cause);
                } else {
                    // Registration was successful, so set the correct executor to use.
                    // See https://github.com/netty/netty/issues/2586
                    promise.registered();

                    doBind0(regFuture, channel, localAddress, promise); // 绑定
                }
            }
        });
        return promise;
    }
}

```

- 第 3 行：调用

   

```java
#initAndRegister()

```

   

  方法，初始化并注册一个 Channel 对象。因为注册是

  异步

  的过程，所以返回一个 ChannelFuture 对象。详细解析，见

   

  「3.14 initAndRegister」

   

  。

- 第 5 至 7 行：若发生异常，直接进行返回。

- 第 9 至 37 行：因为注册是

  异步

  的过程，有可能已完成，有可能未完成。所以实现代码分成了【第 10 至 14 行】和【第 15 至 36 行】分别处理已完成和未完成的情况。

  - **核心**在【第 13 行】或者【第 32 行】的代码，调用 `#doBind0(final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise)` 方法，绑定 Channel 的端口，并注册 Channel 到 SelectionKey 中。
  - 如果**异步**注册对应的 ChanelFuture 未完成，则调用 `ChannelFuture#addListener(ChannelFutureListener)` 方法，添加监听器，在**注册**完成后，进行回调执行 `#doBind0(...)` 方法的逻辑。详细解析，见 见 [「3.13.2 doBind0」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。
  - 所以总结来说，**bind 的逻辑，执行在 register 的逻辑之后**。
  - TODO 1001 Promise 2. PendingRegistrationPromise

### 3.13.2 doBind0

> 老艿艿：此小节的内容，胖友先看完 [「3.14 initAndRegister」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 的内容在回过头来看。因为 `#doBind0(...)`方法的执行，在 `#initAndRegister()` 方法之后。

`#doBind0(...)` 方法，执行 Channel 的端口绑定逻辑。代码如下：

```java
private static void doBind0(
        final ChannelFuture regFuture, final Channel channel,
        final SocketAddress localAddress, final ChannelPromise promise) {

    // This method is invoked before channelRegistered() is triggered.  Give user handlers a chance to set up
    // the pipeline in its channelRegistered() implementation.
    channel.eventLoop().execute(new Runnable() {
        @Override
        public void run() {
            // 注册成功，绑定端口
            if (regFuture.isSuccess()) {
                channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE);
            // 注册失败，回调通知 promise 异常
            } else {
                promise.setFailure(regFuture.cause());
            }
        }
    });
}

```

- 第 7 行：调用 EventLoop 执行 Channel 的端口绑定逻辑。但是，实际上当前线程已经是 EventLoop 所在的线程了，为何还要这样操作呢？答案在【第 5 至 6 行】的英语注释。感叹句，Netty 虽然代码量非常庞大且复杂，但是英文注释真的是非常齐全，包括 Github 的 issue 对代码提交的描述，也非常健全。

- 第 14 至 17 行：注册失败，回调通知 `promise` 异常。

- 第 11 至 13 行：注册成功，调用

   

```java
Channel#bind(SocketAddress localAddress, ChannelPromise promise)

```

   

  方法，执行 Channel 的端口绑定逻辑。后续的方法栈调用如下图：

  

- 还是老样子，我们先省略掉 pipeline 的内部实现代码，从 `AbstractUnsafe#bind(final SocketAddress localAddress, final ChannelPromise promise)` 方法，继续向下分享。

`AbstractUnsafe#bind(final SocketAddress localAddress, final ChannelPromise promise)` 方法，Channel 的端口绑定逻辑。代码如下：

```java
@Override
public final void bind(final SocketAddress localAddress, final ChannelPromise promise) {
    // 判断是否在 EventLoop 的线程中。
    assertEventLoop();

    if (!promise.setUncancellable() || !ensureOpen(promise)) {
        return;
    }

    // See: https://github.com/netty/netty/issues/576
    if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &&
        localAddress instanceof InetSocketAddress &&
        !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &&
        !PlatformDependent.isWindows() && !PlatformDependent.maybeSuperUser()) {
        // Warn a user about the fact that a non-root user can't receive a
        // broadcast packet on *nix if the socket is bound on non-wildcard address.
        logger.warn(
                "A non-root user can't receive a broadcast packet if the socket " +
                "is not bound to a wildcard address; binding to a non-wildcard " +
                "address (" + localAddress + ") anyway as requested.");
    }

    // 记录 Channel 是否激活
    boolean wasActive = isActive();

    // 绑定 Channel 的端口
    try {
        doBind(localAddress);
    } catch (Throwable t) {
        safeSetFailure(promise, t);
        closeIfClosed();
        return;
    }

    // 若 Channel 是新激活的，触发通知 Channel 已激活的事件。
    if (!wasActive && isActive()) {
        invokeLater(new Runnable() {
            @Override
            public void run() {
                pipeline.fireChannelActive();
            }
        });
    }

    // 回调通知 promise 执行成功
    safeSetSuccess(promise);
}

```

- 第 4 行：调用 `#assertEventLoop()` 方法，判断是否在 EventLoop 的线程中。即该方法，只允许在 EventLoop 的线程中执行。代码如下：

```java
// AbstractUnsafe.java
private void assertEventLoop() {
  assert !registered || eventLoop.inEventLoop();
}

```

- 第 6 至 8 行：和 `#register0(...)` 方法的【第 5 至 8 行】的代码，是一致的。
- 第 10 至 21 行：<https://github.com/netty/netty/issues/576>
- 第 24 行：调用 `#isActive()` 方法，获得 Channel 是否激活( active )。NioServerSocketChannel 对该方法的实现代码如下：

```java
// NioServerSocketChannel.java

@Override
public boolean isActive() {
  return javaChannel().socket().isBound();
}

```

- NioServerSocketChannel 的 `#isActive()` 的方法实现，判断 ServerSocketChannel 是否绑定端口。此时，一般返回的是 `false` 。
- 第 28 行：调用 `#doBind(SocketAddress localAddress)` 方法，绑定 Channel 的端口。代码如下：

```java
// NioServerSocketChannel.java

@Override
protected void doBind(SocketAddress localAddress) throws Exception {
  if (PlatformDependent.javaVersion() >= 7) {
	  javaChannel().bind(localAddress, config.getBacklog());
  } else {
	  javaChannel().socket().bind(localAddress, config.getBacklog());
  }
}

```

- 【重要】到了此处，服务端的 Java 原生 NIO ServerSocketChannel 终于绑定端口。😈
- 第 36 行：再次调用 `#isActive()` 方法，获得 Channel 是否激活。此时，一般返回的是 `true` 。因此，Channel 可以认为是**新激活**的，满足【第 36 至 43 行】代码的执行条件。
  - 第 37 行：调用 `#invokeLater(Runnable task)` 方法，提交任务，让【第 40 行】的代码执行，异步化。代码如下：

```java
// AbstractUnsafe.java
private void invokeLater(Runnable task) {
	try {
		// This method is used by outbound operation implementations to trigger an inbound event later.
		// They do not trigger an inbound event immediately because an outbound operation might have been
		// triggered by another inbound event handler method.  If fired immediately, the call stack
		// will look like this for example:
		//
		//   handlerA.inboundBufferUpdated() - (1) an inbound handler method closes a connection.
		//   -> handlerA.ctx.close()
		//      -> channel.unsafe.close()
		//         -> handlerA.channelInactive() - (2) another inbound handler method called while in (1) yet
		//
		// which means the execution of two inbound handler methods of the same handler overlap undesirably.
		eventLoop().execute(task);
	} catch (RejectedExecutionException e) {
		logger.warn("Can't invoke task later as EventLoop rejected it", e);
	}
}

```

```
- 从实现代码可以看出，是通过提交一个新的任务到 EventLoop 的线程中。
- 英文注释虽然有丢丢长，但是胖友耐心看完。有道在手，英文不愁啊。

```

- 第 40 行：调用 `DefaultChannelPipeline#fireChannelActive()` 方法，触发 Channel 激活的事件。详细解析，见 [「3.13.3 beginRead」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。
- 第 46 行：调用 `#safeSetSuccess(ChannelPromise)` 方法，回调通知 `promise` 执行成功。此处的通知，对应回调的是我们添加到 `#bind(...)` 方法返回的 ChannelFuture 的 ChannelFutureListener 的监听器。示例代码如下：

```java
ChannelFuture f = b.bind(PORT).addListener(new ChannelFutureListener() { // 回调的就是我！！！
  @Override
  public void operationComplete(ChannelFuture future) throws Exception {
	  System.out.println("测试下被触发");
  }
}).sync();

```

### 3.13.3 beginRead

> 老艿艿：此小节的内容，胖友先看完 [「3.14 initAndRegister」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 的内容在回过头来看。因为 `#beginRead(...)`方法的执行，在 `#doBind0(...)` 方法之后。

在 `#bind(final SocketAddress localAddress, final ChannelPromise promise)` 方法的【第 40 行】代码，调用 `Channel#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，触发 Channel 激活的事件。后续的方法栈调用如下图：![触发 Channel 激活的事件](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/10.png)

```
* 还是老样子，我们先省略掉 pipeline 的内部实现代码，从 `AbstractUnsafe#beginRead()` 方法，继续向下分享。

```

`AbstractUnsafe#beginRead()` 方法，开始读取操作。代码如下：

```java
@Override
public final void beginRead() {
    // 判断是否在 EventLoop 的线程中。
    assertEventLoop();

    // Channel 必须激活
    if (!isActive()) {
        return;
    }

    // 执行开始读取
    try {
        doBeginRead();
    } catch (final Exception e) {
        invokeLater(new Runnable() {
            @Override
            public void run() {
                pipeline.fireExceptionCaught(e);
            }
        });
        close(voidPromise());
    }
}

```

- 调用 `Channel#doBeginRead()` 方法，执行开始读取。对于 NioServerSocketChannel 来说，该方法实现代码如下：

  ```java
  // AbstractNioMessageChannel.java
  @Override
  protected void doBeginRead() throws Exception {
      if (inputShutdown) {
          return;
      }
      super.doBeginRead();
  }
  
  // AbstractNioChannel.java
  @Override
  protected void doBeginRead() throws Exception {
      // Channel.read() or ChannelHandlerContext.read() was called
      final SelectionKey selectionKey = this.selectionKey;
      if (!selectionKey.isValid()) {
          return;
      }
  
      readPending = true;
  
      final int interestOps = selectionKey.interestOps();
      if ((interestOps & readInterestOp) == 0) {
          selectionKey.interestOps(interestOps | readInterestOp);
      }
  }
  
  ```

  - 【重要】在最后几行，我们可以看到，调用 `SelectionKey#interestOps(ops)` 方法，将我们创建 NioServerSocketChannel 时，设置的 `readInterestOp = SelectionKey.OP_ACCEPT` 添加为感兴趣的事件。也就说，服务端可以开始处理客户端的连接事件。

## 3.14 initAndRegister

`#initAndRegister()` 方法，初始化并注册一个 Channel 对象，并返回一个 ChannelFuture 对象。代码如下：

```java
final ChannelFuture initAndRegister() {
    Channel channel = null;
    try {
        // 创建 Channel 对象
        channel = channelFactory.newChannel();
        // 初始化 Channel 配置
        init(channel);
    } catch (Throwable t) {
        if (channel != null) { // 已创建 Channel 对象
            // channel can be null if newChannel crashed (eg SocketException("too many open files"))
            channel.unsafe().closeForcibly(); // 强制关闭 Channel
            // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor
            return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t);
        }
        // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor
        return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t);
    }

    // 注册 Channel 到 EventLoopGroup 中
    ChannelFuture regFuture = config().group().register(channel);
    if (regFuture.cause() != null) {
        if (channel.isRegistered()) {
            channel.close();
        } else {
            channel.unsafe().closeForcibly(); // 强制关闭 Channel
        }
    }

    return regFuture;
}

```

- 第 5 行：调用

  ```
  ChannelFactory#newChannel()
  
  ```

  方法，创建 Channel 对象。在本文的示例中，会使用 ReflectiveChannelFactory 创建 NioServerSocketChannel 对象。详细解析，见

  「3.14.1 创建 Channel」。

  - 第 16 行：返回带异常的 DefaultChannelPromise 对象。因为创建 Channel 对象失败，所以需要创建一个 FailedChannel 对象，设置到 DefaultChannelPromise 中才可以返回。

- 第 7 行：调用

   

  ```
  #init(Channel)
  
  ```

   

  方法，初始化 Channel 配置。详细解析，见

   

  「3.14.1 创建 Channel」

   

  。

  - 第 9 至 14 行：返回带异常的 DefaultChannelPromise 对象。因为初始化 Channel 对象失败，所以需要调用 `#closeForcibly()` 方法，强制关闭 Channel 。

- 第 20 行：首先获得 EventLoopGroup 对象，后调用 `EventLoopGroup#register(Channel)` 方法，注册 Channel 到 EventLoopGroup 中。实际在方法内部，EventLoopGroup 会分配一个 EventLoop 对象，将 Channel 注册到其上。详细解析，见 [「3.14.3 注册 Channel 到 EventLoopGroup」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。

  - 第 22 至 23 行：若发生异常，并且 Channel 已经注册成功，则调用 `#close()` 方法，正常关闭 Channel 。
  - 第 24 至 26 行：若发生异常，并且 Channel 并未注册成功，则调用 `#closeForcibly()` 方法，强制关闭 Channel 。也就是说，和【第 9 至 14 行】一致。为什么会有正常和强制关闭 Channel 两种不同的处理呢？我们来看下 `#close()` 和 `#closeForcibly()` 方法的注释：

```java
// Channel.java#Unsafe

/**
 * Close the {@link Channel} of the {@link ChannelPromise} and notify the {@link ChannelPromise} once the
 * operation was complete.
 */
void close(ChannelPromise promise);

/**
 * Closes the {@link Channel} immediately without firing any events.  Probably only useful
 * when registration attempt failed.
 */
void closeForcibly();

```

```
- 调用的前提，在于 Channel 是否注册到 EventLoopGroup 成功。😈 因为注册失败，也不好触发相关的事件。

```

### 3.14.1 创建 Channel 对象

考虑到本文的内容，我们以 NioServerSocketChannel 的创建过程作为示例。流程图如下：

![创建 NioServerSocketChannel 对象](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/05.png)

- 我们可以看到，整个流程涉及到 NioServerSocketChannel 的父类们。类图如下： ![Channel 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/06.png)

- 可能有部分胖友对 Netty Channel 的定义不是很理解，如下是官方的英文注释：

  > A nexus to a network socket or a component which is capable of I/O operations such as read, write, connect, and bind

  - 简单点来说，我们可以把 Netty Channel 和 Java 原生 Socket 对应，而 Netty NIO Channel 和 Java 原生 NIO SocketChannel 对象。

下面，我们来看看整个 NioServerSocketChannel 的创建过程的代码实现。

#### 3.14.1.1 NioServerSocketChannel

```java
private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider();

private final ServerSocketChannelConfig config;

public NioServerSocketChannel() {
    this(newSocket(DEFAULT_SELECTOR_PROVIDER));
}

public NioServerSocketChannel(SelectorProvider provider) {
    this(newSocket(provider));
}

```

- `DEFAULT_SELECTOR_PROVIDER` **静态**属性，默认的 SelectorProvider 实现类。

- `config` 属性，Channel 对应的配置对象。每种 Channel 实现类，也会对应一个 ChannelConfig 实现类。例如，NioServerSocketChannel 类，对应 ServerSocketChannelConfig 配置类。

  > ChannelConfig 的官网英文描述： A set of configuration properties of a Channel.

- 在构造方法中，调用 `#newSocket(SelectorProvider provider)` 方法，创建 NIO 的 ServerSocketChannel 对象。代码如下：

```java
private static ServerSocketChannel newSocket(SelectorProvider provider) {
  try {
	  return provider.openServerSocketChannel();
  } catch (IOException e) {
	  throw new ChannelException("Failed to open a server socket.", e);
  }
}

```

- 😈 是不是很熟悉这样的代码，效果和 `ServerSocketChannel#open()` 方法创建 ServerSocketChannel 对象是一致。
- `#NioServerSocketChannel(ServerSocketChannel channel)` 构造方法，代码如下：

```java
public NioServerSocketChannel(ServerSocketChannel channel) {
  super(null, channel, SelectionKey.OP_ACCEPT);
  config = new NioServerSocketChannelConfig(this, javaChannel().socket());
}

```

- 调用父 AbstractNioMessageChannel 的构造方法。详细解析，见 [「3.14.1.2 AbstractNioMessageChannel」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。注意传入的 SelectionKey 的值为 `OP_ACCEPT` 。
- 初始化 `config` 属性，创建 NioServerSocketChannelConfig 对象。

#### 3.14.1.2 AbstractNioMessageChannel

```java
protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) {
    super(parent, ch, readInterestOp);
}

```

- 直接调用父 AbstractNioChannel 的构造方法。详细解析，见 [「3.14.1.3 AbstractNioChannel」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。

#### 3.14.1.3 AbstractNioChannel

```java
private final SelectableChannel ch;
protected final int readInterestOp;

protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) {
    super(parent);
    this.ch = ch;
    this.readInterestOp = readInterestOp;
    try {
        ch.configureBlocking(false);
    } catch (IOException e) {
        try {
            ch.close();
        } catch (IOException e2) {
            if (logger.isWarnEnabled()) {
                logger.warn("Failed to close a partially initialized socket.", e2);
            }
        }

        throw new ChannelException("Failed to enter non-blocking mode.", e);
    }
}

```

- `ch` 属性，**Netty NIO Channel 对象，持有的 Java 原生 NIO 的 Channel 对象**。

- ```
  readInterestOp
  
  ```

   

  属性，感兴趣的读事件的操作位值。

  - 目前笔者看了 AbstractNioMessageChannel 是 `SelectionKey.OP_ACCEPT` ， 而 AbstractNioByteChannel 是 `SelectionKey.OP_READ` 。
  - 详细的用途，我们会在 [「3.13.3 beginRead」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 看到。

- 调用父 AbstractNioChannel 的构造方法。详细解析，见 [「3.14.1.4 AbstractChannel」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 。

- 调用

   

```java
SelectableChannel#configureBlocking(false)

```

   

  方法，设置 NIO Channel 为

  非阻塞

  。😈 这块代码是不是非常熟悉哟。

- 若发生异常，关闭 NIO Channel ，并抛出异常。

#### 3.14.1.4 AbstractChannel

```java
/**
 * 父 Channel 对象
 */
private final Channel parent;
/**
 * Channel 编号
 */
private final ChannelId id;
/**
 * Unsafe 对象
 */
private final Unsafe unsafe;
/**
 * DefaultChannelPipeline 对象
 */
private final DefaultChannelPipeline pipeline;

protected AbstractChannel(Channel parent) {
    this.parent = parent;
    // 创建 ChannelId 对象
    id = newId();
    // 创建 Unsafe 对象
    unsafe = newUnsafe();
    // 创建 DefaultChannelPipeline 对象
    pipeline = newChannelPipeline();
}

```

- `parent` 属性，父 Channel 对象。对于 NioServerSocketChannel 的 `parent` 为空。

- `id` 属性，Channel 编号对象。在构造方法中，通过调用 `#newId()` 方法，进行创建。本文就先不分享，感兴趣的胖友自己看。

- `unsafe` 属性，Unsafe 对象。在构造方法中，通过调用 `#newUnsafe()` 方法，进行创建。本文就先不分享，感兴趣的胖友自己看。

  - 这里的 Unsafe 并不是我们常说的 Java 自带的`sun.misc.Unsafe` ，而是 `io.netty.channel.Channel#Unsafe`。

    ```
    // Channel.java#Unsafe
    /**
    * <em>Unsafe</em> operations that should <em>never</em> be called from user-code. These methods
    * are only provided to implement the actual transport, and must be invoked from an I/O thread except for the
    * following methods:
    * <ul>
    *   <li>{@link #localAddress()}</li>
    *   <li>{@link #remoteAddress()}</li>
    *   <li>{@link #closeForcibly()}</li>
    *   <li>{@link #register(EventLoop, ChannelPromise)}</li>
    *   <li>{@link #deregister(ChannelPromise)}</li>
    *   <li>{@link #voidPromise()}</li>
    * </ul>
    */
    
    ```

    - 这就是为什么叫 Unsafe 的原因。按照上述官网类的英文注释，Unsafe 操作不允许被用户代码使用。这些函数是真正用于数据传输操作，必须被IO线程调用。
    - 实际上，Channel 真正的具体操作，通过调用对应的 Unsafe 实现。😈 下文，我们将会看到。

  - Unsafe 不是一个具体的类，而是一个定义在 Channel 接口中的接口。不同的 Channel 类对应不同的 Unsafe 实现类。整体类图如下：

    

    - 对于 NioServerSocketChannel ，Unsafe 的实现类为 NioMessageUnsafe 。

- `pipeline` 属性，DefaultChannelPipeline 对象。在构造方法中，通过调用 `#newChannelPipeline()` 方法，进行创建。本文就先不分享，感兴趣的胖友自己看。

  > ChannelPipeline 的英文注释：A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel 。

#### 3.14.1.5 小结

看到此处，我们来对 [「3.1.4.1 创建 Channel 对象」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 作一个小结。

对于一个 Netty NIO Channel 对象，它会包含如下几个核心组件：

- ChannelId
- Unsafe
- Pipeline
  - ChannelHandler
- ChannelConfig
- **Java 原生 NIO Channel**

如果不太理解，可以撸起袖子，多调试几次。

### 3.14.2 初始化 Channel 配置

`#init(Channel channel)` 方法，初始化 Channel 配置。它是个**抽象**方法，由子类 ServerBootstrap 或 Bootstrap 自己实现。代码如下：

```
abstract void init(Channel channel) throws Exception;

```

- ServerBootstrap 对该方法的实现，我们在 [「4. ServerBootstrap」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 中，详细解析。

### 3.14.3 注册 Channel 到 EventLoopGroup

`EventLoopGroup#register(Channel channel)` 方法，注册 Channel 到 EventLoopGroup 中。整体流程如下：

![register 流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/08.png)

#### 3.14.3.1 register

EventLoopGroup 和 EventLoop 不是本文的重点，所以省略 1 + 2 + 3 部分的代码，从第 4 步的 `AbstractUnsafe#register(EventLoop eventLoop, final ChannelPromise promise)` 方法开始，代码如下：

```
 1: @Override
 2: public final void register(EventLoop eventLoop, final ChannelPromise promise) {
 3:     // 校验传入的 eventLoop 非空
 4:     if (eventLoop == null) {
 5:         throw new NullPointerException("eventLoop");
 6:     }
 7:     // 校验未注册
 8:     if (isRegistered()) {
 9:         promise.setFailure(new IllegalStateException("registered to an event loop already"));
10:         return;
11:     }
12:     // 校验 Channel 和 eventLoop 匹配
13:     if (!isCompatible(eventLoop)) {
14:         promise.setFailure(new IllegalStateException("incompatible event loop type: " + eventLoop.getClass().getName()));
15:         return;
16:     }
17: 
18:     // 设置 Channel 的 eventLoop 属性
19:     AbstractChannel.this.eventLoop = eventLoop;
20: 
21:     // 在 EventLoop 中执行注册逻辑
22:     if (eventLoop.inEventLoop()) {
23:         register0(promise);
24:     } else {
25:         try {
26:             eventLoop.execute(new Runnable() {
27:                 @Override
28:                 public void run() {
31:                     register0(promise);
32:                 }
33:             });
34:         } catch (Throwable t) {
35:             logger.warn("Force-closing a channel whose registration task was not accepted by an event loop: {}", AbstractChannel.this, t);
36:             closeForcibly();
37:             closeFuture.setClosed();
38:             safeSetFailure(promise, t);
39:         }
40:     }
41: }

```

- 第 3 至 6 行：校验传入的 `eventLoop` 参数非空。

- 第 7 至 11 行：调用 `#isRegistered()` 方法，校验未注册。代码如下：

  ```
  // AbstractChannel.java
  
  /**
   * 是否注册
   */
  private volatile boolean registered;
  
  @Override
  public boolean isRegistered() {
      return registered;
  }
  
  ```

- 第 12 至 16 行：校验 Channel 和 `eventLoop` 类型是否匹配，因为它们都有多种实现类型。代码如下：

  ```
  @Override
  protected boolean isCompatible(EventLoop loop) {
      return loop instanceof NioEventLoop;
  }
  
  ```

  - 要求 `eventLoop` 的类型为 NioEventLoop 。

- 第 19 行：【重要】设置 Channel 的 `eventLoop` 属性。

- 第 21 至 40 行：在

   

  ```
  evnetLoop
  
  ```

   

  中，调用

   

  ```
  #register0()
  
  ```

   

  方法，执行注册的逻辑。详细解析，见

   

  「3.14.3.2 register0」

   

  。

  - 第 34 至 39 行：若调用

     

    ```
    EventLoop#execute(Runnable)
    
    ```

     

    方法发生异常，则进行处理：

    - 第 36 行：调用 `AbstractUnsafe#closeForcibly()` 方法，强制关闭 Channel 。
    - 第 37 行：调用 `CloseFuture#setClosed()` 方法，通知 `closeFuture` 已经关闭。详细解析，见 [《精尽 Netty 源码解析 —— Channel（七）之 close 操作》](http://svip.iocoder.cn/Netty/Channel-7-close/) 。
    - 第 38 行：调用 `AbstractUnsafe#safeSetFailure(ChannelPromise promise, Throwable cause)` 方法，回调通知 `promise` 发生该异常。

#### 3.14.3.2 register0

`#register0(ChannelPromise promise)` 方法，注册逻辑。代码如下：

```
 1: private void register0(ChannelPromise promise) {
 2:     try {
 3:         // check if the channel is still open as it could be closed in the mean time when the register
 4:         // call was outside of the eventLoop
 5:         if (!promise.setUncancellable() // TODO 1001 Promise
 6:                 || !ensureOpen(promise)) { // 确保 Channel 是打开的
 7:             return;
 8:         }
 9:         // 记录是否为首次注册
10:         boolean firstRegistration = neverRegistered;
11: 
12:         // 执行注册逻辑
13:         doRegister();
14: 
15:         // 标记首次注册为 false
16:         neverRegistered = false;
17:         // 标记 Channel 为已注册
18:         registered = true;
19: 
20:         // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the
21:         // user may already fire events through the pipeline in the ChannelFutureListener.
22:         pipeline.invokeHandlerAddedIfNeeded();
23: 
24:         // 回调通知 `promise` 执行成功
25:         safeSetSuccess(promise);
26: 
27:         // 触发通知已注册事件
28:         pipeline.fireChannelRegistered();
29: 
30:         // TODO 芋艿
31:         // Only fire a channelActive if the channel has never been registered. This prevents firing
32:         // multiple channel actives if the channel is deregistered and re-registered.
33:         if (isActive()) {
34:             if (firstRegistration) {
35:                 pipeline.fireChannelActive();
36:             } else if (config().isAutoRead()) {
37:                 // This channel was registered before and autoRead() is set. This means we need to begin read
38:                 // again so that we process inbound data.
39:                 //
40:                 // See https://github.com/netty/netty/issues/4805
41:                 beginRead();
42:             }
43:         }
44:     } catch (Throwable t) {
45:         // Close the channel directly to avoid FD leak.
46:         closeForcibly();
47:         closeFuture.setClosed();
48:         safeSetFailure(promise, t);
49:     }
50: }

```

- 第 5 行：// TODO 1001 Promise

- 第 6 行：调用 `#ensureOpen(ChannelPromise)` 方法，确保 Channel 是打开的。代码如下：

  ```
  // AbstractUnsafe.java
  protected final boolean ensureOpen(ChannelPromise promise) {
      if (isOpen()) {
          return true;
      }
  
      // 若未打开，回调通知 promise 异常
      safeSetFailure(promise, ENSURE_OPEN_CLOSED_CHANNEL_EXCEPTION);
      return false;
  }
  
  // AbstractNioChannel.java
  @Override
  public boolean isOpen() {
      return ch.isOpen();
  }
  
  ```

- 第 10 行：记录是否**首次**注册。`neverRegistered` 变量声明在 AbstractUnsafe 中，代码如下：

  ```
  /**
   * 是否重未注册过，用于标记首次注册
   *
   * true if the channel has never been registered, false otherwise
   */
  private boolean neverRegistered = true;
  
  ```

- 第 13 行：调用 `#doRegister()` 方法，执行注册逻辑。代码如下：

  ```java
  // NioUnsafe.java
    1: @Override
    2: protected void doRegister() throws Exception {
    3:     boolean selected = false;
    4:     for (;;) {
    5:         try {
    6:             selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);
    7:             return;
    8:         } catch (CancelledKeyException e) {
    9:             // TODO TODO 1003 doRegister 异常
   10:             if (!selected) {
   11:                 // Force the Selector to select now as the "canceled" SelectionKey may still be
   12:                 // cached and not removed because no Select.select(..) operation was called yet.
   13:                 eventLoop().selectNow();
   14:                 selected = true;
   15:             } else {
   16:                 // We forced a select operation on the selector before but the SelectionKey is still cached
   17:                 // for whatever reason. JDK bug ?
   18:                 throw e;
   19:             }
   20:         }
   21:     }
   22: }
  
  ```

  - 第 6 行：调用 `#unwrappedSelector()` 方法，返回 Java 原生 NIO Selector 对象。代码如下：

    ```java
    // NioEventLoop.java
    
    private Selector unwrappedSelector;
    
    Selector unwrappedSelector() {
        return unwrappedSelector;
    }
    
    ```

    - 每个 NioEventLoop 对象上，都**独有**一个 Selector 对象。

  - 第 6 行：调用 `#javaChannel()` 方法，获得 Java 原生 NIO 的 Channel 对象。

  - 第 6 行：【重要】调用 `SelectableChannel#register(Selector sel, int ops, Object att)` 方法，注册 Java 原生 NIO 的 Channel 对象到 Selector 对象上。相信胖友对这块的代码是非常熟悉的，但是为什么感兴趣的事件是为 **0** 呢？正常情况下，对于服务端来说，需要注册 `SelectionKey.OP_ACCEPT` 事件呢！这样做的**目的**是( 摘自《Netty权威指南（第二版）》 )：

    > 1. 注册方式是多态的，它既可以被 NIOServerSocketChannel 用来监听客户端的连接接入，也可以注册 SocketChannel 用来监听网络读或者写操作。
    > 2. 通过
    >
    > ```
    > SelectionKey#interestOps(int ops)
    > 
    > ```
    >
    > 方法可以方便地修改监听操作位。所以，此处注册需要获取 SelectionKey 并给 AbstractNIOChannel 的成员变量
    >
    > ```
    > selectionKey
    > 
    > ```
    >
    > 赋值。
    >
    > - 如果不理解，没关系，在下文中，我们会看到服务端对 `SelectionKey.OP_ACCEPT` 事件的关注。😈

  - 第 8 至 20 行：TODO 1003 doRegister 异常

- 第 16 行：标记首次注册为 `false` 。

- 第 18 行：标记 Channel 为已注册。`registered` 变量声明在 AbstractChannel 中，代码如下：

  ```
  /**
   * 是否注册
   */
  private volatile boolean registered;
  
  ```

- 第 22 行：调用 `DefaultChannelPipeline#invokeHandlerAddedIfNeeded()` 方法，触发 ChannelInitializer 执行，进行 Handler 初始化。也就是说，我们在 [「4.init」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 写的 ServerBootstrap 对 Channel 设置的 ChannelInitializer 将被执行，进行 Channel 的 Handler 的初始化。

  - 具体的 pipeline 的内部调用过程，我们在后续文章分享。

- 第 25 行：调用 `#safeSetSuccess(ChannelPromise promise)` 方法，回调通知 `promise` 执行。在 [「3.13.1 doBind」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#)小节，我们向 `regFuture` 注册的 ChannelFutureListener ，就会被**立即回调执行**。

  > 老艿艿：胖友在看完这小节的内容，可以调回 [「3.13.2 doBind0」](http://svip.iocoder.cn/Netty/bootstrap-1-server/#) 小节的内容继续看。

- 第 28 行：调用 `DefaultChannelPipeline#invokeHandlerAddedIfNeeded()` 方法，触发通知 Channel 已注册的事件。

  - 具体的 pipeline 的内部调用过程，我们在后续文章分享。
  - 笔者目前调试下来，没有涉及服务端启动流程的逻辑代码。

- 第 33 至 43 行：TODO 芋艿

- 第 44 至 49 行：发生异常，和 `#register(EventLoop eventLoop, final ChannelPromise promise)` 方法的处理异常的代码，是一致的。

# 4. ServerBootstrap

`io.netty.bootstrap.ServerBootstrap` ，实现 AbstractBootstrap 抽象类，用于 Server 的启动器实现类。

## 4.1 构造方法

```
/**
 * 启动类配置对象
 */
private final ServerBootstrapConfig config = new ServerBootstrapConfig(this);
/**
 * 子 Channel 的可选项集合
 */
private final Map<ChannelOption<?>, Object> childOptions = new LinkedHashMap<ChannelOption<?>, Object>();
/**
 * 子 Channel 的属性集合
 */
private final Map<AttributeKey<?>, Object> childAttrs = new LinkedHashMap<AttributeKey<?>, Object>();
/**
 * 子 Channel 的 EventLoopGroup 对象
 */
private volatile EventLoopGroup childGroup;
/**
 * 子 Channel 的处理器
 */
private volatile ChannelHandler childHandler;

public ServerBootstrap() { }

private ServerBootstrap(ServerBootstrap bootstrap) {
    super(bootstrap);
    childGroup = bootstrap.childGroup;
    childHandler = bootstrap.childHandler;
    synchronized (bootstrap.childOptions) {
        childOptions.putAll(bootstrap.childOptions);
    }
    synchronized (bootstrap.childAttrs) {
        childAttrs.putAll(bootstrap.childAttrs);
    }
}

```

- `config` 属性，ServerBootstrapConfig 对象，启动类配置对象。
- 在 Server 接受**一个** Client 的连接后，会创建**一个**对应的 Channel 对象。因此，我们看到 ServerBootstrap 的 `childOptions`、`childAttrs`、`childGroup`、`childHandler` 属性，都是这种 Channel 的可选项集合、属性集合、EventLoopGroup 对象、处理器。下面，我们会看到 ServerBootstrap 针对这些配置项的设置方法。

## 4.2 group

`#group(..)` 方法，设置 EventLoopGroup 到 `group`、`childGroup` 中。代码如下：

```
@Override
public ServerBootstrap group(EventLoopGroup group) {
    return group(group, group);
}

public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) {
    super.group(parentGroup);
    if (childGroup == null) {
        throw new NullPointerException("childGroup");
    }
    if (this.childGroup != null) {
        throw new IllegalStateException("childGroup set already");
    }
    this.childGroup = childGroup;
    return this;
}

```

- 当只传入一个 EventLoopGroup 对象时，即调用的是 `#group(EventLoopGroup group)` 时，`group` 和 `childGroup` 使用同一个。一般情况下，我们不使用这个方法。

## 4.3 childOption

`#childOption(ChannelOption<T> option, T value)` 方法，设置子 Channel 的可选项。代码如下：

```
public <T> ServerBootstrap childOption(ChannelOption<T> childOption, T value) {
    if (childOption == null) {
        throw new NullPointerException("childOption");
    }
    if (value == null) { // 空，意味着移除
        synchronized (childOptions) {
            childOptions.remove(childOption);
        }
    } else { // 非空，进行修改
        synchronized (childOptions) {
            childOptions.put(childOption, value);
        }
    }
    return this;
}

```

## 4.4 childAttr

`#childAttr(AttributeKey<T> key, T value)` 方法，设置子 Channel 的属性。代码如下：

```
public <T> ServerBootstrap childAttr(AttributeKey<T> childKey, T value) {
    if (childKey == null) {
        throw new NullPointerException("childKey");
    }
    if (value == null) { // 空，意味着移除
        childAttrs.remove(childKey);
    } else { // 非空，进行修改
        childAttrs.put(childKey, value);
    }
    return this;
}

```

## 4.5 childHandler

`#childHandler(ChannelHandler handler)` 方法，设置子 Channel 的处理器。代码如下：

```
public ServerBootstrap childHandler(ChannelHandler childHandler) {
    if (childHandler == null) {
        throw new NullPointerException("childHandler");
    }
    this.childHandler = childHandler;
    return this;
}

```

## 4.6 validate

`#validate()` 方法，校验配置是否正确。代码如下：

```java
@Override
public ServerBootstrap validate() {
    super.validate();
    if (childHandler == null) {
        throw new IllegalStateException("childHandler not set");
    }
    if (childGroup == null) {
        logger.warn("childGroup is not set. Using parentGroup instead.");
        childGroup = config.group();
    }
    return this;
}

```

## 4.7 clone

`#clone()` 方法，克隆 ServerBootstrap 对象。代码如下：

```java
@Override
public ServerBootstrap clone() {
    return new ServerBootstrap(this);
}

```

- 调用参数为 `bootstrap` 为 ServerBootstrap 构造方法，克隆一个 ServerBootstrap 对象。

## 4.8 init

`#init(Channel channel)` 方法，初始化 Channel 配置。代码如下：

```java
1: @Override
2: void init(Channel channel) throws Exception {
3:     // 初始化 Channel 的可选项集合
4:     final Map<ChannelOption<?>, Object> options = options0();
5:     synchronized (options) {
6:         setChannelOptions(channel, options, logger);
7:     }
8: 
9:     // 初始化 Channel 的属性集合
10:     final Map<AttributeKey<?>, Object> attrs = attrs0();
11:     synchronized (attrs) {
12:         for (Entry<AttributeKey<?>, Object> e: attrs.entrySet()) {
13:             @SuppressWarnings("unchecked")
14:             AttributeKey<Object> key = (AttributeKey<Object>) e.getKey();
15:             channel.attr(key).set(e.getValue());
16:         }
17:     }
18: 
19:     ChannelPipeline p = channel.pipeline();
20: 
21:     // 记录当前的属性
22:     final EventLoopGroup currentChildGroup = childGroup;
23:     final ChannelHandler currentChildHandler = childHandler;
24:     final Entry<ChannelOption<?>, Object>[] currentChildOptions;
25:     final Entry<AttributeKey<?>, Object>[] currentChildAttrs;
26:     synchronized (childOptions) {
27:         currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0));
28:     }
29:     synchronized (childAttrs) {
30:         currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0));
31:     }
32: 
33:     // 添加 ChannelInitializer 对象到 pipeline 中，用于后续初始化 ChannelHandler 到 pipeline 中。
34:     p.addLast(new ChannelInitializer<Channel>() {
35:         @Override
36:         public void initChannel(final Channel ch) throws Exception {
38:             final ChannelPipeline pipeline = ch.pipeline();
39: 
40:             // 添加配置的 ChannelHandler 到 pipeline 中。
41:             ChannelHandler handler = config.handler();
42:             if (handler != null) {
43:                 pipeline.addLast(handler);
44:             }
45: 
46:             // 添加 ServerBootstrapAcceptor 到 pipeline 中。
47:             // 使用 EventLoop 执行的原因，参见 https://github.com/lightningMan/netty/commit/4638df20628a8987c8709f0f8e5f3679a914ce1a
48:             ch.eventLoop().execute(new Runnable() {
49:                 @Override
50:                 public void run() {
52:                     pipeline.addLast(new ServerBootstrapAcceptor(
53:                             ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs));
54:                 }
55:             });
56:         }
57:     });
58: }}

```

- 第 3 至 7 行：将启动器配置的可选项集合，调用 `#setChannelOptions(channel, options, logger)` 方法，设置到 Channel 的可选项集合中。

- 第 9 至 17 行：将启动器配置的属性集合，设置到 Channel 的属性集合中。

- 第 21 至 31 行：记录启动器配置的**子 Channel**的属性，用于【第 52 至 53 行】的代码，创建 ServerBootstrapAcceptor 对象。

- 第 34 至 57 行：创建 ChannelInitializer 对象，添加到 pipeline 中，用于后续初始化 ChannelHandler 到 pipeline 中。

  - 第 40 至 44 行：添加启动器配置的 ChannelHandler 到 pipeline 中。

  - 第 46 至 55 行：创建 ServerBootstrapAcceptor 对象，添加到 pipeline 中。为什么使用 EventLoop 执行**添加的过程**？如果启动器配置的处理器，并且 ServerBootstrapAcceptor 不使用 EventLoop 添加，则会导致 ServerBootstrapAcceptor 添加到配置的处理器之前。示例代码如下：

    ```java
    ServerBootstrap b = new ServerBootstrap();
    b.handler(new ChannelInitializer<Channel>() {
    
        @Override
        protected void initChannel(Channel ch) {
            final ChannelPipeline pipeline = ch.pipeline();
            ch.eventLoop().execute(new Runnable() {
                @Override
                public void run() {
                    pipeline.addLast(new LoggingHandler(LogLevel.INFO));
                }
            });
        }
    
    });
    
    ```

    - Netty 官方的提交，可见 [github commit](https://github.com/lightningMan/netty/commit/4638df20628a8987c8709f0f8e5f3679a914ce1a) 。

  - ServerBootstrapAcceptor 也是一个 ChannelHandler 实现类，用于接受客户端的连接请求。详细解析，见后续文章。

  - 该 ChannelInitializer 的初始化的执行，在 `AbstractChannel#register0(ChannelPromise promise)` 方法中触发执行。

  - 那么为什么要使用 ChannelInitializer 进行处理器的初始化呢？而不直接添加到 pipeline 中。例如修改为如下代码：

    ```java
    final Channel ch = channel;
    final ChannelPipeline pipeline = ch.pipeline();
    
    // 添加配置的 ChannelHandler 到 pipeline 中。
    ChannelHandler handler = config.handler();
    if (handler != null) {
        pipeline.addLast(handler);
    }
    
    // 添加 ServerBootstrapAcceptor 到 pipeline 中。
    // 使用 EventLoop 执行的原因，参见 https://github.com/lightningMan/netty/commit/4638df20628a8987c8709f0f8e5f3679a914ce1a
    ch.eventLoop().execute(new Runnable() {
        @Override
        public void run() {
            System.out.println(Thread.currentThread() + ": ServerBootstrapAcceptor");
            pipeline.addLast(new ServerBootstrapAcceptor(
                    ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs));
        }
    });
    
    ```

    - 因为此时 Channel 并未注册到 EventLoop 中。如果调用 `EventLoop#execute(Runnable runnable)` 方法，会抛出 `Exception in thread "main" java.lang.IllegalStateException: channel not registered to an event loop` 异常。

# 666. 彩蛋

Netty 服务端启动涉及的流程非常多，所以有不理解的地方，胖友可以多多调试。在其中涉及到的 EventLoopGroup、EventLoop、Pipeline 等等组件，我们后在后续的文章，正式分享。

另外，也推荐如下和 Netty 服务端启动相关的文章，以加深理解：

- 闪电侠 [《Netty 源码分析之服务端启动全解析》](https://www.jianshu.com/p/c5068caab217)
- 小明哥 [《【死磕 Netty 】—— 服务端启动过程分析》](http://cmsblogs.com/?p=2470)
- 占小狼 [《Netty 源码分析之服务启动》](https://www.jianshu.com/p/e577803f0fb8)
- 杨武兵 [《Netty 源码分析系列 —— Bootstrap》](https://my.oschina.net/ywbrj042/blog/868798)
- 永顺 [《Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (服务器端)》](https://segmentfault.com/a/1190000007283053)

# 精尽 Netty 源码分析 —— 启动（二）之客户端



# 1. 概述

本文，我们来分享 Bootstrap 分享 Netty 客户端。因为我们日常使用 Netty 主要使用 NIO 部分，所以本文也只分享 Netty NIO 客户端。

# 2. Bootstrap 示例

下面，我们先来看一个 ServerBootstrap 的使用示例，就是我们在 [《精尽 Netty 源码分析 —— 调试环境搭建》](http://svip.iocoder.cn/Netty/build-debugging-environment/#5-2-EchoClient) 搭建的 EchoClient 示例。代码如下：

```
public final class EchoClient {

    static final boolean SSL = System.getProperty("ssl") != null;
    static final String HOST = System.getProperty("host", "127.0.0.1");
    static final int PORT = Integer.parseInt(System.getProperty("port", "8007"));
    static final int SIZE = Integer.parseInt(System.getProperty("size", "256"));

    public static void main(String[] args) throws Exception {
        // Configure SSL.git
        // 配置 SSL
        final SslContext sslCtx;
        if (SSL) {
            sslCtx = SslContextBuilder.forClient()
                .trustManager(InsecureTrustManagerFactory.INSTANCE).build();
        } else {
            sslCtx = null;
        }

        // Configure the client.
        // 创建一个 EventLoopGroup 对象
        EventLoopGroup group = new NioEventLoopGroup();
        try {
            // 创建 Bootstrap 对象
            Bootstrap b = new Bootstrap();
            b.group(group) // 设置使用的 EventLoopGroup
             .channel(NioSocketChannel.class) // 设置要被实例化的为 NioSocketChannel 类
             .option(ChannelOption.TCP_NODELAY, true) // 设置 NioSocketChannel 的可选项
             .handler(new ChannelInitializer<SocketChannel>() { // 设置 NioSocketChannel 的处理器
                 @Override
                 public void initChannel(SocketChannel ch) throws Exception {
                     ChannelPipeline p = ch.pipeline();
                     if (sslCtx != null) {
                         p.addLast(sslCtx.newHandler(ch.alloc(), HOST, PORT));
                     }
                     //p.addLast(new LoggingHandler(LogLevel.INFO));
                     p.addLast(new EchoClientHandler());
                 }
             });

            // Start the client.
            // 连接服务器，并同步等待成功，即启动客户端
            ChannelFuture f = b.connect(HOST, PORT).sync();

            // Wait until the connection is closed.
            // 监听客户端关闭，并阻塞等待
            f.channel().closeFuture().sync();
        } finally {
            // Shut down the event loop to terminate all threads.
            // 优雅关闭一个 EventLoopGroup 对象
            group.shutdownGracefully();
        }
    }
}
```

- 示例比较简单，已经添加中文注释，胖友自己查看。

# 3. Bootstrap

`io.netty.bootstrap.Bootstrap` ，实现 AbstractBootstrap 抽象类，用于 Client 的启动器实现类。

## 3.1 构造方法

```
/**
 * 默认地址解析器对象
 */
private static final AddressResolverGroup<?> DEFAULT_RESOLVER = DefaultAddressResolverGroup.INSTANCE;

/**
 * 启动类配置对象
 */
private final BootstrapConfig config = new BootstrapConfig(this);
/**
 * 地址解析器对象
 */
@SuppressWarnings("unchecked")
private volatile AddressResolverGroup<SocketAddress> resolver = (AddressResolverGroup<SocketAddress>) DEFAULT_RESOLVER;
/**
 * 连接地址
 */
private volatile SocketAddress remoteAddress;

public Bootstrap() { }

private Bootstrap(Bootstrap bootstrap) {
    super(bootstrap);
    resolver = bootstrap.resolver;
    remoteAddress = bootstrap.remoteAddress;
}
```

- `config` 属性，BootstrapConfig 对象，启动类配置对象。
- `resolver` 属性，地址解析器对象。绝大多数情况下，使用 `DEFAULT_RESOLVER` 即可。
- `remoteAddress` 属性，连接地址。

## 3.2 resolver

`#resolver(AddressResolverGroup<?> resolver)` 方法，设置 `resolver` 属性。代码如下：

```
public Bootstrap resolver(AddressResolverGroup<?> resolver) {
    this.resolver = (AddressResolverGroup<SocketAddress>) (resolver == null ? DEFAULT_RESOLVER : resolver);
    return this;
}
```

## 3.3 remoteAddress

`#remoteAddress(...)` 方法，设置 `remoteAddress` 属性。代码如下：

```
public Bootstrap resolver(AddressResolverGroup<?> resolver) {
    this.resolver = (AddressResolverGroup<SocketAddress>) (resolver == null ? DEFAULT_RESOLVER : resolver);
    return this;
}

public Bootstrap remoteAddress(SocketAddress remoteAddress) {
    this.remoteAddress = remoteAddress;
    return this;
}

public Bootstrap remoteAddress(String inetHost, int inetPort) {
    remoteAddress = InetSocketAddress.createUnresolved(inetHost, inetPort);
    return this;
}

public Bootstrap remoteAddress(InetAddress inetHost, int inetPort) {
    remoteAddress = new InetSocketAddress(inetHost, inetPort);
    return this;
}
```

## 3.4 validate

`#validate()` 方法，校验配置是否正确。代码如下：

```
@Override
public Bootstrap validate() {
    // 父类校验
    super.validate();
    // handler 非空
    if (config.handler() == null) {
        throw new IllegalStateException("handler not set");
    }
    return this;
}
```

- 在 `#connect(...)` 方法中，连接服务端时，会调用该方法进行校验。

## 3.5 clone

`#clone(...)` 方法，克隆 Bootstrap 对象。代码如下：

```
@Override
public Bootstrap clone() {
    return new Bootstrap(this);
}

public Bootstrap clone(EventLoopGroup group) {
    Bootstrap bs = new Bootstrap(this);
    bs.group = group;
    return bs;
}
```

- 两个克隆方法，都是调用参数为 `bootstrap` 为 Bootstrap 构造方法，克隆一个 Bootstrap 对象。差别在于，下面的方法，多了对 `group` 属性的赋值。

## 3.6 connect

`#connect(...)` 方法，连接服务端，即启动客户端。代码如下：

```
public ChannelFuture connect() {
    // 校验必要参数
    validate();
    SocketAddress remoteAddress = this.remoteAddress;
    if (remoteAddress == null) {
        throw new IllegalStateException("remoteAddress not set");
    }
    // 解析远程地址，并进行连接
    return doResolveAndConnect(remoteAddress, config.localAddress());
}

public ChannelFuture connect(String inetHost, int inetPort) {
    return connect(InetSocketAddress.createUnresolved(inetHost, inetPort));
}

public ChannelFuture connect(InetAddress inetHost, int inetPort) {
    return connect(new InetSocketAddress(inetHost, inetPort));
}

public ChannelFuture connect(SocketAddress remoteAddress) {
    // 校验必要参数
    validate();
    if (remoteAddress == null) {
        throw new NullPointerException("remoteAddress");
    }
    // 解析远程地址，并进行连接
    return doResolveAndConnect(remoteAddress, config.localAddress());
}

public ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress) {
    // 校验必要参数
    validate();
    if (remoteAddress == null) {
        throw new NullPointerException("remoteAddress");
    }
    // 解析远程地址，并进行连接
    return doResolveAndConnect(remoteAddress, localAddress);
}
```

- 该方法返回的是 ChannelFuture 对象，也就是**异步**的连接服务端，启动客户端。如果需要**同步**，则需要调用 `ChannelFuture#sync()` 方法。

`#connect(...)` 方法，核心流程如下图：

`#bind(...)` 方法，核心流程如下图：

![核心流程](http://www.iocoder.cn/images/Netty/2018_04_05/01.png)

- 主要有 5 个步骤，下面我们来拆解代码，看看和我们在 [《精尽 Netty 源码分析 —— NIO 基础（五）之示例》](http://svip.iocoder.cn/Netty/nio-5-demo/?self) 的 NioClient 的代码，是**怎么对应**的。
- 相比 `#bind(...)` 方法的流程，主要是**绿色**的 2 个步骤。

### 3.6.1 doResolveAndConnect

`#doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress)` 方法，代码如下：

```
 1: private ChannelFuture doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress) {
 2:     // 初始化并注册一个 Channel 对象，因为注册是异步的过程，所以返回一个 ChannelFuture 对象。
 3:     final ChannelFuture regFuture = initAndRegister();
 4:     final Channel channel = regFuture.channel();
 5: 
 6:     if (regFuture.isDone()) {
 7:         // 若执行失败，直接进行返回。
 8:         if (!regFuture.isSuccess()) {
 9:             return regFuture;
10:         }
11:         // 解析远程地址，并进行连接
12:         return doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise());
13:     } else {
14:         // Registration future is almost always fulfilled already, but just in case it's not.
15:         final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel);
16:         regFuture.addListener(new ChannelFutureListener() {
17: 
18:             @Override
19:             public void operationComplete(ChannelFuture future) throws Exception {
20:                 // Directly obtain the cause and do a null check so we only need one volatile read in case of a
21:                 // failure.
22:                 Throwable cause = future.cause();
23:                 if (cause != null) {
24:                     // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an
25:                     // IllegalStateException once we try to access the EventLoop of the Channel.
26:                     promise.setFailure(cause);
27:                 } else {
28:                     // Registration was successful, so set the correct executor to use.
29:                     // See https://github.com/netty/netty/issues/2586
30:                     promise.registered();
31: 
32:                     // 解析远程地址，并进行连接
33:                     doResolveAndConnect0(channel, remoteAddress, localAddress, promise);
34:                 }
35:             }
36: 
37:         });
38:         return promise;
39:     }
40: }
```

- 第 3 行：调用`#initAndRegister()`方法，初始化并注册一个 Channel 对象。因为注册是**异步**的过程，所以返回一个 ChannelFuture 对象。详细解析，见 [「3.7 initAndRegister」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#)。
  - 第 6 至 10 行：若执行失败，直接进行返回 `regFuture` 对象。
- 第 9 至 37 行：因为注册是**异步**的过程，有可能已完成，有可能未完成。所以实现代码分成了【第 12 行】和【第 13 至 37 行】分别处理已完成和未完成的情况。
  - **核心**在【第 12 行】或者【第 33 行】的代码，调用 `#doResolveAndConnect0(final Channel channel, SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise)` 方法，解析远程地址，并进行连接。
  - 如果**异步**注册对应的 ChanelFuture 未完成，则调用 `ChannelFuture#addListener(ChannelFutureListener)` 方法，添加监听器，在**注册**完成后，进行回调执行 `#doResolveAndConnect0(...)` 方法的逻辑。详细解析，见 [「3.6.2 doResolveAndConnect0」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
  - 所以总结来说，**resolve 和 connect 的逻辑，执行在 register 的逻辑之后**。

### 3.6.2 doResolveAndConnect0

> 老艿艿：此小节的内容，胖友先看完 [「3.7 initAndRegister」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 的内容在回过头来看。因为 `#doResolveAndConnect0(...)` 方法的执行，在 `#initAndRegister()` 方法之后。

`#doResolveAndConnect0(...)` 方法，解析远程地址，并进行连接。代码如下：

```
 1: private ChannelFuture doResolveAndConnect0(final Channel channel, SocketAddress remoteAddress,
 2:                                            final SocketAddress localAddress, final ChannelPromise promise) {
 3:     try {
 4:         final EventLoop eventLoop = channel.eventLoop();
 5:         final AddressResolver<SocketAddress> resolver = this.resolver.getResolver(eventLoop);
 6: 
 7:         if (!resolver.isSupported(remoteAddress) || resolver.isResolved(remoteAddress)) {
 8:             // Resolver has no idea about what to do with the specified remote address or it's resolved already.
 9:             doConnect(remoteAddress, localAddress, promise);
10:             return promise;
11:         }
12: 
13:         // 解析远程地址
14:         final Future<SocketAddress> resolveFuture = resolver.resolve(remoteAddress);
15: 
16:         if (resolveFuture.isDone()) {
17:             // 解析远程地址失败，关闭 Channel ，并回调通知 promise 异常
18:             final Throwable resolveFailureCause = resolveFuture.cause();
19:             if (resolveFailureCause != null) {
20:                 // Failed to resolve immediately
21:                 channel.close();
22:                 promise.setFailure(resolveFailureCause);
23:             } else {
24:                 // Succeeded to resolve immediately; cached? (or did a blocking lookup)
25:                 // 连接远程地址
26:                 doConnect(resolveFuture.getNow(), localAddress, promise);
27:             }
28:             return promise;
29:         }
30: 
31:         // Wait until the name resolution is finished.
32:         resolveFuture.addListener(new FutureListener<SocketAddress>() {
33:             @Override
34:             public void operationComplete(Future<SocketAddress> future) throws Exception {
35:                 // 解析远程地址失败，关闭 Channel ，并回调通知 promise 异常
36:                 if (future.cause() != null) {
37:                     channel.close();
38:                     promise.setFailure(future.cause());
39:                 // 解析远程地址成功，连接远程地址
40:                 } else {
41:                     doConnect(future.getNow(), localAddress, promise);
42:                 }
43:             }
44:         });
45:     } catch (Throwable cause) {
46:         // 发生异常，并回调通知 promise 异常
47:         promise.tryFailure(cause);
48:     }
49:     return promise;
50: }
```

- 第 3 至 14 行：使用`resolver`解析远程地址。因为解析是**异步**的过程，所以返回一个 Future 对象。
  - 详细的解析远程地址的代码，考虑到暂时不是本文的重点，所以暂时省略。😈 老艿艿猜测胖友应该也暂时不感兴趣，哈哈哈。
- 第 16 至 44 行：因为注册是**异步**的过程，有可能已完成，有可能未完成。所以实现代码分成了【第 16 至 29 行】和【第 31 至 44 行】分别处理已完成和未完成的情况。
  - **核心**在【第 26 行】或者【第 41 行】的代码，调用 `#doConnect(...)` 方法，连接远程地址。
  - 如果**异步**解析对应的 Future 未完成，则调用 `Future#addListener(FutureListener)` 方法，添加监听器，在**解析**完成后，进行回调执行 `#doConnect(...)` 方法的逻辑。详细解析，见 见 [「3.13.3 doConnect」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
  - 所以总结来说，**connect 的逻辑，执行在 resolve 的逻辑之后**。
  - 老艿艿目前使用 [「2. Bootstrap 示例」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 测试下来，符合【第 16 至 30 行】的条件，即无需走**异步**的流程。

### 3.6.3 doConnect

`#doConnect(...)` 方法，执行 Channel 连接远程地址的逻辑。代码如下：

```
 1: private static void doConnect(final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise connectPromise) {
 2: 
 3:     // This method is invoked before channelRegistered() is triggered.  Give user handlers a chance to set up
 4:     // the pipeline in its channelRegistered() implementation.
 5:     final Channel channel = connectPromise.channel();
 6:     channel.eventLoop().execute(new Runnable() {
 7: 
 8:         @Override
 9:         public void run() {
10:             if (localAddress == null) {
11:                 channel.connect(remoteAddress, connectPromise);
12:             } else {
13:                 channel.connect(remoteAddress, localAddress, connectPromise);
14:             }
15:             connectPromise.addListener(ChannelFutureListener.CLOSE_ON_FAILURE);
16:         }
17: 
18:     });
19: }
```

- 第 6 行：调用 EventLoop 执行 Channel 连接远程地址的逻辑。但是，实际上当前线程已经是 EventLoop 所在的线程了，为何还要这样操作呢？答案在【第 3 至 4 行】的英语注释。感叹句，Netty 虽然代码量非常庞大且复杂，但是英文注释真的是非常齐全，包括 Github 的 issue 对代码提交的描述，也非常健全。

- 第 10 至 14 行：调用`Channel#connect(...)`方法，执行 Channel 连接远程地址的逻辑。后续的方法栈调用如下图：

  

  - 还是老样子，我们先省略掉 pipeline 的内部实现代码，从 `AbstractNioUnsafe#connect(final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise)` 方法，继续向下分享。

`AbstractNioUnsafe#connect(final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise)` 方法，执行 Channel 连接远程地址的逻辑。代码如下：

```
 1: @Override
 2: public final void connect(final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) {
 3:     if (!promise.setUncancellable() || !ensureOpen(promise)) {
 4:         return;
 5:     }
 6: 
 7:     try {
 8:         // 目前有正在连接远程地址的 ChannelPromise ，则直接抛出异常，禁止同时发起多个连接。
 9:         if (connectPromise != null) {
10:             // Already a connect in process.
11:             throw new ConnectionPendingException();
12:         }
13: 
14:         // 记录 Channel 是否激活
15:         boolean wasActive = isActive();
16: 
17:         // 执行连接远程地址
18:         if (doConnect(remoteAddress, localAddress)) {
19:             fulfillConnectPromise(promise, wasActive);
20:         } else {
21:             // 记录 connectPromise
22:             connectPromise = promise;
23:             // 记录 requestedRemoteAddress
24:             requestedRemoteAddress = remoteAddress;
25: 
26:             // 使用 EventLoop 发起定时任务，监听连接远程地址超时。若连接超时，则回调通知 connectPromise 超时异常。
27:             // Schedule connect timeout.
28:             int connectTimeoutMillis = config().getConnectTimeoutMillis(); // 默认 30 * 1000 毫秒
29:             if (connectTimeoutMillis > 0) {
30:                 connectTimeoutFuture = eventLoop().schedule(new Runnable() {
31:                     @Override
32:                     public void run() {
33:                         ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise;
34:                         ConnectTimeoutException cause = new ConnectTimeoutException("connection timed out: " + remoteAddress);
35:                         if (connectPromise != null && connectPromise.tryFailure(cause)) {
36:                             close(voidPromise());
37:                         }
38:                     }
39:                 }, connectTimeoutMillis, TimeUnit.MILLISECONDS);
40:             }
41: 
42:             // 添加监听器，监听连接远程地址取消。
43:             promise.addListener(new ChannelFutureListener() {
44:                 @Override
45:                 public void operationComplete(ChannelFuture future) throws Exception {
46:                     if (future.isCancelled()) {
47:                         // 取消定时任务
48:                         if (connectTimeoutFuture != null) {
49:                             connectTimeoutFuture.cancel(false);
50:                         }
51:                         // 置空 connectPromise
52:                         connectPromise = null;
53:                         close(voidPromise());
54:                     }
55:                 }
56:             });
57:         }
58:     } catch (Throwable t) {
59:         // 回调通知 promise 发生异常
60:         promise.tryFailure(annotateConnectException(t, remoteAddress));
61:         closeIfClosed();
62:     }
63: }
```

- 第 8 至 12 行：目前有正在连接远程地址的 ChannelPromise ，则直接抛出异常，禁止同时发起多个连接。`connectPromise` 变量，定义在 AbstractNioChannel 类中，代码如下：

  ```
  /**
   * 目前正在连接远程地址的 ChannelPromise 对象。
   *
   * The future of the current connection attempt.  If not null, subsequent
   * connection attempts will fail.
   */
  private ChannelPromise connectPromise;
  ```

- 第 15 行：调用 `#isActive()` 方法，获得 Channel 是否激活。NioSocketChannel 对该方法的实现代码如下：

  ```
  @Override
  public boolean isActive() {
      SocketChannel ch = javaChannel();
      return ch.isOpen() && ch.isConnected();
  }
  ```

  - 判断 SocketChannel 是否处于打开，并且连接的状态。此时，一般返回的是 `false` 。

- 第 18 行：调用 `#doConnect(SocketAddress remoteAddress, SocketAddress localAddress)` 方法，执行连接远程地址。代码如下：

  ```
  // NioSocketChannel.java
    1: @Override
    2: protected boolean doConnect(SocketAddress remoteAddress, SocketAddress localAddress) throws Exception {
    3:     // 绑定本地地址
    4:     if (localAddress != null) {
    5:         doBind0(localAddress);
    6:     }
    7: 
    8:     boolean success = false; // 执行是否成功
    9:     try {
   10:         // 连接远程地址
   11:         boolean connected = SocketUtils.connect(javaChannel(), remoteAddress);
   12:         // 若未连接完成，则关注连接( OP_CONNECT )事件。
   13:         if (!connected) {
   14:             selectionKey().interestOps(SelectionKey.OP_CONNECT);
   15:         }
   16:         // 标记执行是否成功
   17:         success = true;
   18:         // 返回是否连接完成
   19:         return connected;
   20:     } finally {
   21:         // 执行失败，则关闭 Channel
   22:         if (!success) {
   23:             doClose();
   24:         }
   25:     }
   26: }
  ```

  - 第 3 至 6 行：若 `localAddress` 非空，则调用 `#doBind0(SocketAddress)` 方法，绑定本地地址。一般情况下，NIO Client 是不需要绑定本地地址的。默认情况下，系统会随机分配一个可用的本地地址，进行绑定。

  - 第 11 行：调用 `SocketUtils#connect(SocketChannel socketChannel, SocketAddress remoteAddress)` 方法，Java 原生 NIO SocketChannel 连接 远程地址，并返回是否连接完成( 成功 )。代码如下：

    ```
    public static boolean connect(final SocketChannel socketChannel, final SocketAddress remoteAddress) throws IOException {
        try {
            return AccessController.doPrivileged(new PrivilegedExceptionAction<Boolean>() {
                @Override
                public Boolean run() throws IOException {
                    return socketChannel.connect(remoteAddress);
                }
            });
        } catch (PrivilegedActionException e) {
            throw (IOException) e.getCause();
        }
    }
    ```

    - 可能有胖友有和我一样的疑问，为什么将 connect 操作包在 AccessController 中呢？我们来看下 SocketUtils 类的注释：

      ```
      /**
       * Provides socket operations with privileges enabled. This is necessary for applications that use the
       * {@link SecurityManager} to restrict {@link SocketPermission} to their application. By asserting that these
       * operations are privileged, the operations can proceed even if some code in the calling chain lacks the appropriate
       * {@link SocketPermission}.
       */
      ```

      - 一般情况下，我们用不到，所以也可以暂时不用理解。
      - 感兴趣的胖友，可以 Google “AccessController” 关键字，或者阅读 [《Java 安全模型介绍》](https://www.ibm.com/developerworks/cn/java/j-lo-javasecurity/index.html) 。

  - 【重要】第 12 至 15 行：若连接未完成( `connected == false` )时，我们可以看到，调用 `SelectionKey#interestOps(ops)` 方法，添加连接事件( `SelectionKey.OP_CONNECT` )为感兴趣的事件。也就说，也就是说，当连接远程地址成功时，Channel 对应的 Selector 将会轮询到该事件，可以进一步处理。

  - 第 20 至 25 行：若执行失败( `success == false` )时，调用 `#doClose()` 方法，关闭 Channel 。

- 第 18 至 19 行：笔者测试下来，`#doConnect(SocketChannel socketChannel, SocketAddress remoteAddress)` 方法的结果为 `false` ，所以不会执行【第 19 行】代码的 `#fulfillConnectPromise(ChannelPromise promise, boolean wasActive)` 方法，而是执行【第 20 至 57 行】的代码逻辑。

- 第 22 行：记录 `connectPromise` 。

- 第 24 行：记录 `requestedRemoteAddress` 。`requestedRemoteAddress` 变量，在 AbstractNioChannel 类中定义，代码如下：

  ```
  /**
   * 正在连接的远程地址
   */
  private SocketAddress requestedRemoteAddress;
  
  ```

- 第 26 至 40 行：调用 `EventLoop#schedule(Runnable command, long delay, TimeUnit unit)` 方法，发起定时任务 `connectTimeoutFuture` ，监听连接远程地址**是否超时**。若连接超时，则回调通知 `connectPromise` 超时异常。`connectPromise` 变量，在 AbstractNioChannel 类中定义，代码如下：

  ```
  /**
   * 连接超时监听 ScheduledFuture 对象。
   */
  private ScheduledFuture<?> connectTimeoutFuture;
  
  ```

- 第 42 至 57 行：调用 `ChannelPromise#addListener(ChannelFutureListener)` 方法，添加监听器，监听连接远程地址**是否取消**。若取消，则取消 `connectTimeoutFuture` 任务，并置空 `connectPromise` 。这样，客户端 Channel 可以发起下一次连接。

### 3.6.4 finishConnect

看到此处，可能胖友会有疑问，客户端的连接在哪里完成呢？答案在 `AbstractNioUnsafe#finishConnect()` 方法中。而该方法通过 Selector 轮询到 `SelectionKey.OP_CONNECT` 事件时，进行触发。调用栈如下图：![finishConnect 调用栈](http://www.iocoder.cn/images/Netty/2018_04_05/03.png)

```
* 哈哈哈，还是老样子，我们先省略掉 EventLoop 的内部实现代码，从 `AbstractNioUnsafe#finishConnect()` 方法，继续向下分享。

```

`AbstractNioUnsafe#finishConnect()` 方法，完成客户端的连接。代码如下：

```
 1: @Override
 2: public final void finishConnect() {
 3:     // Note this method is invoked by the event loop only if the connection attempt was
 4:     // neither cancelled nor timed out.
 5:     // 判断是否在 EventLoop 的线程中。
 6:     assert eventLoop().inEventLoop();
 7: 
 8:     try {
 9:         // 获得 Channel 是否激活
10:         boolean wasActive = isActive();
11:         // 执行完成连接
12:         doFinishConnect();
13:         // 通知 connectPromise 连接完成
14:         fulfillConnectPromise(connectPromise, wasActive);
15:     } catch (Throwable t) {
16:         // 通知 connectPromise 连接异常
17:         fulfillConnectPromise(connectPromise, annotateConnectException(t, requestedRemoteAddress));
18:     } finally {
19:         // 取消 connectTimeoutFuture 任务
20:         // Check for null as the connectTimeoutFuture is only created if a connectTimeoutMillis > 0 is used
21:         // See https://github.com/netty/netty/issues/1770
22:         if (connectTimeoutFuture != null) {
23:             connectTimeoutFuture.cancel(false);
24:         }
25:         // 置空 connectPromise
26:         connectPromise = null;
27:     }
28: }

```

- 第 6 行：判断是否在 EventLoop 的线程中。
- 第 10 行：调用 `#isActive()` 方法，获得 Channel 是否激活。笔者调试时，此时返回 `false` ，因为连接还没完成。
- 第 12 行：调用 `#doFinishConnect()` 方法，执行完成连接的逻辑。详细解析，见 [「3.6.4.1 doFinishConnect」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
- 第 14 行：执行完成连接**成功**，调用 `#fulfillConnectPromise(ChannelPromise promise, boolean wasActive)` 方法，通知 `connectPromise` 连接完成。详细解析，见 [「3.6.4.2 fulfillConnectPromise 成功」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
- 第 15 至 17 行：执行完成连接**异常**，调用 `#fulfillConnectPromise(ChannelPromise promise, Throwable cause)`方法，通知 `connectPromise` 连接异常。详细解析，见 [「3.6.4.3 fulfillConnectPromise 异常」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
- 第 18 至 27 行：执行完成连接**结束**，取消 `connectTimeoutFuture` 任务，并置空 `connectPromise` 。

#### 3.6.4.1 doFinishConnect

`NioSocketChannel#doFinishConnect()` 方法，执行完成连接的逻辑。代码如下：

```
@Override
protected void doFinishConnect() throws Exception {
    if (!javaChannel().finishConnect()) {
        throw new Error();
    }
}

```

- 【重要】是不是非常熟悉的，调用 `SocketChannel#finishConnect()` 方法，完成连接。😈 美滋滋。

#### 3.6.4.2 fulfillConnectPromise 成功

`AbstractNioUnsafe#fulfillConnectPromise(ChannelPromise promise, Throwable cause)` 方法，通知 `connectPromise` 连接完成。代码如下：

```
 1: private void fulfillConnectPromise(ChannelPromise promise, boolean wasActive) {
 2:     if (promise == null) {
 3:         // Closed via cancellation and the promise has been notified already.
 4:         return;
 5:     }
 6: 
 7:     // 获得 Channel 是否激活
 8:     // Get the state as trySuccess() may trigger an ChannelFutureListener that will close the Channel.
 9:     // We still need to ensure we call fireChannelActive() in this case.
10:     boolean active = isActive();
11: 
12:     // 回调通知 promise 执行成功
13:     // trySuccess() will return false if a user cancelled the connection attempt.
14:     boolean promiseSet = promise.trySuccess();
15: 
16:     // 若 Channel 是新激活的，触发通知 Channel 已激活的事件。
17:     // Regardless if the connection attempt was cancelled, channelActive() event should be triggered,
18:     // because what happened is what happened.
19:     if (!wasActive && active) {
20:         pipeline().fireChannelActive();
21:     }
22: 
23:     // If a user cancelled the connection attempt, close the channel, which is followed by channelInactive().
24:     // TODO 芋艿
25:     if (!promiseSet) {
26:         close(voidPromise());
27:     }
28: }

```

- 第 10 行：调用 `#isActive()` 方法，获得 Channel 是否激活。笔者调试时，此时返回 `true` ，因为连接已经完成。

- 第 14 行：回调通知 `promise` 执行成功。此处的通知，对应回调的是我们添加到 `#connect(...)` 方法返回的 ChannelFuture 的 ChannelFutureListener 的监听器。示例代码如下：

  ```
  ChannelFuture f = b.connect(HOST, PORT).addListener(new ChannelFutureListener() { // 回调的就是我！！！
      @Override
      public void operationComplete(ChannelFuture future) throws Exception {
          System.out.println("连接完成");
      }
  }).sync();
  
  ```

- 第 19 行：因为`wasActive == false`并且`active == true`，因此，Channel 可以认为是**新激活**的，满足【第 20 行】代码的执行条件。

  - 第 40 行：调用 `DefaultChannelPipeline#fireChannelActive()` 方法，触发 Channel 激活的事件。【重要】后续的流程，和 NioServerSocketChannel 一样，也就说，会调用到 `AbstractUnsafe#beginRead()` 方法。这意味着什么呢？将我们创建 NioSocketChannel 时，设置的 `readInterestOp = SelectionKey.OP_READ` 添加为感兴趣的事件。也就说，客户端可以读取服务端发送来的数据。
  - 关于 `AbstractUnsafe#beginRead()` 方法的解析，见 [《精尽 Netty 源码分析 —— 启动（一）之服务端》的 「3.13.3 beginRead」](http://svip.iocoder.cn/Netty/bootstrap-1-server/?self) 部分。

- 第 23 至 27 行：TODO 芋艿 1004 fulfillConnectPromise promiseSet

#### 3.6.4.3 fulfillConnectPromise 异常

`#fulfillConnectPromise(ChannelPromise promise, Throwable cause)` 方法，通知 `connectPromise` 连接异常。代码如下：

```
private void fulfillConnectPromise(ChannelPromise promise, Throwable cause) {
    if (promise == null) {
        // Closed via cancellation and the promise has been notified already.
        return;
    }

    // 回调通知 promise 发生异常
    // Use tryFailure() instead of setFailure() to avoid the race against cancel().
    promise.tryFailure(cause);
    // 关闭
    closeIfClosed();
}

```

- 比较简单，已经添加中文注释，胖友自己查看。

## 3.7 initAndRegister

Bootstrap 继承 AbstractBootstrap 抽象类，所以 `#initAndRegister()` 方法的流程上是一致的。所以和 ServerBootstrap 的差别在于：

1. 创建的 Channel 对象不同。
2. 初始化 Channel 配置的代码实现不同。

### 3.7.1 创建 Channel 对象

考虑到本文的内容，我们以 NioSocketChannel 的创建过程作为示例。创建 NioSocketChannel 对象的流程，和 NioServerSocketChannel 基本是一致的，所以流程图我们就不提供了，直接开始撸源码。

#### 3.7.1.1 NioSocketChannel

```
private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider();

private final SocketChannelConfig config;

public NioSocketChannel() {
    this(DEFAULT_SELECTOR_PROVIDER);
}

public NioSocketChannel(SelectorProvider provider) {
    this(newSocket(provider));
}

```

- `DEFAULT_SELECTOR_PROVIDER` **静态**属性，默认的 SelectorProvider 实现类。

- `config` 属性，Channel 对应的配置对象。每种 Channel 实现类，也会对应一个 ChannelConfig 实现类。例如，NioSocketChannel 类，对应 SocketChannelConfig 配置类。

- 在构造方法中，调用 `#newSocket(SelectorProvider provider)` 方法，创建 NIO 的 ServerSocketChannel 对象。代码如下：

  ```
  private static SocketChannel newSocket(SelectorProvider provider) {
      try {
          /**
           *  Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in
           *  {@link SelectorProvider#provider()} which is called by each SocketChannel.open() otherwise.
           *
           *  See <a href="https://github.com/netty/netty/issues/2308">#2308</a>.
           */
          return provider.openSocketChannel();
      } catch (IOException e) {
          throw new ChannelException("Failed to open a socket.", e);
      }
  }
  
  ```

  - 😈 是不是很熟悉这样的代码，效果和 `SocketChannel#open()` 方法创建 SocketChannel 对象是一致。

- `#NioSocketChannel(SocketChannel channel)` 构造方法，代码如下：

  ```
  public NioSocketChannel(SocketChannel socket) {
      this(null, socket);
  }
  
  public NioSocketChannel(Channel parent, SocketChannel socket) {
      super(parent, socket);
      config = new NioSocketChannelConfig(this, socket.socket());
  }
  
  ```

  - 调用父 AbstractNioByteChannel 的构造方法。详细解析，见 [「3.7.1.2 AbstractNioByteChannel」](http://svip.iocoder.cn/Netty/bootstrap-2-client/#) 。
  - 初始化 `config` 属性，创建 NioSocketChannelConfig 对象。

#### 3.7.1.2 AbstractNioByteChannel

```
protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) {
    super(parent, ch, SelectionKey.OP_READ);
}

```

- 调用父 AbstractNioChannel 的构造方法。后续的构造方法，和 NioServerSocketChannel 是一致的。
  - 注意传入的 SelectionKey 的值为 `OP_READ` 。

### 3.7.2 初始化 Channel 配置

`#init(Channel channel)` 方法，初始化 Channel 配置。代码如下：

```
@Override
void init(Channel channel) throws Exception {
    ChannelPipeline p = channel.pipeline();

    // 添加处理器到 pipeline 中
    p.addLast(config.handler());

    // 初始化 Channel 的可选项集合
    final Map<ChannelOption<?>, Object> options = options0();
    synchronized (options) {
        setChannelOptions(channel, options, logger);
    }

    // 初始化 Channel 的属性集合
    final Map<AttributeKey<?>, Object> attrs = attrs0();
    synchronized (attrs) {
        for (Entry<AttributeKey<?>, Object> e: attrs.entrySet()) {
            channel.attr((AttributeKey<Object>) e.getKey()).set(e.getValue());
        }
    }
}

```

- 比较简单，已经添加中文注释，胖友自己查看。

# 666. 彩蛋

撸完 Netty 服务端启动之后，再撸 Netty 客户端启动之后，出奇的顺手。美滋滋。

另外，也推荐如下和 Netty 客户端启动相关的文章，以加深理解：

- 杨武兵 [《Netty 源码分析系列 —— Bootstrap》](https://my.oschina.net/ywbrj042/blog/868798)
- 永顺 [《Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端)》](https://segmentfault.com/a/1190000007282789)

# 精尽 Netty 源码解析 —— EventLoop（一）之 Reactor 模型



# 1. 概述

从本文开始，我们来分享 Netty 非常重要的一个组件 EventLoop 。在看 EventLoop 的具体实现之前，我们先来对 Reactor 模型做个简单的了解。

为什么要了解 Reactor 模型呢？因为 EventLoop 是 Netty 基于 Reactor 模型的思想进行实现。所以理解 Reactor 模型，对于我们理解 EventLoop 会有很大帮助。

我们来看看 Reactor 模型的**核心思想**：

> 将关注的 I/O 事件注册到多路复用器上，一旦有 I/O 事件触发，将事件分发到事件处理器中，执行就绪 I/O 事件对应的处理函数中。模型中有三个重要的组件：
>
> - 多路复用器：由操作系统提供接口，Linux 提供的 I/O 复用接口有select、poll、epoll 。
> - 事件分离器：将多路复用器返回的就绪事件分发到事件处理器中。
> - 事件处理器：处理就绪事件处理函数。

初步一看，Java NIO 符合 Reactor 模型啊？因为 Reactor 有 3 种模型实现：

1. 单 Reactor 单线程模型
2. 单 Reactor 多线程模型
3. 多 Reactor 多线程模型

> 😈 由于老艿艿不擅长相对理论文章的内容编写，所以 [「2.」](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/#)、[「3.」](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/#)、[「4.」](http://svip.iocoder.cn/Netty/EventLoop-1-Reactor-Model/#) 小节的内容，我决定一本正经的引用基友 wier 的 [《【NIO 系列】—— 之Reactor 模型》](https://my.oschina.net/u/1859679/blog/1844109) 。

# 2. 单 Reactor 单线程模型

示例图如下：

![单 Reactor 单线程模型](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554206393429.png)

> 老艿艿：示例代码主要表达大体逻辑，比较奔放。所以，胖友理解大体意思就好。

Reactor 示例代码如下：

```java
/**
* 等待事件到来，分发事件处理
*/
class Reactor implements Runnable {

  private Reactor() throws Exception {
      SelectionKey sk = serverSocket.register(selector, SelectionKey.OP_ACCEPT);
      // attach Acceptor 处理新连接
      sk.attach(new Acceptor());
  }

  @Override
  public void run() {
      try {
          while (!Thread.interrupted()) {
              selector.select();
              Set selected = selector.selectedKeys();
              Iterator it = selected.iterator();
              while (it.hasNext()) {
                  it.remove();
                  //分发事件处理
                  dispatch((SelectionKey) (it.next()));
              }
          }
      } catch (IOException ex) {
          //do something
      }
  }

  void dispatch(SelectionKey k) {
      // 若是连接事件获取是acceptor
      // 若是IO读写事件获取是handler
      Runnable runnable = (Runnable) (k.attachment());
      if (runnable != null) {
          runnable.run();
      }
  }

}
```

> 老艿艿：示例的 Handler 的代码实现应该是漏了。胖友脑补一个实现 Runnable 接口的 Handler 类。😈

这是最基础的单 Reactor 单线程模型。

Reactor 线程，负责多路分离套接字。

- 有新连接到来触发 `OP_ACCEPT` 事件之后， 交由 Acceptor 进行处理。
- 有 IO 读写事件之后，交给 Handler 处理。

Acceptor 主要任务是构造 Handler 。

- 在获取到 Client 相关的 SocketChannel 之后，绑定到相应的 Handler 上。
- 对应的 SocketChannel 有读写事件之后，基于 Reactor 分发，Handler 就可以处理了。

**注意，所有的 IO 事件都绑定到 Selector 上，由 Reactor 统一分发**。

------

该模型适用于处理器链中业务处理组件能快速完成的场景。不过，这种单线程模型不能充分利用多核资源，**所以实际使用的不多**。

# 3. 单 Reactor 多线程模型

示例图如下：

![单 Reactor 多线程模型](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554206393439.png)

相对于第一种单线程的模式来说，在处理业务逻辑，也就是获取到 IO 的读写事件之后，交由线程池来处理，这样可以减小主 Reactor 的性能开销，从而更专注的做事件分发工作了，从而提升整个应用的吞吐。

MultiThreadHandler 示例代码如下：

```java
/**
* 多线程处理读写业务逻辑
*/
class MultiThreadHandler implements Runnable {
  public static final int READING = 0, WRITING = 1;
  int state;
  final SocketChannel socket;
  final SelectionKey sk;

  //多线程处理业务逻辑
  ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());


  public MultiThreadHandler(SocketChannel socket, Selector sl) throws Exception {
      this.state = READING;
      this.socket = socket;
      sk = socket.register(selector, SelectionKey.OP_READ);
      sk.attach(this);
      socket.configureBlocking(false);
  }

  @Override
  public void run() {
      if (state == READING) {
          read();
      } else if (state == WRITING) {
          write();
      }
  }

  private void read() {
      //任务异步处理
      executorService.submit(() -> process());

      //下一步处理写事件
      sk.interestOps(SelectionKey.OP_WRITE);
      this.state = WRITING;
  }

  private void write() {
      //任务异步处理
      executorService.submit(() -> process());

      //下一步处理读事件
      sk.interestOps(SelectionKey.OP_READ);
      this.state = READING;
  }

  /**
    * task 业务处理
    */
  public void process() {
      //do IO ,task,queue something
  }
}
```

- 在 `#read()` 和 `#write()` 方法中，提交 `executorService` 线程池，进行处理。

# 4. 多 Reactor 多线程模型

示例图如下：

![多 Reactor 多线程模型](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554206393450.png)

第三种模型比起第二种模型，是将 Reactor 分成两部分：

1. mainReactor 负责监听 ServerSocketChannel ，用来处理客户端新连接的建立，并将建立的客户端的 SocketChannel 指定注册给 subReactor 。
2. subReactor 维护自己的 Selector ，基于 mainReactor 建立的客户端的 SocketChannel 多路分离 IO 读写事件，读写网络数据。对于业务处理的功能，另外扔给 worker 线程池来完成。

MultiWorkThreadAcceptor 示例代码如下：

```java
/**
* 多work 连接事件Acceptor,处理连接事件
*/
class MultiWorkThreadAcceptor implements Runnable {

  // cpu线程数相同多work线程
  int workCount = Runtime.getRuntime().availableProcessors();
  SubReactor[] workThreadHandlers = new SubReactor[workCount];
  volatile int nextHandler = 0;

  public MultiWorkThreadAcceptor() {
      this.init();
  }

  public void init() {
      nextHandler = 0;
      for (int i = 0; i < workThreadHandlers.length; i++) {
          try {
              workThreadHandlers[i] = new SubReactor();
          } catch (Exception e) {
          }
      }
  }

  @Override
  public void run() {
      try {
          SocketChannel c = serverSocket.accept();
          if (c != null) {// 注册读写
              synchronized (c) {
                  // 顺序获取SubReactor，然后注册channel 
                  SubReactor work = workThreadHandlers[nextHandler];
                  work.registerChannel(c);
                  nextHandler++;
                  if (nextHandler >= workThreadHandlers.length) {
                      nextHandler = 0;
                  }
              }
          }
      } catch (Exception e) {
      }
  }
}
```

SubReactor 示例代码如下：

```java
/**
* 多work线程处理读写业务逻辑
*/
class SubReactor implements Runnable {
  final Selector mySelector;

  //多线程处理业务逻辑
  int workCount =Runtime.getRuntime().availableProcessors();
  ExecutorService executorService = Executors.newFixedThreadPool(workCount);


  public SubReactor() throws Exception {
      // 每个SubReactor 一个selector 
      this.mySelector = SelectorProvider.provider().openSelector();
  }

  /**
    * 注册chanel
    *
    * @param sc
    * @throws Exception
    */
  public void registerChannel(SocketChannel sc) throws Exception {
      sc.register(mySelector, SelectionKey.OP_READ | SelectionKey.OP_CONNECT);
  }

  @Override
  public void run() {
      while (true) {
          try {
          //每个SubReactor 自己做事件分派处理读写事件
              selector.select();
              Set<SelectionKey> keys = selector.selectedKeys();
              Iterator<SelectionKey> iterator = keys.iterator();
              while (iterator.hasNext()) {
                  SelectionKey key = iterator.next();
                  iterator.remove();
                  if (key.isReadable()) {
                      read();
                  } else if (key.isWritable()) {
                      write();
                  }
              }

          } catch (Exception e) {

          }
      }
  }

  private void read() {
      //任务异步处理
      executorService.submit(() -> process());
  }

  private void write() {
      //任务异步处理
      executorService.submit(() -> process());
  }

  /**
    * task 业务处理
    */
  public void process() {
      //do IO ,task,queue something
  }
}
```

从代码中，我们可以看到：

1. mainReactor 主要用来处理网络 IO 连接建立操作，通常，mainReactor 只需要一个，因为它一个线程就可以处理。
2. subReactor 主要和建立起来的客户端的 SocketChannel 做数据交互和事件业务处理操作。通常，subReactor 的个数和 CPU 个数**相等**，每个 subReactor **独占**一个线程来处理。

------

此种模式中，每个模块的工作更加专一，耦合度更低，性能和稳定性也大大的提升，支持的可并发客户端数量可达到上百万级别。

> 老艿艿：一般来说，是达到数十万级别。

关于此种模式的应用，目前有很多优秀的框架已经在应用，比如 Mina 和 Netty 等等。**上述中去掉线程池的第三种形式的变种，也是 Netty NIO 的默认模式**。

# 5. Netty NIO 客户端

我们来看看 Netty NIO 客户端的示例代码中，和 EventLoop 相关的代码：

```java 
// 创建一个 EventLoopGroup 对象
EventLoopGroup group = new NioEventLoopGroup();
// 创建 Bootstrap 对象
Bootstrap b = new Bootstrap();
// 设置使用的 EventLoopGroup
b.group(group);
```

- 对于 Netty NIO 客户端来说，仅创建一个 EventLoopGroup 。
- 一个 EventLoop 可以对应一个 Reactor 。因为 EventLoopGroup 是 EventLoop 的分组，所以对等理解，EventLoopGroup 是**一种** Reactor 的分组。
- 一个 Bootstrap 的启动，只能发起对一个远程的地址。所以只会使用一个 NIO Selector ，也就是说仅使用**一个** Reactor 。即使，我们在声明使用一个 EventLoopGroup ，该 EventLoopGroup 也只会分配一个 EventLoop 对 IO 事件进行处理。
- 因为 Reactor 模型主要使用服务端的开发中，如果套用在 Netty NIO 客户端中，到底使用了哪一种模式呢？
  - 如果只有一个业务线程使用 Netty NIO 客户端，那么可以认为是【单 Reactor **单**线程模型】。
  - 如果有**多个**业务线程使用 Netty NIO 客户端，那么可以认为是【单 Reactor **多**线程模型】。
- 那么 Netty NIO 客户端是否能够使用【多 Reactor 多线程模型】呢？😈 创建多个 Netty NIO 客户端，连接同一个服务端。那么多个 Netty 客户端就可以认为符合多 Reactor 多线程模型了。
  - 一般情况下，我们不会这么干。
  - 当然，实际也有这样的示例。例如 Dubbo 或 Motan 这两个 RPC 框架，支持通过配置，同一个 Consumer 对同一个 Provider 实例同时建立多个客户端连接。

# 6. Netty NIO 服务端

我们来看看 Netty NIO 服务端的示例代码中，和 EventLoop 相关的代码：

```java
// 创建两个 EventLoopGroup 对象
EventLoopGroup bossGroup = new NioEventLoopGroup(1); // 创建 boss 线程组 用于服务端接受客户端的连接
EventLoopGroup workerGroup = new NioEventLoopGroup(); // 创建 worker 线程组 用于进行 SocketChannel 的数据读写
// 创建 ServerBootstrap 对象
ServerBootstrap b = new ServerBootstrap();
// 设置使用的 EventLoopGroup
b.group(bossGroup, workerGroup);
```

- 对于 Netty NIO 服务端来说，创建两个 EventLoopGroup 。
  - `bossGroup` 对应 Reactor 模式的 mainReactor ，用于服务端接受客户端的连接。比较特殊的是，传入了方法参数 `nThreads = 1` ，表示只使用一个 EventLoop ，即只使用一个 Reactor 。这个也符合我们上面提到的，“*通常，mainReactor 只需要一个，因为它一个线程就可以处理*”。
  - `workerGroup` 对应 Reactor 模式的 subReactor ，用于进行 SocketChannel 的数据读写。对于 EventLoopGroup ，如果未传递方法参数 `nThreads` ，表示使用 CPU 个数 Reactor 。这个也符合我们上面提到的，“*通常，subReactor 的个数和 CPU 个数相等，每个 subReactor 独占一个线程来处理*”。
- 因为使用两个 EventLoopGroup ，所以符合【多 Reactor 多线程模型】的多 Reactor 的要求。实际在使用时，`workerGroup` 在读完数据时，具体的业务逻辑处理，我们会提交到**专门的业务逻辑线程池**，例如在 Dubbo 或 Motan 这两个 RPC 框架中。这样一来，就完全符合【多 Reactor 多线程模型】。
- 那么可能有胖友可能和我有一样的疑问，`bossGroup` 如果配置多个线程，是否可以使用**多个 mainReactor** 呢？我们来分析一波，一个 Netty NIO 服务端**同一时间**，只能 bind 一个端口，那么只能使用一个 Selector 处理客户端连接事件。又因为，Selector 操作是非线程安全的，所以无法在多个 EventLoop ( 多个线程 )中，同时操作。所以这样就导致，即使 `bossGroup` 配置多个线程，实际能够使用的也就是一个线程。
- 那么如果一定一定一定要多个 mainReactor 呢？创建多个 Netty NIO 服务端，并绑定多个端口。

# 666. 彩蛋

如果 Reactor 模式讲解的不够清晰，或者想要更加深入的理解，推荐阅读如下文章：

- wier [《【NIO 系列】—— 之 Reactor 模型》](https://my.oschina.net/u/1859679/blog/1844109)
- 永顺 [《Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)》](https://segmentfault.com/a/1190000007403873) 里面有几个图不错。
- Essviv [《Reactor 模型》](https://essviv.github.io/2017/01/25/IO/netty/reactor%E6%A8%A1%E5%9E%8B/) 里面的代码示例不错。
- xieshuang [《异步网络模型》](https://tech.youzan.com/yi-bu-wang-luo-mo-xing/) 内容很高端，一看就是高玩。

另外，还有一个经典的 Proactor 模型，因为 Netty 并未实现，所以笔者就省略了。如果感兴趣的胖友，可以自行 Google 理解下。

# 精尽 Netty 源码解析 —— EventLoop（二）之 EventLoopGroup



# 1. 概述

在 [《精尽 Netty 源码分析 —— Netty 简介（二）之核心组件》](http://svip.iocoder.cn/Netty/intro-2/?self) 中，对 EventLoopGroup 和 EventLoop 做了定义，我们再来回顾下：

> - Channel 为Netty 网络操作抽象类，EventLoop 负责处理注册到其上的 Channel 处理 I/O 操作，两者配合参与 I/O 操作。
> - EventLoopGroup 是一个 EventLoop 的分组，它可以获取到一个或者多个 EventLoop 对象，因此它提供了迭代出 EventLoop 对象的方法。

在 [《精尽 Netty 源码分析 —— 启动》](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#) 中，我们特别熟悉的一段代码就是：

- `new NioEventLoopGroup()` ，创建一个 EventLoopGroup 对象。
- `EventLoopGroup#register(Channel channel)` ，将 Channel 注册到 EventLoopGroup 上。

那么，本文我们分享 EventLoopGroup 的具体代码实现，来一探究竟。

# 2. 类结构图

EventLoopGroup 的整体类结构如下图：

![EventLoopGroup 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554206448003.png)

- 红框部分，为 EventLoopGroup 相关的类关系。其他部分，为 EventLoop 相关的类关系。
- 因为我们实际上使用的是 **NioEventLoopGroup** 和 NioEventLoop ，所以笔者省略了其它相关的类，例如 OioEventLoopGroup、EmbeddedEventLoop 等等。

下面，我们逐层看看每个接口和类的实现代码。

# 3. EventExecutorGroup

`io.netty.util.concurrent.EventExecutorGroup` ，实现 Iterable、ScheduledExecutorService 接口，EventExecutor ( 事件执行器 )的分组接口。代码如下：

```
// ========== 自定义接口 ==========

boolean isShuttingDown();

// 优雅关闭
Future<?> shutdownGracefully();
Future<?> shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit);

Future<?> terminationFuture();

// 选择一个 EventExecutor 对象
EventExecutor next(); 

// ========== 实现自 Iterable 接口 ==========

@Override
Iterator<EventExecutor> iterator();

// ========== 实现自 ExecutorService 接口 ==========

@Override
Future<?> submit(Runnable task);
@Override
<T> Future<T> submit(Runnable task, T result);
@Override
<T> Future<T> submit(Callable<T> task);

@Override
@Deprecated
void shutdown();
@Override
@Deprecated
List<Runnable> shutdownNow();

// ========== 实现自 ScheduledExecutorService 接口 ==========

@Override
ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit);
@Override
<V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit);
@Override
ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit);
@Override
ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);
```

- 每个接口的方法的意思比较好理解，笔者就不一一赘述了。
- 比较特殊的是，接口方法返回类型为 Future 不是 Java 原生的 `java.util.concurrent.Future` ，而是 Netty 自己实现的 Future 接口。详细解析，见后续文章。
- EventExecutorGroup 自身不执行任务，而是将任务 `#submit(...)` 或 `#schedule(...)` 给自己管理的 EventExecutor 的分组。至于提交给哪一个 EventExecutor ，一般是通过 `#next()` 方法，选择一个 EventExecutor 。

# 4. AbstractEventExecutorGroup

`io.netty.util.concurrent.AbstractEventExecutorGroup` ，实现 EventExecutorGroup 接口，EventExecutor ( 事件执行器 )的分组抽象类。

## 4.1 submit

`#submit(...)` 方法，提交**一个**普通任务到 EventExecutor 中。代码如下：

```
@Override
public Future<?> submit(Runnable task) {
    return next().submit(task);
}

@Override
public <T> Future<T> submit(Runnable task, T result) {
    return next().submit(task, result);
}

@Override
public <T> Future<T> submit(Callable<T> task) {
    return next().submit(task);
}
```

- 提交的 EventExecutor ，通过 `#next()` 方法选择。

## 4.2 schedule

`#schedule(...)` 方法，提交**一个**定时任务到 EventExecutor 中。代码如下：

```
@Override
public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {
    return next().schedule(command, delay, unit);
}

@Override
public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit) {
    return next().schedule(callable, delay, unit);
}

@Override
public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) {
    return next().scheduleAtFixedRate(command, initialDelay, period, unit);
}

@Override
public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) {
    return next().scheduleWithFixedDelay(command, initialDelay, delay, unit);
}
```

- 提交的 EventExecutor ，通过 `#next()` 方法选择。

## 4.3 execute

`#execute(...)` 方法，在 EventExecutor 中执行**一个**普通任务。代码如下：

```
@Override
public void execute(Runnable command) {
    next().execute(command);
}
```

- 执行的 EventExecutor ，通过 `#next()` 方法选择。
- 看起来 `#execute(...)` 和 `#submit(...)` 方法有几分相似，具体的差异，由 EventExecutor 的实现决定。

## 4.4 invokeAll

`#invokeAll(...)` 方法，在 EventExecutor 中执行**多个**普通任务。代码如下：

```
@Override
public <T> List<java.util.concurrent.Future<T>> invokeAll(Collection<? extends Callable<T>> tasks) throws InterruptedException {
    return next().invokeAll(tasks);
}

@Override
public <T> List<java.util.concurrent.Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit) throws InterruptedException {
    return next().invokeAll(tasks, timeout, unit);
}
```

- 执行的 EventExecutor ，通过 `#next()` 方法选择。并且，多个任务使用同一个 EventExecutor 。

## 4.5 invokeAny

`#invokeAll(...)` 方法，在 EventExecutor 中执行**多个**普通任务，有**一个**执行完成即可。代码如下：

```
@Override
public <T> T invokeAny(Collection<? extends Callable<T>> tasks) throws InterruptedException, ExecutionException {
    return next().invokeAny(tasks);
}

@Override
public <T> T invokeAny(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
    return next().invokeAny(tasks, timeout, unit);
}
```

- 执行的 EventExecutor ，通过 `#next()` 方法选择。并且，多个任务使用同一个 EventExecutor 。

## 4.6 shutdown

`#shutdown(...)` 方法，关闭 EventExecutorGroup 。代码如下：

```
@Override
public Future<?> shutdownGracefully() {
    return shutdownGracefully(DEFAULT_SHUTDOWN_QUIET_PERIOD /* 2 */, DEFAULT_SHUTDOWN_TIMEOUT /* 15 */, TimeUnit.SECONDS);
}

@Override
@Deprecated
public List<Runnable> shutdownNow() {
    shutdown();
    return Collections.emptyList();
}

@Override
@Deprecated
public abstract void shutdown();
```

- 具体的 `#shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit)` 和 `#shutdown()` 方法，由子类实现。

# 5. MultithreadEventExecutorGroup

`io.netty.util.concurrent.MultithreadEventExecutorGroup` ，继承 AbstractEventExecutorGroup 抽象类，**基于多线程**的 EventExecutor ( 事件执行器 )的分组抽象类。

## 5.1 构造方法

```
/**
 * EventExecutor 数组
 */
private final EventExecutor[] children;
/**
 * 不可变( 只读 )的 EventExecutor 数组
 *
 * @see #MultithreadEventExecutorGroup(int, Executor, EventExecutorChooserFactory, Object...)
 */
private final Set<EventExecutor> readonlyChildren;
/**
 * 已终止的 EventExecutor 数量
 */
private final AtomicInteger terminatedChildren = new AtomicInteger();
/**
 * 用于终止 EventExecutor 的异步 Future
 */
private final Promise<?> terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE);
/**
 * EventExecutor 选择器
 */
private final EventExecutorChooserFactory.EventExecutorChooser chooser;

protected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) {
    this(nThreads, threadFactory == null ? null : new ThreadPerTaskExecutor(threadFactory), args);
}

protected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object... args) {
    this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);
}

  1: protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) {
  2:     if (nThreads <= 0) {
  3:         throw new IllegalArgumentException(String.format("nThreads: %d (expected: > 0)", nThreads));
  4:     }
  5: 
  6:     // 创建执行器
  7:     if (executor == null) {
  8:         executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());
  9:     }
 10: 
 11:     // 创建 EventExecutor 数组
 12:     children = new EventExecutor[nThreads];
 13: 
 14:     for (int i = 0; i < nThreads; i ++) {
 15:         boolean success = false; // 是否创建成功
 16:         try {
 17:             // 创建 EventExecutor 对象
 18:             children[i] = newChild(executor, args);
 19:             // 标记创建成功
 20:             success = true;
 21:         } catch (Exception e) {
 22:             // 创建失败，抛出 IllegalStateException 异常
 23:             // TODO: Think about if this is a good exception type
 24:             throw new IllegalStateException("failed to create a child event loop", e);
 25:         } finally {
 26:             // 创建失败，关闭所有已创建的 EventExecutor
 27:             if (!success) {
 28:                 // 关闭所有已创建的 EventExecutor
 29:                 for (int j = 0; j < i; j ++) {
 30:                     children[j].shutdownGracefully();
 31:                 }
 32:                 // 确保所有已创建的 EventExecutor 已关闭
 33:                 for (int j = 0; j < i; j ++) {
 34:                     EventExecutor e = children[j];
 35:                     try {
 36:                         while (!e.isTerminated()) {
 37:                             e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS);
 38:                         }
 39:                     } catch (InterruptedException interrupted) {
 40:                         // Let the caller handle the interruption.
 41:                         Thread.currentThread().interrupt();
 42:                         break;
 43:                     }
 44:                 }
 45:             }
 46:         }
 47:     }
 48: 
 49:     // 创建 EventExecutor 选择器
 50:     chooser = chooserFactory.newChooser(children);
 51: 
 52:     // 创建监听器，用于 EventExecutor 终止时的监听
 53:     final FutureListener<Object> terminationListener = new FutureListener<Object>() {
 54: 
 55:         @Override
 56:         public void operationComplete(Future<Object> future) throws Exception {
 57:             if (terminatedChildren.incrementAndGet() == children.length) { // 全部关闭
 58:                 terminationFuture.setSuccess(null); // 设置结果，并通知监听器们。
 59:             }
 60:         }
 61: 
 62:     };
 63:     // 设置监听器到每个 EventExecutor 上
 64:     for (EventExecutor e: children) {
 65:         e.terminationFuture().addListener(terminationListener);
 66:     }
 67: 
 68:     // 创建不可变( 只读 )的 EventExecutor 数组
 69:     Set<EventExecutor> childrenSet = new LinkedHashSet<EventExecutor>(children.length);
 70:     Collections.addAll(childrenSet, children);
 71:     readonlyChildren = Collections.unmodifiableSet(childrenSet);
 72: }
```

- 每个属性的定义，胖友直接看代码注释。
- 方法参数`executor`，执行器。详细解析，见  [「5.2 ThreadPerTaskExecutor」](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#)。
  - 第 6 至 9 行：若 `executor` 为空，则创建执行器。
- 第 12 行：创建 EventExecutor 数组。
  - 第 18 行：调用 `#newChild(Executor executor, Object... args)` 方法，创建 EventExecutor 对象，然后设置到数组中。
  - 第 21 至 24 行：创建失败，抛出 IllegalStateException 异常。
  - 第 25 至 45 行：创建失败，关闭所有已创建的 EventExecutor 。
- 第 50 行：调用 `EventExecutorChooserFactory#newChooser(EventExecutor[] executors)` 方法，创建 EventExecutor 选择器。详细解析，见 [「5.3 EventExecutorChooserFactory」](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#) 。
- 第 52 至 62 行：创建监听器，用于 EventExecutor 终止时的监听。
  - 第 55 至 60 行：回调的具体逻辑是，当所有 EventExecutor 都终止完成时，通过调用 `Future#setSuccess(V result)` 方法，通知监听器们。至于为什么设置的值是 `null` ，因为监听器们不关注具体的结果。
  - 第 63 至 66 行：设置监听器到每个 EventExecutor 上。
- 第 68 至 71 行：创建不可变( 只读 )的 EventExecutor 数组。

## 5.2 ThreadPerTaskExecutor

`io.netty.util.concurrent.ThreadPerTaskExecutor` ，实现 Executor 接口，每个任务一个线程的执行器实现类。代码如下：

```
public final class ThreadPerTaskExecutor implements Executor {

    /**
     * 线程工厂对象
     */
    private final ThreadFactory threadFactory;

    public ThreadPerTaskExecutor(ThreadFactory threadFactory) {
        if (threadFactory == null) {
            throw new NullPointerException("threadFactory");
        }
        this.threadFactory = threadFactory;
    }

    /**
     * 执行任务
     *
     * @param command 任务
     */
    @Override
    public void execute(Runnable command) {
        threadFactory.newThread(command).start();
    }

}
```

- `threadFactory` 属性，线程工厂对象。Netty 实现自定义的 ThreadFactory 类，为 `io.netty.util.concurrent.DefaultThreadFactory` 。关于 DefaultThreadFactory 比较简单，胖友可以自己看看。
- `#execute(Runnable command)` 方法，通过 `ThreadFactory#newThread(Runnable)` 方法，创建一个 Thread ，然后调用 `Thread#start()` 方法，**启动线程执行任务**。

## 5.3 EventExecutorChooserFactory

`io.netty.util.concurrent.EventExecutorChooserFactory` ，EventExecutorChooser 工厂接口。代码如下：

```
public interface EventExecutorChooserFactory {

    /**
     * 创建一个 EventExecutorChooser 对象
     *
     * Returns a new {@link EventExecutorChooser}.
     */
    EventExecutorChooser newChooser(EventExecutor[] executors);

    /**
     *  EventExecutor 选择器接口
     *
     * Chooses the next {@link EventExecutor} to use.
     */
    @UnstableApi
    interface EventExecutorChooser {

        /**
         * 选择下一个 EventExecutor 对象
         *
         * Returns the new {@link EventExecutor} to use.
         */
        EventExecutor next();

    }

}
```

- `#newChooser(EventExecutor[] executors)` 方法，创建一个 EventExecutorChooser 对象。
- EventExecutorChooser 接口，EventExecutor 选择器接口。
  - `#next()` 方法，选择下一个 EventExecutor 对象。

### 5.3.1 DefaultEventExecutorChooserFactory

`io.netty.util.concurrent.DefaultEventExecutorChooserFactory` ，实现 EventExecutorChooserFactory 接口，默认 EventExecutorChooser 工厂实现类。代码如下

```
/**
 * 单例
 */
public static final DefaultEventExecutorChooserFactory INSTANCE = new DefaultEventExecutorChooserFactory();

private DefaultEventExecutorChooserFactory() { }

@SuppressWarnings("unchecked")
@Override
public EventExecutorChooser newChooser(EventExecutor[] executors) {
    if (isPowerOfTwo(executors.length)) { // 是否为 2 的幂次方
        return new PowerOfTwoEventExecutorChooser(executors);
    } else {
        return new GenericEventExecutorChooser(executors);
    }
}

private static boolean isPowerOfTwo(int val) {
    return (val & -val) == val;
}
```

- `INSTANCE` **静态**属性，单例。
- `#newChooser(EventExecutor[] executors)`方法，调用`#isPowerOfTwo(int val)`方法，判断 EventExecutor 数组的大小是否为 2 的幂次方。
  - 若是，创建 PowerOfTwoEventExecutorChooser 对象。详细解析，见 [「5.3.3 PowerOfTwoEventExecutorChooser」](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#) 。
  - 若否，创建 GenericEventExecutorChooser 对象。详细解析，见 [「5.3.2 GenericEventExecutorChooser」](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#) 。
- `#isPowerOfTwo(int val)`方法，为什么`(val & -val) == val`可以判断数字是否为 2 的幂次方呢？
  - 我们以 8 来举个例子。
    - 8 的二进制为 `1000` 。
    - -8 的二进制使用补码表示。所以，先求反生成反码为 `0111` ，然后加一生成补码为 `1000` 。
    - 8 和 -8 并操作后，还是 8 。
    - 实际上，以 2 为幂次方的数字，都是最高位为 1 ，剩余位为 0 ，所以对应的负数，求完补码还是自己。
  - 胖友也可以自己试试非 2 的幂次方数字的效果。

### 5.3.2 GenericEventExecutorChooser

GenericEventExecutorChooser 实现 EventExecutorChooser 接口，通用的 EventExecutor 选择器实现类。代码如下：

> GenericEventExecutorChooser 内嵌在 DefaultEventExecutorChooserFactory 类中。

```
private static final class GenericEventExecutorChooser implements EventExecutorChooser {

    /**
     * 自增序列
     */
    private final AtomicInteger idx = new AtomicInteger();
    /**
     * EventExecutor 数组
     */
    private final EventExecutor[] executors;

    GenericEventExecutorChooser(EventExecutor[] executors) {
        this.executors = executors;
    }

    @Override
    public EventExecutor next() {
        return executors[Math.abs(idx.getAndIncrement() % executors.length)];
    }

}
```

- 实现比较**简单**，使用 `idx` 自增，并使用 EventExecutor 数组的大小来取余。

### 5.3.3 PowerOfTwoEventExecutorChooser

PowerOfTwoEventExecutorChooser 实现 EventExecutorChooser 接口，基于 EventExecutor 数组的大小为 2 的幂次方的 EventExecutor 选择器实现类。这是一个优化的实现，代码如下：

> PowerOfTwoEventExecutorChooser 内嵌在 DefaultEventExecutorChooserFactory 类中。

```
private static final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser {

    /**
     * 自增序列
     */
    private final AtomicInteger idx = new AtomicInteger();
    /**
     * EventExecutor 数组
     */
    private final EventExecutor[] executors;

    PowerOfTwoEventExecutorChooser(EventExecutor[] executors) {
        this.executors = executors;
    }

    @Override
    public EventExecutor next() {
        return executors[idx.getAndIncrement() & executors.length - 1];
    }

}
```

- 实现比较**巧妙**，通过`idx`自增，并使用【EventExecutor 数组的大小 - 1】进行进行`&`并操作。
  - 因为 `-` ( 二元操作符 ) 的计算优先级高于 `&` ( 一元操作符 ) 。
  - 因为 EventExecutor 数组的大小是以 2 为幂次方的数字，那么减一后，除了最高位是 0 ，剩余位都为 1 ( 例如 8 减一后等于 7 ，而 7 的二进制为 0111 。)，那么无论 `idx` 无论如何递增，再进行 `&`并操作，都不会超过 EventExecutor 数组的大小。并且，还能保证顺序递增。

## 5.4 newDefaultThreadFactory

`#newDefaultThreadFactory()` 方法，创建线程工厂对象。代码如下：

```
protected ThreadFactory newDefaultThreadFactory() {
    return new DefaultThreadFactory(getClass());
}
```

- 创建的对象为 DefaultThreadFactory ，并且使用类名作为 `poolType` 。

## 5.5 next

`#next()` 方法，选择下一个 EventExecutor 对象。代码如下：

```
@Override
public EventExecutor next() {
    return chooser.next();
}
```

## 5.6 iterator

`#iterator()` 方法，获得 EventExecutor 数组的迭代器。代码如下：

```
@Override
public Iterator<EventExecutor> iterator() {
    return readonlyChildren.iterator();
}
```

- 为了避免调用方，获得迭代器后，对 EventExecutor 数组进行修改，所以返回是**不可变**的 EventExecutor 数组 `readonlyChildren` 的迭代器。

## 5.7 executorCount

`#executorCount()` 方法，获得 EventExecutor 数组的大小。代码如下：

```
public final int executorCount() {
    return children.length;
}

```

## 5.8 newChild

`#newChild(Executor executor, Object... args)` **抽象**方法，创建 EventExecutor 对象。代码如下：

```
protected abstract EventExecutor newChild(Executor executor, Object... args) throws Exception;

```

- 子类实现该方法，创建其对应的 EventExecutor 实现类的对象。

## 5.9 关闭相关方法

如下是关闭相关的方法，比较简单，胖友自己研究：

- `#terminationFuture()`
- `#shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit)`
- `#shutdown()`
- `#awaitTermination(long timeout, TimeUnit unit)`
- `#isShuttingDown()`
- `#isShutdown()`
- `#isTerminated()`

# 6. EventLoopGroup

`io.netty.channel.EventExecutorGroup` ，继承 EventExecutorGroup 接口，EventLoop 的分组接口。代码如下：

```
// ========== 自定义接口 ==========

/**
 * Register a {@link Channel} with this {@link EventLoop}. The returned {@link ChannelFuture}
 * will get notified once the registration was complete.
 */
ChannelFuture register(Channel channel);
ChannelFuture register(ChannelPromise promise);
@Deprecated
ChannelFuture register(Channel channel, ChannelPromise promise);

// ========== 实现自 EventExecutorGroup 接口 ==========

@Override
EventLoop next();

```

- `#next()` 方法，选择下一个 EventLoop 对象。
- `#register(...)` 方法，注册 Channel 到 EventLoopGroup 中。实际上，EventLoopGroup 会分配一个 EventLoop 给该 Channel 注册。

# 7. MultithreadEventLoopGroup

`io.netty.channel.MultithreadEventLoopGroup` ，实现 EventLoopGroup 接口，继承 MultithreadEventExecutorGroup 抽象类，**基于多线程**的 EventLoop 的分组抽象类。

## 7.1 构造方法

```java
/**
 * 默认 EventLoop 线程数
 */
private static final int DEFAULT_EVENT_LOOP_THREADS;

static {
    DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt("io.netty.eventLoopThreads", NettyRuntime.availableProcessors() * 2));

    if (logger.isDebugEnabled()) {
        logger.debug("-Dio.netty.eventLoopThreads: {}", DEFAULT_EVENT_LOOP_THREADS);
    }
}

protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) {
    super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);
}

protected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) {
    super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args);
}

protected MultithreadEventLoopGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) {
    super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, chooserFactory, args);
}

```

- `DEFAULT_EVENT_LOOP_THREADS`属性，EventLoopGroup 默认拥有的 EventLoop 数量。因为一个 EventLoop 对应一个线程，所以为 CPU 数量 * 2 。
  - 为什么会 * 2 呢？因为目前 CPU 基本都是超线程，**一个 CPU 可对应 2 个线程**。
  - 在构造方法未传入 `nThreads` 方法参数时，使用 `DEFAULT_EVENT_LOOP_THREADS` 。

## 7.2 newDefaultThreadFactory

newDefaultThreadFactory

`#newDefaultThreadFactory()` 方法，创建线程工厂对象。代码如下：

```
@Override
protected ThreadFactory newDefaultThreadFactory() {
    return new DefaultThreadFactory(getClass(), Thread.MAX_PRIORITY);
}

```

- 覆盖父类方法，增加了线程优先级为 `Thread.MAX_PRIORITY` 。

## 7.3 next

`#next()` 方法，选择下一个 EventLoop 对象。代码如下：

```
@Override
public EventLoop next() {
    return (EventLoop) super.next();
}

```

- 覆盖父类方法，将返回值转换成 EventLoop 类。

## 7.4 newChild

`#newChild(Executor executor, Object... args)` **抽象**方法，创建 EventExecutor 对象。代码如下：

```
@Override
protected abstract EventLoop newChild(Executor executor, Object... args) throws Exception;

```

- 覆盖父类方法，返回值改为 EventLoop 类。

## 7.5 register

`#register()` 方法，注册 Channel 到 EventLoopGroup 中。实际上，EventLoopGroup 会分配一个 EventLoop 给该 Channel 注册。代码如下：

```java
@Override
public ChannelFuture register(Channel channel) {
    return next().register(channel);
}

@Override
public ChannelFuture register(ChannelPromise promise) {
    return next().register(promise);
}

@Deprecated
@Override
public ChannelFuture register(Channel channel, ChannelPromise promise) {
    return next().register(channel, promise);
}

```

- Channel 注册的 EventLoop ，通过 `#next()` 方法来选择。

# 8. NioEventLoopGroup

`io.netty.channel.nio.NioEventLoopGroup` ，继承 MultithreadEventLoopGroup 抽象类，NioEventLoop 的分组实现类。

## 8.1 构造方法

```java
public NioEventLoopGroup() {
    this(0);
}

public NioEventLoopGroup(int nThreads) {
    this(nThreads, (Executor) null);
}

public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory) {
    this(nThreads, threadFactory, SelectorProvider.provider());
}

public NioEventLoopGroup(int nThreads, Executor executor) {
    this(nThreads, executor, SelectorProvider.provider());
}

public NioEventLoopGroup(
        int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider) {
    this(nThreads, threadFactory, selectorProvider, DefaultSelectStrategyFactory.INSTANCE);
}

public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory,
    final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) {
    super(nThreads, threadFactory, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject());
}

public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider) {
    this(nThreads, executor, selectorProvider, DefaultSelectStrategyFactory.INSTANCE);
}

public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider,
                         final SelectStrategyFactory selectStrategyFactory) {
    super(nThreads, executor, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject());
}

public NioEventLoopGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory,
                         final SelectorProvider selectorProvider,
                         final SelectStrategyFactory selectStrategyFactory) {
    super(nThreads, executor, chooserFactory, selectorProvider, selectStrategyFactory,
            RejectedExecutionHandlers.reject());
}

public NioEventLoopGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory,
                         final SelectorProvider selectorProvider,
                         final SelectStrategyFactory selectStrategyFactory,
                         final RejectedExecutionHandler rejectedExecutionHandler) {
    super(nThreads, executor, chooserFactory, selectorProvider, selectStrategyFactory, rejectedExecutionHandler);
}

```

- 构造方法比较多，主要是明确了父构造方法的`Object ... args`方法参数：
  - 第一个参数，`selectorProvider` ，`java.nio.channels.spi.SelectorProvider` ，用于创建 Java NIO Selector 对象。
  - 第二个参数，`selectStrategyFactory` ，`io.netty.channel.SelectStrategyFactory` ，选择策略工厂。详细解析，见后续文章。
  - 第三个参数，`rejectedExecutionHandler` ，`io.netty.channel.SelectStrategyFactory` ，拒绝执行处理器。详细解析，见后续文章。

## 8.2 newChild

`#newChild(Executor executor, Object... args)` 方法，创建 NioEventLoop 对象。代码如下：

```java
@Override
protected EventLoop newChild(Executor executor, Object... args) throws Exception {
    return new NioEventLoop(this, executor,
            (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);
}

```

- 通过 `Object... args` 方法参数，传入给 NioEventLoop 创建需要的参数。

## 8.3 setIoRatio

`#setIoRatio(int ioRatio)` 方法，设置所有 EventLoop 的 IO 任务占用执行时间的比例。代码如下：

```java
/**
 * Sets the percentage of the desired amount of time spent for I/O in the child event loops.  The default value is
 * {@code 50}, which means the event loop will try to spend the same amount of time for I/O as for non-I/O tasks.
 */
public void setIoRatio(int ioRatio) {
    for (EventExecutor e: this) {
        ((NioEventLoop) e).setIoRatio(ioRatio);
    }
}

```

## 8.4 rebuildSelectors

`#rebuildSelectors()` 方法，重建所有 EventLoop 的 Selector 对象。代码如下：

```java
/**
 * Replaces the current {@link Selector}s of the child event loops with newly created {@link Selector}s to work
 * around the  infamous epoll 100% CPU bug.
 */
public void rebuildSelectors() {
    for (EventExecutor e: this) {
        ((NioEventLoop) e).rebuildSelector();
    }
}

```

- 因为 JDK 有 [epoll 100% CPU Bug](https://www.jianshu.com/p/da4398743b5a) 。实际上，NioEventLoop 当触发该 Bug 时，也会**自动**调用 `NioEventLoop#rebuildSelector()` 方法，进行重建 Selector 对象，以修复该问题。

# 666. 彩蛋

还是比较简单的文章。如果有不清晰的地方，也可以阅读如下文章：

- 永顺 [《Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)》](https://segmentfault.com/a/1190000007403873#articleHeader2) 的 [「NioEventLoopGroup 实例化过程」](http://svip.iocoder.cn/Netty/EventLoop-2-EventLoopGroup/#) 小节。
- Hypercube [《自顶向下深入分析Netty（四）—— EventLoop-1》](https://www.jianshu.com/p/da4398743b5a)

# 精尽 Netty 源码解析 —— EventLoop（三）之 EventLoop 初始化



# 1. 概述

本文我们分享 EventLoop 的具体代码实现。因为 EventLoop 涉及的代码量较大，所以笔者会分成好几篇文章分别分享。而本文，我们来分享 EventLoop 的初始化。

但是要将 EventLoop 拆出“初始化”部分的内容，笔者又觉得是件非常困难的事情。所以本文希望能达到如下的效果：

1. 理解 EventLoop 有哪些属性
2. 创建 EventLoop 的过程
3. Channel 注册到 EventLoop 的过程
4. EventLoop 的任务提交。
   - 虽然任务的提交，比较接近任务的执行，但是考虑到胖友可以更容易的理解 EventLoop ，所以放在本文。

# 2. 类结构图

EventLoopGroup 的整体类结构如下图：

![EventLoopGroup 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554274250800.png)

- 红框部分，为 EventLoopGroup 相关的类关系。**其他部分，为 EventLoop 相关的类关系**。
- 因为我们实际上使用的是 NioEventLoopGroup 和 **NioEventLoop** ，所以笔者省略了其它相关的类，例如 OioEventLoopGroup、EmbeddedEventLoop 等等。

下面，我们逐层看看每个接口和类的实现代码。

# 3. EventExecutor

`io.netty.util.concurrent.EventExecutor` ，继承 EventExecutorGroup 接口，事件执行器接口。代码如下：

```
// ========== 实现自 EventExecutorGroup 接口 ==========

/**
 * 返回自己
 *
 * Returns a reference to itself.
 */
@Override
EventExecutor next();

// ========== 自定义接口 ==========

/**
 * 所属 EventExecutorGroup
 *
 * Return the {@link EventExecutorGroup} which is the parent of this {@link EventExecutor},
 */
EventExecutorGroup parent();

/**
 * 当前线程是否在 EventLoop 线程中
 *
 * Calls {@link #inEventLoop(Thread)} with {@link Thread#currentThread()} as argument
 */
boolean inEventLoop();
/**
 * 指定线程是否是 EventLoop 线程
 *
 * Return {@code true} if the given {@link Thread} is executed in the event loop,
 * {@code false} otherwise.
 */
boolean inEventLoop(Thread thread);

/**
 * 创建一个 Promise 对象
 *
 * Return a new {@link Promise}.
 */
<V> Promise<V> newPromise();
/**
 * 创建一个 ProgressivePromise 对象
 *
 * Create a new {@link ProgressivePromise}.
 */
<V> ProgressivePromise<V> newProgressivePromise();
/**
 * 创建成功结果的 Future 对象
 *
 * Create a new {@link Future} which is marked as succeeded already. So {@link Future#isSuccess()}
 * will return {@code true}. All {@link FutureListener} added to it will be notified directly. Also
 * every call of blocking methods will just return without blocking.
 */
<V> Future<V> newSucceededFuture(V result);
/**
 * 创建异常的 Future 对象
 *
 * Create a new {@link Future} which is marked as failed already. So {@link Future#isSuccess()}
 * will return {@code false}. All {@link FutureListener} added to it will be notified directly. Also
 * every call of blocking methods will just return without blocking.
 */
<V> Future<V> newFailedFuture(Throwable cause);
```

- 接口定义的方法比较简单，已经添加中文注释，胖友自己看下。

# 4. OrderedEventExecutor

`io.netty.util.concurrent.OrderedEventExecutor` ，继承 EventExecutor 接口，有序的事件执行器接口。代码如下：

```
/**
 * Marker interface for {@link EventExecutor}s that will process all submitted tasks in an ordered / serial fashion.
 */
public interface OrderedEventExecutor extends EventExecutor {
}
```

- 没有定义任何方法，仅仅是一个标记接口，表示该执行器会有序 / 串行的方式执行。

# 5. EventLoop

`io.netty.channel.EventLoop` ，继承 OrderedEventExecutor 和 EventLoopGroup 接口，EventLoop 接口。代码如下：

```
/**
 * Will handle all the I/O operations for a {@link Channel} once registered.
 *
 * One {@link EventLoop} instance will usually handle more than one {@link Channel} but this may depend on
 * implementation details and internals.
 *
 */
public interface EventLoop extends OrderedEventExecutor, EventLoopGroup {

    @Override
    EventLoopGroup parent();

}
```

- `#parent()` 接口方法，覆写方法的返回类型为 EventLoopGroup 。
- 接口上的英文注释，意思如下：
  - EventLoop 将会处理注册在其上的 Channel 的所有 IO 操作。
  - 通常，一个 EventLoop 上可以注册不只一个 Channel 。当然，这个也取决于具体的实现。

# 6. AbstractEventExecutor

`io.netty.util.concurrent.AbstractEventExecutor` ，实现 EventExecutor 接口，继承 AbstractExecutorService 抽象类，EventExecutor 抽象类。

## 6.1 构造方法

```
/**
 * 所属 EventExecutorGroup
 */
private final EventExecutorGroup parent;
/**
 * EventExecutor 数组。只包含自己，用于 {@link #iterator()}
 */
private final Collection<EventExecutor> selfCollection = Collections.<EventExecutor>singleton(this);

protected AbstractEventExecutor() {
    this(null);
}

protected AbstractEventExecutor(EventExecutorGroup parent) {
    this.parent = parent;
}
```

## 6.2 parent

`#parent()` 方法，获得所属 EventExecutorGroup 。代码如下：

```
@Override
public EventExecutorGroup parent() {
    return parent;
}
```

## 6.3 next

`#next()` 方法，获得自己。代码如下：

```
@Override
public EventExecutor next() {
    return this;
}
```

## 6.4 inEventLoop()

`#inEventLoop()` 方法，判断当前线程是否在 EventLoop 线程中。代码如下：

```
@Override
public boolean inEventLoop() {
    return inEventLoop(Thread.currentThread());
}
```

- 具体的 `#inEventLoop(Thread thread)` 方法，需要在子类实现。因为 AbstractEventExecutor 类还体现不出它所拥有的线程。

## 6.5 iterator

`#iterator()` 方法，代码如下：

```
@Override
public Iterator<EventExecutor> iterator() {
    return selfCollection.iterator();
}
```

## 6.6 newPromise 和 newProgressivePromise

`#newPromise()` 和 `#newProgressivePromise()` 方法，分别创建 DefaultPromise 和 DefaultProgressivePromise 对象。代码如下：

```
@Override
public <V> Promise<V> newPromise() {
    return new DefaultPromise<V>(this);
}

@Override
public <V> ProgressivePromise<V> newProgressivePromise() {
    return new DefaultProgressivePromise<V>(this);
}
```

- 我们可以看到，创建的 Promise 对象，都会传入自身作为 EventExecutor 。关于 Promise 相关的，我们在后续文章详细解析。实在想了解，也可以看看 [《Netty 源码笔记 —— 第四章 Future 和 Promise》](https://www.kancloud.cn/ssj234/netty-source/433215)。

## 6.7 newSucceededFuture 和 newFailedFuture

`#newSucceededFuture(V result)` 和 `#newFailedFuture(Throwable cause)` 方法，分别创建成功结果和异常的 Future 对象。代码如下：

```
@Override
public <V> Future<V> newSucceededFuture(V result) {
    return new SucceededFuture<V>(this, result);
}

@Override
public <V> Future<V> newFailedFuture(Throwable cause) {
    return new FailedFuture<V>(this, cause);
}
```

- 创建的 Future 对象，会传入自身作为 EventExecutor ，并传入 `result` 或 `cause` 分别作为成功结果和异常。

## 6.8 newTaskFor

`#newTaskFor(...)` 方法，创建 PromiseTask 对象。代码如下：

```
@Override
protected final <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {
    return new PromiseTask<T>(this, runnable, value);
}

@Override
protected final <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {
    return new PromiseTask<T>(this, callable);
}
```

- 创建的 PromiseTask 对象，会传入自身作为 EventExecutor ，并传入 Runnable + Value 或 Callable 作为任务( Task )。

## 6.9 submit

`#submit(...)` 方法，提交任务。代码如下：

```
@Override
public Future<?> submit(Runnable task) {
    return (Future<?>) super.submit(task);
}

@Override
public <T> Future<T> submit(Runnable task, T result) {
    return (Future<T>) super.submit(task, result);
}

@Override
public <T> Future<T> submit(Callable<T> task) {
    return (Future<T>) super.submit(task);
}
```

- 每个方法的实现上，是调用父类 AbstractExecutorService 的实现。

## 6.10 schedule

`#schedule(...)` 方法，都不支持，交给子类 AbstractScheduledEventExecutor 实现。代码如下：

```
@Override
public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {
    throw new UnsupportedOperationException();
}
@Override
public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit) {
    throw new UnsupportedOperationException();
}

@Override
public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) {
    throw new UnsupportedOperationException();
}
@Override
public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) {
    throw new UnsupportedOperationException();
}
```

## 6.11 safeExecute

`#safeExecute(Runnable task)` **静态**方法，安全的执行任务。代码如下：

```
protected static void safeExecute(Runnable task) {
    try {
        task.run();
    } catch (Throwable t) {
        logger.warn("A task raised an exception. Task: {}", task, t);
    }
}
```

- 所谓“安全”指的是，当任务执行发生异常时，仅仅打印**告警**日志。

## 6.12 shutdown

`#shutdown()` 方法，关闭执行器。代码如下：

```
@Override
public Future<?> shutdownGracefully() {
    return shutdownGracefully(DEFAULT_SHUTDOWN_QUIET_PERIOD, DEFAULT_SHUTDOWN_TIMEOUT, TimeUnit.SECONDS);
}

@Override
@Deprecated
public List<Runnable> shutdownNow() {
    shutdown();
    return Collections.emptyList();
}
```

- 具体的 `#shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit)` 和 `#shutdown()` 方法的实现，在子类中。

# 7. AbstractScheduledEventExecutor

`io.netty.util.concurrent.AbstractScheduledEventExecutor` ，继承 AbstractEventExecutor 抽象类，**支持定时任务**的 EventExecutor 的抽象类。

详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（七）之 EventLoop 处理定时任务》](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init) 。

# 8. SingleThreadEventExecutor

`io.netty.util.concurrent.SingleThreadEventExecutor` ，实现 OrderedEventExecutor 接口，继承 AbstractScheduledEventExecutor 抽象类，基于单线程的 EventExecutor 抽象类，**即一个 EventExecutor 对应一个线程**。

## 8.1 构造方法

```
/**
 * {@link #state} 字段的原子更新器
 */
private static final AtomicIntegerFieldUpdater<SingleThreadEventExecutor> STATE_UPDATER =AtomicIntegerFieldUpdater.newUpdater(SingleThreadEventExecutor.class, "state");
/**
 * {@link #thread} 字段的原子更新器
 */
private static final AtomicReferenceFieldUpdater<SingleThreadEventExecutor, ThreadProperties> PROPERTIES_UPDATER = AtomicReferenceFieldUpdater.newUpdater(SingleThreadEventExecutor.class, ThreadProperties.class, "threadProperties");

/**
 * 任务队列
 *
 * @see #newTaskQueue(int)
 */
private final Queue<Runnable> taskQueue;
/**
 * 线程
 */
private volatile Thread thread;
/**
 * 线程属性
 */
@SuppressWarnings("unused")
private volatile ThreadProperties threadProperties;
/**
 * 执行器
 */
private final Executor executor;
/**
 * 线程是否已经打断
 *
 * @see #interruptThread()
 */
private volatile boolean interrupted;

/**
 * TODO 1006 EventLoop 优雅关闭
 */
private final Semaphore threadLock = new Semaphore(0);
/**
 * TODO 1006 EventLoop 优雅关闭
 */
private final Set<Runnable> shutdownHooks = new LinkedHashSet<Runnable>();
/**
 * 添加任务时，是否唤醒线程{@link #thread}
 */
private final boolean addTaskWakesUp;
/**
 * 最大等待执行任务数量，即 {@link #taskQueue} 的队列大小
 */
private final int maxPendingTasks;
/**
 * 拒绝执行处理器
 *
 * @see #reject()
 * @see #reject(Runnable)
 */
private final RejectedExecutionHandler rejectedExecutionHandler;

/**
 * 最后执行时间
 */
private long lastExecutionTime;

/**
 * 状态
 */
@SuppressWarnings({ "FieldMayBeFinal", "unused" })
private volatile int state = ST_NOT_STARTED;

/**
 * TODO 优雅关闭
 */
private volatile long gracefulShutdownQuietPeriod;
/**
 * 优雅关闭超时时间，单位：毫秒 TODO 1006 EventLoop 优雅关闭
 */
private volatile long gracefulShutdownTimeout;
/**
 * 优雅关闭开始时间，单位：毫秒 TODO 1006 EventLoop 优雅关闭
 */
private long gracefulShutdownStartTime;

/**
 * TODO 1006 EventLoop 优雅关闭
 */
private final Promise<?> terminationFuture = new DefaultPromise<Void>(GlobalEventExecutor.INSTANCE);

protected SingleThreadEventExecutor(
        EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) {
    this(parent, new ThreadPerTaskExecutor(threadFactory), addTaskWakesUp);
}

protected SingleThreadEventExecutor(
        EventExecutorGroup parent, ThreadFactory threadFactory,
        boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) {
    this(parent, new ThreadPerTaskExecutor(threadFactory), addTaskWakesUp, maxPendingTasks, rejectedHandler);
}

protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp) {
    this(parent, executor, addTaskWakesUp, DEFAULT_MAX_PENDING_EXECUTOR_TASKS, RejectedExecutionHandlers.reject());
}

protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor,
                                    boolean addTaskWakesUp, int maxPendingTasks,
                                    RejectedExecutionHandler rejectedHandler) {
    super(parent);
    this.addTaskWakesUp = addTaskWakesUp;
    this.maxPendingTasks = Math.max(16, maxPendingTasks);
    this.executor = ObjectUtil.checkNotNull(executor, "executor");
    taskQueue = newTaskQueue(this.maxPendingTasks);
    rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, "rejectedHandler");
}
```

- 属性比较多，我们耐心往下看。

- ```
  taskQueue
  
  ```

   

  属性，任务队列。

  - `addTaskWakesUp` 属性，添加任务到 `taskQueue` 队列时，是否唤醒 `thread` 线程。详细解析，见 [「8.11 execute」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。
  - `maxPendingTasks` 属性，最大等待执行任务数量，即 `taskQueue` 队列大小。
  - `rejectedExecutionHandler` 属性，拒绝执行处理器。在 `taskQueue` 队列超过最大任务数量时，怎么拒绝处理新提交的任务。

- `thread` 属性，线程。在 SingleThreadEventExecutor 中，任务是提交到 `taskQueue` 队列中，而执行在 `thread` 线程中。

  - `threadProperties` 属性，线程属性。详细解析，见 [「8.15 threadProperties」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

  - `executor` 属性，执行器。通过它创建 `thread` 线程。详细解析，见 [「8.11 execute」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

  - `interrupted` 属性，线程是否打断。详细解析，详细解析，见 [「8.14 interruptThread」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

  - `lastExecutionTime` 属性，最后执行时间。

  - `state` 属性，线程状态。SingleThreadEventExecutor 在实现上，`thread` 的初始化采用延迟启动的方式，只有在第一个任务时，`executor` 才会执行并创建该线程，从而节省资源。目前 `thread` 线程有 5 种状态，代码如下：

    ```
    private static final int ST_NOT_STARTED = 1; // 未开始
    private static final int ST_STARTED = 2; // 已开始
    private static final int ST_SHUTTING_DOWN = 3; // 正在关闭中
    private static final int ST_SHUTDOWN = 4; // 已关闭
    private static final int ST_TERMINATED = 5; // 已经终止
    
    ```

    - 状态变更流程如下图：![状态变更流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554274250717.png)

- 构造方法，虽然比较多，但是很简单，胖友自己看下。

## 8.2 newTaskQueue

`#newTaskQueue(int maxPendingTasks)` 方法，创建任务队列。代码如下：

```
/**
 * Create a new {@link Queue} which will holds the tasks to execute. This default implementation will return a
 * {@link LinkedBlockingQueue} but if your sub-class of {@link SingleThreadEventExecutor} will not do any blocking
 * calls on the this {@link Queue} it may make sense to {@code @Override} this and return some more performant
 * implementation that does not support blocking operations at all.
 */
protected Queue<Runnable> newTaskQueue(int maxPendingTasks) {
    return new LinkedBlockingQueue<Runnable>(maxPendingTasks);
}

```

- 方法上有一大段注释，简单的说，这个方法默认返回的是 LinkedBlockingQueue 阻塞队列。如果子类有更好的队列选择( 例如非阻塞队列 )，可以重写该方法。在下文，我们会看到它的子类 NioEventLoop ，就重写了这个方法。

## 8.3 inEventLoop

`#inEventLoop(Thread thread)` 方法，判断指定线程是否是 EventLoop 线程。代码如下：

```
@Override
public boolean inEventLoop(Thread thread) {
    return thread == this.thread;
}

```

## 8.4 offerTask

`#offerTask(Runnable task)` 方法，添加任务到队列中。若添加失败，则返回 `false` 。代码如下：

```
final boolean offerTask(Runnable task) {
    // 关闭时，拒绝任务
    if (isShutdown()) {
        reject();
    }
    // 添加任务到队列
    return taskQueue.offer(task);
}

```

- 注意，即使对于 BlockingQueue 的 `#offer(E e)` 方法，也**不是阻塞的**！

## 8.5 addTask

`#offerTask(Runnable task)` 方法，在 `#offerTask(Runnable task)` 的方法的基础上，若添加任务到队列中失败，则进行拒绝任务。代码如下：

```
protected void addTask(Runnable task) {
    if (task == null) {
        throw new NullPointerException("task");
    }
    // 添加任务到队列
    if (!offerTask(task)) {
        // 添加失败，则拒绝任务
        reject(task);
    }
}

```

- 调用 `#reject(task)` 方法，拒绝任务。详细解析，见 [「8.6 reject」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。
- 该方法是 `void` ，无返回值。

## 8.6 removeTask

`#removeTask(Runnable task)` 方法，移除指定任务。代码如下：

```
protected boolean removeTask(Runnable task) {
    if (task == null) {
        throw new NullPointerException("task");
    }
    return taskQueue.remove(task);
}

```

## 8.7 peekTask

`#peekTask()` 方法，返回队头的任务，但是**不移除**。代码如下：

```
protected Runnable peekTask() {
    assert inEventLoop(); // 仅允许在 EventLoop 线程中执行
    return taskQueue.peek();
}

```

## 8.8 hasTasks

`#hasTasks()` 方法，队列中是否有任务。代码如下：

```
protected boolean hasTasks() {
    assert inEventLoop(); // 仅允许在 EventLoop 线程中执行
    return !taskQueue.isEmpty();
}

```

## 8.9 pendingTasks

`#pendingTasks()` 方法，获得队列中的任务数。代码如下：

```
public int pendingTasks() {
    return taskQueue.size();
}

```

## 8.10 reject

`#reject(Runnable task)` 方法，拒绝任务。代码如下：

```
protected final void reject(Runnable task) {
    rejectedExecutionHandler.rejected(task, this);
}

```

- 调用 `RejectedExecutionHandler#rejected(Runnable task, SingleThreadEventExecutor executor)` 方法，拒绝该任务。

`#reject()` 方法，拒绝任何任务，用于 SingleThreadEventExecutor 已关闭( `#isShutdown()` 方法返回的结果为 `true` )的情况。代码如下：

```
protected static void reject() {
    throw new RejectedExecutionException("event executor terminated");
}

```

### 8.10.1 RejectedExecutionHandler

`io.netty.util.concurrent.RejectedExecutionHandler` ，拒绝执行处理器接口。代码如下：

```
/**
 * Called when someone tried to add a task to {@link SingleThreadEventExecutor} but this failed due capacity
 * restrictions.
 */
void rejected(Runnable task, SingleThreadEventExecutor executor);

```

### 8.10.2 RejectedExecutionHandlers

`io.netty.util.concurrent.RejectedExecutionHandlers` ，RejectedExecutionHandler 实现类枚举，目前有 2 种实现类。

**第一种**

```
private static final RejectedExecutionHandler REJECT = new RejectedExecutionHandler() {

    @Override
    public void rejected(Runnable task, SingleThreadEventExecutor executor) {
        throw new RejectedExecutionException();
    }

};

public static RejectedExecutionHandler reject() {
    return REJECT;
}

```

- 通过 `#reject()` 方法，返回 `REJECT` 实现类的对象。该实现在拒绝时，直接抛出 RejectedExecutionException 异常。
- 默认情况下，使用这种实现。

**第二种**

```
public static RejectedExecutionHandler backoff(final int retries, long backoffAmount, TimeUnit unit) {
    ObjectUtil.checkPositive(retries, "retries");
    final long backOffNanos = unit.toNanos(backoffAmount);
    return new RejectedExecutionHandler() {
        @Override
        public void rejected(Runnable task, SingleThreadEventExecutor executor) {
            if (!executor.inEventLoop()) { // 非 EventLoop 线程中。如果在 EventLoop 线程中，就无法执行任务，这就导致完全无法重试了。
                // 循环多次尝试添加到队列中
                for (int i = 0; i < retries; i++) {
                    // 唤醒执行器，进行任务执行。这样，就可能执行掉部分任务。
                    // Try to wake up the executor so it will empty its task queue.
                    executor.wakeup(false);

                    // 阻塞等待
                    LockSupport.parkNanos(backOffNanos);
                    // 添加任务
                    if (executor.offerTask(task)) {
                        return;
                    }
                }
            }
            // Either we tried to add the task from within the EventLoop or we was not able to add it even with
            // backoff.
            // 多次尝试添加失败，抛出 RejectedExecutionException 异常
            throw new RejectedExecutionException();
        }
    };
}

```

- 通过 `#backoff(final int retries, long backoffAmount, TimeUnit unit)` 方法，创建带多次尝试添加到任务队列的 RejectedExecutionHandler 实现类。
- 代码已经添加中文注释，胖友自己理解下，比较简单的。

## 8.11 execute

`#execute(Runnable task)` 方法，执行一个任务。但是方法名无法很完整的体现出具体的方法实现，甚至有一些出入，所以我们直接看源码，代码如下：

```
 1: @Override
 2: public void execute(Runnable task) {
 3:     if (task == null) {
 4:         throw new NullPointerException("task");
 5:     }
 6: 
 7:     // 获得当前是否在 EventLoop 的线程中
 8:     boolean inEventLoop = inEventLoop();
 9:     // 添加到任务队列
10:     addTask(task);
11:     if (!inEventLoop) {
12:         // 创建线程
13:         startThread();
14:         // 若已经关闭，移除任务，并进行拒绝
15:         if (isShutdown() && removeTask(task)) {
16:             reject();
17:         }
18:     }
19: 
20:     // 唤醒线程
21:     if (!addTaskWakesUp && wakesUpForTask(task)) {
22:         wakeup(inEventLoop);
23:     }
24: }

```

- 第 8 行：调用 `#inEventLoop()` 方法，获得当前是否在 EventLoop 的线程中。

- 第 10 行：调用 `#addTask(Runnable task)` 方法，添加任务到队列中。

- 第 11 行：非 EventLoop 的线程

  - 第 13 行：调用 `#startThread()` 方法，启动 EventLoop **独占**的线程，即 `thread` 属性。详细解析，见 [「8.12 startThread」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。
  - 第 14 至 17 行：若已经关闭，则移除任务，并拒绝执行。

- 第 20 至 23 行：调用 `#wakeup(boolean inEventLoop)` 方法，唤醒线程。详细解析，见 [「8.13 wakeup」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

  - 等等，第 21 行的`!addTaskWakesUp`有点奇怪，不是说好的`addTaskWakesUp`表示“添加任务时，是否唤醒线程”？！但是，怎么使用`!`取反了。这样反倒变成了，“添加任务时，是否【**不**】唤醒线程”。具体的原因是为什么呢？笔者 Google、Github Netty Issue、和基佬讨论，都未找到解答。目前笔者的理解是：`addTaskWakesUp`真正的意思是，“添加任务后，任务是否会自动导致线程唤醒”。为什么呢？

    - 对于 Nio 使用的 NioEventLoop ，它的线程执行任务是基于 Selector 监听感兴趣的事件，所以当任务添加到 `taskQueue` 队列中时，线程是无感知的，所以需要调用 `#wakeup(boolean inEventLoop)` 方法，进行**主动**的唤醒。
    - 对于 Oio 使用的 ThreadPerChannelEventLoop ，它的线程执行是基于 `taskQueue` 队列监听( **阻塞拉取** )事件和任务，所以当任务添加到 `taskQueue` 队列中时，线程是可感知的，相当于说，进行**被动**的唤醒。
    - 感谢闪电侠，证实我的理解是正确的。参见：
      - https://github.com/netty/netty/commit/23d017849429c18e1890b0a5799e5262df4f269f
        - ![提交图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/05-1554274250730.png)

  - 调用 `#wakesUpForTask(task)` 方法，判断该任务是否需要唤醒线程。代码如下：

    ```
    protected boolean wakesUpForTask(Runnable task) {
        return true;
    }
    
    ```

    - 默认返回 `true` 。在 [「9. SingleThreadEventLoop」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 中，我们会看到对该方法的重写。

## 8.12 startThread

`#startThread()` 方法，启动 EventLoop **独占**的线程，即 `thread` 属性。代码如下：

```
 1: private void doStartThread() {
 2:     assert thread == null;
 3:     executor.execute(new Runnable() {
 4: 
 5:         @Override
 6:         public void run() {
 7:             // 记录当前线程
 8:             thread = Thread.currentThread();
 9: 
10:             // 如果当前线程已经被标记打断，则进行打断操作。
11:             if (interrupted) {
12:                 thread.interrupt();
13:             }
14: 
15:             boolean success = false; // 是否执行成功
16: 
17:             // 更新最后执行时间
18:             updateLastExecutionTime();
19:             try {
20:                 // 执行任务
21:                 SingleThreadEventExecutor.this.run();
22:                 success = true; // 标记执行成功
23:             } catch (Throwable t) {
24:                 logger.warn("Unexpected exception from an event executor: ", t);
25:             } finally {
26:                 // TODO 1006 EventLoop 优雅关闭
27:                 for (;;) {
28:                     int oldState = state;
29:                     if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(
30:                             SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {
31:                         break;
32:                     }
33:                 }
34: 
35:                 // TODO 1006 EventLoop 优雅关闭
36:                 // Check if confirmShutdown() was called at the end of the loop.
37:                 if (success && gracefulShutdownStartTime == 0) {
38:                     if (logger.isErrorEnabled()) {
39:                         logger.error("Buggy " + EventExecutor.class.getSimpleName() + " implementation; " +
40:                                 SingleThreadEventExecutor.class.getSimpleName() + ".confirmShutdown() must " +
41:                                 "be called before run() implementation terminates.");
42:                     }
43:                 }
44: 
45:                 // TODO 1006 EventLoop 优雅关闭
46:                 try {
47:                     // Run all remaining tasks and shutdown hooks.
48:                     for (;;) {
49:                         if (confirmShutdown()) {
50:                             break;
51:                         }
52:                     }
53:                 } finally {
54:                     try {
55:                         cleanup(); // 清理，释放资源
56:                     } finally {
57:                         STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);
58:                         threadLock.release();
59:                         if (!taskQueue.isEmpty()) {
60:                             if (logger.isWarnEnabled()) {
61:                                 logger.warn("An event executor terminated with " +
62:                                         "non-empty task queue (" + taskQueue.size() + ')');
63:                             }
64:                         }
65: 
66:                         terminationFuture.setSuccess(null);
67:                     }
68:                 }
69:             }
70:             
71:         }
72:     });
73: }

```

- 第 2 行：断言，保证 `thread` 为空。

- 第 3 行 至 72 行：调用 `Executor#execute(Runnable runnable)` 方法，执行任务。下面，我们来详细解析。

- 第 8 行：赋值当前的线程给 `thread` 属性。这就是，每个 SingleThreadEventExecutor 独占的线程的创建方式。

- 第 10 至 13 行：如果当前线程已经被标记打断，则进行打断操作。为什么会有这样的逻辑呢？详细解析，见 [「8.14 interruptThread」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

- 第 18 行：调用 `#updateLastExecutionTime()` 方法，更新最后执行时间。代码如下：

  ```
  /**
   * Updates the internal timestamp that tells when a submitted task was executed most recently.
   * {@link #runAllTasks()} and {@link #runAllTasks(long)} updates this timestamp automatically, and thus there's
   * usually no need to call this method.  However, if you take the tasks manually using {@link #takeTask()} or
   * {@link #pollTask()}, you have to call this method at the end of task execution loop for accurate quiet period
   * checks.
   */
  protected void updateLastExecutionTime() {
      lastExecutionTime = ScheduledFutureTask.nanoTime();
  }
  
  ```

  - 英文注释，自己看。😈

- 第 21 行：调用 `SingleThreadEventExecutor#run()` 方法，执行任务。详细解析，见 [8.X run](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

- 第 25 至 69 行：TODO 1006 EventLoop 优雅关闭

- 第 55 行：调用 `#cleanup()` 方法，清理释放资源。详细解析，见 [8.X cleanup](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

## 8.13 wakeup

`#wakeup(boolean inEventLoop)` 方法，唤醒线程。代码如下：

```
protected void wakeup(boolean inEventLoop) {
    if (!inEventLoop // <1>
            || state == ST_SHUTTING_DOWN) { // TODO 1006 EventLoop 优雅关闭
        // Use offer as we actually only need this to unblock the thread and if offer fails we do not care as there
        // is already something in the queue.
        taskQueue.offer(WAKEUP_TASK); // <2>
    }
}

```

- `<1>` 处的 `!inEventLoop` 代码段，判断不在 EventLoop 的线程中。因为，如果在 EventLoop 线程中，意味着线程就在执行中，不必要唤醒。

- `<2>` 处，调用 `Queue#offer(E e)` 方法，添加任务到队列中。而添加的任务是 `WAKEUP_TASK` ，代码如下：

  ```
  private static final Runnable WAKEUP_TASK = new Runnable() {
      @Override
      public void run() {
          // Do nothing.
      }
  };
  
  ```

  - 这是一个空的 Runnable 实现类。仅仅用于唤醒基于 `taskQueue` 阻塞拉取的 EventLoop 实现类。

  - 对于 NioEventLoop 会重写该方法，代码如下：

    ```
    @Override
    protected void wakeup(boolean inEventLoop) {
        if (!inEventLoop && wakenUp.compareAndSet(false, true)) {
            selector.wakeup();
        }
    }
    
    ```

    - 通过 NIO Selector 唤醒。

## 8.14 interruptThread

`#interruptThread()` 方法，打断 EventLoop 的线程。代码如下：

```
protected void interruptThread() {
    Thread currentThread = thread;
    // 线程不存在，则标记线程被打断
    if (currentThread == null) {
        interrupted = true;
    // 打断线程
    } else {
        currentThread.interrupt();
    }
}

```

- 因为 EventLoop 的线程是延迟启动，所以可能 `thread` 并未创建，此时通过 `interrupted` 标记打断。之后在 `#startThread()` 方法中，创建完线程后，再进行打断，也就是说，“延迟打断”。

## 8.15 threadProperties

`#threadProperties()` 方法，获得 EventLoop 的线程属性。代码如下：

```
 1: public final ThreadProperties threadProperties() {
 2:     ThreadProperties threadProperties = this.threadProperties;
 3:     if (threadProperties == null) {
 4:         Thread thread = this.thread;
 5:         if (thread == null) {
 6:             assert !inEventLoop();
 7:             // 提交空任务，促使 execute 方法执行
 8:             submit(NOOP_TASK).syncUninterruptibly();
 9:             // 获得线程
10:             thread = this.thread;
11:             assert thread != null;
12:         }
13: 
14:         // 创建 DefaultThreadProperties 对象
15:         threadProperties = new DefaultThreadProperties(thread);
16:         // CAS 修改 threadProperties 属性
17:         if (!PROPERTIES_UPDATER.compareAndSet(this, null, threadProperties)) {
18:             threadProperties = this.threadProperties;
19:         }
20:     }
21: 
22:     return threadProperties;
23: }

```

- 第 2 至 3 行：获得 ThreadProperties 对象。若不存在，则进行创建 ThreadProperties 对象。
  - 第 4 至 5 行：获得 EventLoop 的线程。因为线程是延迟启动的，所以会出现线程为空的情况。若线程为空，则需要进行创建。
    - 第 8 行：调用 `#submit(Runnable)` 方法，提交任务，就能促使 `#execute(Runnable)` 方法执行。如下图所示：![submit => execute 的流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554274250722.png)
    - 第 8 行：调用 `Future#syncUninterruptibly()` 方法，保证 `execute()` 方法中**异步**创建 `thread` 完成。
    - 第 10 至 11 行：获得线程，并断言保证线程存在。
  - 第 15 行：调用 DefaultThreadProperties 对象。
  - 第 16 至 19 行：CAS 修改 `threadProperties` 属性。
- 第 22 行：返回 `threadProperties` 。

### 8.15.1 ThreadProperties

`io.netty.util.concurrent.ThreadProperties` ，线程属性接口。代码如下：

```
Thread.State state();

int priority();

boolean isInterrupted();

boolean isDaemon();

String name();

long id();

StackTraceElement[] stackTrace();

boolean isAlive();

```

### 8.15.2 DefaultThreadProperties

DefaultThreadProperties 实现 ThreadProperties 接口，默认线程属性实现类。代码如下：

> DefaultThreadProperties 内嵌在 SingleThreadEventExecutor 中。

```
private static final class DefaultThreadProperties implements ThreadProperties {

    private final Thread t;

    DefaultThreadProperties(Thread t) {
        this.t = t;
    }

    @Override
    public State state() {
        return t.getState();
    }

    @Override
    public int priority() {
        return t.getPriority();
    }

    @Override
    public boolean isInterrupted() {
        return t.isInterrupted();
    }

    @Override
    public boolean isDaemon() {
        return t.isDaemon();
    }

    @Override
    public String name() {
        return t.getName();
    }

    @Override
    public long id() {
        return t.getId();
    }

    @Override
    public StackTraceElement[] stackTrace() {
        return t.getStackTrace();
    }

    @Override
    public boolean isAlive() {
        return t.isAlive();
    }

}

```

- 我们可以看到，每个实现方法，实际上就是对被包装的线程 `t` 的方法的封装。
- 那为什么 `#threadProperties()` 方法不直接返回 `thread` 呢？因为如果直接返回 `thread` ，调用方可以调用到该变量的其他方法，这个是我们不希望看到的。

## 8.16 run

`#run()` 方法，它是一个**抽象方法**，由子类实现，如何执行 `taskQueue` 队列中的任务。代码如下：

```
protected abstract void run();

```

SingleThreadEventExecutor 提供了很多执行任务的方法，方便子类在实现自定义运行任务的逻辑时：

- [x] `#runAllTasks()`
- [x] `#runAllTasks(long timeoutNanos)`
- [x] `#runAllTasksFrom(Queue<Runnable> taskQueue)`
- [x] `#afterRunningAllTasks()`
- [x] `#pollTask()`
- [x] `#pollTaskFrom(Queue<Runnable> taskQueue)`
- `#takeTask()`
- `#fetchFromScheduledTaskQueue()`
- `#delayNanos(long currentTimeNanos)`

详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（四）之 EventLoop 运行》](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run) 。

## 8.17 cleanup

`#cleanup()` 方法，清理释放资源。代码如下：

```
/**
 * Do nothing, sub-classes may override
 */
protected void cleanup() {
    // NOOP
}

```

- 目前该方法为空的。在子类 NioEventLoop 中，我们会看到它覆写该方法，关闭 NIO Selector 对象。

## 8.18 invokeAll

`#invokeAll(...)` 方法，在 EventExecutor 中执行**多个**普通任务。代码如下：

```
@Override
public <T> List<java.util.concurrent.Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException {
    throwIfInEventLoop("invokeAll");
    return super.invokeAll(tasks);
}

@Override
public <T> List<java.util.concurrent.Future<T>> invokeAll(
        Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit) throws InterruptedException {
    throwIfInEventLoop("invokeAll");
    return super.invokeAll(tasks, timeout, unit);
}

```

- 调用 `#throwIfInEventLoop(String method)` 方法，判断若在 EventLoop 的线程中调用该方法，抛出 RejectedExecutionException 异常。代码如下：

  ```
  private void throwIfInEventLoop(String method) {
      if (inEventLoop()) {
          throw new RejectedExecutionException("Calling " + method + " from within the EventLoop is not allowed");
      }
  }
  
  ```

- 调用父类 AbstractScheduledEventExecutor 的 `#invokeAll(tasks, ...)` 方法，执行**多个**普通任务。在该方法内部，会调用 `#execute(Runnable task)` 方法，执行任务。调用栈如下图：![invokeAll => execute 的流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554274250737.png)

## 8.19 invokeAny

> 和 `#invokeAll(...)` 方法，**类似**。

`#invokeAll(...)` 方法，在 EventExecutor 中执行**多个**普通任务，有**一个**执行完成即可。代码如下：

```
@Override
public <T> T invokeAny(Collection<? extends Callable<T>> tasks) throws InterruptedException, ExecutionException {
    throwIfInEventLoop("invokeAny");
    return super.invokeAny(tasks);
}

@Override
public <T> T invokeAny(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException {
    throwIfInEventLoop("invokeAny");
    return super.invokeAny(tasks, timeout, unit);
}

```

- 调用 `#throwIfInEventLoop(String method)` 方法，判断若在 EventLoop 的线程中调用该方法，抛出 RejectedExecutionException 异常。
- 调用父类 AbstractScheduledEventExecutor 的 `#invokeAny(tasks, ...)` 方法，执行**多个**普通任务，有**一个**执行完成即可。在该方法内部，会调用 `#execute(Runnable task)` 方法，执行任务。调用栈如下图：![invokeAny => execute 的流程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/04-1554274250766.png)

## 8.20 shutdown

如下是优雅关闭，我们在 TODO 1006 EventLoop 优雅关闭

- `#addShutdownHook(final Runnable task)`
- `#removeShutdownHook(final Runnable task)`
- `#runShutdownHooks()`
- `#shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit)`
- `#shutdown()`
- `#terminationFuture()`
- `#isShuttingDown()`
- `#isShutdown()`
- `#isTerminated()`
- `#confirmShutdown()`
- `#awaitTermination(long timeout, TimeUnit unit)`

# 9. SingleThreadEventLoop

`io.netty.channel.SingleThreadEventLoop` ，实现 EventLoop 接口，继承 SingleThreadEventExecutor 抽象类，基于单线程的 EventLoop 抽象类，主要增加了 Channel 注册到 EventLoop 上。

## 9.1 构造方法

```
/**
 * 默认任务队列最大数量
 */
protected static final int DEFAULT_MAX_PENDING_TASKS = Math.max(16, SystemPropertyUtil.getInt("io.netty.eventLoop.maxPendingTasks", Integer.MAX_VALUE));

/**
 * 尾部任务队列，执行在 {@link #taskQueue} 之后
 *
 * Commits
 *  * [Ability to run a task at the end of an eventloop iteration.](https://github.com/netty/netty/pull/5513)
 *
 * Issues
 *  * [Auto-flush for channels. (`ChannelHandler` implementation)](https://github.com/netty/netty/pull/5716)
 *  * [Consider removing executeAfterEventLoopIteration](https://github.com/netty/netty/issues/7833)
 *
 * 老艿艿：未来会移除该队列，前提是实现了 Channel 的 auto flush 功能。按照最后一个 issue 的讨论
 */
private final Queue<Runnable> tailTasks;

protected SingleThreadEventLoop(EventLoopGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) {
    this(parent, threadFactory, addTaskWakesUp, DEFAULT_MAX_PENDING_TASKS, RejectedExecutionHandlers.reject());
}

protected SingleThreadEventLoop(EventLoopGroup parent, Executor executor, boolean addTaskWakesUp) {
    this(parent, executor, addTaskWakesUp, DEFAULT_MAX_PENDING_TASKS, RejectedExecutionHandlers.reject());
}

protected SingleThreadEventLoop(EventLoopGroup parent, ThreadFactory threadFactory,
                                boolean addTaskWakesUp, int maxPendingTasks,
                                RejectedExecutionHandler rejectedExecutionHandler) {
    super(parent, threadFactory, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler);
    tailTasks = newTaskQueue(maxPendingTasks);
}

protected SingleThreadEventLoop(EventLoopGroup parent, Executor executor,
                                boolean addTaskWakesUp, int maxPendingTasks,
                                RejectedExecutionHandler rejectedExecutionHandler) {
    super(parent, executor, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler);
    tailTasks = newTaskQueue(maxPendingTasks);
}

```

- 新增了一条 `tailTasks` 队列，执行的顺序在 `taskQueue` 之后。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（六）之 EventLoop 处理普通任务》](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task) 。
- 构造方法比较简单，胖友自己看下就可以了。

## 9.2 parent

`#parent()` 方法，获得所属 EventLoopGroup 。代码如下：

```
@Override
public EventLoopGroup parent() {
    return (EventLoopGroup) super.parent();
}

```

- 覆盖父类方法，将返回值转换成 EventLoopGroup 类。

## 9.3 next

`#next()` 方法，获得自己。代码如下：

```
@Override
public EventLoop next() {
    return (EventLoop) super.next();
}

```

- 覆盖父类方法，将返回值转换成 EventLoop 类。

## 9.4 register

`#register(Channel channel)` 方法，注册 Channel 到 EventLoop 上。代码如下：

```
@Override
public ChannelFuture register(Channel channel) {
    return register(new DefaultChannelPromise(channel, this));
}

```

- 将 Channel 和 EventLoop 创建一个 DefaultChannelPromise 对象。通过这个 DefaultChannelPromise 对象，我们就能实现对**异步**注册过程的监听。

- 调用 `#register(final ChannelPromise promise)` 方法，注册 Channel 到 EventLoop 上。代码如下：

  ```
  @Override
  public ChannelFuture register(final ChannelPromise promise) {
      ObjectUtil.checkNotNull(promise, "promise");
      // 注册 Channel 到 EventLoop 上
      promise.channel().unsafe().register(this, promise);
      // 返回 ChannelPromise 对象
      return promise;
  }
  
  ```

  - 在方法内部，我们就看到在 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server?self) 的 [「3.14.3 注册 Channel 到 EventLoopGroup」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 章节，熟悉的内容，调用 `AbstractUnsafe#register(EventLoop eventLoop, final ChannelPromise promise)` 方法，**注册 Channel 到 EventLoop 上**。

## 9.5 hasTasks

`#hasTasks()` 方法，队列中是否有任务。代码如下：

```
@Override
protected boolean hasTasks() {
    return super.hasTasks() || !tailTasks.isEmpty();
}

```

- 基于两个队列来判断是否还有任务。

## 9.6 pendingTasks

`#pendingTasks()` 方法，获得队列中的任务数。代码如下：

```
@Override
public int pendingTasks() {
    return super.pendingTasks() + tailTasks.size();
}

```

- 计算两个队列的任务之和。

## 9.7 executeAfterEventLoopIteration

`#executeAfterEventLoopIteration(Runnable task)` 方法，执行一个任务。但是方法名无法很完整的体现出具体的方法实现，甚至有一些出入，所以我们直接看源码，代码如下：

```
 1: @UnstableApi
 2: public final void executeAfterEventLoopIteration(Runnable task) {
 3:     ObjectUtil.checkNotNull(task, "task");
 4:     // 关闭时，拒绝任务
 5:     if (isShutdown()) {
 6:         reject();
 7:     }
 8: 
 9:     // 添加到任务队列
10:     if (!tailTasks.offer(task)) {
11:         // 添加失败，则拒绝任务
12:         reject(task);
13:     }
14: 
15:     // 唤醒线程
16:     if (wakesUpForTask(task)) {
17:         wakeup(inEventLoop());
18:     }
19: }

```

- 第 4 至 7 行：SingleThreadEventLoop 关闭时，拒绝任务。
- 第 10 行：调用`Queue#offer(E e)` 方法，添加任务到队列中。
  - 第 12 行：若添加失败，调用 `#reject(Runnable task)` 方法，拒绝任务。
- 第 15 至 18 行：唤醒线程。
  - 第 16 行：SingleThreadEventLoop 重写了 `#wakesUpForTask(Runnable task)` 方法。详细解析，见 [「9.9 wakesUpForTask」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 。

## 9.8 removeAfterEventLoopIterationTask

`#removeAfterEventLoopIterationTask(Runnable task)` 方法，移除指定任务。代码如下：

```
@UnstableApi
final boolean removeAfterEventLoopIterationTask(Runnable task) {
    return tailTasks.remove(ObjectUtil.checkNotNull(task, "task"));
}

```

## 9.9 wakesUpForTask

`#wakesUpForTask(task)` 方法，判断该任务是否需要唤醒线程。代码如下：

```
@Override
protected boolean wakesUpForTask(Runnable task) {
    return !(task instanceof NonWakeupRunnable);
}

```

- 当任务类型为 NonWakeupRunnable ，则不进行唤醒线程。

### 9.9.1 NonWakeupRunnable

NonWakeupRunnable 实现 Runnable 接口，用于标记不唤醒线程的任务。代码如下：

```
/**
 * Marker interface for {@link Runnable} that will not trigger an {@link #wakeup(boolean)} in all cases.
 */
interface NonWakeupRunnable extends Runnable { }

```

## 9.10 afterRunningAllTasks

`#afterRunningAllTasks()` 方法，在运行完所有任务后，执行 `tailTasks` 队列中的任务。代码如下：

```
protected void afterRunningAllTasks() {
    runAllTasksFrom(tailTasks);
}

```

- 调用 `#runAllTasksFrom(queue)` 方法，执行 `tailTasks` 队列中的所有任务。

# 10. NioEventLoop

`io.netty.channel.nio.NioEventLoop` ，继承 SingleThreadEventLoop 抽象类，NIO EventLoop 实现类，实现对注册到其中的 Channel 的就绪的 IO 事件，和对用户提交的任务进行处理。

详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（四）之 EventLoop 运行》](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run) 。

# 666. 彩蛋

自顶向下的过了下 EventLoop 相关的类和方法。因为仅涉及 EventLoop 初始化相关的内容，所以对于 EventLoop 运行相关的内容，就不得不省略了。

那么，饥渴难耐的我们，[《精尽 Netty 源码解析 —— EventLoop（四）之 EventLoop 运行》](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run) ，走起！

------

推荐阅读如下文章：

- 永顺 [《Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)》](https://segmentfault.com/a/1190000007403873#articleHeader7) 的 [「NioEventLoop」](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/#) 小节。
- Hypercube [《自顶向下深入分析Netty（四）—— EventLoop-2》](https://www.jianshu.com/p/d0f06b13e2fb)

# 精尽 Netty 源码解析 —— EventLoop（四）之 EventLoop 运行



# 1. 概述

本文我们分享 EventLoop 的**运行**相关代码的实现。

因为 EventLoop 的**运行**主要是通过 NioEventLoop 的 `#run()` 方法实现，考虑到内容相对的完整性，在 [《精尽 Netty 源码解析 —— EventLoop（三）之 EventLoop 初始化》](http://svip.iocoder.cn/) 一文中，我们并未分享 NioEventLoop 的**初始化**，所以本文也会分享这部分的内容。

OK ，还是老样子，自上而下的方式，一起来看看 NioEventLoop 的代码实现。

> 老艿艿，本文的重点在 [「2.9 run」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 和 [「2.12 select」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 中。

# 2. NioEventLoop

`io.netty.channel.nio.NioEventLoop` ，继承 SingleThreadEventLoop 抽象类，NIO EventLoop 实现类，实现对注册到其中的 Channel 的就绪的 IO 事件，和对用户提交的任务进行处理。

## 2.1 static

在 `static` 代码块中，初始化了 NioEventLoop 的静态属性们。代码如下：

```
/**
 * TODO 1007 NioEventLoop cancel
 */
private static final int CLEANUP_INTERVAL = 256; // XXX Hard-coded value, but won't need customization.

/**
 * 是否禁用 SelectionKey 的优化，默认开启
 */
private static final boolean DISABLE_KEYSET_OPTIMIZATION = SystemPropertyUtil.getBoolean("io.netty.noKeySetOptimization", false);

/**
 * 少于该 N 值，不开启空轮询重建新的 Selector 对象的功能
 */
private static final int MIN_PREMATURE_SELECTOR_RETURNS = 3;
/**
 * NIO Selector 空轮询该 N 次后，重建新的 Selector 对象
 */
private static final int SELECTOR_AUTO_REBUILD_THRESHOLD;

static {
    // 解决 Selector#open() 方法 // <1>
    final String key = "sun.nio.ch.bugLevel";
    final String buglevel = SystemPropertyUtil.get(key);
    if (buglevel == null) {
        try {
            AccessController.doPrivileged(new PrivilegedAction<Void>() {
                @Override
                public Void run() {
                    System.setProperty(key, "");
                    return null;
                }
            });
        } catch (final SecurityException e) {
            logger.debug("Unable to get/set System Property: " + key, e);
        }
    }

    // 初始化
    int selectorAutoRebuildThreshold = SystemPropertyUtil.getInt("io.netty.selectorAutoRebuildThreshold", 512);
    if (selectorAutoRebuildThreshold < MIN_PREMATURE_SELECTOR_RETURNS) {
        selectorAutoRebuildThreshold = 0;
    }
    SELECTOR_AUTO_REBUILD_THRESHOLD = selectorAutoRebuildThreshold;

    if (logger.isDebugEnabled()) {
        logger.debug("-Dio.netty.noKeySetOptimization: {}", DISABLE_KEYSET_OPTIMIZATION);
        logger.debug("-Dio.netty.selectorAutoRebuildThreshold: {}", SELECTOR_AUTO_REBUILD_THRESHOLD);
    }
}
```

- `CLEANUP_INTERVAL` 属性，TODO 1007 NioEventLoop cancel

- `DISABLE_KEYSET_OPTIMIZATION` 属性，是否禁用 SelectionKey 的优化，默认开启。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。

- ```
  SELECTOR_AUTO_REBUILD_THRESHOLD
  ```

   

  属性，NIO Selector 空轮询该 N 次后，重建新的 Selector 对象，用以解决 JDK NIO 的 epoll 空轮询 Bug 。

  - `MIN_PREMATURE_SELECTOR_RETURNS` 属性，少于该 N 值，不开启空轮询重建新的 Selector 对象的功能。

- `<1>` 处，解决 `Selector#open()` 方法，发生 NullPointException 异常。详细解析，见 <http://bugs.sun.com/view_bug.do?bug_id=6427854> 和 <https://github.com/netty/netty/issues/203> 。

- `<2>` 处，初始化 `SELECTOR_AUTO_REBUILD_THRESHOLD` 属性。默认 512 。

## 2.2 构造方法

```
/**
 * The NIO {@link Selector}.
 *
 * 包装的 Selector 对象，经过优化
 *
 * {@link #openSelector()}
 */
private Selector selector;
/**
 * 未包装的 Selector 对象
 */
private Selector unwrappedSelector;
/**
 * 注册的 SelectionKey 集合。Netty 自己实现，经过优化。
 */
private SelectedSelectionKeySet selectedKeys;
/**
 * SelectorProvider 对象，用于创建 Selector 对象
 */
private final SelectorProvider provider;

/**
 * Boolean that controls determines if a blocked Selector.select should
 * break out of its selection process. In our case we use a timeout for
 * the select method and the select method will block for that time unless
 * waken up.
 *
 * 唤醒标记。因为唤醒方法 {@link Selector#wakeup()} 开销比较大，通过该标识，减少调用。
 *
 * @see #wakeup(boolean)
 * @see #run() 
 */
private final AtomicBoolean wakenUp = new AtomicBoolean();
/**
 * Select 策略
 *
 * @see #select(boolean)
 */
private final SelectStrategy selectStrategy;
/**
 * 处理 Channel 的就绪的 IO 事件，占处理任务的总时间的比例
 */
private volatile int ioRatio = 50;
/**
 * 取消 SelectionKey 的数量
 *
 * TODO 1007 NioEventLoop cancel
 */
private int cancelledKeys;
/**
 * 是否需要再次 select Selector 对象
 *
 * TODO 1007 NioEventLoop cancel
 */
private boolean needsToSelectAgain;

NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,
             SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) {
    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);
    if (selectorProvider == null) {
        throw new NullPointerException("selectorProvider");
    }
    if (strategy == null) {
        throw new NullPointerException("selectStrategy");
    }
    provider = selectorProvider;
    // 创建 Selector 对象 <1>
    final SelectorTuple selectorTuple = openSelector();
    selector = selectorTuple.selector;
    unwrappedSelector = selectorTuple.unwrappedSelector;
    selectStrategy = strategy;
}
```

- Selector 相关：
  - `unwrappedSelector` 属性，未包装的 NIO Selector 对象。
  - `selector` 属性，包装的 NIO Selector 对象。Netty 对 NIO Selector 做了优化。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。
  - `selectedKeys` 属性，注册的 NIO SelectionKey 集合。Netty 自己实现，经过优化。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。
  - `provider` 属性，NIO SelectorProvider 对象，用于创建 NIO Selector 对象。
  - 在 `<1>` 处，调用 `#openSelector()` 方法，创建 NIO Selector 对象。
- `wakenUp` 属性，唤醒标记。因为唤醒方法 `Selector#wakeup()` 开销比较大，通过该标识，减少调用。详细解析，见 [「2.8 wakeup」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 。
- `selectStrategy` 属性，Select 策略。详细解析，见 [「2.10 SelectStrategy」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 。
- `ioRatio` 属性，在 NioEventLoop 中，会三种类型的任务：1) Channel 的就绪的 IO 事件；2) 普通任务；3) 定时任务。而 `ioRatio` 属性，处理 Channel 的就绪的 IO 事件，占处理任务的总时间的比例。
- 取消 SelectionKey 相关：
  - `cancelledKeys` 属性， 取消 SelectionKey 的数量。TODO 1007 NioEventLoop cancel
  - `needsToSelectAgain` 属性，是否需要再次 select Selector 对象。TODO 1007 NioEventLoop cancel

## 2.3 openSelector

`#openSelector()` 方法，创建 NIO Selector 对象。

考虑到让本文更专注在 EventLoop 的逻辑，并且不影响对本文的理解，所以暂时不讲解它的具体实现。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。

## 2.4 rebuildSelector

`#rebuildSelector()` 方法，重建 NIO Selector 对象。

考虑到让本文更专注在 EventLoop 的逻辑，并且不影响对本文的理解，所以暂时不讲解它的具体实现。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。

## 2.5 newTaskQueue

`#newTaskQueue(int maxPendingTasks)` 方法，创建任务队列。代码如下：

> 该方法覆写父类的该方法。

```
@Override
protected Queue<Runnable> newTaskQueue(int maxPendingTasks) {
    // This event loop never calls takeTask()
    return maxPendingTasks == Integer.MAX_VALUE ? PlatformDependent.<Runnable>newMpscQueue()
                                                : PlatformDependent.<Runnable>newMpscQueue(maxPendingTasks);
}
```

- 调用 `PlatformDependent#newMpscQueue(...)` 方法，创建 mpsc 队列。我们来看看代码注释对 mpsc 队列的描述：

  ```
  Create a new {@link Queue} which is safe to use for multiple producers (different threads) and a single consumer (one thread!).
  ```

  - mpsc 是 multiple producers and a single consumer 的缩写。
  - mpsc 是对**多**线程生产任务，**单**线程消费任务的消费，恰好符合 NioEventLoop 的情况。
  - 详细解析，见后续文章。当然，着急的胖友，可以先看看 [《原理剖析（第 012 篇）Netty 之无锁队列 MpscUnboundedArrayQueue 原理分析》](https://www.jianshu.com/p/119a03332619) 。

## 2.6 pendingTasks

`#pendingTasks()` 方法，获得待执行的任务数量。代码如下：

> 该方法覆写父类的该方法。

```
@Override
public int pendingTasks() {
    // As we use a MpscQueue we need to ensure pendingTasks() is only executed from within the EventLoop as
    // otherwise we may see unexpected behavior (as size() is only allowed to be called by a single consumer).
    // See https://github.com/netty/netty/issues/5297
    if (inEventLoop()) {
        return super.pendingTasks();
    } else {
        return submit(pendingTasksCallable).syncUninterruptibly().getNow();
    }
}
```

- 因为 MpscQueue 仅允许单消费，所以获得队列的大小，仅允许在 EventLoop 的线程中调用。

## 2.7 setIoRatio

`#setIoRatio(int ioRatio)` 方法，设置 `ioRatio` 属性。代码如下：

```
/**
 * Sets the percentage of the desired amount of time spent for I/O in the event loop.  The default value is
 * {@code 50}, which means the event loop will try to spend the same amount of time for I/O as for non-I/O tasks.
 */
public void setIoRatio(int ioRatio) {
    if (ioRatio <= 0 || ioRatio > 100) {
        throw new IllegalArgumentException("ioRatio: " + ioRatio + " (expected: 0 < ioRatio <= 100)");
    }
    this.ioRatio = ioRatio;
}
```

## 2.8 wakeup

`#wakeup(boolean inEventLoop)` 方法，唤醒线程。代码如下：

```
@Override
protected void wakeup(boolean inEventLoop) {
    if (!inEventLoop && wakenUp.compareAndSet(false, true)) { // <2>
        selector.wakeup(); // <1>
    }
}
```

- `<1>` 处，因为 NioEventLoop 的线程阻塞，主要是调用 `Selector#select(long timeout)` 方法，阻塞等待有 Channel 感兴趣的 IO 事件，或者超时。所以需要调用 `Selector#wakeup()` 方法，进行唤醒 Selector 。
- `<2>` 处，因为 `Selector#wakeup()` 方法的唤醒操作是开销比较大的操作，并且每次重复调用相当于重复唤醒。所以，通过 `wakenUp` 属性，通过 CAS 修改 `false => true` ，保证有且仅有进行一次唤醒。
- 当然，详细的解析，可以结合 [「2.9 run」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 一起看，这样会更加清晰明了。

## 2.9 run

`#run()` 方法，NioEventLoop 运行，处理任务。**这是本文最重要的方法**。代码如下：

```
 1: @Override
 2: protected void run() {
 3:     for (;;) {
 4:         try {
 5:             switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) {
 6:                 case SelectStrategy.CONTINUE: // 默认实现下，不存在这个情况。
 7:                     continue;
 8:                 case SelectStrategy.SELECT:
 9:                     // 重置 wakenUp 标记为 false
10:                     // 选择( 查询 )任务
11:                     select(wakenUp.getAndSet(false));
12: 
13:                     // 'wakenUp.compareAndSet(false, true)' is always evaluated
14:                     // before calling 'selector.wakeup()' to reduce the wake-up
15:                     // overhead. (Selector.wakeup() is an expensive operation.)
16:                     //
17:                     // However, there is a race condition in this approach.
18:                     // The race condition is triggered when 'wakenUp' is set to
19:                     // true too early.
20:                     //
21:                     // 'wakenUp' is set to true too early if:
22:                     // 1) Selector is waken up between 'wakenUp.set(false)' and
23:                     //    'selector.select(...)'. (BAD)
24:                     // 2) Selector is waken up between 'selector.select(...)' and
25:                     //    'if (wakenUp.get()) { ... }'. (OK)
26:                     //
27:                     // In the first case, 'wakenUp' is set to true and the
28:                     // following 'selector.select(...)' will wake up immediately.
29:                     // Until 'wakenUp' is set to false again in the next round,
30:                     // 'wakenUp.compareAndSet(false, true)' will fail, and therefore
31:                     // any attempt to wake up the Selector will fail, too, causing
32:                     // the following 'selector.select(...)' call to block
33:                     // unnecessarily.
34:                     //
35:                     // To fix this problem, we wake up the selector again if wakenUp
36:                     // is true immediately after selector.select(...).
37:                     // It is inefficient in that it wakes up the selector for both
38:                     // the first case (BAD - wake-up required) and the second case
39:                     // (OK - no wake-up required).
40: 
41:                     // 唤醒。原因，见上面中文注释
42:                     if (wakenUp.get()) {
43:                         selector.wakeup();
44:                     }
45:                     // fall through
46:                 default:
47:             }
48: 
49:             // TODO 1007 NioEventLoop cancel 方法
50:             cancelledKeys = 0;
51:             needsToSelectAgain = false;
52: 
53:             final int ioRatio = this.ioRatio;
54:             if (ioRatio == 100) {
55:                 try {
56:                     // 处理 Channel 感兴趣的就绪 IO 事件
57:                     processSelectedKeys();
58:                 } finally {
59:                     // 运行所有普通任务和定时任务，不限制时间
60:                     // Ensure we always run tasks.
61:                     runAllTasks();
62:                 }
63:             } else {
64:                 final long ioStartTime = System.nanoTime();
65:                 try {
66:                     // 处理 Channel 感兴趣的就绪 IO 事件
67:                     processSelectedKeys();
68:                 } finally {
69:                     // 运行所有普通任务和定时任务，限制时间
70:                     // Ensure we always run tasks.
71:                     final long ioTime = System.nanoTime() - ioStartTime;
72:                     runAllTasks(ioTime * (100 - ioRatio) / ioRatio);
73:                 }
74:             }
75:         } catch (Throwable t) {
76:             handleLoopException(t);
77:         }
78:         // TODO 1006 EventLoop 优雅关闭
79:         // Always handle shutdown even if the loop processing threw an exception.
80:         try {
81:             if (isShuttingDown()) {
82:                 closeAll();
83:                 if (confirmShutdown()) {
84:                     return;
85:                 }
86:             }
87:         } catch (Throwable t) {
88:             handleLoopException(t);
89:         }
90:     }
91: }
```

- 第 3 行：“死”循环，直到 NioEventLoop 关闭，即【第 78 至 89 行】的代码。

- 第 5 行：调用

   

  ```
  SelectStrategy#calculateStrategy(IntSupplier selectSupplier, boolean hasTasks)
  ```

   

  方法，获得使用的 select 策略。详细解析，胖友先跳到

   

  「2.10 SelectStrategy」

   

  中研究。😈 看完回来。

  - 我们知道 `SelectStrategy#calculateStrategy(...)` 方法，有 3 种返回的情况。

  - 第 6 至 7 行：第一种，`SelectStrategy.CONTINUE` ，默认实现下，不存在这个情况。

  - 第 8 至 44 行：第二种，

    ```
    SelectStrategy.SELECT
    ```

     

    ，进行 Selector

     

    阻塞

     

    select 。

    - 第 11 行：重置 `wakeUp` 标识为 `false` ，并返回修改前的值。

    - 第 11 行：调用 `#select(boolean oldWakeUp)` 方法，选择( 查询 )任务。直接看这个方法不能完全表达出该方法的用途，所以详细解析，见 [「2.12 select」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 。

    - 第 41 至 44 行：若唤醒标识

       

      ```
      wakeup
      ```

       

      为

       

      ```
      true
      ```

       

      时，调用

       

      ```
      Selector#wakeup()
      ```

       

      方法，唤醒 Selector 。可能看到此处，很多胖友会和我一样，一脸懵逼。实际上，

      耐下性子

      ，答案在上面的

      英文注释

      中。笔者来简单解析下：

      - 1）在 `wakenUp.getAndSet(false)` 和 `#select(boolean oldWakeUp)` 之间，在标识 `wakeUp` 设置为 `false` 时，在 `#select(boolean oldWakeUp)` 方法中，正在调用 `Selector#select(...)` 方法，处于**阻塞**中。
      - 2）此时，有另外的线程调用了 `#wakeup()` 方法，会将标记 `wakeUp` 设置为 `true` ，并**唤醒** `Selector#select(...)` 方法的阻塞等待。
      - 3）标识 `wakeUp` 为 `true` ，所以再有另外的线程调用 `#wakeup()` 方法，都无法唤醒 `Selector#select(...)` 。为什么呢？因为 `#wakeup()` 的 CAS 修改 `false => true` 会**失败**，导致无法调用 `Selector#wakeup()` 方法。
      - 解决方式：所以在 `#select(boolean oldWakeUp)` 执行完后，增加了【第 41 至 44 行】来解决。
      - 😈😈😈 整体比较绕，胖友结合实现代码 + 英文注释，再好好理解下。

  - 第 46 行：第三种，`>= 0` ，已经有可以处理的任务，直接向下。

- 第 49 至 51 行：TODO 1007 NioEventLoop cancel 方法

- 第 53 至 74 行：根据

   

  ```
  ioRatio
  ```

   

  的配置不同，分成

  略有差异

  的 2 种：

  - 第一种，

    ```
    ioRatio
    ```

     

    为 100 ，则

    不考虑

    时间占比的分配。

    - 第 57 行：调用 `#processSelectedKeys()` 方法，处理 Channel 感兴趣的就绪 IO 事件。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。
    - 第 58 至 62 行：调用 `#runAllTasks()` 方法，运行所有普通任务和定时任务，**不限制时间**。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 。

  - 第二种，

    ```
    ioRatio
    
    ```

     

    为

     

    ```
    < 100
    
    ```

     

    ，则

    考虑

    时间占比的分配。

    - 第 64 行：记录当前时间。
    - 第 67 行：和【第 57 行】的代码**一样**。
    - 第 71 至 72 行：🙂 比较巧妙的方式，是不是和胖友之前认为的不太一样。它是以 `#processSelectedKeys()` 方法的执行时间作为**基准**，计算 `#runAllTasks(long timeoutNanos)` 方法可执行的时间。
    - 第 72 行：调用 #runAllTasks(long timeoutNanos)` 方法，运行所有普通任务和定时任务，**限制时间**。

- 第 75 至 77 行：当发生异常时，调用 `#handleLoopException(Throwable t)` 方法，处理异常。代码如下：

  ```
  private static void handleLoopException(Throwable t) {
      logger.warn("Unexpected exception in the selector loop.", t);
  
      // Prevent possible consecutive immediate failures that lead to
      // excessive CPU consumption.
      try {
          Thread.sleep(1000);
      } catch (InterruptedException e) {
          // Ignore.
      }
  }
  
  ```

- 第 78 至 89 行：TODO 1006 EventLoop 优雅关闭

- 总的来说，`#run()` 的执行过程，就是如下一张图：![run](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554274302088.png)

## 2.10 SelectStrategy

`io.netty.channel.SelectStrategy` ，选择( select )策略接口。代码如下：

```
public interface SelectStrategy {

    /**
     * Indicates a blocking select should follow.
     *
     * 表示使用阻塞 select 的策略。
     */
    int SELECT = -1;
    /**
     * Indicates the IO loop should be retried, no blocking select to follow directly.
     *
     * 表示需要进行重试的策略。
     */
    int CONTINUE = -2;

    /**
     * The {@link SelectStrategy} can be used to steer the outcome of a potential select
     * call.
     *
     * @param selectSupplier The supplier with the result of a select result.
     * @param hasTasks true if tasks are waiting to be processed.
     * @return {@link #SELECT} if the next step should be blocking select {@link #CONTINUE} if
     *         the next step should be to not select but rather jump back to the IO loop and try
     *         again. Any value >= 0 is treated as an indicator that work needs to be done.
     */
    int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception;
    
}

```

- `calculateStrategy(IntSupplier selectSupplier, boolean hasTasks)`接口方法有 **3** 种返回的情况：
  - `SELECT`，`-1` ，表示使用阻塞 **select** 的策略。
  - `CONTINUE`，`-2`，表示需要进行重试的策略。实际上，默认情况下，不会返回 `CONTINUE` 的策略。
  - `>= 0` ，表示不需要 select ，目前已经有可以执行的任务了。

### 2.10.1 DefaultSelectStrategy

`io.netty.channel.DefaultSelectStrategy` ，实现 SelectStrategy 接口，默认选择策略实现类。代码如下：

```
final class DefaultSelectStrategy implements SelectStrategy {

    /**
     * 单例
     */
    static final SelectStrategy INSTANCE = new DefaultSelectStrategy();

    private DefaultSelectStrategy() { }

    @Override
    public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception {
        return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT;
    }

}

```

- 当 `hasTasks` 为 `true` ，表示当前已经有任务，所以调用 `IntSupplier#get()` 方法，返回当前 Channel 新增的 IO 就绪事件的数量。代码如下：

  ```
  private final IntSupplier selectNowSupplier = new IntSupplier() {
      @Override
      public int get() throws Exception {
          return selectNow();
      }
  };
  
  ```

  - `io.netty.util.IntSupplier` ，代码如下：

    ```
    public interface IntSupplier {
    
        /**
         * Gets a result.
         *
         * @return a result
         */
        int get() throws Exception;
    
    }
    
    ```

    - 类似 Java 自带的 `Callable<Int>` 。

  - IntSupplier 在 NioEventLoop 中的实现为 `selectNowSupplier` 属性。在它的内部会调用 `#selectNow()` 方法。详细解析，见 [「2.11 selectNow」](http://svip.iocoder.cn/Netty/EventLoop-4-EventLoop-run/#) 。

  - 实际上，这里不调用 `IntSupplier#get()` 方法，也是可以的。只不过考虑到，可以通过 `#selectNow()` 方法，**无阻塞**的 select Channel 是否有感兴趣的就绪事件。

- 当 `hasTasks` 为 `false` 时，直接返回 `SelectStrategy.SELECT` ，进行**阻塞** select Channel 感兴趣的就绪 IO 事件。

## 2.11 selectNow

`#selectNow()` 方法，代码如下：

```
int selectNow() throws IOException {
    try {
        return selector.selectNow(); // <1>
    } finally {
        // restore wakeup state if needed <2>
        if (wakenUp.get()) {
            selector.wakeup();
        }
    }
}

```

- `<1>` 处，调用 `Selector#selectorNow()` 方法，立即( **无阻塞** )返回 Channel 新增的感兴趣的就绪 IO 事件数量。

- `<2>` 处，若唤醒标识 `wakeup` 为 `true` 时，调用 `Selector#wakeup()` 方法，唤醒 Selector 。因为 `<1>` 处的 `Selector#selectorNow()` 会使用我们对 Selector 的唤醒，所以需要进行**复原**。有一个冷知道，可能有胖友不知道：

  > 注意，如果有其它线程调用了 `#wakeup()` 方法，但当前没有线程阻塞在 `#select()` 方法上，下个调用 `#select()` 方法的线程会立即被唤醒。😈 有点神奇。

## 2.12 select

`#select(boolean oldWakenUp)` 方法，选择( 查询 )任务。**这是本文最重要的方法**。代码如下：

```
  1: private void select(boolean oldWakenUp) throws IOException {
  2:     // 记录下 Selector 对象
  3:     Selector selector = this.selector;
  4:     try {
  5:         // select 计数器
  6:         int selectCnt = 0; // cnt 为 count 的缩写
  7:         // 记录当前时间，单位：纳秒
  8:         long currentTimeNanos = System.nanoTime();
  9:         // 计算 select 截止时间，单位：纳秒。
 10:         long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos);
 11: 
 12:         for (;;) {
 13:             // 计算本次 select 的超时时长，单位：毫秒。
 14:             // + 500000L 是为了四舍五入
 15:             // / 1000000L 是为了纳秒转为毫秒
 16:             long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L;
 17:             // 如果超时时长，则结束 select
 18:             if (timeoutMillis <= 0) {
 19:                 if (selectCnt == 0) { // 如果是首次 select ，selectNow 一次，非阻塞
 20:                     selector.selectNow();
 21:                     selectCnt = 1;
 22:                 }
 23:                 break;
 24:             }
 25: 
 26:             // If a task was submitted when wakenUp value was true, the task didn't get a chance to call
 27:             // Selector#wakeup. So we need to check task queue again before executing select operation.
 28:             // If we don't, the task might be pended until select operation was timed out.
 29:             // It might be pended until idle timeout if IdleStateHandler existed in pipeline.
 30:             // 若有新的任务加入
 31:             if (hasTasks() && wakenUp.compareAndSet(false, true)) {
 32:                 // selectNow 一次，非阻塞
 33:                 selector.selectNow();
 34:                 // 重置 select 计数器
 35:                 selectCnt = 1;
 36:                 break;
 37:             }
 38: 
 39:             // 阻塞 select ，查询 Channel 是否有就绪的 IO 事件
 40:             int selectedKeys = selector.select(timeoutMillis);
 41:             // select 计数器 ++
 42:             selectCnt ++;
 43: 
 44:             // 结束 select ，如果满足下面任一一个条件
 45:             if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) {
 46:                 // - Selected something,
 47:                 // - waken up by user, or
 48:                 // - the task queue has a pending task.
 49:                 // - a scheduled task is ready for processing
 50:                 break;
 51:             }
 52:             // 线程被打断。一般情况下不会出现，出现基本是 bug ，或者错误使用。
 53:             if (Thread.interrupted()) {
 54:                 // Thread was interrupted so reset selected keys and break so we not run into a busy loop.
 55:                 // As this is most likely a bug in the handler of the user or it's client library we will
 56:                 // also log it.
 57:                 //
 58:                 // See https://github.com/netty/netty/issues/2426
 59:                 if (logger.isDebugEnabled()) {
 60:                     logger.debug("Selector.select() returned prematurely because " +
 61:                             "Thread.currentThread().interrupt() was called. Use " +
 62:                             "NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.");
 63:                 }
 64:                 selectCnt = 1;
 65:                 break;
 66:             }
 67: 
 68:             // 记录当前时间
 69:             long time = System.nanoTime();
 70:             // 符合 select 超时条件，重置 selectCnt 为 1
 71:             if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) {
 72:                 // timeoutMillis elapsed without anything selected.
 73:                 selectCnt = 1;
 74:             // 不符合 select 超时的提交，若 select 次数到达重建 Selector 对象的上限，进行重建
 75:             } else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 &&
 76:                     selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) {
 77:                 // The selector returned prematurely many times in a row.
 78:                 // Rebuild the selector to work around the problem.
 79:                 logger.warn("Selector.select() returned prematurely {} times in a row; rebuilding Selector {}.", selectCnt, selector);
 80: 
 81:                 // 重建 Selector 对象
 82:                 rebuildSelector();
 83:                 // 修改下 Selector 对象
 84:                 selector = this.selector;
 85: 
 86:                 // Select again to populate selectedKeys.
 87:                 // 立即 selectNow 一次，非阻塞
 88:                 selector.selectNow();
 89:                 // 重置 selectCnt 为 1
 90:                 selectCnt = 1;
 91:                 // 结束 select
 92:                 break;
 93:             }
 94: 
 95:             currentTimeNanos = time;
 96:         }
 97: 
 98:         if (selectCnt > MIN_PREMATURE_SELECTOR_RETURNS) {
 99:             if (logger.isDebugEnabled()) {
100:                 logger.debug("Selector.select() returned prematurely {} times in a row for Selector {}.", selectCnt - 1, selector);
101:             }
102:         }
103:     } catch (CancelledKeyException e) {
104:         if (logger.isDebugEnabled()) {
105:             logger.debug(CancelledKeyException.class.getSimpleName() + " raised by a Selector {} - JDK bug?", selector, e);
106:         }
107:         // Harmless exception - log anyway
108:     }
109: }

```

- 第 3 行：获得使用的 Selector 对象，不需要每次访问使用 `volatile` 修饰的 `selector` 属性。

- 第 6 行：获得 select 操作的计数器。主要用于记录 Selector 空轮询次数，所以每次在正在轮询完成( 例如：轮询超时 )，则重置 `selectCnt` 为 1 。

- 第 8 行：记录当前时间，单位：纳秒。

- 第 10 行：计算 select 操作的截止时间，单位：纳秒。

  - `#delayNanos(currentTimeNanos)` 方法返回的为下一个定时任务距离现在的时间，如果不存在定时任务，则默认返回 1000 ms 。该方法的详细解析，见后续文章。

- 第 12 行：“死”循环，直到符合如下**任一**一种情况后**结束**：

  1. select 操作超时，对应【第 18 至 24 行】。
  2. 若有新的任务加入，对应【第 26 至 37 行】。
  3. 查询到任务或者唤醒，对应【第 45 至 51 行】。
  4. 线程被异常打断，对应【第 52 至 66 行】。
  5. 发生 NIO 空轮询的 Bug 后重建 Selector 对象后，对应【第 75 至 93 行】。

- 第 16 行：计算本次 select 的**超时时长**，单位：毫秒。因为【第 40 行】的 `Selector#select(timeoutMillis)` 方法，可能因为**各种情况结束**，所以需要循环，并且每次**重新**计算超时时间。至于 `+ 500000L` 和 `/ 1000000L` 的用途，看下代码注释。

- 第 17 至 24 行：如果超过 select 超时时长，则结束 select 。

  - 第 19 至 21 行：如果是首次 select ，则调用 `Selector#selectNow()` 方法，获得**非阻塞**的 Channel 感兴趣的就绪的 IO 事件，并重置 `selectCnt` 为 1 。

- 第 26 至 37 行：若有新的任务加入。这里实际要分成两种情况：

  - 第一种，提交的任务的类型是 NonWakeupRunnable ，那么它并不会调用 `#wakeup()` 方法，原因胖友自己看 `#execute(Runnable task)` 思考下。Netty 在 `#select()` 方法的设计上，**能尽快执行任务**。此时如果标记 `wakeup` 为 `false` ，说明符合这种情况，直接结束 select 。
  - 第二种，提交的任务的类型**不是**NonWakeupRunnable ，那么在`#run()` 方法的【第 8 至 11 行】的`wakenUp.getAndSet(false)`之前，发起了一次`#wakeup()`方法，那么因为`wakenUp.getAndSet(false)`会将标记`wakeUp`设置为`false`，所以就能满足 `hasTasks() && wakenUp.compareAndSet(false, true)`的条件。
    - 这个解释，就和【第 27 至 28 行】的英文注释 `So we need to check task queue again before executing select operation.If we don't, the task might be pended until select operation was timed out.` 有出入了？这是为什么呢？因为 Selector 被提前 wakeup 了，所以下一次 Selector 的 select 是被直接唤醒结束的。
  - 第 33 行：虽然已经发现任务，但是还是调用 `Selector#selectNow()` 方法，**非阻塞**的获取一次 Channel 新增的就绪的 IO 事件。
  - 对应 Github 的代码提交为 <https://github.com/lightningMan/netty/commit/f44f3e7926f1676315ae86d0f18bdd9b95681d9f> 。

- 第 40 行：调用 `Selector#select(timeoutMillis)` 方法，**阻塞** select ，获得 Channel 新增的就绪的 IO 事件的数量。

- 第 42 行：select 计数器加 1 。

- 第 44 至 51 行：如果满足下面**任一**一个条件，结束 select ：

  1. `selectedKeys != 0` 时，表示有 Channel 新增的就绪的 IO 事件，所以结束 select ，很好理解。
  2. `oldWakenUp || wakenUp.get()` 时，表示 Selector 被唤醒，所以结束 select 。
  3. `hasTasks() || hasScheduledTasks()` ，表示有普通任务或定时任务，所以结束 select 。
  4. 那么剩余的情况，主要是 select **超时**或者发生**空轮询**，即【第 68 至 93 行】的代码。

- 第 52 至 66 行：线程被打断。一般情况下不会出现，出现基本是 **bug** ，或者错误使用。感兴趣的胖友，可以看看 <https://github.com/netty/netty/issues/2426> 。

- 第 69 行：记录当前时间。

  - 第 70 至 73 行：若满足 `time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos` ，说明到达此处时，Selector 是**超时** select ，那么是**正常**的，所以重置 `selectCnt` 为 1 。

  - 第 74 至 93 行：不符合 select 超时的提交，若 select 次数到达重建 Selector 对象的上限，进行重建。

    这就是 Netty 判断发生 NIO Selector 空轮询的方式

    ，N ( 默认 512 )次 select 并未阻塞超时这么长，那么就认为发生 NIO Selector 空轮询。过多的 NIO Selector 将会导致 CPU 100% 。

    - 第 82 行：调用 `#rebuildSelector()` 方法，重建 Selector 对象。
    - 第 84 行：**重新**获得使用的 Selector 对象。
    - 第 86 至 90 行：同【第 20 至 21 行】的代码。
    - 第 92 行：结束 select 。

- 第 95 行：记录新的当前时间，用于【第 16 行】，**重新**计算本次 select 的超时时长。

# 666. 彩蛋

总的来说还是比较简单的，比较困难的，在于对标记 `wakeup` 的理解。真的是，细思极恐！！！感谢在理解过程中，闪电侠和大表弟普架的帮助。

推荐阅读文章：

- 闪电侠 [《netty 源码分析之揭开 reactor 线程的面纱（一）》](https://www.jianshu.com/p/0d0eece6d467)
- Hypercube [《自顶向下深入分析 Netty（四）–EventLoop-2》](https://www.jianshu.com/p/d0f06b13e2fb)

> 老艿艿：全文的 NIO Selector 空轮询，指的是 epoll cpu 100% 的 bug 。

# 精尽 Netty 源码解析 —— EventLoop（五）之 EventLoop 处理 IO 事件



# 1. 概述

本文我们分享 EventLoop 的**处理 IO 事件**相关代码的实现。对应如下图的绿条 **process selected keys** 部分：![run](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554274824167.png)

因为在 [《精尽 Netty 源码解析 —— EventLoop（四）之 EventLoop 运行》](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event?self) 中，`#openSelector()` 和 `#rebuildSelector()` 方法并未做分享，所以我们先来一起看看。

# 2. SelectorTuple

SelectorTuple ，Selector 元组。代码如下：

> SelectorTuple 内嵌在 NioEventLoop

```
private static final class SelectorTuple {

    /**
     * 未包装的 Selector 对象
     */
    final Selector unwrappedSelector;
    /**
     * 未包装的 Selector 对象
     */
    final Selector selector;

    SelectorTuple(Selector unwrappedSelector) {
        this.unwrappedSelector = unwrappedSelector;
        this.selector = unwrappedSelector;
    }

    SelectorTuple(Selector unwrappedSelector, Selector selector) {
        this.unwrappedSelector = unwrappedSelector;
        this.selector = selector;
    }

}
```

# 3. openSelector

`#openSelector()` 方法，创建 Selector 对象。代码如下：

```
 1: private SelectorTuple openSelector() {
 2:     // 创建 Selector 对象，作为 unwrappedSelector
 3:     final Selector unwrappedSelector;
 4:     try {
 5:         unwrappedSelector = provider.openSelector();
 6:     } catch (IOException e) {
 7:         throw new ChannelException("failed to open a new selector", e);
 8:     }
 9: 
10:     // 禁用 SelectionKey 的优化，则直接返回 SelectorTuple 对象。即，selector 也使用 unwrappedSelector 。
11:     if (DISABLE_KEYSET_OPTIMIZATION) {
12:         return new SelectorTuple(unwrappedSelector);
13:     }
14: 
15:     // 获得 SelectorImpl 类
16:     Object maybeSelectorImplClass = AccessController.doPrivileged(new PrivilegedAction<Object>() {
17:         @Override
18:         public Object run() {
19:             try {
20:                 return Class.forName(
21:                         "sun.nio.ch.SelectorImpl",
22:                         false,
23:                         PlatformDependent.getSystemClassLoader()); // 成功，则返回该类
24:             } catch (Throwable cause) {
25:                 return cause; // 失败，则返回该异常
26:             }
27:         }
28:     });
29: 
30:     // 获得 SelectorImpl 类失败，则直接返回 SelectorTuple 对象。即，selector 也使用 unwrappedSelector 。
31:     if (!(maybeSelectorImplClass instanceof Class) ||
32:             // ensure the current selector implementation is what we can instrument.
33:             !((Class<?>) maybeSelectorImplClass).isAssignableFrom(unwrappedSelector.getClass())) {
34:         if (maybeSelectorImplClass instanceof Throwable) {
35:             Throwable t = (Throwable) maybeSelectorImplClass;
36:             logger.trace("failed to instrument a special java.util.Set into: {}", unwrappedSelector, t);
37:         }
38:         return new SelectorTuple(unwrappedSelector);
39:     }
40: 
41:     final Class<?> selectorImplClass = (Class<?>) maybeSelectorImplClass;
42: 
43:     // 创建 SelectedSelectionKeySet 对象
44:     final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet();
45: 
46:     // 设置 SelectedSelectionKeySet 对象到 unwrappedSelector 中
47:     Object maybeException = AccessController.doPrivileged(new PrivilegedAction<Object>() {
48:         @Override
49:         public Object run() {
50:             try {
51:                 // 获得 "selectedKeys" "publicSelectedKeys" 的 Field
52:                 Field selectedKeysField = selectorImplClass.getDeclaredField("selectedKeys");
53:                 Field publicSelectedKeysField = selectorImplClass.getDeclaredField("publicSelectedKeys");
54: 
55:                 // 设置 Field 可访问
56:                 Throwable cause = ReflectionUtil.trySetAccessible(selectedKeysField, true);
57:                 if (cause != null) {
58:                     return cause;
59:                 }
60:                 cause = ReflectionUtil.trySetAccessible(publicSelectedKeysField, true);
61:                 if (cause != null) {
62:                     return cause;
63:                 }
64: 
65:                 // 设置 SelectedSelectionKeySet 对象到 unwrappedSelector 的 Field 中
66:                 selectedKeysField.set(unwrappedSelector, selectedKeySet);
67:                 publicSelectedKeysField.set(unwrappedSelector, selectedKeySet);
68:                 return null;
69:             } catch (NoSuchFieldException e) {
70:                 return e; // 失败，则返回该异常
71:             } catch (IllegalAccessException e) {
72:                 return e; // 失败，则返回该异常
73:             }
74:         }
75:     });
76: 
77:     // 设置 SelectedSelectionKeySet 对象到 unwrappedSelector 中失败，则直接返回 SelectorTuple 对象。即，selector 也使用 unwrappedSelector 。
78:     if (maybeException instanceof Exception) {
79:         selectedKeys = null;
80:         Exception e = (Exception) maybeException;
81:         logger.trace("failed to instrument a special java.util.Set into: {}", unwrappedSelector, e);
82:         return new SelectorTuple(unwrappedSelector);
83:     }
84: 
85:     // 设置 SelectedSelectionKeySet 对象到 selectedKeys 中
86:     selectedKeys = selectedKeySet;
87:     logger.trace("instrumented a special java.util.Set into: {}", unwrappedSelector);
88: 
89:     // 创建 SelectedSelectionKeySetSelector 对象
90:     // 创建 SelectorTuple 对象。即，selector 也使用 SelectedSelectionKeySetSelector 对象。
91:     return new SelectorTuple(unwrappedSelector, new SelectedSelectionKeySetSelector(unwrappedSelector, selectedKeySet));
92: }
```

- 第 2 至 8 行：创建 Selector 对象，作为 `unwrappedSelector` 。

- 第 10 至 13 行：禁用 SelectionKey 的优化，则直接返回 SelectorTuple 对象。即，`selector` 也使用 `unwrappedSelector` 。

- 第 15 至 28 行：获得 SelectorImpl 类。胖友可以自动过滤掉`AccessController#.doPrivileged(...)`外层代码。在方法内部，调用`Class#forName(String name, boolean initialize, ClassLoader loader)`方法，加载`sun.nio.ch.SelectorImpl`类。加载成功，则返回该类，否则返回异常。

  - 第 30 至 39 行： 获得 SelectorImpl 类失败，则直接返回 SelectorTuple 对象。即，`selector` 也使用 `unwrappedSelector` 。

- 第 44 行：创建 SelectedSelectionKeySet 对象。这是 Netty 对 Selector 的 `selectionKeys` 的优化。关于 SelectedSelectionKeySet 的详细实现，见 [「4. SelectedSelectionKeySet」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。

  - 第 46 至 75 行： 设置 SelectedSelectionKeySet 对象到 `unwrappedSelector` 中的 `selectedKeys` 和 `publicSelectedKeys` 属性。整个过程，笔者已经添加中文注释，胖友自己看下。

  - `selectedKeys` 和 `publicSelectedKeys` 属性在 SelectorImpl 类中，代码如下：

    ```
    protected HashSet<SelectionKey> keys = new HashSet(); // => publicKeys
    private Set<SelectionKey> publicKeys;
    
    protected Set<SelectionKey> selectedKeys = new HashSet(); // => publicSelectedKeys
    private Set<SelectionKey> publicSelectedKeys;
    
    protected SelectorImpl(SelectorProvider var1) {
        super(var1);
        if (Util.atBugLevel("1.4")) { // 可以无视
            this.publicKeys = this.keys;
            this.publicSelectedKeys = this.selectedKeys;
        } else {
            this.publicKeys = Collections.unmodifiableSet(this.keys);
            this.publicSelectedKeys = Util.ungrowableSet(this.selectedKeys);
        }
    
    }
    ```

    - 可以看到，`selectedKeys` 和 `publicSelectedKeys` 的类型都是 HashSet 。

  - 第 77 至 83 行：设置 SelectedSelectionKeySet 对象到 `unwrappedSelector` 中失败，则直接返回 SelectorTuple 对象。即，`selector` 也使用 `unwrappedSelector` 。

- 第 86 行：设置 SelectedSelectionKeySet 对象到 `selectedKeys` 中。在下文，我们会看到，是否成功优化 Selector 对象，是通过 `selectedKeys` 是否成功初始化来判断。

- 第 91 行：创建 SelectedSelectionKeySetSelector 对象。这是 Netty 对 Selector 的优化实现类。关于 SelectedSelectionKeySetSelector 的详细实现，见 [「5. SelectedSelectionKeySetSelector」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。

- 第 91 行：创建 SelectorTuple 对象。即，`selector` 使用 SelectedSelectionKeySetSelector 对象。😈 总算，创建成功优化的 `selector` 对象了。

# 4. SelectedSelectionKeySet

`io.netty.channel.nio.SelectedSelectionKeySet` ，继承 AbstractSet 抽象类，已 **select** 的 NIO SelectionKey 集合。代码如下：

```
final class SelectedSelectionKeySet extends AbstractSet<SelectionKey> {

    /**
     * SelectionKey 数组
     */
    SelectionKey[] keys;
    /**
     * 数组可读大小
     */
    int size;

    SelectedSelectionKeySet() {
        keys = new SelectionKey[1024]; // 默认 1024 大小
    }

    @Override
    public boolean add(SelectionKey o) {
        if (o == null) {
            return false;
        }

        // 添加到数组
        keys[size++] = o;

        // 超过数组大小上限，进行扩容
        if (size == keys.length) {
            increaseCapacity();
        }

        return true;
    }

    @Override
    public int size() {
        return size;
    }

    @Override
    public boolean remove(Object o) {
        return false;
    }

    @Override
    public boolean contains(Object o) {
        return false;
    }

    @Override
    public Iterator<SelectionKey> iterator() {
        throw new UnsupportedOperationException();
    }

    void reset() {
        reset(0);
    }

    void reset(int start) {
        // 重置数组内容为空
        Arrays.fill(keys, start, size, null);
        // 重置可读大小为 0
        size = 0;
    }

    private void increaseCapacity() {
        // 两倍扩容
        SelectionKey[] newKeys = new SelectionKey[keys.length << 1];
        // 复制老数组到新数组
        System.arraycopy(keys, 0, newKeys, 0, size);
        // 赋值给老数组
        keys = newKeys;
    }

}
```

- 通过 `keys` 和 `size` 两个属性，实现**可重用**的数组。
- `#add(SelectionKey o)` 方法，添加新 **select** 到就绪事件的 SelectionKey 到 `keys` 中。当超过数组大小上限时，调用 `#increaseCapacity()` 方法，进行**两倍**扩容。相比 SelectorImpl 中使用的 `selectedKeys` 所使用的 HashSet 的 `#add(E e)` 方法，事件复杂度从 `O(lgn)` **降低**到 `O(1)` 。
- `#reset(...)` 方法，每次读取使用完数据，调用该方法，进行重置。
- 因为 `#remove(Object o)`、`#contains(Object o)`、`#iterator()` 不会使用到，索性不进行实现。

# 5. SelectedSelectionKeySetSelector

`io.netty.channel.nio.SelectedSelectionKeySetSelector` ，基于 Netty SelectedSelectionKeySet 作为 `selectionKeys` 的 Selector 实现类。代码如下：

```
final class SelectedSelectionKeySetSelector extends Selector {

    /**
     * SelectedSelectionKeySet 对象
     */
    private final SelectedSelectionKeySet selectionKeys;
    /**
     * 原始 Java NIO Selector 对象
     */
    private final Selector delegate;

    SelectedSelectionKeySetSelector(Selector delegate, SelectedSelectionKeySet selectionKeys) {
        this.delegate = delegate;
        this.selectionKeys = selectionKeys;
    }

    @Override
    public boolean isOpen() {
        return delegate.isOpen();
    }

    @Override
    public SelectorProvider provider() {
        return delegate.provider();
    }

    @Override
    public Set<SelectionKey> keys() {
        return delegate.keys();
    }

    @Override
    public Set<SelectionKey> selectedKeys() {
        return delegate.selectedKeys();
    }

    @Override
    public int selectNow() throws IOException {
        // 重置 selectionKeys
        selectionKeys.reset();
        // selectNow
        return delegate.selectNow();
    }

    @Override
    public int select(long timeout) throws IOException {
        // 重置 selectionKeys
        selectionKeys.reset();
        // select
        return delegate.select(timeout);
    }

    @Override
    public int select() throws IOException {
        // 重置 selectionKeys
        selectionKeys.reset();
        // select
        return delegate.select();
    }

    @Override
    public Selector wakeup() {
        return delegate.wakeup();
    }

    @Override
    public void close() throws IOException {
        delegate.close();
    }

}
```

- 除了 **select** 相关的 3 个方法，每个实现方法，都是基于 Java NIO Selector 对应的方法的调用。
- **select** 相关的 3 个方法，在调用对应的 Java NIO Selector 方法之前，会调用 `SelectedSelectionKeySet#reset()` 方法，重置 `selectionKeys` 。从而实现，每次 select 之后，都是**新的**已 select 的 NIO SelectionKey 集合。

# 6. rebuildSelector

`#rebuildSelector()` 方法，重建 Selector 对象。代码如下：

> 该方法用于 NIO Selector 发生 epoll bug 时，重建 Selector 对象。
>
> 😈 突然又找到一个讨论，可以看看 [《JDK 1.7 及以下 NIO 的 epoll bug》](https://github.com/Yhzhtk/note/issues/26) 和 [《应用服务器中对JDK的epoll空转bug的处理》](http://www.10tiao.com/html/308/201602/401718035/1.html) 。

```
public void rebuildSelector() {
    // 只允许在 EventLoop 的线程中执行
    if (!inEventLoop()) {
        execute(new Runnable() {
            @Override
            public void run() {
                rebuildSelector0();
            }
        });
        return;
    }
    rebuildSelector0();
}
```

- 只允许在 EventLoop 的线程中，调用 `#rebuildSelector0()` 方法，重建 Selector 对象。

## 6.1 rebuildSelector0

`#rebuildSelector0()` 方法，重建 Selector 对象。代码如下：

```
 1: private void rebuildSelector0() {
 2:     final Selector oldSelector = selector;
 3:     if (oldSelector == null) {
 4:         return;
 5:     }
 6: 
 7:     // 创建新的 Selector 对象
 8:     final SelectorTuple newSelectorTuple;
 9:     try {
10:         newSelectorTuple = openSelector();
11:     } catch (Exception e) {
12:         logger.warn("Failed to create a new Selector.", e);
13:         return;
14:     }
15: 
16:     // Register all channels to the new Selector.
17:     // 将注册在 NioEventLoop 上的所有 Channel ，注册到新创建 Selector 对象上
18:     int nChannels = 0; // 计算重新注册成功的 Channel 数量
19:     for (SelectionKey key: oldSelector.keys()) {
20:         Object a = key.attachment();
21:         try {
22:             if (!key.isValid() || key.channel().keyFor(newSelectorTuple.unwrappedSelector) != null) {
23:                 continue;
24:             }
25: 
26:             int interestOps = key.interestOps();
27:             // 取消老的 SelectionKey
28:             key.cancel();
29:             // 将 Channel 注册到新的 Selector 对象上
30:             SelectionKey newKey = key.channel().register(newSelectorTuple.unwrappedSelector, interestOps, a);
31:             // 修改 Channel 的 selectionKey 指向新的 SelectionKey 上
32:             if (a instanceof AbstractNioChannel) {
33:                 // Update SelectionKey
34:                 ((AbstractNioChannel) a).selectionKey = newKey;
35:             }
36: 
37:             // 计数 ++
38:             nChannels ++;
39:         } catch (Exception e) {
40:             logger.warn("Failed to re-register a Channel to the new Selector.", e);
41:             // 关闭发生异常的 Channel
42:             if (a instanceof AbstractNioChannel) {
43:                 AbstractNioChannel ch = (AbstractNioChannel) a;
44:                 ch.unsafe().close(ch.unsafe().voidPromise());
45:             // 调用 NioTask 的取消注册事件
46:             } else {
47:                 @SuppressWarnings("unchecked")
48:                 NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;
49:                 invokeChannelUnregistered(task, key, e);
50:             }
51:         }
52:     }
53: 
54:     // 修改 selector 和 unwrappedSelector 指向新的 Selector 对象
55:     selector = newSelectorTuple.selector;
56:     unwrappedSelector = newSelectorTuple.unwrappedSelector;
57: 
58:     // 关闭老的 Selector 对象
59:     try {
60:         // time to close the old selector as everything else is registered to the new one
61:         oldSelector.close();
62:     } catch (Throwable t) {
63:         if (logger.isWarnEnabled()) {
64:             logger.warn("Failed to close the old Selector.", t);
65:         }
66:     }
67: 
68:     if (logger.isInfoEnabled()) {
69:         logger.info("Migrated " + nChannels + " channel(s) to the new Selector.");
70:     }
71: }
```

- 第 7 行：调用 `#openSelector()` 方法，创建新的 Selector 对象。

- 第 16 至 52 行：遍历

  老

  的 Selector 对象的`selectionKeys`，将注册在 NioEventLoop 上的所有 Channel ，注册到

  新

  创建 Selector 对象上。

  - 第 22 至 24 行：校验 SelectionKey 有效，并且 Java NIO Channel 并未注册在**新**的 Selector 对象上。
  - 第 28 行：调用 `SelectionKey#cancel()` 方法，取消**老**的 SelectionKey 。
  - 第 30 行：将 Java NIO Channel 注册到**新**的 Selector 对象上，返回**新**的 SelectionKey 对象。
  - 第 31 至 35 行：修改 Channel 的 `selectionKey` 指向**新**的 SelectionKey 对象
  - 第 39 至 51 行：当发生异常时候，根据不同的 SelectionKey 的`attachment`来判断处理方式：
    - 第 41 至 44 行：当 `attachment` 是 Netty NIO Channel 时，调用 `Unsafe#close(ChannelPromise promise)` 方法，**关闭**发生异常的 Channel 。
    - 第 45 至 50 行：当 `attachment` 是 Netty NioTask 时，调用 `#invokeChannelUnregistered(NioTask<SelectableChannel> task, SelectionKey k, Throwable cause)` 方法，通知 Channel 取消注册。详细解析，见 [「8. NioTask」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。

- 第 54 至 56 行：修改 `selector` 和 `unwrappedSelector` 指向**新**的 Selector 对象。

- 第 58 至 66 行：调用 `Selector#close()` 方法，关闭**老**的 Selector 对象。

总的来说，`#rebuildSelector()` 方法，相比 `#openSelector()` 方法，主要是需要将老的 Selector 对象的“数据”复制到新的 Selector 对象上，并关闭老的 Selector 对象。

# 7. processSelectedKeys

在 `#run()` 方法中，会调用 `#processSelectedKeys()` 方法，处理 Channel **新增**就绪的 IO 事件。代码如下：

```
private void processSelectedKeys() {
    if (selectedKeys != null) {
        processSelectedKeysOptimized();
    } else {
        processSelectedKeysPlain(selector.selectedKeys());
    }
}
```

- 当 `selectedKeys` 非空，意味着使用优化的 SelectedSelectionKeySetSelector ，所以调用 `#processSelectedKeysOptimized()` 方法；否则，调用 `#processSelectedKeysPlain()` 方法。

## 7.1 processSelectedKeysOptimized

`#processSelectedKeysOptimized()` 方法，基于 Netty SelectedSelectionKeySetSelector ，处理 Channel **新增**就绪的 IO 事件。代码如下：

> 老艿艿：从方法名，我们也可以看出，这是个经过**优化**的实现。

```
 1: private void processSelectedKeysOptimized() {
 2:     // 遍历数组
 3:     for (int i = 0; i < selectedKeys.size; ++i) {
 4:         final SelectionKey k = selectedKeys.keys[i];
 5:         // null out entry in the array to allow to have it GC'ed once the Channel close
 6:         // See https://github.com/netty/netty/issues/2363
 7:         selectedKeys.keys[i] = null;
 8: 
 9:         final Object a = k.attachment();
10: 
11:         // 处理一个 Channel 就绪的 IO 事件
12:         if (a instanceof AbstractNioChannel) {
13:             processSelectedKey(k, (AbstractNioChannel) a);
14:         // 使用 NioTask 处理一个 Channel 就绪的 IO 事件
15:         } else {
16:             @SuppressWarnings("unchecked")
17:             NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;
18:             processSelectedKey(k, task);
19:         }
20: 
21:         // TODO 1007 NioEventLoop cancel 方法
22:         if (needsToSelectAgain) {
23:             // null out entries in the array to allow to have it GC'ed once the Channel close
24:             // See https://github.com/netty/netty/issues/2363
25:             selectedKeys.reset(i + 1);
26: 
27:             selectAgain();
28:             i = -1;
29:         }
30:     }
31: }
```

- 第 3 行：循环`selectedKeys`数组。
  - 第 4 至 7 行：置空，原因见 <https://github.com/netty/netty/issues/2363> 。
  - 第 11 至 13 行：当 `attachment` 是 Netty NIO Channel 时，调用 `#processSelectedKey(SelectionKey k, AbstractNioChannel ch)` 方法，处理一个 Channel 就绪的 IO 事件。详细解析，见 [「7.3 processSelectedKey」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。
  - 第 14 至 19 行：当 `attachment` 是 Netty NioTask 时，调用 `#processSelectedKey(SelectionKey k, NioTask<SelectableChannel> task)` 方法，使用 NioTask 处理一个 Channel 的 IO 事件。详细解析，见 [「8. NioTask」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。
  - 第 21 至 29 行：TODO 1007 NioEventLoop cancel 方法

## 7.2 processSelectedKeysPlain

`#processSelectedKeysOptimized()` 方法，基于 Java NIO 原生 Selecotr ，处理 Channel **新增**就绪的 IO 事件。代码如下：

> 老艿艿：总体和 `#processSelectedKeysOptimized()` 方法**类似**。

```
 1: private void processSelectedKeysPlain(Set<SelectionKey> selectedKeys) {
 2:     // check if the set is empty and if so just return to not create garbage by
 3:     // creating a new Iterator every time even if there is nothing to process.
 4:     // See https://github.com/netty/netty/issues/597
 5:     if (selectedKeys.isEmpty()) {
 6:         return;
 7:     }
 8: 
 9:     // 遍历 SelectionKey 迭代器
10:     Iterator<SelectionKey> i = selectedKeys.iterator();
11:     for (;;) {
12:         // 获得 SelectionKey 对象
13:         final SelectionKey k = i.next();
14:         // 从迭代器中移除
15:         i.remove();
16: 
17:         final Object a = k.attachment();
18:         // 处理一个 Channel 就绪的 IO 事件
19:         if (a instanceof AbstractNioChannel) {
20:             processSelectedKey(k, (AbstractNioChannel) a);
21:         // 使用 NioTask 处理一个 Channel 就绪的 IO 事件
22:         } else {
23:             @SuppressWarnings("unchecked")
24:             NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;
25:             processSelectedKey(k, task);
26:         }
27: 
28:         // 无下一个节点，结束
29:         if (!i.hasNext()) {
30:             break;
31:         }
32: 
33:         // TODO 1007 NioEventLoop cancel 方法
34:         if (needsToSelectAgain) {
35:             selectAgain();
36:             selectedKeys = selector.selectedKeys();
37: 
38:             // Create the iterator again to avoid ConcurrentModificationException
39:             if (selectedKeys.isEmpty()) {
40:                 break;
41:             } else {
42:                 i = selectedKeys.iterator();
43:             }
44:         }
45:     }
46: }
```

- 第 10 至 11 行：遍历 SelectionKey**迭代器**。
  - 第 12 至 15 行：获得下一个 SelectionKey 对象，并从迭代器中移除。
  - 第 18 至 20 行：当 `attachment` 是 Netty NIO Channel 时，调用 `#processSelectedKey(SelectionKey k, AbstractNioChannel ch)` 方法，处理一个 Channel 就绪的 IO 事件。详细解析，见 [「7.3 processSelectedKey」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。
  - 第 21 至 26 行：当 `attachment` 是 Netty NioTask 时，调用 `#processSelectedKey(SelectionKey k, NioTask<SelectableChannel> task)` 方法，使用 NioTask 处理一个 Channel 的 IO 事件。详细解析，见 [「8. NioTask」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 。
  - 第 33 至 44 行：TODO 1007 NioEventLoop cancel 方法

## 7.3 processSelectedKey

`#processSelectedKey(SelectionKey k, AbstractNioChannel ch)` 方法，处理一个 Channel 就绪的 IO 事件。代码如下：

```
 1: private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) {
 2:     // 如果 SelectionKey 是不合法的，则关闭 Channel
 3:     final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe();
 4:     if (!k.isValid()) {
 5:         final EventLoop eventLoop;
 6:         try {
 7:             eventLoop = ch.eventLoop();
 8:         } catch (Throwable ignored) {
 9:             // If the channel implementation throws an exception because there is no event loop, we ignore this
10:             // because we are only trying to determine if ch is registered to this event loop and thus has authority
11:             // to close ch.
12:             return;
13:         }
14:         // Only close ch if ch is still registered to this EventLoop. ch could have deregistered from the event loop
15:         // and thus the SelectionKey could be cancelled as part of the deregistration process, but the channel is
16:         // still healthy and should not be closed.
17:         // See https://github.com/netty/netty/issues/5125
18:         if (eventLoop != this) {
19:             return;
20:         }
21:         // close the channel if the key is not valid anymore
22:         unsafe.close(unsafe.voidPromise());
23:         return;
24:     }
25: 
26:     try {
27:         // 获得就绪的 IO 事件的 ops
28:         int readyOps = k.readyOps();
29: 
30:         // OP_CONNECT 事件就绪
31:         // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise
32:         // the NIO JDK channel implementation may throw a NotYetConnectedException.
33:         if ((readyOps & SelectionKey.OP_CONNECT) != 0) {
34:             // 移除对 OP_CONNECT 感兴趣
35:             // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking
36:             // See https://github.com/netty/netty/issues/924
37:             int ops = k.interestOps();
38:             ops &= ~SelectionKey.OP_CONNECT;
39:             k.interestOps(ops);
40:             // 完成连接
41:             unsafe.finishConnect();
42:         }
43: 
44:         // OP_WRITE 事件就绪
45:         // Process OP_WRITE first as we may be able to write some queued buffers and so free memory.
46:         if ((readyOps & SelectionKey.OP_WRITE) != 0) {
47:             // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write
48:             // 向 Channel 写入数据
49:             ch.unsafe().forceFlush();
50:         }
51: 
52:         // SelectionKey.OP_READ 或 SelectionKey.OP_ACCEPT 就绪
53:         // readyOps == 0 是对 JDK Bug 的处理，防止空的死循环
54:         // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead
55:         // to a spin loop
56:         if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {
57:             unsafe.read();
58:         }
59:     } catch (CancelledKeyException ignored) {
60:         // 发生异常，关闭 Channel
61:         unsafe.close(unsafe.voidPromise());
62:     }
63: }
```

- 第 2 至 24 行：如果 SelectionKey 是不合法的，则关闭 Channel 。
- 第 30 至 42 行：如果对`OP_CONNECT`事件就绪：
  - 第 34 至 39 行：移除对 `OP_CONNECT` 的感兴趣，即不再监听连接事件。
  - 【重要】第 41 行：调用 `Unsafe#finishConnect()` 方法，完成连接。后续的逻辑，对应 [《精尽 Netty 源码分析 —— 启动（二）之客户端》](http://svip.iocoder.cn/Netty/bootstrap-2-client/) 的 [「3.6.4 finishConnect」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 小节。
- 第 44 至 50 行：如果对 `OP_WRITE` 事件就绪，调用 `Unsafe#forceFlush()` 方法，向 Channel 写入数据。在完成写入数据后，会移除对 `OP_WRITE` 的感兴趣。想要提前了解的胖友，可以自己看下 `AbstractNioByteChannel#clearOpWrite()` 和 `AbstractNioMessageChannel#doWrite(ChannelOutboundBuffer in)` 方法。
- 第 52 至 58 行：如果对 `OP_READ` 或 `OP_ACCEPT` 事件就绪：调用 `Unsafe#read()` 方法，处理读**或者**者接受客户端连接的事件。

# 8. NioTask

`io.netty.channel.nio.NioTask` ，用于自定义 Nio 事件处理**接口**。对于每个 Nio 事件，可以认为是一个任务( Task )，代码如下：

```
public interface NioTask<C extends SelectableChannel> {

    /**
     * Invoked when the {@link SelectableChannel} has been selected by the {@link Selector}.
     */
    void channelReady(C ch, SelectionKey key) throws Exception;

    /**
     * Invoked when the {@link SelectionKey} of the specified {@link SelectableChannel} has been cancelled and thus
     * this {@link NioTask} will not be notified anymore.
     *
     * @param cause the cause of the unregistration. {@code null} if a user called {@link SelectionKey#cancel()} or
     *              the event loop has been shut down.
     */
    void channelUnregistered(C ch, Throwable cause) throws Exception;

}
```

- `#channelReady(C ch, SelectionKey key)` 方法，处理 Channel IO 就绪的事件。相当于说，我们可以通过实现该接口方法，实现 [「7.3 processSelectedKey」](http://svip.iocoder.cn/Netty/EventLoop-5-EventLoop-handle-io-event/#) 的逻辑。
- `#channelUnregistered(C ch, Throwable cause)` 方法，Channel 取消注册。一般来说，我们可以通过实现该接口方法，关闭 Channel 。

😈 实际上，NioTask 在 Netty 自身中并未有相关的实现类，并且和闪电侠沟通了下，他在项目中，也并未使用。所以对 NioTask 不感兴趣的胖友，可以跳过本小节。另外，NioTask 是在 [Allow a user to access the Selector of an EventLoop](https://github.com/netty/netty/issues/681) 中有相关的讨论。

## 8.1 register

`#register(final SelectableChannel ch, final int interestOps, final NioTask<?> task)` 方法，注册 Java NIO Channel ( 不一定需要通过 Netty 创建的 Channel )到 Selector 上，相当于说，也注册到了 EventLoop 上。代码如下：

```
/**
 * Registers an arbitrary {@link SelectableChannel}, not necessarily created by Netty, to the {@link Selector}
 * of this event loop.  Once the specified {@link SelectableChannel} is registered, the specified {@code task} will
 * be executed by this event loop when the {@link SelectableChannel} is ready.
 */
public void register(final SelectableChannel ch, final int interestOps, final NioTask<?> task) {
    if (ch == null) {
        throw new NullPointerException("ch");
    }
    if (interestOps == 0) {
        throw new IllegalArgumentException("interestOps must be non-zero.");
    }
    if ((interestOps & ~ch.validOps()) != 0) {
        throw new IllegalArgumentException(
                "invalid interestOps: " + interestOps + "(validOps: " + ch.validOps() + ')');
    }
    if (task == null) {
        throw new NullPointerException("task");
    }

    if (isShutdown()) {
        throw new IllegalStateException("event loop shut down");
    }

    // <1>
    try {
        ch.register(selector, interestOps, task);
    } catch (Exception e) {
        throw new EventLoopException("failed to register a channel", e);
    }
}
```

- `<1>` 处，调用 `SelectableChannel#register(Selector sel, int ops, Object att)` 方法，注册 Java NIO Channel 到 Selector 上。这里我们可以看到，`attachment` 为 NioTask 对象，而不是 Netty Channel 对象。

## 8.2 invokeChannelUnregistered

`#invokeChannelUnregistered(NioTask<SelectableChannel> task, SelectionKey k, Throwable cause)` 方法，执行 Channel 取消注册。代码如下：

```
private static void invokeChannelUnregistered(NioTask<SelectableChannel> task, SelectionKey k, Throwable cause) {
    try {
        task.channelUnregistered(k.channel(), cause);
    } catch (Exception e) {
        logger.warn("Unexpected exception while running NioTask.channelUnregistered()", e);
    }
}
```

- 在方法内部，调用 `NioTask#channelUnregistered()` 方法，执行 Channel 取消注册。

## 8.3 processSelectedKey

`#processSelectedKey(SelectionKey k, NioTask<SelectableChannel> task)` 方法，使用 NioTask ，自定义实现 Channel 处理 Channel IO 就绪的事件。代码如下：

```
private static void processSelectedKey(SelectionKey k, NioTask<SelectableChannel> task) {
    int state = 0; // 未执行
    try {
        // 调用 NioTask 的 Channel 就绪事件
        task.channelReady(k.channel(), k);
        state = 1; // 执行成功
    } catch (Exception e) {
        // SelectionKey 取消
        k.cancel();
        // 执行 Channel 取消注册
        invokeChannelUnregistered(task, k, e);
        state = 2; // 执行异常
    } finally {
        switch (state) {
        case 0:
            // SelectionKey 取消
            k.cancel();
            // 执行 Channel 取消注册
            invokeChannelUnregistered(task, k, null);
            break;
        case 1:
            // SelectionKey 不合法，则执行 Channel 取消注册
            if (!k.isValid()) { // Cancelled by channelReady()
                invokeChannelUnregistered(task, k, null);
            }
            break;
        }
    }
}
```

- 代码比较简单，胖友自己看中文注释。主要是看懂`state`有 3 种情况：
  - `0` ：未执行。
  - `1` ：执行成功。
  - `2` ：执行异常。

# 666. 彩蛋

简单小文一篇，没什么太大难度的一篇。

如果有不理解的地方，也可以看看下面的文章：

- 闪电侠 [《netty 源码分析之揭开 reactor 线程的面纱（二）》](https://www.jianshu.com/p/467a9b41833e)
- Hypercube [《自顶向下深入分析 Netty（四）–EventLoop-2》](https://www.jianshu.com/p/d0f06b13e2fb)
- 杨武兵 [《netty 源码分析系列 —— EventLoop》](https://my.oschina.net/ywbrj042/blog/889748)
- 占小狼 [《Netty 源码分析之 NioEventLoop》](https://www.jianshu.com/p/9acf36f7e025)

# 精尽 Netty 源码解析 —— EventLoop（六）之 EventLoop 处理普通任务



# 1. 概述

本文我们分享 EventLoop 的**执行任务**相关代码的实现。对应如下图的紫条 **run tasks** 部分：![run](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554275002338.png)

EventLoop 执行的任务分成**普通**任务和**定时**任务，考虑到内容切分的更细粒度，本文近仅仅分享【**普通任务**】的部分。

# 2. runAllTasks 带超时

在 `#run()` 方法中，会调用 `#runAllTasks(long timeoutNanos)` 方法，执行所有任务直到完成所有，或者超过执行时间上限。代码如下：

```
 1: protected boolean runAllTasks(long timeoutNanos) {
 2:     // 从定时任务获得到时间的任务
 3:     fetchFromScheduledTaskQueue();
 4:     // 获得队头的任务
 5:     Runnable task = pollTask();
 6:     // 获取不到，结束执行
 7:     if (task == null) {
 8:         // 执行所有任务完成的后续方法
 9:         afterRunningAllTasks();
10:         return false;
11:     }
12: 
13:     // 计算执行任务截止时间
14:     final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos;
15:     long runTasks = 0; // 执行任务计数
16:     long lastExecutionTime;
17:     // 循环执行任务
18:     for (;;) {
19:         // 执行任务
20:         safeExecute(task);
21: 
22:         // 计数 +1
23:         runTasks ++;
24: 
25:         // 每隔 64 个任务检查一次时间，因为 nanoTime() 是相对费时的操作
26:         // 64 这个值当前是硬编码的，无法配置，可能会成为一个问题。
27:         // Check timeout every 64 tasks because nanoTime() is relatively expensive.
28:         // XXX: Hard-coded value - will make it configurable if it is really a problem.
29:         if ((runTasks & 0x3F) == 0) {
30:             // 重新获得时间
31:             lastExecutionTime = ScheduledFutureTask.nanoTime();
32:             // 超过任务截止时间，结束
33:             if (lastExecutionTime >= deadline) {
34:                 break;
35:             }
36:         }
37: 
38:         // 获得队头的任务
39:         task = pollTask();
40:         // 获取不到，结束执行
41:         if (task == null) {
42:             // 重新获得时间
43:             lastExecutionTime = ScheduledFutureTask.nanoTime();
44:             break;
45:         }
46:     }
47: 
48:     // 执行所有任务完成的后续方法
49:     afterRunningAllTasks();
50: 
51:     // 设置最后执行时间
52:     this.lastExecutionTime = lastExecutionTime;
53:     return true;
54: }
```

- 方法的返回值，表示是否执行过任务。因为，任务队列可能为空，那么就会返回 `false` ，表示没有执行过任务。

- 第 3 行：调用 `#fetchFromScheduledTaskQueue()` 方法，将定时任务队列 `scheduledTaskQueue` 到达可执行的任务，添加到任务队列 `taskQueue` 中。通过这样的方式，定时任务得以被执行。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（七）之 EventLoop 处理定时任务》](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task) 。

- 第 5 行：**首次**调用`#pollTask()`方法，获得队头的任务。详细解析，胖友先跳到[「4. pollTask」](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task/#) 。

  - 第 6 至 11 行：获取不到任务，结束执行，并返回`false`。
    - 第 9 行：调用 `#afterRunningAllTasks()` 方法，执行所有任务完成的**后续**方法。详细解析，见 [「5. afterRunningAllTasks」](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task/#) 。

- 第 14 行：计算执行任务截止时间。其中，`ScheduledFutureTask#nanoTime()` 方法，我们可以暂时理解成，获取当前的时间，单位为**纳秒**。详细解析，见 [《精尽 Netty 源码解析 —— EventLoop（七）之 EventLoop 处理定时任务》](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task) 。

- 第 17 至 46 行：

  循环

  执行任务。

  - 第 20 行：【重要】调用 `#safeExecute(Runnable task)` 方法，执行任务。

  - 第 23 行：计算 `runTasks` **加一**。

  - 第 29 至 36 行：每隔**64**个任务检查一次时间，因为`System#nanoTime()`是**相对费时**

    的操作。也因此，超过执行时间上限是“**近似的**”，而不是绝对准确。

    - 第 31 行：调用 `ScheduledFutureTask#nanoTime()` 方法，获取当前的时间。
    - 第 32 至 35 行：超过执行时间上限，结束执行。

  - 第 39 行：**再次**调用`#pollTask()`方法，获得队头的任务。

    - 第 41 至 45 行：获取不到，结束执行。
    - 第 43 行：调用 `ScheduledFutureTask#nanoTime()` 方法，获取当前的时间，作为**最终**的 `.lastExecutionTime` ，即【第 52 行】的代码。

- 第 49 行：调用 `#afterRunningAllTasks()` 方法，执行所有任务完成的**后续**方法。

- 第 53 行：返回 `true` ，表示有执行任务。

# 3. runAllTasks

在 `#run()` 方法中，会调用 `#runAllTasks()` 方法，执行所有任务直到完成所有。代码如下：

```
 1: protected boolean runAllTasks() {
 2:     assert inEventLoop();
 3:     boolean fetchedAll;
 4:     boolean ranAtLeastOne = false; // 是否执行过任务
 5: 
 6:     do {
 7:         // 从定时任务获得到时间的任务
 8:         fetchedAll = fetchFromScheduledTaskQueue();
 9:         // 执行任务队列中的所有任务
10:         if (runAllTasksFrom(taskQueue)) {
11:             // 若有任务执行，则标记为 true
12:             ranAtLeastOne = true;
13:         }
14:     } while (!fetchedAll); // keep on processing until we fetched all scheduled tasks.
15: 
16:     // 如果执行过任务，则设置最后执行时间
17:     if (ranAtLeastOne) {
18:         lastExecutionTime = ScheduledFutureTask.nanoTime();
19:     }
20: 
21:     // 执行所有任务完成的后续方法
22:     afterRunningAllTasks();
23:     return ranAtLeastOne;
24: }
```

- 第 4 行：`ranAtLeastOne` ，标记是否执行过任务。

- 第 6 至 14 行：调用 `#fetchFromScheduledTaskQueue()` 方法，将定时任务队列 `scheduledTaskQueue` 到达可执行的任务，添加到任务队列 `taskQueue` 中。但是实际上，任务队列 `taskQueue` 是有队列大小上限的，因此使用 `while` 循环，直到没有到达可执行的任务为止。

  - 第 10 行：调用 `#runAllTasksFrom(taskQueue)` 方法，执行任务队列中的所有任务。代码如下：

    ```
    protected final boolean runAllTasksFrom(Queue<Runnable> taskQueue) {
        // 获得队头的任务
        Runnable task = pollTaskFrom(taskQueue);
        // 获取不到，结束执行，返回 false
        if (task == null) {
            return false;
        }
        for (;;) {
            // 执行任务
            safeExecute(task);
            // 获得队头的任务
            task = pollTaskFrom(taskQueue);
            // 获取不到，结束执行，返回 true
            if (task == null) {
                return true;
            }
        }
    }
    ```

    - 代码比较简单，和 `#runAllTasks(long timeoutNanos))` 方法的代码，大体是相似的。

  - 第 12 行：若有任务被执行，则标记 `ranAtLeastOne` 为 `true` 。

- 第 16 至 19 行：如果执行过任务，则设置最后执行时间。

- 第 22 行：调用 `#afterRunningAllTasks()` 方法，执行所有任务完成的**后续**方法。

- 第 23 行：返回是否执行过任务。和 `#runAllTasks(long timeoutNanos))` 方法的返回是**一致**的。

# 4. pollTask

`#pollTask()` 方法，获得**队头**的任务。代码如下：

```
protected Runnable pollTask() {
    assert inEventLoop();
    return pollTaskFrom(taskQueue);
}

protected static Runnable pollTaskFrom(Queue<Runnable> taskQueue) {
    for (;;) { // <2>
        // 获得并移除队首元素。如果获得不到，返回 null
        Runnable task = taskQueue.poll(); // <1>
        // 忽略 WAKEUP_TASK 任务，因为是空任务
        if (task == WAKEUP_TASK) {
            continue;
        }
        return task;
    }
}
```

- `<1>` 处，调用 `Queue#poll()` 方法，获得并移除队首元素。如果获得不到，返回 null 。**注意**，这个操作是**非阻塞**的。如果胖友不知道，请 Google 重新学习下。
- `<2>` 处，因为获得的任务可能是 `WAKEUP_TASK` ，所以需要通过循环来跳过。

# 5. afterRunningAllTasks

在 [《精尽 Netty 源码解析 —— EventLoop（三）之 EventLoop 初始化》](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init/) 的 [「9.10 afterRunningAllTasks」](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task/#) 中，`#afterRunningAllTasks()` 方法，执行所有任务完成的**后续**方法。代码如下：

```
// SingleThreadEventLoop.java

protected void afterRunningAllTasks() {
    runAllTasksFrom(tailTasks);
}
```

- 在方法内部，会调用 `#runAllTasksFrom(tailTasks)` 方法，执行任务队列 `tailTasks` 的任务。

那么，可能很多胖友会和我有一样的疑问，**到底什么样的任务**，适合添加到 `tailTasks` 中呢？笔者请教了自己的好基友，闪电侠，来解答了这个问题。他实现了**批量提交写入**功能的 Handler ，代码如下：

```
public class BatchFlushHandler extends ChannelOutboundHandlerAdapter {

    private CompositeByteBuf compositeByteBuf;
    /**
    * 是否使用 CompositeByteBuf 对象，用于数据写入
    **/
    private boolean preferComposite;

    private SingleThreadEventLoop eventLoop;

    private Channel.Unsafe unsafe;

    /**
    * 是否添加任务到 tailTaskQueue 队列中
    */
    private boolean hasAddTailTask = false;

    public BatchFlushHandler() {
        this(true);
    }

    public BatchFlushHandler(boolean preferComposite) {
        this.preferComposite = preferComposite;
    }

    @Override
    public void handlerAdded(ChannelHandlerContext ctx) {
        // 初始化 CompositeByteBuf 对象，如果开启 preferComposite 功能
        if (preferComposite) {
            compositeByteBuf = ctx.alloc().compositeBuffer();
        }
        eventLoop = (SingleThreadEventLoop) ctx.executor();
        unsafe = ctx.channel().unsafe();
    }

    @Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
        // 写入到 CompositeByteBuf 对象中
        if (preferComposite) {
            compositeByteBuf.addComponent(true, (ByteBuf) msg);
        // 普通写入
        } else {
            ctx.write(msg);
        }
    }

    @Override
    public void flush(ChannelHandlerContext ctx) {
        // 通过 hasAddTailTask 有且仅有每个 EventLoop 执行循环( run )，只添加一次任务
        if (!hasAddTailTask) {
            hasAddTailTask = true;

            // 【重点】添加最终批量提交( flush )的任务
            // 【重点】添加最终批量提交( flush )的任务
            // 【重点】添加最终批量提交( flush )的任务
            eventLoop.executeAfterEventLoopIteration(() -> {
                if (preferComposite) {
                    ctx.writeAndFlush(compositeByteBuf).addListener(future -> compositeByteBuf = ctx.alloc()
                            .compositeBuffer());
                } else {
                    unsafe.flush();
                }
                
                // 重置 hasAddTailTask ，从而实现下个 EventLoop 执行循环( run )，可以再添加一次任务
                hasAddTailTask = false;
            });
        }
    }
}
```

- 代码可能略微有一丢丢难懂，不过笔者已经添加中文注释，胖友可以自己理解下。

- 为什么这样做会有好处呢？在 [《蚂蚁通信框架实践》](https://mp.weixin.qq.com/s/JRsbK1Un2av9GKmJ8DK7IQ) 的 [「5. 批量解包与批量提交」 ](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task/#)有相关分享。

  > 如此能减少 `pipeline` 的执行次数，同时提升吞吐量。这个模式在低并发场景，并没有什么优势，而在高并发场景下对提升吞吐量有不小的性能提升。

# 666. 彩蛋

美滋滋，比较简单。又是一个失眠的夜晚。

# 精尽 Netty 源码解析 —— EventLoop（七）之 EventLoop 处理定时任务



# 1. 概述

本文接 [《精尽 Netty 源码解析 —— EventLoop（六）之 EventLoop 处理普通任务》](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task) ，分享【处理**定时任务**】的部分。

因为 AbstractScheduledEventExecutor 在 [《精尽 Netty 源码解析 —— EventLoop（三）之 EventLoop 初始化》](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task/%E7%B2%BE%E5%B0%BD%20Netty%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%20%E2%80%94%E2%80%94%20EventLoop%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%20EventLoop%20%E5%88%9D%E5%A7%8B%E5%8C%96) 并未分享，并且它是本文的**处理定时任务的前置**，所以本文先写这部分内容。

# 2. ScheduledFutureTask

`io.netty.util.concurrent.ScheduledFutureTask` ，实现 ScheduledFuture、PriorityQueueNode 接口，继承 PromiseTask 抽象类，Netty 定时任务。

> 老艿艿：也有文章喜欢把“定时任务”叫作“调度任务”，意思是相同的，本文统一使用“定时任务”。

## 2.1 静态属性

```
/**
 * 任务序号生成器，通过 AtomicLong 实现递增发号
 */
private static final AtomicLong nextTaskId = new AtomicLong();
/**
 * 定时任务时间起点
 */
private static final long START_TIME = System.nanoTime();
```

- `nextTaskId` 静态属性，任务序号生成器，通过 AtomicLong 实现**递增**发号。

- `START_TIME` 静态属性，定时任务时间**起点**。在 ScheduledFutureTask 中，定时任务的执行时间，都是基于 `START_TIME` 做**相对**时间。😈 至于为什么使用相对时间？笔者暂时没有搞清楚。

  - 笔者也搜索了下和 `System.nanoTime()` 相关的内容，唯一能看的是 [《System.nanoTime() 的隐患》](http://hold-on.iteye.com/blog/1943436) ，但是应该不是这个原因。

  - 和我的大表弟普架交流了一波，他的理解是：

    > 因为是定时调度，我改了系统时间也没关系
    > 存的是距离下次调度还要多长时间
    > 不受系统时间影响
    > 最大的好处

    - 哎哟，牛逼如我大表弟啊！！！

## 2.2 nanoTime

`#nanoTime()` **静态**方法，获得当前时间，这个是相对 `START_TIME` 来算的。代码如下：

```
static long nanoTime() {
    return System.nanoTime() - START_TIME;
}
```

- 这是个重要的方法，后续很多方法都会调用到它。

## 2.3 deadlineNanos

`#deadlineNanos(long delay)` **静态**方法，获得任务执行时间，这个也是相对 `START_TIME` 来算的。代码如下：

```
/**
 * @param delay 延迟时长，单位：纳秒
 * @return 获得任务执行时间，也是相对 {@link #START_TIME} 来算的。
 *          实际上，返回的结果，会用于 {@link #deadlineNanos} 字段
 */
static long deadlineNanos(long delay) {
    long deadlineNanos = nanoTime() + delay;
    // Guard against overflow 防御性编程
    return deadlineNanos < 0 ? Long.MAX_VALUE : deadlineNanos;
}
```

## 2.4 构造方法

```
/**
 * 任务编号
 */
private final long id = nextTaskId.getAndIncrement();
/**
 * 任务执行时间，即到了该时间，该任务就会被执行
 */
private long deadlineNanos;
/**
 * 任务执行周期
 *
 * =0 - 只执行一次
 * >0 - 按照计划执行时间计算
 * <0 - 按照实际执行时间计算
 *
 * 推荐阅读文章 https://blog.csdn.net/gtuu0123/article/details/6040159
 */
/* 0 - no repeat, >0 - repeat at fixed rate, <0 - repeat with fixed delay */
private final long periodNanos;
/**
 * 队列编号
 */
private int queueIndex = INDEX_NOT_IN_QUEUE;

ScheduledFutureTask(
        AbstractScheduledEventExecutor executor,
        Runnable runnable, V result, long nanoTime) {
    this(executor, toCallable(runnable, result), nanoTime);
}

ScheduledFutureTask(
        AbstractScheduledEventExecutor executor,
        Callable<V> callable, long nanoTime, long period) {
    super(executor, callable);
    if (period == 0) {
        throw new IllegalArgumentException("period: 0 (expected: != 0)");
    }
    deadlineNanos = nanoTime;
    periodNanos = period;
}

ScheduledFutureTask(
        AbstractScheduledEventExecutor executor,
        Callable<V> callable, long nanoTime) {
    super(executor, callable);
    deadlineNanos = nanoTime;
    periodNanos = 0;
}
```

- 每个字段比较简单，胖友看上面的注释。

## 2.5 delayNanos

`#delayNanos(...)` 方法，获得距离指定时间，还要多久可执行。代码如下：

```
/**
 * @return 距离当前时间，还要多久可执行。若为负数，直接返回 0
 */
public long delayNanos() {
    return Math.max(0, deadlineNanos() - nanoTime());
}

/**
 * @param currentTimeNanos 指定时间
 * @return 距离指定时间，还要多久可执行。若为负数，直接返回 0
 */
public long delayNanos(long currentTimeNanos) {
    return Math.max(0, deadlineNanos() - (currentTimeNanos - START_TIME));
}

@Override
public long getDelay(TimeUnit unit) {
    return unit.convert(delayNanos(), TimeUnit.NANOSECONDS);
}
```

## 2.6 run

`#run()` 方法，执行定时任务。代码如下：

```
 1: @Override
 2: public void run() {
 3:     assert executor().inEventLoop();
 4:     try {
 5:         if (periodNanos == 0) {
 6:             // 设置任务不可取消
 7:             if (setUncancellableInternal()) {
 8:                 // 执行任务
 9:                 V result = task.call();
10:                 // 通知任务执行成功
11:                 setSuccessInternal(result);
12:             }
13:         } else {
14:             // 判断任务并未取消
15:             // check if is done as it may was cancelled
16:             if (!isCancelled()) {
17:                 // 执行任务
18:                 task.call();
19:                 if (!executor().isShutdown()) {
20:                     // 计算下次执行时间
21:                     long p = periodNanos;
22:                     if (p > 0) {
23:                         deadlineNanos += p;
24:                     } else {
25:                         deadlineNanos = nanoTime() - p;
26:                     }
27:                     // 判断任务并未取消
28:                     if (!isCancelled()) {
29:                         // 重新添加到任务队列，等待下次定时执行
30:                         // scheduledTaskQueue can never be null as we lazy init it before submit the task!
31:                         Queue<ScheduledFutureTask<?>> scheduledTaskQueue =
32:                                 ((AbstractScheduledEventExecutor) executor()).scheduledTaskQueue;
33:                         assert scheduledTaskQueue != null;
34:                         scheduledTaskQueue.add(this);
35:                     }
36:                 }
37:             }
38:         }
39:     // 发生异常，通知任务执行失败
40:     } catch (Throwable cause) {
41:         setFailureInternal(cause);
42:     }
43: }
```

- 第 3 行：校验，必须在 EventLoop 的线程中。

- 根据不同的任务执行周期 `periodNanos` ，在执行任务会略有不同。当然，大体是相同的。

- 第 5 至 12 行：执行周期为“

  只执行一次

  ”的定时任务。

  - 第 7 行：调用 `PromiseTask#setUncancellableInternal()` 方法，设置任务不可取消。具体的方法实现，我们在后续关于 Promise 的文章中分享。
  - 第 9 行：【重要】调用 `Callable#call()` 方法，执行任务。
  - 第 11 行：调用 `PromiseTask#setSuccessInternal(V result)` 方法，回调通知注册在定时任务上的监听器。为什么能这么做呢？因为 ScheduledFutureTask 继承了 PromiseTask 抽象类。

- 第 13 至 38 行：执行周期为“

  固定周期

  ”的定时任务。

  - 第 16 行：调用 `DefaultPromise#isCancelled()` 方法，判断任务是否已经取消。这一点，和【第 7 行】的代码，**是不同的**。具体的方法实现，我们在后续关于 Promise 的文章中分享。
  - 第 18 行：【重要】调用 `Callable#call()` 方法，执行任务。
  - 第 19 行：判断 EventExecutor 并未关闭。
  - 第 20 至 26 行：计算下次定时执行的时间。不同的执行 `fixed` 方式，计算方式不同。其中【第 25 行】的 `- p` 的代码，因为 `p` 是负数，所以通过**负负得正**来计算。另外，这块会修改定时任务的 `deadlineNanos` 属性，从而变成新的定时任务执行时间。
  - 第 28 行：和【第 16 行】的代码是**一致**的。
  - 第 29 至 34 行：重新添加到定时任务队列 `scheduledTaskQueue` 中，等待下次定时执行。

- 第 39 至 42 行：发生异常，调用 `PromiseTask#setFailureInternal(Throwable cause)` 方法，回调通知注册在定时任务上的监听器。

## 2.7 cancel

有两个方法，可以取消定时任务。代码如下：

```
@Override
public boolean cancel(boolean mayInterruptIfRunning) {
    boolean canceled = super.cancel(mayInterruptIfRunning);
    // 取消成功，移除出定时任务队列
    if (canceled) {
        ((AbstractScheduledEventExecutor) executor()).removeScheduled(this);
    }
    return canceled;
}

// 移除任务
boolean cancelWithoutRemove(boolean mayInterruptIfRunning) {
    return super.cancel(mayInterruptIfRunning);
}
```

- 差别在于，是否 调用 `AbstractScheduledEventExecutor#removeScheduled(ScheduledFutureTask)` 方法，从定时任务队列移除自己。

## 2.8 compareTo

`#compareTo(Delayed o)` 方法，用于队列( ScheduledFutureTask 使用 PriorityQueue 作为**优先级队列** )排序。代码如下：

```
@Override
public int compareTo(Delayed o) {
    if (this == o) {
        return 0;
    }

    ScheduledFutureTask<?> that = (ScheduledFutureTask<?>) o;
    long d = deadlineNanos() - that.deadlineNanos();
    if (d < 0) {
        return -1;
    } else if (d > 0) {
        return 1;
    } else if (id < that.id) {
        return -1;
    } else if (id == that.id) {
        throw new Error();
    } else {
        return 1;
    }
}
```

- 按照 `deadlineNanos`、`id` 属性**升序**排序。

## 2.9 priorityQueueIndex

`#priorityQueueIndex(...)` 方法，获得或设置 `queueIndex` 属性。代码如下：

```
@Override
public int priorityQueueIndex(DefaultPriorityQueue<?> queue) { // 获得
    return queueIndex;
}

@Override
public void priorityQueueIndex(DefaultPriorityQueue<?> queue, int i) { // 设置
    queueIndex = i;
}
```

- 因为 ScheduledFutureTask 实现 PriorityQueueNode 接口，所以需要实现这两个方法。

# 3. AbstractScheduledEventExecutor

`io.netty.util.concurrent.AbstractScheduledEventExecutor` ，继承 AbstractEventExecutor 抽象类，**支持定时任务**的 EventExecutor 的抽象类。

## 3.1 构造方法

```
/**
 * 定时任务队列
 */
PriorityQueue<ScheduledFutureTask<?>> scheduledTaskQueue;

protected AbstractScheduledEventExecutor() {
}

protected AbstractScheduledEventExecutor(EventExecutorGroup parent) {
    super(parent);
}
```

- `scheduledTaskQueue` 属性，定时任务队列。

## 3.2 scheduledTaskQueue

`#scheduledTaskQueue()` 方法，获得定时任务队列。若未初始化，则进行创建。代码如下：

```
/**
 * 定时任务排序器
 */
private static final Comparator<ScheduledFutureTask<?>> SCHEDULED_FUTURE_TASK_COMPARATOR =
        new Comparator<ScheduledFutureTask<?>>() {
            @Override
            public int compare(ScheduledFutureTask<?> o1, ScheduledFutureTask<?> o2) {
                return o1.compareTo(o2); //
            }
        };

PriorityQueue<ScheduledFutureTask<?>> scheduledTaskQueue() {
    if (scheduledTaskQueue == null) {
        scheduledTaskQueue = new DefaultPriorityQueue<ScheduledFutureTask<?>>(
                SCHEDULED_FUTURE_TASK_COMPARATOR,
                // Use same initial capacity as java.util.PriorityQueue
                11);
    }
    return scheduledTaskQueue;
}
```

- 创建的队列是 `io.netty.util.internal.DefaultPriorityQueue` 类型。具体的代码实现，本文先不解析。在这里，我们只要知道它是一个**优先级**队列，通过 `SCHEDULED_FUTURE_TASK_COMPARATOR` 来比较排序 ScheduledFutureTask 的任务优先级( 顺序 )。
- `SCHEDULED_FUTURE_TASK_COMPARATOR` 的具体实现，是调用 [「2.8 compareTo」](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task/#) 方法来实现，所以队列**首个**任务，就是**第一个**需要执行的定时任务。

## 3.3 nanoTime

`#nanoTime()` **静态**方法，获得当前时间。代码如下：

```
protected static long nanoTime() {
    return ScheduledFutureTask.nanoTime();
}
```

- 在方法内部，会调用 [「2.2 nanoTime」](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task/#) 方法。

## 3.4 schedule

`#schedule(final ScheduledFutureTask<V> task)` 方法，提交定时任务。代码如下：

```
<V> ScheduledFuture<V> schedule(final ScheduledFutureTask<V> task) {
    if (inEventLoop()) {
        // 添加到定时任务队列
        scheduledTaskQueue().add(task);
    } else {
        // 通过 EventLoop 的线程，添加到定时任务队列
        execute(new Runnable() {
            @Override
            public void run() {
                scheduledTaskQueue().add(task);
            }
        });
    }
    return task;
}
```

- 必须在 EventLoop 的线程中，**才能**添加到定时任务到队列中。

在 ScheduledFutureTask 中，有四个方法，会调用 `#schedule(final ScheduledFutureTask<V> task)` 方法，分别创建 **3** 种不同类型的定时任务。代码如下：

```
@Override
public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit) {
    ObjectUtil.checkNotNull(callable, "callable");
    ObjectUtil.checkNotNull(unit, "unit");
    if (delay < 0) {
        delay = 0;
    }
    // 无视，已经废弃
    validateScheduled0(delay, unit);

    return schedule(new ScheduledFutureTask<V>(
            this, callable, ScheduledFutureTask.deadlineNanos(unit.toNanos(delay))));
}

@Override
public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) {
    ObjectUtil.checkNotNull(command, "command");
    ObjectUtil.checkNotNull(unit, "unit");
    if (initialDelay < 0) {
        throw new IllegalArgumentException(
                String.format("initialDelay: %d (expected: >= 0)", initialDelay));
    }
    if (period <= 0) {
        throw new IllegalArgumentException(
                String.format("period: %d (expected: > 0)", period));
    }
    // 无视，已经废弃
    validateScheduled0(initialDelay, unit);
    validateScheduled0(period, unit);

    return schedule(new ScheduledFutureTask<Void>(
            this, Executors.<Void>callable(command, null), // Runnable => Callable
            ScheduledFutureTask.deadlineNanos(unit.toNanos(initialDelay)), unit.toNanos(period)));
}

@Override
public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) {
    ObjectUtil.checkNotNull(command, "command");
    ObjectUtil.checkNotNull(unit, "unit");
    if (initialDelay < 0) {
        throw new IllegalArgumentException(
                String.format("initialDelay: %d (expected: >= 0)", initialDelay));
    }
    if (delay <= 0) {
        throw new IllegalArgumentException(
                String.format("delay: %d (expected: > 0)", delay));
    }
    // 无视，已经废弃
    validateScheduled0(initialDelay, unit);
    validateScheduled0(delay, unit);

    return schedule(new ScheduledFutureTask<Void>(
            this, Executors.<Void>callable(command, null), // Runnable => Callable
            ScheduledFutureTask.deadlineNanos(unit.toNanos(initialDelay)), -unit.toNanos(delay)));
}
```

- 每个方法，前面都是校验参数的代码，重点是在最后对 `#schedule(final ScheduledFutureTask<V> task)` 方法的调用。

## 3.5 removeScheduled

`#removeScheduled(final ScheduledFutureTask<?> task)` 方法，移除出定时任务队列。代码如下：

```
final void removeScheduled(final ScheduledFutureTask<?> task) {
    if (inEventLoop()) {
        // 移除出定时任务队列
        scheduledTaskQueue().removeTyped(task);
    } else {
        // 通过 EventLoop 的线程，移除出定时任务队列
        execute(new Runnable() {
            @Override
            public void run() {
                removeScheduled(task);
            }
        });
    }
}
```

- 必须在 EventLoop 的线程中，**才能**移除出定时任务队列。

## 3.6 hasScheduledTasks

`#hasScheduledTasks()` 方法，判断是否有可执行的定时任务。代码如下：

```
/**
 * Returns {@code true} if a scheduled task is ready for processing.
 */
protected final boolean hasScheduledTasks() {
    Queue<ScheduledFutureTask<?>> scheduledTaskQueue = this.scheduledTaskQueue;
    // 获得队列首个定时任务。不会从队列中，移除该任务
    ScheduledFutureTask<?> scheduledTask = scheduledTaskQueue == null ? null : scheduledTaskQueue.peek();
    // 判断该任务是否到达可执行的时间
    return scheduledTask != null && scheduledTask.deadlineNanos() <= nanoTime();
}
```

- 代码比较简单，胖友直接看方法注释。

## 3.7 peekScheduledTask

`#peekScheduledTask()` 方法，获得队列首个定时任务。不会从队列中，移除该任务。代码如下：

```
final ScheduledFutureTask<?> peekScheduledTask() {
    Queue<ScheduledFutureTask<?>> scheduledTaskQueue = this.scheduledTaskQueue;
    if (scheduledTaskQueue == null) {
        return null;
    }
    return scheduledTaskQueue.peek();
}

```

## 3.8 nextScheduledTaskNano

`#nextScheduledTaskNano()` 方法，获得定时任务队列，距离当前时间，还要多久可执行。

- 若队列**为空**，则返回 `-1` 。
- 若队列**非空**，若为负数，直接返回 0 。实际等价，ScheduledFutureTask#delayNanos() 方法。

代码如下：

```
/**
 * Return the nanoseconds when the next scheduled task is ready to be run or {@code -1} if no task is scheduled.
 */
protected final long nextScheduledTaskNano() {
    Queue<ScheduledFutureTask<?>> scheduledTaskQueue = this.scheduledTaskQueue;
    // 获得队列首个定时任务。不会从队列中，移除该任务
    ScheduledFutureTask<?> scheduledTask = scheduledTaskQueue == null ? null : scheduledTaskQueue.peek();
    if (scheduledTask == null) {
        return -1;
    }
    // 距离当前时间，还要多久可执行。若为负数，直接返回 0 。实际等价，ScheduledFutureTask#delayNanos() 方法。
    return Math.max(0, scheduledTask.deadlineNanos() - nanoTime());
}

```

- 基本可以等价 [「2.5 delayNanos」](http://svip.iocoder.cn/Netty/EventLoop-7-EventLoop-handle-schedule-task/#) 的方法。

## 3.9 pollScheduledTask

`#pollScheduledTask(...)` 方法，获得指定时间内，定时任务队列**首个**可执行的任务，并且从队列中移除。代码如下：

```
/**
 * @see #pollScheduledTask(long)
 */
protected final Runnable pollScheduledTask() {
    return pollScheduledTask(nanoTime()); // 当前时间
}

/**
 * Return the {@link Runnable} which is ready to be executed with the given {@code nanoTime}.
 * You should use {@link #nanoTime()} to retrieve the correct {@code nanoTime}.
 */
protected final Runnable pollScheduledTask(long nanoTime) {
    assert inEventLoop();

    Queue<ScheduledFutureTask<?>> scheduledTaskQueue = this.scheduledTaskQueue;
    // 获得队列首个定时任务。不会从队列中，移除该任务
    ScheduledFutureTask<?> scheduledTask = scheduledTaskQueue == null ? null : scheduledTaskQueue.peek();
    // 直接返回，若获取不到
    if (scheduledTask == null) {
        return null;
    }

    // 在指定时间内，则返回该任务
    if (scheduledTask.deadlineNanos() <= nanoTime) {
        scheduledTaskQueue.remove(); // 移除任务
        return scheduledTask;
    }
    return null;
}

```

## 3.10 cancelScheduledTasks

`#cancelScheduledTasks()` 方法，取消定时任务队列的所有任务。代码如下：

```
/**
 * Cancel all scheduled tasks.
 * <p>
 * This method MUST be called only when {@link #inEventLoop()} is {@code true}.
 */
protected void cancelScheduledTasks() {
    assert inEventLoop();

    // 若队列为空，直接返回
    PriorityQueue<ScheduledFutureTask<?>> scheduledTaskQueue = this.scheduledTaskQueue;
    if (isNullOrEmpty(scheduledTaskQueue)) {
        return;
    }

    // 循环，取消所有任务
    final ScheduledFutureTask<?>[] scheduledTasks = scheduledTaskQueue.toArray(new ScheduledFutureTask<?>[0]);
    for (ScheduledFutureTask<?> task : scheduledTasks) {
        task.cancelWithoutRemove(false);
    }

    scheduledTaskQueue.clearIgnoringIndexes();
}

private static boolean isNullOrEmpty(Queue<ScheduledFutureTask<?>> queue) {
    return queue == null || queue.isEmpty();
}

```

- 代码比较简单，胖友自己看注释。

# 4. SingleThreadEventExecutor

在 [《精尽 Netty 源码解析 —— EventLoop（六）之 EventLoop 处理普通任务》](http://svip.iocoder.cn/Netty/EventLoop-6-EventLoop-handle-normal-task?self) 中，有个 `#fetchFromScheduledTaskQueue()` 方法，将定时任务队列 `scheduledTaskQueue` 到达可执行的任务，添加到任务队列 `taskQueue` 中。代码如下：

```
private boolean fetchFromScheduledTaskQueue() {
    // 获得当前时间
    long nanoTime = AbstractScheduledEventExecutor.nanoTime();
    // 获得指定时间内，定时任务队列**首个**可执行的任务，并且从队列中移除。
    Runnable scheduledTask  = pollScheduledTask(nanoTime);
    // 不断从定时任务队列中，获得
    while (scheduledTask != null) {
        // 将定时任务添加到 taskQueue 中。若添加失败，则结束循环，返回 false ，表示未获取完所有课执行的定时任务
        if (!taskQueue.offer(scheduledTask)) {
            // 将定时任务添加回 scheduledTaskQueue 中
            // No space left in the task queue add it back to the scheduledTaskQueue so we pick it up again.
            scheduledTaskQueue().add((ScheduledFutureTask<?>) scheduledTask);
            return false;
        }
        // 获得指定时间内，定时任务队列**首个**可执行的任务，并且从队列中移除。
        scheduledTask  = pollScheduledTask(nanoTime);
    }
    // 返回 true ，表示获取完所有可执行的定时任务
    return true;
}

```

- 代码比较简单，胖友看下笔者的详细代码注释。哈哈哈

# 666. 彩蛋

没有彩蛋，简单水文一篇。

# 精尽 Netty 源码解析 —— EventLoop（八）之 EventLoop 优雅关闭



# 1. 概述

笔者先把 Netty 主要的内容写完，所以关于 EventLoop 的优雅关闭的分享，先放在后续的计划里。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了两篇不错的文章：

- Hypercube [《自顶向下深入分析 Netty（四）–优雅退出机制》](https://www.jianshu.com/p/088c5017acd6)
- tomas家的小拨浪鼓 [《Netty 源码解析 ——— Netty 优雅关闭流程》](https://www.jianshu.com/p/e0ba9050aaef)

为避免可能 [《自顶向下深入分析 Netty（四）–优雅退出机制》](https://www.jianshu.com/p/088c5017acd6) 被作者删除，笔者这里先复制一份作为备份。

# 666. Netty优雅退出机制

你也许已经习惯了使用下面的代码，使一个线程池退出：

```
bossGroup.shutdownGracefully();
```

那么它是如何工作的呢？由于bossGroup是一个线程池，线程池的关闭要求其中的每一个线程关闭。而线程的实现是在SingleThreadEventExecutor类，所以我们将再次回到这个类，首先看其中的shutdownGracefully()方法，其中的参数quietPeriod为静默时间，timeout为截止时间，此外还有一个相关参数gracefulShutdownStartTime即优雅关闭开始时间，代码如下：

```
@Override
public Future<?> shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit) {
    if (isShuttingDown()) {
        return terminationFuture(); // 正在关闭阻止其他线程
    }

    boolean inEventLoop = inEventLoop();
    boolean wakeup;
    int oldState;
    for (;;) {
        if (isShuttingDown()) {
            return terminationFuture(); // 正在关闭阻止其他线程
        }
        int newState;
        wakeup = true;
        oldState = STATE_UPDATER.get(this);
        if (inEventLoop) {
            newState = ST_SHUTTING_DOWN;
        } else {
            switch (oldState) {
                case ST_NOT_STARTED:
                case ST_STARTED:
                    newState = ST_SHUTTING_DOWN;
                    break;
                default: // 一个线程已修改好线程状态，此时这个线程才执行16行代码
                    newState = oldState;
                    wakeup = false; // 已经有线程唤醒，所以不用再唤醒
            }
        }
        if (STATE_UPDATER.compareAndSet(this, oldState, newState)) {
            break;  // 保证只有一个线程将oldState修改为newState
        }
        // 隐含STATE_UPDATER已被修改，则在下一次循环返回
    }
     // 在default情况下会更新这两个值
    gracefulShutdownQuietPeriod = unit.toNanos(quietPeriod);
    gracefulShutdownTimeout = unit.toNanos(timeout);

    if (oldState == ST_NOT_STARTED) {
        thread.start();
    }
    if (wakeup) {
        wakeup(inEventLoop);
    }
    return terminationFuture();
}
```

这段代码真是为多线程同时调用关闭的情况操碎了心，我们抓住其中的关键点：该方法只是将线程状态修改为ST_SHUTTING_DOWN并不执行具体的关闭操作（类似的shutdown方法将线程状态修改为ST_SHUTDOWN）。for()循环是为了保证修改state的线程（原生线程或者外部线程）有且只有一个。如果你还没有理解这句话，请查阅compareAndSet()方法的说明然后再看一遍。39-44行代码之所以这样处理，是因为子类的实现中run()方法是一个EventLoop即一个循环。40行代码启动线程可以完整走一遍正常流程并且可以处理添加到队列中的任务以及IO事件。43行唤醒阻塞在阻塞点上的线程，使其从阻塞状态退出。要从一个EventLoop循环中退出，有什么好方法吗？可能你会想到这样处理：设置一个标记，每次循环都检测这个标记，如果标记为真就退出。Netty正是使用这种方法，NioEventLoop的run()方法的循环部分有这样一段代码：

```
if (isShuttingDown()) { // 检测线程状态
    closeAll(); // 关闭注册的channel
    if (confirmShutdown()) {
        break;
    }
}
```

查询线程状态的方法有三个，实现简单，一并列出：

```
public boolean isShuttingDown() {
    return STATE_UPDATER.get(this) >= ST_SHUTTING_DOWN;
}

public boolean isShutdown() {
    return STATE_UPDATER.get(this) >= ST_SHUTDOWN;
}

public boolean isTerminated() {
    return STATE_UPDATER.get(this) == ST_TERMINATED;
}
```

需要注意的是调用shutdownGracefully()方法后线程状态为ST_SHUTTING_DOWN，调用shutdown()方法后线程状态为ST_SHUTDOWN。isShuttingDown()可以一并判断这两种调用方法。closeAll()方法关闭注册到NioEventLoop的所有Channel，代码不再列出。confirmShutdown()方法在SingleThreadEventExecutor类，确定是否可以关闭或者说是否可以从EventLoop循环中跳出。代码如下：

```
protected boolean confirmShutdown() {
    if (!isShuttingDown()) {
        return false;   // 没有调用shutdown相关的方法直接返回
    }
    if (!inEventLoop()) {   // 必须是原生线程
        throw new IllegalStateException("must be invoked from an event loop");
    }

    cancelScheduledTasks(); // 取消调度任务
    if (gracefulShutdownStartTime == 0) {   // 优雅关闭开始时间，这也是一个标记
        gracefulShutdownStartTime = ScheduledFutureTask.nanoTime();
    }
    
    // 执行完普通任务或者没有普通任务时执行完shutdownHook任务
    if (runAllTasks() || runShutdownHooks()) {
        if (isShutdown()) {
            return true;    // 调用shutdown()方法直接退出
        }
        if (gracefulShutdownQuietPeriod == 0) {
            return true;    // 优雅关闭静默时间为0也直接退出
        }
        wakeup(true);   // 优雅关闭但有未执行任务，唤醒线程执行
        return false;
    }

    final long nanoTime = ScheduledFutureTask.nanoTime();
    // shutdown()方法调用直接返回，优雅关闭截止时间到也返回
    if (isShutdown() || nanoTime - gracefulShutdownStartTime > gracefulShutdownTimeout) {
        return true;
    }
    // 在静默期间每100ms唤醒线程执行期间提交的任务
    if (nanoTime - lastExecutionTime <= gracefulShutdownQuietPeriod) {
        wakeup(true);
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            // Ignore
        }
        return false;
    }
    // 静默时间内没有任务提交，可以优雅关闭，此时若用户又提交任务则不会被执行
    return true;
}
```

我们总结一下，调用shutdown()方法从循环跳出的条件有：
(1).执行完普通任务
(2).没有普通任务，执行完shutdownHook任务
(3).既没有普通任务也没有shutdownHook任务
调用shutdownGracefully()方法从循环跳出的条件有：
(1).执行完普通任务且静默时间为0
(2).没有普通任务，执行完shutdownHook任务且静默时间为0
(3).静默期间没有任务提交
(4).优雅关闭截止时间已到
注意上面所列的条件之间是**或**的关系，也就是说满足任意一条就会从EventLoop循环中跳出。我们可以将静默时间看为一段观察期，在此期间如果没有任务执行，说明可以跳出循环；如果此期间有任务执行，执行完后立即进入下一个观察期继续观察；如果连续多个观察期一直有任务执行，那么截止时间到则跳出循环。我们看一下shutdownGracefully()的默认参数：

```
public Future<?> shutdownGracefully() {
    return shutdownGracefully(2, 15, TimeUnit.SECONDS);
}
```

可知，Netty默认的shutdownGracefully()机制为：在2秒的静默时间内如果没有任务，则关闭；否则15秒截止时间到达时关闭。换句话说，在15秒时间段内，如果有超过2秒的时间段没有任务则关闭。至此，我们明白了从EvnetLoop循环中跳出的机制，最后，我们抵达终点站：线程结束机制。这一部分的代码实现在线程工厂的生成方法中：

```
thread = threadFactory.newThread(new Runnable() {
        @Override
        public void run() {
            boolean success = false;
            updateLastExecutionTime();
            try {
                SingleThreadEventExecutor.this.run();   // 模板方法，EventLoop实现
                success = true;
            } catch (Throwable t) {
                logger.warn("Unexpected exception from an event executor: ", t);
            } finally {
                for (;;) {
                    int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this);
                    // 用户调用了关闭的方法或者抛出异常
                    if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(
                            SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {
                        break;  // 抛出异常也将状态置为ST_SHUTTING_DOWN
                    }
                }
                if (success && gracefulShutdownStartTime == 0) {
                    // time=0，说明confirmShutdown()方法没有调用，记录日志
                }

                try {
                    for (;;) {
                        // 抛出异常时，将普通任务和shutdownHook任务执行完毕
                        // 正常关闭时，结合前述的循环跳出条件
                        if (confirmShutdown()) {
                            break;
                        }
                    }
                } finally {
                    try {
                        cleanup();
                    } finally {
                        // 线程状态设置为ST_TERMINATED，线程终止
                        STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);
                        threadLock.release();
                        if (!taskQueue.isEmpty()) {
                            //  关闭时，任务队列中添加了任务，记录日志
                        }
                        terminationFuture.setSuccess(null); // 异步结果设置为成功
                    }
                }
            }
        }
    });
```

20-22行代码说明子类在实现模板方法run()时，须调用confirmShutdown()方法，不调用的话会有错误日志。25-31行的for()循环主要是对异常情况的处理，但同时也兼顾了正常调用关闭方法的情况。可以将抛出异常的情况视为静默时间为0的shutdownGracefully()方法，这样便于理解循环跳出条件。34行代码cleanup()的默认实现什么也不做，NioEventLoop覆盖了基类，实现关闭NioEventLoop持有的selector：

```
protected void cleanup() {
    try {
        selector.close();
    } catch (IOException e) {
        logger.warn("Failed to close a selector.", e);
    }
}
```

关于Netty优雅关闭的机制，还有最后一点细节，那就是runShutdownHooks()方法：

```
private boolean runShutdownHooks() {
    boolean ran = false;
    while (!shutdownHooks.isEmpty()) {
        // 使用copy是因为shutdwonHook任务中可以添加或删除shutdwonHook任务
        List<Runnable> copy = new ArrayList<Runnable>(shutdownHooks);
        shutdownHooks.clear();
        for (Runnable task: copy) {
            try {
                task.run();
            } catch (Throwable t) {
                logger.warn("Shutdown hook raised an exception.", t);
            } finally {
                ran = true;
            }
        }
    }
    if (ran) {
        lastExecutionTime = ScheduledFutureTask.nanoTime();
    }
    return ran;
}
```

此外，还有threadLock.release()方法，如果你还记得字段定义，threadLock是一个初始值为0的信号量。一个初值为0的信号量，当线程请求锁时只会阻塞，这有什么用呢？awaitTermination()方法揭晓答案，用来使其他线程阻塞等待原生线程关闭 ：

```
public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException {
    // 由于tryAcquire()永远不会成功，所以必定阻塞timeout时间
    if (threadLock.tryAcquire(timeout, unit)) {
        threadLock.release();
    }
    return isTerminated();
}
```

# 精尽 Netty 源码解析 —— ChannelPipeline（一）之初始化



# 1. 概述

在 [《精尽 Netty 源码分析 —— Netty 简介（二）之核心组件》](http://svip.iocoder.cn/Netty/intro-2/?self) 中，对 EventLoopGroup 和 EventLoop 做了定义，我们再来回顾下：

> ChannelPipeline 为 ChannelHandler 的**链**，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。一个数据或者事件可能会被多个 Handler 处理，在这个过程中，数据或者事件经流 ChannelPipeline ，由 ChannelHandler 处理。在这个处理过程中，一个 ChannelHandler 接收数据后处理完成后交给下一个 ChannelHandler，或者什么都不做直接交给下一个 ChannelHandler。

因为 ChannelPipeline 涉及的代码量较大，所以笔者会分成好几篇文章分别分享。而本文，我们来分享 ChannelPipeline 的**初始化**。也因此，本文更多是体现 ChannelPipeline 的**整体性**，所以不会过多介绍每个类的具体的**每个方法**的实现。

# 2. ChannelPipeline

`io.netty.channel.ChannelPipeline` ，继承 ChannelInboundInvoker、ChannelOutboundInvoker、Iterable 接口，Channel Pipeline 接口。代码如下：

```
public interface ChannelPipeline
        extends ChannelInboundInvoker, ChannelOutboundInvoker, Iterable<Entry<String, ChannelHandler>> {

    // ========== 添加 ChannelHandler 相关 ==========
    ChannelPipeline addFirst(String name, ChannelHandler handler);
    ChannelPipeline addFirst(EventExecutorGroup group, String name, ChannelHandler handler);
    ChannelPipeline addLast(String name, ChannelHandler handler);
    ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler);
    ChannelPipeline addBefore(String baseName, String name, ChannelHandler handler);
    ChannelPipeline addBefore(EventExecutorGroup group, String baseName, String name, ChannelHandler handler);
    ChannelPipeline addAfter(String baseName, String name, ChannelHandler handler);
    ChannelPipeline addAfter(EventExecutorGroup group, String baseName, String name, ChannelHandler handler);
    ChannelPipeline addFirst(ChannelHandler... handlers);
    ChannelPipeline addFirst(EventExecutorGroup group, ChannelHandler... handlers);
    ChannelPipeline addLast(ChannelHandler... handlers);
    ChannelPipeline addLast(EventExecutorGroup group, ChannelHandler... handlers);

    // ========== 移除 ChannelHandler 相关 ==========
    ChannelPipeline remove(ChannelHandler handler);
    ChannelHandler remove(String name);
    <T extends ChannelHandler> T remove(Class<T> handlerType);
    ChannelHandler removeFirst();
    ChannelHandler removeLast();
    
    // ========== 替换 ChannelHandler 相关 ==========
    ChannelPipeline replace(ChannelHandler oldHandler, String newName, ChannelHandler newHandler);
    ChannelHandler replace(String oldName, String newName, ChannelHandler newHandler);
    <T extends ChannelHandler> T replace(Class<T> oldHandlerType, String newName, ChannelHandler newHandler);

    // ========== 查询 ChannelHandler 相关 ==========
    ChannelHandler first();
    ChannelHandlerContext firstContext();
    ChannelHandler last();
    ChannelHandlerContext lastContext();
    ChannelHandler get(String name);
    <T extends ChannelHandler> T get(Class<T> handlerType);
    ChannelHandlerContext context(ChannelHandler handler);
    ChannelHandlerContext context(String name);
    ChannelHandlerContext context(Class<? extends ChannelHandler> handlerType);
    List<String> names();

    // ========== Channel 相关 ==========
    Channel channel();

    // ========== ChannelInboundInvoker 相关 ==========    
    @Override
    ChannelPipeline fireChannelRegistered();
    @Override
    ChannelPipeline fireChannelUnregistered();
    @Override
    ChannelPipeline fireChannelActive();
    @Override
    ChannelPipeline fireChannelInactive();
    @Override
    ChannelPipeline fireExceptionCaught(Throwable cause);
    @Override
    ChannelPipeline fireUserEventTriggered(Object event);
    @Override
    ChannelPipeline fireChannelRead(Object msg);
    @Override
    ChannelPipeline fireChannelReadComplete();
    @Override
    ChannelPipeline fireChannelWritabilityChanged();

    // ========== ChannelOutboundInvoker 相关 ==========    
    @Override
    ChannelPipeline flush();
    
}
```

虽然接口的方法比较多，笔者做了归类如下：

- ChannelHandler 的增删改查的相关方法。
- Channel 的相关方法，目前只有一个。
- 继承自 ChannelInboundInvoker 的相关方法。
- 继承自 ChannelOutboundInvoker 的相关方法。

有可能会疑惑为什么继承 Iterable 接口？因为 ChannelPipeline 是 ChannelHandler 的**链**。

ChannelPipeline 的类图如下：

![ChannelPipeline 类图](http://static2.iocoder.cn/images/Netty/2018_06_01/01.png)

## 2.1 ChannelInboundInvoker

`io.netty.channel.ChannelInboundInvoker` ，Channel Inbound Invoker( 调用者 ) 接口。代码如下：

```
ChannelPipeline fireChannelRegistered();
ChannelPipeline fireChannelUnregistered();
ChannelPipeline fireChannelActive();
ChannelPipeline fireChannelInactive();
ChannelPipeline fireExceptionCaught(Throwable cause);
ChannelPipeline fireUserEventTriggered(Object event);
ChannelPipeline fireChannelRead(Object msg);
ChannelPipeline fireChannelReadComplete();
ChannelPipeline fireChannelWritabilityChanged();
```

- 通知 Channel 事件的接口方法。

## 2.2 ChannelOutboundInvoker

`io.netty.channel.ChannelOutboundInvoker` ，Channel Outbound Invoker( 调用者 ) 接口。代码如下：

```
// ========== Channel 操作相关 ==========    
ChannelFuture bind(SocketAddress localAddress);
ChannelFuture connect(SocketAddress remoteAddress);
ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress);
ChannelFuture disconnect();
ChannelFuture close();
ChannelFuture deregister();
ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise);
ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise);
ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise);
ChannelFuture disconnect(ChannelPromise promise);
ChannelFuture close(ChannelPromise promise);
ChannelFuture deregister(ChannelPromise promise);
ChannelOutboundInvoker read();
ChannelFuture write(Object msg);
ChannelFuture write(Object msg, ChannelPromise promise);
ChannelOutboundInvoker flush();
ChannelFuture writeAndFlush(Object msg, ChannelPromise promise);
ChannelFuture writeAndFlush(Object msg);

// ========== Promise 相关 ==========    
ChannelPromise newPromise();
ChannelProgressivePromise newProgressivePromise();
ChannelFuture newSucceededFuture();
ChannelFuture newFailedFuture(Throwable cause);
ChannelPromise voidPromise();
```

- 发起 Channel 操作的接口方法。
- 创建 Promise 对象的接口方法。

## 2.3 Outbound v.s Inbound 事件

在 [《Netty 源码分析之 二 贯穿Netty 的大动脉 ── ChannelPipeline (二)》](https://segmentfault.com/a/1190000007309311) 中，笔者看到一个比较不错的总结：

> 老艿艿：因为要加一些注释，所以暂时不使用引用。

**对于 Outbound 事件**：

- Outbound 事件是【请求】事件(由 Connect 发起一个请求, 并最终由 Unsafe 处理这个请求)

- Outbound 事件的发起者是 Channel

- Outbound 事件的处理者是 Unsafe

- Outbound 事件在 Pipeline 中的传输方向是 `tail` -> `head`

  > 旁白：Outbound 翻译为“出站”，所以从 `tail`( 尾 )到 `head`( 头 )也合理。
  >
  > 至于什么是 `head` 和 `tail` ，等看了具体的 ChannelPipeline 实现类 DefaultChannelPipeline 再说。

- 在 ChannelHandler 中处理事件时, 如果这个 Handler 不是最后一个 Handler, 则需要调用 `ctx.xxx` (例如 `ctx.connect` ) 将此事件继续传播下去. 如果不这样做, 那么此事件的传播会提前终止.

- Outbound 事件流: `Context.OUT_EVT` -> `Connect.findContextOutbound` -> `nextContext.invokeOUT_EVT` -> `nextHandler.OUT_EVT` -> `nextContext.OUT_EVT`

**对于 Inbound 事件**：

- Inbound 事件是【通知】事件, 当某件事情已经就绪后, 通知上层.

- Inbound 事件发起者是 Unsafe

- Inbound 事件的处理者是 TailContext, 如果用户没有实现自定义的处理方法, 那么Inbound 事件默认的处理者是 TailContext, 并且其处理方法是空实现.

- Inbound 事件在 Pipeline 中传输方向是 `head`( 头 ) -> `tail`( 尾 )

  > 旁白：Inbound 翻译为“入站”，所以从 `head`( 头 )到 `tail`( 尾 )也合理。

- 在 ChannelHandler 中处理事件时, 如果这个 Handler 不是最后一个 Handler, 则需要调用 `ctx.fireIN_EVT` (例如 `ctx.fireChannelActive` ) 将此事件继续传播下去. 如果不这样做, 那么此事件的传播会提前终止.

- Inbound 事件流: `Context.fireIN_EVT` -> `Connect.findContextInbound` -> `nextContext.invokeIN_EVT` -> `nextHandler.IN_EVT` -> `nextContext.fireIN_EVT`

Outbound 和 Inbound 事件十分的镜像, 并且 Context 与 Handler 直接的调用关系是否容易混淆, 因此读者在阅读这里的源码时, 需要特别的注意。

# 3. DefaultChannelPipeline

`io.netty.channel.DefaultChannelPipeline` ，实现 ChannelPipeline 接口，默认 ChannelPipeline 实现类。😈 实际上，也只有这个实现类。

## 3.1 静态属性

```
/**
 * {@link #head} 的名字
 */
private static final String HEAD_NAME = generateName0(HeadContext.class);
/**
 * {@link #tail} 的名字
 */
private static final String TAIL_NAME = generateName0(TailContext.class);

/**
 * 名字({@link AbstractChannelHandlerContext#name})缓存 ，基于 ThreadLocal ，用于生成在线程中唯一的名字。
 */
private static final FastThreadLocal<Map<Class<?>, String>> nameCaches = new FastThreadLocal<Map<Class<?>, String>>() {

    @Override
    protected Map<Class<?>, String> initialValue() throws Exception {
        return new WeakHashMap<Class<?>, String>();
    }

};

/**
 * {@link #estimatorHandle} 的原子更新器
 */
private static final AtomicReferenceFieldUpdater<DefaultChannelPipeline, MessageSizeEstimator.Handle> ESTIMATOR =
        AtomicReferenceFieldUpdater.newUpdater(
                DefaultChannelPipeline.class, MessageSizeEstimator.Handle.class, "estimatorHandle");
```

- `HEAD_NAME` 和 `TAIL_NAME` 静态属性，通过调用 `#generateName0(Class<?> handlerType)` 方法，生成对应的名字。代码如下：

  ```
  private static String generateName0(Class<?> handlerType) {
      return StringUtil.simpleClassName(handlerType) + "#0";
  }
  ```

  - 即 `HEAD_NAME = "HeadContext#0"`，`TAIL_NAME= "TailContext#0"` 。

- `nameCaches` 静态属性，名字( `AbstractChannelHandlerContext.name` )缓存 ，基于 ThreadLocal ，用于生成**在线程中唯一的名字**。详细解析，见 [《精尽 Netty 源码解析 —— Pipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler) 。

- `ESTIMATOR` 静态属性，`estimatorHandle` 属性的**原子**更新器。

## 3.2 构造方法

```
/**
 * Head 节点
 */
final AbstractChannelHandlerContext head;
/**
 * Tail 节点
 */
final AbstractChannelHandlerContext tail;

/**
 * 所属 Channel 对象
 */
private final Channel channel;
/**
 * 成功的 Promise 对象
 */
private final ChannelFuture succeededFuture;
/**
 * 不进行通知的 Promise 对象
 *
 * 用于一些方法执行，需要传入 Promise 类型的方法参数，但是不需要进行通知，就传入该值
 *
 * @see io.netty.channel.AbstractChannel.AbstractUnsafe#safeSetSuccess(ChannelPromise) 
 */
private final VoidChannelPromise voidPromise;
/**
 * TODO 1008 DefaultChannelPipeline 字段用途
 */
private final boolean touch = ResourceLeakDetector.isEnabled();

/**
 * 子执行器集合。
 *
 * 默认情况下，ChannelHandler 使用 Channel 所在的 EventLoop 作为执行器。
 * 但是如果有需要，也可以自定义执行器。详细解析，见 {@link #childExecutor(EventExecutorGroup)} 。
 * 实际情况下，基本不会用到。和基友【闪电侠】沟通过。
 */
private Map<EventExecutorGroup, EventExecutor> childExecutors;
/**
 * TODO 1008 DefaultChannelPipeline 字段用途
 */
private volatile MessageSizeEstimator.Handle estimatorHandle;
/**
 * 是否首次注册
 */
private boolean firstRegistration = true;

/**
 * This is the head of a linked list that is processed by {@link #callHandlerAddedForAllHandlers()} and so process
 * all the pending {@link #callHandlerAdded0(AbstractChannelHandlerContext)}.
 *
 * We only keep the head because it is expected that the list is used infrequently and its size is small.
 * Thus full iterations to do insertions is assumed to be a good compromised to saving memory and tail management
 * complexity.
 * 
 * 准备添加 ChannelHandler 的回调
 */
private PendingHandlerCallback pendingHandlerCallbackHead;

/**
 * Set to {@code true} once the {@link AbstractChannel} is registered.Once set to {@code true} the value will never
 * change.
 * Channel 是否已注册
 */
private boolean registered;

protected DefaultChannelPipeline(Channel channel) {
    this.channel = ObjectUtil.checkNotNull(channel, "channel");
    // succeededFuture 的创建
    succeededFuture = new SucceededChannelFuture(channel, null);
    // voidPromise 的创建
    voidPromise =  new VoidChannelPromise(channel, true);

    // 创建 Tail 及诶点
    tail = new TailContext(this); // <1>
    // 创建 Head 节点
    head = new HeadContext(this); // <2>

    // 相互指向 <3>
    head.next = tail;
    tail.prev = head;
}
```

- `head` 属性，Head 节点，在构造方法的 `<1>` 处初始化。详细解析，见 [「4.2 HeadContext」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#) 。

- `tail` 节点，Tail 节点，在构造方法的 `<2>` 处初始化。详细解析，见 [「4.3 TailContext」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#) 。

- 在构造方法的 `<3>` 处，`head` 节点向**下**指向 `tail` 节点，`tail` 节点向**上**指向 `head` 节点，从而形成**相互**的指向。即如下图所示：

  > FROM [《netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
  >
  > ![pipeline 节点链(默认)](http://static2.iocoder.cn/images/Netty/2018_06_01/02.png)

  - pipeline 中的节点的数据结构是 ChannelHandlerContext 类。每个 ChannelHandlerContext 包含**一个** ChannelHandler、它的**上下**节点( **从而形成 ChannelHandler 链** )、以及其他上下文。详细解析，见 [「4. ChannelHandlerContext」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#) 。

  - 默认情况下，pipeline 有 `head` 和 `tail` 节点，形成默认的 ChannelHandler 链。而我们可以在它们之间，加入自定义的 ChannelHandler 节点。如下图所示：

    > FROM [《netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
    >
    > ![pipeline 节点链(自定义)](http://static2.iocoder.cn/images/Netty/2018_06_01/03.png)

- `childExecutors` 属性，子执行器集合。默认情况下，ChannelHandler 使用 Channel 所在的 EventLoop 作为执行器。

  - 但是如果有需要，也可以自定义执行器。详细解析，见 [《精尽 Netty 源码解析 —— Pipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler) 。
  - 实际情况下，基本不会用到。和基友【闪电侠】沟通过。

- `pendingHandlerCallbackHead` 属性，准备添加 ChannelHandler 的回调。详细解析，见 [《精尽 Netty 源码解析 —— Pipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler) 。

- `registered` 属性，Channel 是否已注册。详细解析，见 [《精尽 Netty 源码解析 —— Pipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler) 。

- `firstRegistration` 属性，是否首次注册。详细解析，见 [《精尽 Netty 源码解析 —— Pipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler) 。

## 3.3 其他方法

DefaultChannelPipeline 中的其他方法，详细解析，见后续的文章。

# 4. ChannelHandlerContext

`io.netty.channel.ChannelHandlerContext` ，继承 ChannelInboundInvoker、ChannelOutboundInvoker、AttributeMap 接口，ChannelHandler Context( 上下文 )接口，作为 ChannelPipeline 中的**节点**。代码如下：

```
// ========== Context 相关 ==========
String name();
Channel channel();
EventExecutor executor();
ChannelHandler handler();
ChannelPipeline pipeline();
boolean isRemoved(); // 是否已经移除

// ========== ByteBuf 相关 ==========    
ByteBufAllocator alloc();

// ========== ChannelInboundInvoker 相关 ==========    
@Override
ChannelHandlerContext fireChannelRegistered();
@Override
ChannelHandlerContext fireChannelUnregistered();
@Override
ChannelHandlerContext fireChannelActive();
@Override
ChannelHandlerContext fireChannelInactive();
@Override
ChannelHandlerContext fireExceptionCaught(Throwable cause);
@Override
ChannelHandlerContext fireUserEventTriggered(Object evt);
@Override
ChannelHandlerContext fireChannelRead(Object msg);
@Override
ChannelHandlerContext fireChannelReadComplete();
@Override
ChannelHandlerContext fireChannelWritabilityChanged();

// ========== ChannelOutboundInvoker 相关 ==========
@Override
ChannelHandlerContext read();
@Override
ChannelHandlerContext flush();

// ========== AttributeMap 相关 ==========
@Deprecated
@Override
<T> Attribute<T> attr(AttributeKey<T> key);
@Deprecated
@Override
<T> boolean hasAttr(AttributeKey<T> key);
```

虽然接口的方法比较多，笔者做了归类如下：

- Context 相关的接口方法。
- 继承自 ChannelInboundInvoker 的相关方法，*和 ChannelPipeline 一样*。
- 继承自 ChannelOutboundInvoker 的相关方法，*和 ChannelPipeline 一样*。
- 继承自 AttributeMap 的相关方法，实际上已经废弃( `@Deprecated` )了，不再从 ChannelHandlerContext 中获取，而是从 Channel 中获取。

ChannelHandlerContext 的类图如下：

![ChannelHandlerContext 类图](http://static2.iocoder.cn/images/Netty/2018_06_01/04.png)

- 😈 类图中的 AttributeMap 和 DefaultAttributeMap 可以无视。

## 4.1 AbstractChannelHandlerContext

`io.netty.channel.AbstractChannelHandlerContext` ，实现 ChannelHandlerContext、ResourceLeakHint 接口，继承 DefaultAttributeMap 类，ChannelHandlerContext 抽象基类。

### 4.1.1 静态属性

```
/**
 * Neither {@link ChannelHandler#handlerAdded(ChannelHandlerContext)}
 * nor {@link ChannelHandler#handlerRemoved(ChannelHandlerContext)} was called.
 */
private static final int INIT = 0; // 初始化
/**
 * {@link ChannelHandler#handlerAdded(ChannelHandlerContext)} is about to be called.
 */
private static final int ADD_PENDING = 1; // 添加准备中
/**
 * {@link ChannelHandler#handlerAdded(ChannelHandlerContext)} was called.
 */
private static final int ADD_COMPLETE = 2; // 已添加
/**
 * {@link ChannelHandler#handlerRemoved(ChannelHandlerContext)} was called.
 */
private static final int REMOVE_COMPLETE = 3; // 已移除

/**
 * {@link #handlerState} 的原子更新器
 */
private static final AtomicIntegerFieldUpdater<AbstractChannelHandlerContext> HANDLER_STATE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(AbstractChannelHandlerContext.class, "handlerState");

// ========== 非静态属性 ==========

/**
 * 处理器状态
 */
private volatile int handlerState = INIT;
```

- ```
  handlerState
  ```

   

  属性(

   

  非静态

  属性，放这里主要是为了统一讲 )，处理器状态。共有

   

  4

   

  种状态。状态变迁如下图：

  

  - 详细解析，见 [「4.1.3 setAddComplete」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#)、[「4.1.4 setRemoved」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#)、[「4.1.5 setAddPending」](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init/#) 中。

- `HANDLER_STATE_UPDATER` **静态**属性，`handlerState` 的原子更新器。

### 4.1.2 构造方法

```
/**
 * 上一个节点
 */
volatile AbstractChannelHandlerContext next;
/**
 * 下一个节点
 */
volatile AbstractChannelHandlerContext prev;
/**
 * 是否为 inbound
 */
private final boolean inbound;
/**
 * 是否为 outbound
 */
private final boolean outbound;
/**
 * 所属 pipeline
 */
private final DefaultChannelPipeline pipeline;
/**
 * 名字
 */
private final String name;
/**
 * 是否使用有序的 EventExecutor ( {@link #executor} )，即 OrderedEventExecutor
 */
private final boolean ordered;

// Will be set to null if no child executor should be used, otherwise it will be set to the
// child executor.
/**
 * EventExecutor 对象
 */
final EventExecutor executor;
/**
 * 成功的 Promise 对象
 */
private ChannelFuture succeededFuture;

// Lazily instantiated tasks used to trigger events to a handler with different executor. 懒加载
// There is no need to make this volatile as at worse it will just create a few more instances then needed.
/**
 * 执行 Channel ReadComplete 事件的任务
 */
private Runnable invokeChannelReadCompleteTask;
/**
 * 执行 Channel Read 事件的任务
 */
private Runnable invokeReadTask;
/**
 * 执行 Channel WritableStateChanged 事件的任务
 */
private Runnable invokeChannelWritableStateChangedTask;
/**
 * 执行 flush 事件的任务
 */
private Runnable invokeFlushTask;
/**
 * 处理器状态
 */
private volatile int handlerState = INIT;

AbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name,
                              boolean inbound, boolean outbound) {
    this.name = ObjectUtil.checkNotNull(name, "name");
    this.pipeline = pipeline;
    this.executor = executor;
    this.inbound = inbound;
    this.outbound = outbound;
    // Its ordered if its driven by the EventLoop or the given Executor is an instanceof OrderedEventExecutor.
    ordered = executor == null || executor instanceof OrderedEventExecutor; // <1>
}
```

- `next`、`prev` 属性，分别记录上、下一个节点。

- Handler 相关属性：

  - 在 AbstractChannelHandlerContext 抽象类中，按照我们上文的分享，应该会看到一个类型为 ChannelHandler 的处理器，但是**实际并不是这样**。而是，😈 我们下文 DefaultChannelHandlerContext、TailContext、HeadContext 见。
  - `inbound`、`outbound` 属性，分别是否为 Inbound、Outbound 处理器。
  - `name` 属性，处理器名字。
  - `handlerState` 属性，处理器状态，初始为 `INIT` 。

- ```
  executor
  ```

   

  属性，EventExecutor 对象

  - `ordered` 属性，是否使用有序的 `executor`，即 OrderedEventExecutor ，在构造方法的 `<1>` 处理的初始化。

- `pipeline` 属性，所属 DefaultChannelPipeline 对象。

### 4.1.3 setAddComplete

`#setAddComplete()` 方法，设置 ChannelHandler 添加完成。完成后，状态有两种结果：

1. `REMOVE_COMPLETE`
2. `ADD_COMPLETE`

代码如下：

```
final void setAddComplete() {
    for (;;) {
        int oldState = handlerState;
        // Ensure we never update when the handlerState is REMOVE_COMPLETE already.
        // oldState is usually ADD_PENDING but can also be REMOVE_COMPLETE when an EventExecutor is used that is not
        // exposing ordering guarantees.
        if (oldState == REMOVE_COMPLETE || HANDLER_STATE_UPDATER.compareAndSet(this, oldState, ADD_COMPLETE)) {
            return;
        }
    }
}
```

- 循环 + CAS 保证多线程下的安全变更 `handlerState` 属性。

### 4.1.4 setRemoved

`#setRemoved()` 方法，设置 ChannelHandler 已移除。代码如下：

```
final void setRemoved() {
    handlerState = REMOVE_COMPLETE;
}
```

### 4.1.5 setAddPending

`#setAddPending()` 方法，设置 ChannelHandler 准备添加中。代码如下：

```
final void setAddPending() {
    boolean updated = HANDLER_STATE_UPDATER.compareAndSet(this, INIT, ADD_PENDING);
    assert updated; // This should always be true as it MUST be called before setAddComplete() or setRemoved().
}
```

- 当且仅当 `INIT` 可修改为 `ADD_PENDING` 。理论来说，这是一个绝对会成功的操作，原因见英文注释。

### 4.1.6 其他方法

AbstractChannelHandlerContext 中的其他方法，详细解析，见后续的文章。

## 4.2 HeadContext

HeadContext ，实现 ChannelOutboundHandler、ChannelInboundHandler 接口，继承 AbstractChannelHandlerContext 抽象类，**pipe 头节点** Context 实现类。

> HeadContext 是 DefaultChannelPipeline 的内部类。

### 4.2.1 构造方法

```
private final Unsafe unsafe;

HeadContext(DefaultChannelPipeline pipeline) {
    super(pipeline, null, HEAD_NAME, false, true); // <1>
    unsafe = pipeline.channel().unsafe(); // <2>
    setAddComplete(); // <3>
}
```

- `<1>` 处，调用父 AbstractChannelHandlerContext 的构造方法，设置 `inbound = false`、`outbound = true` 。

- `<2>` 处，使用 Channel 的 Unsafe 作为 `unsafe` 属性。HeadContext 实现 ChannelOutboundHandler 接口的方法，都会调用 Unsafe 对应的方法。代码如下：

  ```
  @Override
  public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
      unsafe.bind(localAddress, promise);
  }
  
  @Override
  public void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception {
      unsafe.connect(remoteAddress, localAddress, promise);
  }
  
  @Override
  public void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
      unsafe.disconnect(promise);
  }
  
  @Override
  public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
      unsafe.close(promise);
  }
  
  @Override
  public void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
      unsafe.deregister(promise);
  }
  
  @Override
  public void read(ChannelHandlerContext ctx) {
      unsafe.beginRead();
  }
  
  @Override
  public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
      unsafe.write(msg, promise);
  }
  
  @Override
  public void flush(ChannelHandlerContext ctx) throws Exception {
      unsafe.flush();
  }
  ```

  - 这也就是为什么设置 `outbound = true` 的原因。

- `<3>` 处，调用 `#setAddComplete()` 方法，设置 ChannelHandler 添加完成。此时，`handlerStatus` 会变成 `ADD_COMPLETE` 状态。

### 4.2.2 handler

`#handler()` 方法，返回自己作为 Context 的 **ChannelHandler** 。代码如下：

```
@Override
public ChannelHandler handler() {
    return this;
}

```

- 因为 HeadContext ，实现 ChannelOutboundHandler、ChannelInboundHandler 接口，而它们本身就是 ChannelHandler 。

### 4.2.3 其他方法

HeadContext 中的其他方法，详细解析，见后续的文章。

## 4.3 TailContext

TailContext ，实现 ChannelInboundHandler 接口，继承 AbstractChannelHandlerContext 抽象类，**pipe 尾节点** Context 实现类。

> TailContext 是 DefaultChannelPipeline 的内部类。

### 4.3.1 构造方法

```
TailContext(DefaultChannelPipeline pipeline) {
    super(pipeline, null, TAIL_NAME, true, false); // <1>
    setAddComplete(); // <2>
}

```

- `<1>` 处，调用父 AbstractChannelHandlerContext 的构造方法，设置 `inbound = true`、`outbound = false` ，和 HeadContext **相反**。
- `<2>` 处，调用 `#setAddComplete()` 方法，设置 ChannelHandler 添加完成。此时，`handlerStatus` 会变成 `ADD_COMPLETE` 状态。

### 4.3.2 handler

`#handler()` 方法，返回自己作为 Context 的 **ChannelHandler** 。代码如下：

```
@Override
public ChannelHandler handler() {
    return this;
}

```

- 因为 HeadContext ，实现 ChannelInboundHandler 接口，而它们本身就是 ChannelHandler 。

### 4.3.3 其他方法

TailContext 中的其他方法，详细解析，见后续的文章。

## 4.4 DefaultChannelHandlerContext

`io.netty.channel.DefaultChannelHandlerContext` ，实现 AbstractChannelHandlerContext 抽象类。代码如下：

```
final class DefaultChannelHandlerContext extends AbstractChannelHandlerContext {

    private final ChannelHandler handler;

    DefaultChannelHandlerContext(
            DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) {
        super(pipeline, executor, name, isInbound(handler), isOutbound(handler)); // <1>
        if (handler == null) {
            throw new NullPointerException("handler");
        }
        this.handler = handler; // <2>
    }

    @Override
    public ChannelHandler handler() {
        return handler;
    }

    private static boolean isInbound(ChannelHandler handler) {
        return handler instanceof ChannelInboundHandler;
    }

    private static boolean isOutbound(ChannelHandler handler) {
        return handler instanceof ChannelOutboundHandler;
    }

}

```

- 不同于 HeadContext、TailContext，它们自身就是一个 Context 的同时，也是一个 ChannelHandler 。而 DefaultChannelHandlerContext 是**内嵌** 一个 ChannelHandler 对象，即 `handler` 。这个属性通过构造方法传入，在 `<2>` 处进行赋值。
- `<1>` 处，调用父 AbstractChannelHandlerContext 的构造方法，通过判断传入的 `handler` 是否为 ChannelInboundHandler 和 ChannelOutboundHandler 来分别判断是否为 `inbound` 和 `outbound` 。

# 666. 彩蛋

推荐阅读如下文章：

- 闪电侠 [《netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
- 永顺 [《Netty 源码分析之 二 贯穿Netty 的大动脉 ── ChannelPipeline (一)》](https://segmentfault.com/a/1190000007308934)
- 占小狼 [《Netty 源码分析之 ChannelPipeline》](https://www.jianshu.com/p/3876874306d5)

# 精尽 Netty 源码解析 —— ChannelPipeline（二）之添加 ChannelHandler



# 1. 概述

本文我们来分享，**添加** ChannelHandler 到 pipeline 中的代码具体实现。

在 [《精尽 Netty 源码解析 —— ChannelPipeline（一）之初始化》](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init) 中，我们看到 ChannelPipeline 定义了一大堆**添加** ChannelHandler 的接口方法：

```java
ChannelPipeline addFirst(String name, ChannelHandler handler);
ChannelPipeline addFirst(EventExecutorGroup group, String name, ChannelHandler handler);
ChannelPipeline addLast(String name, ChannelHandler handler);
ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler);
ChannelPipeline addBefore(String baseName, String name, ChannelHandler handler);
ChannelPipeline addBefore(EventExecutorGroup group, String baseName, String name, ChannelHandler handler);
ChannelPipeline addAfter(String baseName, String name, ChannelHandler handler);
ChannelPipeline addAfter(EventExecutorGroup group, String baseName, String name, ChannelHandler handler);
ChannelPipeline addFirst(ChannelHandler... handlers);
ChannelPipeline addFirst(EventExecutorGroup group, ChannelHandler... handlers);
ChannelPipeline addLast(ChannelHandler... handlers);
ChannelPipeline addLast(EventExecutorGroup group, ChannelHandler... handlers);
```

- 考虑到实际当中，我们使用 `#addLast(ChannelHandler... handlers)` 方法较多，所以本文只分享这个方法的具体实现。

# 2. addLast

`#addLast(ChannelHandler... handlers)` 方法，添加任意数量的 ChannelHandler 对象。代码如下：

```java
@Override
public final ChannelPipeline addLast(ChannelHandler... handlers) {
    return addLast(null, handlers);
}

@Override
public final ChannelPipeline addLast(EventExecutorGroup executor, ChannelHandler... handlers) {
    if (handlers == null) {
        throw new NullPointerException("handlers");
    }

    for (ChannelHandler h: handlers) {
        if (h == null) {
            break;
        }
        addLast(executor, null, h); // <1>
    }

    return this;
}
```

- `<1>` 处，调用 `#addLast(EventExecutorGroup group, String name, ChannelHandler handler)` 方法，添加一个 ChannelHandler 对象到 pipeline 中。

`#addLast(EventExecutorGroup group, String name, ChannelHandler handler)` 方法，代码如下：

```java
 1: @Override
 2: @SuppressWarnings("Duplicates")
 3: public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) {
 4:     final AbstractChannelHandlerContext newCtx;
 5:     synchronized (this) { // 同步，为了防止多线程并发操作 pipeline 底层的双向链表
 6:         // 检查是否有重复 handler
 7:         checkMultiplicity(handler);
 8: 
 9:         // 创建节点名
10:         // 创建节点
11:         newCtx = newContext(group, filterName(name, handler), handler);
12: 
13:         // 添加节点
14:         addLast0(newCtx);
15: 
16:         // <1> pipeline 暂未注册，添加回调。再注册完成后，执行回调。详细解析，见 {@link #invokeHandlerAddedIfNeeded} 方法。
17:         // If the registered is false it means that the channel was not registered on an eventloop yet.
18:         // In this case we add the context to the pipeline and add a task that will call
19:         // ChannelHandler.handlerAdded(...) once the channel is registered.
20:         if (!registered) {
21:             // 设置 AbstractChannelHandlerContext 准备添加中
22:             newCtx.setAddPending();
23:             // 添加 PendingHandlerCallback 回调
24:             callHandlerCallbackLater(newCtx, true);
25:             return this;
26:         }
27: 
28:         // <2> 不在 EventLoop 的线程中，提交 EventLoop 中，执行回调用户方法
29:         EventExecutor executor = newCtx.executor();
30:         if (!executor.inEventLoop()) {
31:             // 设置 AbstractChannelHandlerContext 准备添加中
32:             newCtx.setAddPending();
33:             // 提交 EventLoop 中，执行回调 ChannelHandler added 事件
34:             executor.execute(new Runnable() {
35:                 @Override
36:                 public void run() {
37:                     callHandlerAdded0(newCtx);
38:                 }
39:             });
40:             return this;
41:         }
42:     }
43: 
44:     // <3> 回调 ChannelHandler added 事件
45:     callHandlerAdded0(newCtx);
46:     return this;
47: }
```

- 第 5 行：`synchronized` 同步，为了防止多线程并发操作 pipeline 底层的双向链表。
- 第 7 行：调用 `#checkMultiplicity(ChannelHandler)` 方法，校验是否重复的 ChannelHandler 。详细解析，见 [「3. checkMultiplicity」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- 第 11 行：调用 `#filterName(String name, ChannelHandler handler)` 方法，获得 ChannelHandler 的名字。详细解析，见 [「4. filterName」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- 第 11 行：调用 `#newContext(EventExecutorGroup group, String name, ChannelHandler handler)` 方法，创建 **DefaultChannelHandlerContext** 节点。详细解析，见 [「5. newContext」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- 第 14 行：`#addLast0(AbstractChannelHandlerContext newCtx)` 方法，添加到最后一个节点。详细解析，见 [「6. addLast0」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- ========== 后续分成 3 种情况 ==========
- `<1>`
- 第 20 行：Channel 并未注册。这种情况，发生于 ServerBootstrap 启动的过程中。在 `ServerBootstrap#init(Channel channel)` 方法中，会添加 ChannelInitializer 对象到 pipeline 中，恰好此时 Channel 并未注册。
- 第 22 行：调用 `AbstractChannelHandlerContext#setAddPending()` 方法，设置 AbstractChannelHandlerContext **准备添加中**。
- 第 24 行：调用 `#callHandlerCallbackLater(AbstractChannelHandlerContext, added)` 方法，添加 PendingHandlerAddedTask 回调。在 Channel 注册完成后，执行该回调。详细解析，见 [「8. PendingHandlerCallback」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- `<2>`
- 第 30 行：不在 EventLoop 的线程中。
- 第 32 行：调用 `AbstractChannelHandlerContext#setAddPending()` 方法，设置 AbstractChannelHandlerContext **准备添加中**。
- 第 34 至 39 行：提交 EventLoop 中，调用 `#callHandlerAdded0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 添加完成( added )事件。详细解析，见 [「7. callHandlerAdded0」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- `<3>`
- 这种情况，是 `<2>` 在 EventLoop 的线程中的版本。也因为此，已经确认在 EventLoop 的线程中，所以不需要在 `synchronized` 中。
- 第 45 行：和【第 37 行】的代码一样，调用 `#callHandlerAdded0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 添加完成( added )事件。

# 3. checkMultiplicity

`#checkMultiplicity(ChannelHandler handler)` 方法，校验是否重复的 ChannelHandler 。代码如下：

```java
private static void checkMultiplicity(ChannelHandler handler) {
    if (handler instanceof ChannelHandlerAdapter) {
        ChannelHandlerAdapter h = (ChannelHandlerAdapter) handler;
        // 若已经添加，并且未使用 @Sharable 注解，则抛出异常
        if (!h.isSharable() && h.added) {
            throw new ChannelPipelineException(
                    h.getClass().getName() +
                    " is not a @Sharable handler, so can't be added or removed multiple times.");
        }
        // 标记已经添加
        h.added = true;
    }
}
```

- 在 pipeline 中，一个创建的 ChannelHandler 对象，如果不使用 Netty `@Sharable` 注解，则只能添加到一个 Channel 的 pipeline 中。所以，如果我们想要重用一个 ChannelHandler 对象( 例如在 Spring 环境中 )，则必须给这个 ChannelHandler 添加 `@Sharable` 注解。

例如，在 Dubbo 的 `com.alibaba.dubbo.remoting.transport.netty.NettyHandler` 处理器，它就使用了 `@Sharable` 注解。

# 4. filterName

`#filterName(String name, ChannelHandler handler)` 方法，获得 ChannelHandler 的名字。代码如下：

```java
private String filterName(String name, ChannelHandler handler) {
    if (name == null) { // <1>
        return generateName(handler);
    }
    checkDuplicateName(name); // <2>
    return name;
}
```

- `<1>` 处，若**未**传入默认的名字 `name` ，则调用 `#generateName(ChannelHandler)` 方法，根据 ChannelHandler 生成一个**唯一**的名字。详细解析，见 [「4.1 generateName」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。
- `<2>` 处，若**已**传入默认的名字 `name` ，则调用 `#checkDuplicateName(String name)` 方法，校验名字唯一。详细解析，见 [「4.2 checkDuplicateName」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 。

## 4.1 generateName

`#generateName(ChannelHandler)` 方法，根据 ChannelHandler 生成一个**唯一**名字。代码如下：

```java
 1: private String generateName(ChannelHandler handler) {
 2:     // 从缓存中查询，是否已经生成默认名字
 3:     Map<Class<?>, String> cache = nameCaches.get();
 4:     Class<?> handlerType = handler.getClass();
 5:     String name = cache.get(handlerType);
 6:     // 若未生成过，进行生成
 7:     if (name == null) {
 8:         name = generateName0(handlerType);
 9:         cache.put(handlerType, name);
10:     }
11: 
12:     // 判断是否存在相同名字的节点
13:     // It's not very likely for a user to put more than one handler of the same type, but make sure to avoid
14:     // any name conflicts.  Note that we don't cache the names generated here.
15:     if (context0(name) != null) {
16:         // 若存在，则使用基础名字 + 编号，循环生成，直到一个是唯一的
17:         String baseName = name.substring(0, name.length() - 1); // Strip the trailing '0'.
18:         for (int i = 1;; i ++) {
19:             String newName = baseName + i;
20:             if (context0(newName) == null) { // // 判断是否存在相同名字的节点
21:                 name = newName;
22:                 break;
23:             }
24:         }
25:     }
26:     return name;
27: }
```

- 第 2 至 5 行：从缓存`nameCaches`中，查询是否已经生成**默认**名字。

  - 若未生成过，调用 `#generateName0(ChannelHandler)` 方法，进行生成。而后，添加到缓存 `nameCaches` 中。

- 第 15 行：调用 `#context0(String name)` 方法，判断是否存在相同名字的节点。代码如下：

  ```java
  private AbstractChannelHandlerContext context0(String name) {
      AbstractChannelHandlerContext context = head.next;
      // 顺序向下遍历节点，判断是否有指定名字的节点。如果有，则返回该节点。
      while (context != tail) {
          if (context.name().equals(name)) {
              return context;
          }
          context = context.next;
      }
      return null;
  }
  ```

  - 顺序向下遍历节点，判断是否有指定名字的节点。如果有，则返回该节点。

- 第 15 至 25 行：若存在相同名字的节点，则使用**基础**名字 + 编号，循环生成，直到一个名字是**唯一**的，然后结束循环。

## 4.2 checkDuplicateName

`#checkDuplicateName(String name)` 方法，校验名字唯一。代码如下：

```java
private void checkDuplicateName(String name) {
    if (context0(name) != null) {
        throw new IllegalArgumentException("Duplicate handler name: " + name);
    }
}
```

- 通过调用 `#context0(String name)` 方法，获得指定名字的节点。若存在节点，意味着**不唯一**，抛出 IllegalArgumentException 异常。

# 5. newContext

`#newContext(EventExecutorGroup group, String name, ChannelHandler handler)` 方法，创建 **DefaultChannelHandlerContext** 节点。而这个节点，**内嵌**传入的 ChannelHandler 参数。代码如下：

```java
private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) {
    return new DefaultChannelHandlerContext(this, childExecutor(group) /** <1> **/, name, handler);
}
```

- `<1>` 处，调用 `#childExecutor(EventExecutorGroup group)` 方法，创建**子**执行器。代码如下：

  ```java
  private EventExecutor childExecutor(EventExecutorGroup group) {
      // <1> 不创建子执行器
      if (group == null) {
          return null;
      }
      // <2> 根据配置项 SINGLE_EVENTEXECUTOR_PER_GROUP ，每个 Channel 从 EventExecutorGroup 获得不同 EventExecutor 执行器
      Boolean pinEventExecutor = channel.config().getOption(ChannelOption.SINGLE_EVENTEXECUTOR_PER_GROUP);
      if (pinEventExecutor != null && !pinEventExecutor) {
          return group.next();
      }
      // <3> 通过 childExecutors 缓存实现，一个 Channel 从 EventExecutorGroup 获得相同 EventExecutor 执行器
      Map<EventExecutorGroup, EventExecutor> childExecutors = this.childExecutors;
      if (childExecutors == null) {
          // Use size of 4 as most people only use one extra EventExecutor.
          childExecutors = this.childExecutors = new IdentityHashMap<EventExecutorGroup, EventExecutor>(4);
      }
      // Pin one of the child executors once and remember it so that the same child executor
      // is used to fire events for the same channel.
      EventExecutor childExecutor = childExecutors.get(group);
      // 缓存不存在，进行 从 EventExecutorGroup 获得 EventExecutor 执行器
      if (childExecutor == null) {
          childExecutor = group.next();
          childExecutors.put(group, childExecutor); // 进行缓存
      }
      return childExecutor;
  }
  ```

  - 一共有三种情况：
    - `<1>` ，当**不传入** EventExecutorGroup 时，不创建**子**执行器。即，使用 Channel 所注册的 EventLoop 作为执行器。**对于我们日常使用，基本完全都是这种情况**。所以，下面两种情况，胖友不理解也是没关系的。
    - `<2>` ，根据配置项 `ChannelOption.SINGLE_EVENTEXECUTOR_PER_GROUP` ，每个 Channel 从 EventExecutorGroup 获得**不同** EventExecutor 执行器。
    - `<3>` ，通过 `childExecutors` 缓存实现，每个 Channel 从 EventExecutorGroup 获得**相同** EventExecutor 执行器。是否获得相同的 EventExecutor 执行器，这就是 `<2>`、`<3>` 的不同。

- **注意**，创建的是 DefaultChannelHandlerContext 对象。

# 6. addLast0

`#addLast0(AbstractChannelHandlerContext newCtx)` 方法，添加到最后一个节点。**注意**，实际上，是添加到 `tail` 节点**之前**。代码如下：

```java
private void addLast0(AbstractChannelHandlerContext newCtx) {
    // 获得 tail 节点的前一个节点
    AbstractChannelHandlerContext prev = tail.prev;
    // 新节点，指向 prev 和 tail 节点
    newCtx.prev = prev; // <1>
    newCtx.next = tail; // <2>
    // 在 prev 和 tail ，指向新节点
    prev.next = newCtx; // <3>
    tail.prev = newCtx; // <4>
}
```

> FROM 闪电侠 [《Netty 源码分析之pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
>
> - 用下面这幅图可见简单的表示这段过程，说白了，其实就是一个双向链表的插入操作：
>
> ![添加节点过程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554345488782.png)
>
> - 操作完毕，该节点就加入到 pipeline 中：
>
> ![添加节点之后](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554345488782.png)

# 7. callHandlerAdded0

`#callHandlerAdded0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 添加完成( added )事件。代码如下：

```java
 1: private void callHandlerAdded0(final AbstractChannelHandlerContext ctx) {
 2:     try {
 3:         // We must call setAddComplete before calling handlerAdded. Otherwise if the handlerAdded method generates
 4:         // any pipeline events ctx.handler() will miss them because the state will not allow it.
 5:         // 设置 AbstractChannelHandlerContext 已添加
 6:         ctx.setAddComplete();
 7:         // 回调 ChannelHandler 添加完成( added )事件
 8:         ctx.handler().handlerAdded(ctx);
 9:     } catch (Throwable t) {
10:         // 发生异常，移除该节点
11:         boolean removed = false;
12:         try {
13:             remove0(ctx); // 移除
14:             try {
15:                 ctx.handler().handlerRemoved(ctx); // 回调 ChannelHandler 移除完成( removed )事件
16:             } finally {
17:                 ctx.setRemoved(); // 标记节点已移除
18:             }
19:             removed = true; // 标记移除成功
20:         } catch (Throwable t2) {
21:             if (logger.isWarnEnabled()) {
22:                 logger.warn("Failed to remove a handler: " + ctx.name(), t2);
23:             }
24:         }
25: 
26:         // 触发异常的传播
27:         if (removed) {
28:             fireExceptionCaught(new ChannelPipelineException(
29:                     ctx.handler().getClass().getName() +
30:                     ".handlerAdded() has thrown an exception; removed.", t));
31:         } else {
32:             fireExceptionCaught(new ChannelPipelineException(
33:                     ctx.handler().getClass().getName() +
34:                     ".handlerAdded() has thrown an exception; also failed to remove.", t));
35:         }
36:     }
37: }
```

- 第 6 行：调用 `AbstractChannelHandlerContext#setAddComplete()` 方法，设置 AbstractChannelHandlerContext 已添加。
- 第 8 行：调用 `ChannelHandler#handlerAdded(AbstractChannelHandlerContext)` 方法，回调 ChannelHandler 添加完成( added )事件。一般来说，通过这个方法，来初始化 ChannelHandler 。**注意**，因为这个方法的执行在 EventLoop 的线程中，所以要尽量避免执行时间过长。
- 第 9 行：发生异常。
  - 第 10 至 24 行：移除该节点( ChannelHandler )。详细解析，见《精尽 Netty 源码解析 —— ChannelPipeline（三）之移除 ChannelHandler》。
    - 😈 所以，`ChannelHandler#handlerAdded(AbstractChannelHandlerContext)` 方法的执行**异常**时，将被移除。
  - 第 26 至 35 行：触发异常的传播。详细解析，见 [《精尽 Netty 源码解析 —— ChannelPipeline（六）之异常事件的传播》](http://svip.iocoder.cn/Netty/ChannelPipeline-6-exception) 。

# 8. PendingHandlerCallback

PendingHandlerCallback ，实现 Runnable 接口，等待添加 ChannelHandler 回调抽象类。代码如下：

> PendingHandlerCallback 是 DefaultChannelPipeline 的内部静态类。

```
private abstract static class PendingHandlerCallback implements Runnable {

    /**
     * AbstractChannelHandlerContext 节点
     */
    final AbstractChannelHandlerContext ctx;
    /**
     * 下一个回调 PendingHandlerCallback 对象
     */
    PendingHandlerCallback next;

    PendingHandlerCallback(AbstractChannelHandlerContext ctx) {
        this.ctx = ctx;
    }

    /**
     * 执行方法
     */
    abstract void execute();

}
```

- 通过 `ctx` 和 `next` 字段，形成**回调链**。
- `#execute()` 抽象方法，通过实现它，执行回调逻辑。

------

**为什么会有 PendingHandlerCallback 呢**？

因为 ChannelHandler 添加到 pipeline 中，会触发 ChannelHandler 的添加完成( added )事件，并且该事件需要在 Channel 所属的 EventLoop 中执行。

但是 Channel 并未注册在 EventLoop 上时，需要暂时将“触发 ChannelHandler 的添加完成( added )事件”的逻辑，作为一个 PendingHandlerCallback 进行“缓存”。在 Channel 注册到 EventLoop 上时，进行回调执行。

------

PendingHandlerCallback 有两个实现类：

- PendingHandlerAddedTask
- PendingHandlerRemovedTask

本文只分享 PendingHandlerAddedTask 的代码实现。

## 8.1 PendingHandlerAddedTask

PendingHandlerAddedTask 实现 PendingHandlerCallback 抽象类，用于回调添加 ChannelHandler 节点。代码如下：

```
private final class PendingHandlerAddedTask extends PendingHandlerCallback {

    PendingHandlerAddedTask(AbstractChannelHandlerContext ctx) {
        super(ctx);
    }

    @Override
    public void run() {
        callHandlerAdded0(ctx);
    }

    @Override
    void execute() {
        EventExecutor executor = ctx.executor();
        // 在 EventLoop 的线程中，回调 ChannelHandler added 事件
        if (executor.inEventLoop()) {
            callHandlerAdded0(ctx);
        } else {
            // 提交 EventLoop 中，执行回调 ChannelHandler added 事件
            try {
                executor.execute(this); // <1>
            } catch (RejectedExecutionException e) {
                if (logger.isWarnEnabled()) {
                    logger.warn(
                            "Can't invoke handlerAdded() as the EventExecutor {} rejected it, removing handler {}.",
                            executor, ctx.name(), e);
                }
                // 发生异常，进行移除
                remove0(ctx);
                // 标记 AbstractChannelHandlerContext 为已移除
                ctx.setRemoved();
            }
        }
    }
    
}
```

- 在 `#execute()` 实现方法中，我们可以看到，和 `#addLast(EventExecutorGroup group, String name, ChannelHandler handler)` 方法的【第 28 至 45 行】的代码比较类似，目的是，在 EventLoop 的线程中，执行 `#callHandlerAdded0(AbstractChannelHandlerContext)` 方法，回调 ChannelHandler 添加完成( added )事件。
- `<1>` 处，为什么 PendingHandlerAddedTask 可以直接提交到 EventLoop 中呢？因为 PendingHandlerAddedTask 是个 Runnable ，这也就是为什么 PendingHandlerCallback 实现 Runnable 接口的原因。

> 老艿艿：下面开始分享的方法，属于 DefaultChannelPipeline 类。

## 8.2 callHandlerCallbackLater

`#callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added)` 方法，添加 PendingHandlerCallback 回调。代码如下：

```
/**
 * This is the head of a linked list that is processed by {@link #callHandlerAddedForAllHandlers()} and so process
 * all the pending {@link #callHandlerAdded0(AbstractChannelHandlerContext)}.
 *
 * We only keep the head because it is expected that the list is used infrequently and its size is small.
 * Thus full iterations to do insertions is assumed to be a good compromised to saving memory and tail management
 * complexity.
 *
 * 准备添加 ChannelHandler 的回调
 *
 * @see #callHandlerCallbackLater(AbstractChannelHandlerContext, boolean)
 */
private PendingHandlerCallback pendingHandlerCallbackHead;
    
  1: private void callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added) {
  2:     assert !registered;
  3: 
  4:     // 创建 PendingHandlerCallback 对象
  5:     PendingHandlerCallback task = added ? new PendingHandlerAddedTask(ctx) : new PendingHandlerRemovedTask(ctx);
  6:     PendingHandlerCallback pending = pendingHandlerCallbackHead;
  7:     // 若原 pendingHandlerCallbackHead 不存在，则赋值给它
  8:     if (pending == null) {
  9:         pendingHandlerCallbackHead = task;
 10:     // 若原 pendingHandlerCallbackHead 已存在，则最后一个回调指向新创建的回调
 11:     } else {
 12:         // Find the tail of the linked-list.
 13:         while (pending.next != null) {
 14:             pending = pending.next;
 15:         }
 16:         pending.next = task;
 17:     }
 18: }
```

- `added` 方法参数，表示是否是添加 ChannelHandler 的回调。所以在【第 5 行】的代码，根据 `added` 是否为 `true` ，创建 PendingHandlerAddedTask 或 PendingHandlerRemovedTask 对象。在本文中，当然创建的是 PendingHandlerAddedTask 。
- 第 7 至 17 行：将创建的 PendingHandlerCallback 对象，“添加”到 `pendingHandlerCallbackHead` 中。

## 8.3 invokeHandlerAddedIfNeeded

`#invokeHandlerAddedIfNeeded()` 方法，执行**在 PendingHandlerCallback 中**的 ChannelHandler 添加完成( added )事件。它被两个方法所调用：

- `AbstractUnsafe#register0(ChannelPromise promise)` 方法

  - 原因是：

    ```
    // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the
    // user may already fire events through the pipeline in the ChannelFutureListener.
    ```

    - 例如 ServerBootstrap 通过 ChannelInitializer 注册自定义的 ChannelHandler 到 pipeline 上的情况。

  - 调用栈如下图：![register0](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554345488794.png)

- `HeadContext#channelRegistered(ChannelHandlerContext ctx)`方法。

  - 笔者调试下来，对于 Netty NIO Server 和 NIO Client 貌似没啥作用，因为已经在 `AbstractUnsafe#register0(ChannelPromise promise)` 中触发。胖友也可以自己调试下。
  - 调用栈如下图：![channelRegistered](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/04-1554345488815.png)

------

`#invokeHandlerAddedIfNeeded()` 方法，代码如下：

```
/**
 * 是否首次注册
 *
 * {@link #invokeHandlerAddedIfNeeded()}
 */
private boolean firstRegistration = true;

final void invokeHandlerAddedIfNeeded() {
    assert channel.eventLoop().inEventLoop(); // 必须在 EventLoop 的线程中
    // 仅有首次注册有效 <1>
    if (firstRegistration) {
        // 标记非首次注册
        firstRegistration = false;
        
        // 执行在 PendingHandlerCallback 中的 ChannelHandler 添加完成( added )事件 // <2>
        // We are now registered to the EventLoop. It's time to call the callbacks for the ChannelHandlers,
        // that were added before the registration was done.
        callHandlerAddedForAllHandlers();
    }
}

```

- `<1>`处，仅有首次注册有效(`firstRegistration = true`) 时。而后，标记`firstRegistration = false`。

  - 这也就是笔者为什么说，`HeadContext#channelRegistered(ChannelHandlerContext ctx)` 方法对这个方法的调用，是没有效果的。

- `<2>` 处，调用 `#callHandlerAddedForAllHandlers()` 方法，执行**在 PendingHandlerCallback 中**的 ChannelHandler 添加完成( added )事件。代码如下：

  ```
   1: private void callHandlerAddedForAllHandlers() {
   2:     final PendingHandlerCallback pendingHandlerCallbackHead;
   3:     // 获得 pendingHandlerCallbackHead
   4:     synchronized (this) {
   5:         assert !registered;
   6: 
   7:         // This Channel itself was registered.
   8:         registered = true; // 标记已注册
   9: 
  10:         pendingHandlerCallbackHead = this.pendingHandlerCallbackHead;
  11:         // Null out so it can be GC'ed.
  12:         this.pendingHandlerCallbackHead = null; // 置空，help gc
  13:     }
  14: 
  15:     // 顺序向下，执行 PendingHandlerCallback 的回调
  16:     // This must happen outside of the synchronized(...) block as otherwise handlerAdded(...) may be called while
  17:     // holding the lock and so produce a deadlock if handlerAdded(...) will try to add another handler from outside
  18:     // the EventLoop.
  19:     PendingHandlerCallback task = pendingHandlerCallbackHead;
  20:     while (task != null) {
  21:         task.execute();
  22:         task = task.next;
  23:     }
  24: }
  
  ```

  - 第 3 至 13 行：获得`pendingHandlerCallbackHead`变量。
    - 第 8 行：标记 `registered = true` ，表示已注册。
    - 第 10 至 12 行：置空对象的 `pendingHandlerCallbackHead` 属性，help GC 。
    - 使用 `synchronized` 的原因，和 `#addLast(EventExecutorGroup group, String name, ChannelHandler handler)` 的【第 16 至 26 行】的代码需要对 `pendingHandlerCallbackHead` 互斥，避免并发修改的问题。
  - 第 15 至 23 行：顺序循环向下，调用`PendingHandlerCallback#execute()`方法，执行 PendingHandlerCallback 的回调，从而将 ChannelHandler 添加到 pipeline 中。
    - 这里不适用 `synchronized` 的原因，看英文注释哈。

# 666. 彩蛋

**添加** ChannelHandler 到 pipeline 中的代码，大部分的比较简单。比较复杂的可能是，[「8. PendingHandlerCallback」](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler/#) 中，调用的过程涉及**回调**，所以理解上稍微可能困难。胖友可以多多调试进行解决噢。

推荐阅读文章：

- 闪电侠 [《Netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
- Hypercube [《自顶向下深入分析 Netty（七）–ChannelPipeline 源码实现》](https://www.jianshu.com/p/0e15165714fc)

# 精尽 Netty 源码解析 —— ChannelPipeline（三）之移除 ChannelHandler



# 1. 概述

本文我们来分享，从 pipeline 中**移除** ChannelHandler 的代码具体实现。

在 [《精尽 Netty 源码解析 —— ChannelPipeline（一）之初始化》](http://svip.iocoder.cn/Netty/ChannelPipeline-1-init) 中，我们看到 ChannelPipeline 定义了一大堆**移除** ChannelHandler 的接口方法：

```
ChannelPipeline remove(ChannelHandler handler);
ChannelHandler remove(String name);
<T extends ChannelHandler> T remove(Class<T> handlerType);
ChannelHandler removeFirst();
ChannelHandler removeLast();
```

- 本文仅分享 `#remove(ChannelHandler handler)` 方法，从 pipeline **移除**指定的 ChannelHandler 对象。

# 2. remove

`#remove(ChannelHandler handler)` 方法，从 pipeline **移除**指定的 ChannelHandler 对象。代码如下：

```
@Override
public final ChannelPipeline remove(ChannelHandler handler) {
    remove(getContextOrDie(handler));
    return this;
}
```

- 调用 `#getContextOrDie(ChannelHandler handler)` 方法，获得对应的 AbstractChannelHandlerContext 节点。代码如下：

  ```
  private AbstractChannelHandlerContext getContextOrDie(ChannelHandler handler) {
      AbstractChannelHandlerContext ctx = (AbstractChannelHandlerContext) context(handler);
      if (ctx == null) { // die
          throw new NoSuchElementException(handler.getClass().getName());
      } else {
          return ctx;
      }
  }
  
  @Override
  public final ChannelHandlerContext context(ChannelHandler handler) {
      if (handler == null) {
          throw new NullPointerException("handler");
      }
      AbstractChannelHandlerContext ctx = head.next;
      // 循环，获得指定 ChannelHandler 对象的节点
      for (;;) {
          if (ctx == null) {
              return null;
          }
          if (ctx.handler() == handler) { // ChannelHandler 相等
              return ctx;
          }
          ctx = ctx.next;
      }
  }
  ```

  - 方法使用 Die 的原因是，获得不到节点的情况下，抛出 NoSuchElementException 异常。

- 调用 `#remove(AbstractChannelHandlerContext ctx)` 方法，移除指定 AbstractChannelHandlerContext 节点。

------

`#remove(AbstractChannelHandlerContext ctx)` 方法，移除指定 AbstractChannelHandlerContext 节点。代码如下：

> 代码的整体结构，和 `#addLast(EventExecutorGroup group, String name, ChannelHandler handler)` 方法是**一致**的。

```
 1: private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) {
 2:     assert ctx != head && ctx != tail;
 3: 
 4:     synchronized (this) { // 同步，为了防止多线程并发操作 pipeline 底层的双向链表
 5:         // 移除节点
 6:         remove0(ctx);
 7: 
 8:         // pipeline 暂未注册，添加回调。再注册完成后，执行回调。详细解析，见 {@link #callHandlerCallbackLater} 方法。
 9:         // If the registered is false it means that the channel was not registered on an eventloop yet.
10:         // In this case we remove the context from the pipeline and add a task that will call
11:         // ChannelHandler.handlerRemoved(...) once the channel is registered.
12:         if (!registered) {
13:             callHandlerCallbackLater(ctx, false);
14:             return ctx;
15:         }
16: 
17:         // 不在 EventLoop 的线程中，提交 EventLoop 中，执行回调用户方法
18:         EventExecutor executor = ctx.executor();
19:         if (!executor.inEventLoop()) {
20:             // 提交 EventLoop 中，执行回调 ChannelHandler removed 事件
21:             executor.execute(new Runnable() {
22:                 @Override
23:                 public void run() {
24:                     callHandlerRemoved0(ctx);
25:                 }
26:             });
27:             return ctx;
28:         }
29:     }
30: 
31:     // 回调 ChannelHandler removed 事件
32:     callHandlerRemoved0(ctx);
33:     return ctx;
34: }
```

- 第 4 行：`synchronized` 同步，为了防止多线程并发操作 pipeline 底层的双向链表。
- 第 6 行：调用 `#remove0(AbstractChannelHandlerContext ctx)` 方法，从 pipeline **移除**指定的 AbstractChannelHandlerContext 节点。详细解析，见 [「3. remove0」](http://svip.iocoder.cn/Netty/ChannelPipeline-3-remove-channel-handler/#) 。
- ========== 后续分成 3 种情况 ==========
- `<1>`
- 第 12 行：Channel 并未注册。
- 第 13 行：调用 `#callHandlerCallbackLater(AbstractChannelHandlerContext, added)` 方法，添加 PendingHandlerRemovedTask 回调。在 Channel 注册完成后，执行该回调。详细解析，见 [「8. PendingHandlerCallback」](http://svip.iocoder.cn/Netty/ChannelPipeline-3-remove-channel-handler/#) 。
- `<2>`
- 第 19 行：不在 EventLoop 的线程中。
- 第 20 至 26 行：提交 EventLoop 中，调用 `#callHandlerRemoved0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 移除完成( removed )事件。详细解析，见 [「4. callHandlerRemoved0」](http://svip.iocoder.cn/Netty/ChannelPipeline-3-remove-channel-handler/#) 。
- `<3>`
- 这种情况，是 `<2>` 在 EventLoop 的线程中的版本。也因为此，已经确认在 EventLoop 的线程中，所以不需要在 `synchronized` 中。
- 第 32 行：和【第 24 行】的代码一样，调用 `#callHandlerRemoved0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 移除完成( removed )事件。

# 3. remove0

`#remove0(AbstractChannelHandlerContext ctx)` 方法，从 pipeline **移除**指定的 AbstractChannelHandlerContext 节点。代码如下：

```
private static void remove0(AbstractChannelHandlerContext ctx) {
    // 获得移除节点的前后节点
    AbstractChannelHandlerContext prev = ctx.prev;
    AbstractChannelHandlerContext next = ctx.next;
    // 前后节点互相指向
    prev.next = next;
    next.prev = prev;
}
```

> FROM 闪电侠 [《netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)
>
> - 经历的过程要比添加节点要简单，可以用下面一幅图来表示
>
> ![删除节点过程](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554345511065.png)
>
> - 最后的结果为
>
> ![删除节点之后](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554345511081.png)
>
> 结合这两幅图，可以很清晰地了解移除 Handler 的过程，另外，被删除的节点因为没有对象引用到，果过段时间就会被 gc 自动回收。

# 4. callHandlerRemoved0

`#callHandlerRemoved0(AbstractChannelHandlerContext)` 方法，执行回调 ChannelHandler 移除完成( removed )事件。代码如下：

```
 1: private void callHandlerRemoved0(final AbstractChannelHandlerContext ctx) {
 2:     // Notify the complete removal.
 3:     try {
 4:         try {
 5:             // 回调 ChannelHandler 移除完成( removed )事件
 6:             ctx.handler().handlerRemoved(ctx);
 7:         } finally {
 8:             // 设置 AbstractChannelHandlerContext 已移除
 9:             ctx.setRemoved();
10:         }
11:     } catch (Throwable t) {
12:         // 触发异常的传播
13:         fireExceptionCaught(new ChannelPipelineException(
14:                 ctx.handler().getClass().getName() + ".handlerRemoved() has thrown an exception.", t));
15:     }
16: }
```

- 第 6 行：调用 `ChannelHandler#handlerRemoved(AbstractChannelHandlerContext)` 方法，回调 ChannelHandler 移除完成( removed )事件。一般来说，通过这个方法，来释放 ChannelHandler 占用的资源。**注意**，因为这个方法的执行在 EventLoop 的线程中，所以要尽量避免执行时间过长。
- 第 9 行：调用 `AbstractChannelHandlerContext#setRemoved()` 方法，设置 AbstractChannelHandlerContext 已移除。
- 第 11 至 15 行：发生异常，触发异常的传播。详细解析，见 [《精尽 Netty 源码解析 —— ChannelPipeline（六）之异常事件的传播》](http://svip.iocoder.cn/Netty/ChannelPipeline-6-exception) 。

# 5. PendingHandlerRemovedTask

PendingHandlerRemovedTask 实现 PendingHandlerCallback 抽象类，用于回调移除 ChannelHandler 节点。代码如下：

```
private final class PendingHandlerRemovedTask extends PendingHandlerCallback {

    PendingHandlerRemovedTask(AbstractChannelHandlerContext ctx) {
        super(ctx);
    }

    @Override
    public void run() {
        callHandlerRemoved0(ctx);
    }

    @Override
    void execute() {
        EventExecutor executor = ctx.executor();
        // 在 EventLoop 的线程中，回调 ChannelHandler removed 事件
        if (executor.inEventLoop()) {
            callHandlerRemoved0(ctx);
        } else {
            // 提交 EventLoop 中，执行回调 ChannelHandler removed 事件
            try {
                executor.execute(this); // <1>
            } catch (RejectedExecutionException e) {
                if (logger.isWarnEnabled()) {
                    logger.warn(
                            "Can't invoke handlerRemoved() as the EventExecutor {} rejected it," +
                                    " removing handler {}.", executor, ctx.name(), e);
                }
                // 标记 AbstractChannelHandlerContext 为已移除
                // remove0(...) was call before so just call AbstractChannelHandlerContext.setRemoved().
                ctx.setRemoved();
            }
        }
    }
    
}
```

- 在 `#execute()` 实现方法中，我们可以看到，和 `#remove((AbstractChannelHandlerContext ctx)` 方法的【第 17 至 32 行】的代码比较类似，目的是，在 EventLoop 的线程中，执行 `#callHandlerRemoved0(AbstractChannelHandlerContext)` 方法，回调 ChannelHandler 移除完成( removed )事件。
- `<1>` 处，为什么 PendingHandlerRemovedTask 可以直接提交到 EventLoop 中呢？因为 PendingHandlerRemovedTask 是个 Runnable ，这也就是为什么 PendingHandlerCallback 实现 Runnable 接口的原因。

# 666. 彩蛋

水文一小篇。推荐阅读文章：

- 闪电侠 [《Netty 源码分析之 pipeline(一)》](https://www.jianshu.com/p/6efa9c5fa702)

# 精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播



# 1. 概述

本文我们来分享，在 pipeline 中的 **Outbound 事件的传播**。我们先来回顾下 Outbound 事件的定义：

> 老艿艿：A01、A02 等等，是我们每条定义的编号。

- [x] A01：Outbound 事件是【请求】事件(由 Connect 发起一个请求, 并最终由 Unsafe 处理这个请求)

  > 老艿艿：A01 = A02 + A03

- [x] A02：Outbound 事件的发起者是 Channel

- [x] A03：Outbound 事件的处理者是 Unsafe

- [x] A04：Outbound 事件在 Pipeline 中的传输方向是 `tail` -> `head`

- [x] A05：在 ChannelHandler 中处理事件时, 如果这个 Handler 不是最后一个 Handler ，则需要调用 `ctx.xxx` (例如 `ctx.connect` ) 将此事件继续传播下去. 如果不这样做, 那么此事件的传播会提前终止.

- [x] A06：Outbound 事件流: `Context.OUT_EVT` -> `Connect.findContextOutbound` -> `nextContext.invokeOUT_EVT` -> `nextHandler.OUT_EVT` -> `nextContext.OUT_EVT`

下面，我们来跟着代码，理解每条定义。

# 2. ChannelOutboundInvoker

在 `io.netty.channel.ChannelOutboundInvoker` 接口中，定义了所有 Outbound 事件对应的方法：

```
ChannelFuture bind(SocketAddress localAddress);
ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise);

ChannelFuture connect(SocketAddress remoteAddress);
ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress);
ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise);
ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise);

ChannelFuture disconnect();
ChannelFuture disconnect(ChannelPromise promise);

ChannelFuture close();
ChannelFuture close(ChannelPromise promise);

ChannelFuture deregister();
ChannelFuture deregister(ChannelPromise promise);

ChannelOutboundInvoker read();

ChannelFuture write(Object msg);
ChannelFuture write(Object msg, ChannelPromise promise);

ChannelOutboundInvoker flush();

ChannelFuture writeAndFlush(Object msg, ChannelPromise promise);
ChannelFuture writeAndFlush(Object msg);
```

而 ChannelOutboundInvoker 的**部分**子类/接口如下图：

![类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554345563645.png)

- 我们可以看到类图，有 Channel、ChannelPipeline、AbstractChannelHandlerContext 都继承/实现了该接口。那这意味着什么呢？我们继续往下看。

在 [《精尽 Netty 源码解析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 中，我们可以看到 Outbound 事件的其中之一 **bind** ，本文就以 **bind** 的过程，作为示例。调用栈如下：

![调用栈](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554345563658.png)

- `AbstractChannel#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，代码如下：

  ```
  @Override
  public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {
      return pipeline.bind(localAddress, promise);
  }
  ```

  - ```
    AbstractChannel#bind(SocketAddress localAddress, ChannelPromise promise)
    ```

     

    方法，实现的自 ChannelOutboundInvoker 接口。

    - Channel 是 **bind** 的发起者，**这符合 Outbound 事件的定义 A02** 。

  - 在方法内部，会调用

     

    ```
    ChannelPipeline#bind(SocketAddress localAddress, ChannelPromise promise)
    ```

     

    方法，而这个方法，也是实现的自 ChannelOutboundInvoker 接口。

    从这里可以看出，对于 ChannelOutboundInvoker 接口方法的实现，Channel 对它的实现，会调用 ChannelPipeline 的对应方法

    ( ( 有一点绕，胖友理解下 ) )。

    - 那么接口下，让我们看看 `ChannelPipeline#bind(SocketAddress localAddress, ChannelPromise promise)` 方法的具体实现。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#bind(SocketAddress localAddress, ChannelPromise promise)` 方法的实现，代码如下：

```
@Override
public final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {
    return tail.bind(localAddress, promise);
}
```

- 在方法内部，会调用

   

  ```
  TailContext#bind(SocketAddress localAddress, ChannelPromise promise)
  ```

   

  方法。

  这符合 Outbound 事件的定义 A04

   

  。

  - 实际上，TailContext 的该方法，继承自 AbstractChannelHandlerContext 抽象类，而 AbstractChannelHandlerContext 实现了 ChannelOutboundInvoker 接口。*从这里可以看出，对于 ChannelOutboundInvoker 接口方法的实现，ChannelPipeline 对它的实现，会调用 AbstractChannelHandlerContext 的对应方法*( 有一点绕，胖友理解下 )。

# 4. AbstractChannelHandlerContext

`AbstractChannelHandlerContext#bind(SocketAddress localAddress, ChannelPromise promise)` 方法的实现，代码如下：

```
 1: @Override
 2: public ChannelFuture bind(final SocketAddress localAddress, final ChannelPromise promise) {
 3:     if (localAddress == null) {
 4:         throw new NullPointerException("localAddress");
 5:     }
 6:     // 判断是否为合法的 Promise 对象
 7:     if (isNotValidPromise(promise, false)) {
 8:         // cancelled
 9:         return promise;
10:     }
11: 
12:     // 获得下一个 Outbound 节点
13:     final AbstractChannelHandlerContext next = findContextOutbound();
14:     // 获得下一个 Outbound 节点的执行器
15:     EventExecutor executor = next.executor();
16:     // 调用下一个 Outbound 节点的 bind 方法
17:     if (executor.inEventLoop()) {
18:         next.invokeBind(localAddress, promise);
19:     } else {
20:         safeExecute(executor, new Runnable() {
21:             @Override
22:             public void run() {
23:                 next.invokeBind(localAddress, promise);
24:             }
25:         }, promise, null);
26:     }
27:     return promise;
28: }
```

- 第 6 至 10 行：判断 `promise` 是否为合法的 Promise 对象。代码如下：

  ```
  private boolean isNotValidPromise(ChannelPromise promise, boolean allowVoidPromise) {
      if (promise == null) {
          throw new NullPointerException("promise");
      }
  
      // Promise 已经完成
      if (promise.isDone()) {
          // Check if the promise was cancelled and if so signal that the processing of the operation
          // should not be performed.
          //
          // See https://github.com/netty/netty/issues/2349
          if (promise.isCancelled()) {
              return true;
          }
          throw new IllegalArgumentException("promise already done: " + promise);
      }
  
      // Channel 不符合
      if (promise.channel() != channel()) {
          throw new IllegalArgumentException(String.format(
                  "promise.channel does not match: %s (expected: %s)", promise.channel(), channel()));
      }
  
      // DefaultChannelPromise 合法 // <1>
      if (promise.getClass() == DefaultChannelPromise.class) {
          return false;
      }
      // 禁止 VoidChannelPromise 
      if (!allowVoidPromise && promise instanceof VoidChannelPromise) {
          throw new IllegalArgumentException(
                  StringUtil.simpleClassName(VoidChannelPromise.class) + " not allowed for this operation");
      }
      // 禁止 CloseFuture
      if (promise instanceof AbstractChannel.CloseFuture) {
          throw new IllegalArgumentException(
                  StringUtil.simpleClassName(AbstractChannel.CloseFuture.class) + " not allowed in a pipeline");
      }
      return false;
  }
  ```

  - 虽然方法很长，重点是 `<1>` 处，`promise` 的类型为 DefaultChannelPromise 。

- 第 13 行：【重要】调用 `#findContextOutbound()` 方法，获得下一个 Outbound 节点。代码如下：

  ```
  private AbstractChannelHandlerContext findContextOutbound() {
      // 循环，向前获得一个 Outbound 节点
      AbstractChannelHandlerContext ctx = this;
      do {
          ctx = ctx.prev;
      } while (!ctx.outbound);
      return ctx;
  }
  ```

  - 循环，**向前**获得一个 Outbound 节点。
  - 循环，**向前**获得一个 Outbound 节点。
  - 循环，**向前**获得一个 Outbound 节点。
  - 😈 重要的事情说三遍，对于 Outbound 事件的传播，是从 pipeline 的尾巴到头部，**这符合 Outbound 事件的定义 A04** 。

- 第 15 行：调用 `AbstractChannelHandlerContext#executor()` 方法，获得下一个 Outbound 节点的执行器。代码如下：

  ```
  // Will be set to null if no child executor should be used, otherwise it will be set to the
  // child executor.
  /**
   * EventExecutor 对象
   */
  final EventExecutor executor;
  
  @Override
  public EventExecutor executor() {
      if (executor == null) {
          return channel().eventLoop();
      } else {
          return executor;
      }
  }
  ```

  - 如果未设置**子执行器**，则使用 Channel 的 EventLoop 作为执行器。😈 一般情况下，我们可以忽略**子执行器**的逻辑，也就是说，可以直接认为是使用 **Channel 的 EventLoop 作为执行器**。

- 第 16 至 26 行：**在 EventLoop 的线程中**，调用**下一个节点**的 `AbstractChannelHandlerContext#invokeBind(SocketAddress localAddress, ChannelPromise promise)` 方法，传播 **bind**事件给**下一个节点**。

  - 第 20 至 25 行：如果不在 EventLoop 的线程中，会调用 `#safeExecute(EventExecutor executor, Runnable runnable, ChannelPromise promise, Object msg)` 方法，提交到 EventLoop 的线程中执行。代码如下：

    ```
    private static void safeExecute(EventExecutor executor, Runnable runnable, ChannelPromise promise, Object msg) {
        try {
            // 提交 EventLoop 的线程中，进行执行任务
            executor.execute(runnable);
        } catch (Throwable cause) {
            try {
                // 发生异常，回调通知 promise 相关的异常
                promise.setFailure(cause);
            } finally {
                // 释放 msg 相关的资源
                if (msg != null) {
                    ReferenceCountUtil.release(msg);
                }
            }
        }
    }
    ```

    - x

------

`AbstractChannelHandlerContext#invokeBind(SocketAddress localAddress, ChannelPromise promise)` 方法，代码如下：

```
 1: private void invokeBind(SocketAddress localAddress, ChannelPromise promise) {
 2:     if (invokeHandler()) { // 判断是否符合的 ChannelHandler
 3:         try {
 4:             // 调用该 ChannelHandler 的 bind 方法
 5:             ((ChannelOutboundHandler) handler()).bind(this, localAddress, promise);
 6:         } catch (Throwable t) {
 7:             notifyOutboundHandlerException(t, promise); // 通知 Outbound 事件的传播，发生异常
 8:         }
 9:     } else {
10:         // 跳过，传播 Outbound 事件给下一个节点
11:         bind(localAddress, promise);
12:     }
13: }
```

- 第 2 行：调用 `#invokeHandler()` 方法，判断是否符合的 ChannelHandler 。代码如下：

  ```
  /**
   * Makes best possible effort to detect if {@link ChannelHandler#handlerAdded(ChannelHandlerContext)} was called
   * yet. If not return {@code false} and if called or could not detect return {@code true}.
   *
   * If this method returns {@code false} we will not invoke the {@link ChannelHandler} but just forward the event.
   * This is needed as {@link DefaultChannelPipeline} may already put the {@link ChannelHandler} in the linked-list
   * but not called {@link ChannelHandler#handlerAdded(ChannelHandlerContext)}.
   */
  private boolean invokeHandler() {
      // Store in local variable to reduce volatile reads.
      int handlerState = this.handlerState;
      return handlerState == ADD_COMPLETE || (!ordered && handlerState == ADD_PENDING);
  }
  ```

  - 对于 `ordered = true` 的节点，必须 ChannelHandler 已经添加完成。
  - 对于 `ordered = false` 的节点，没有 ChannelHandler 的要求。

- 第 9 至 12 行：若是**不符合**的 ChannelHandler ，则**跳过**该节点，调用 `AbstractChannelHandlerContext#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，传播 Outbound 事件给下一个节点。即，又回到 [「4. AbstractChannelHandlerContext」](http://svip.iocoder.cn/Netty/Pipeline-4-outbound/#) 的开头。

- 第 2 至 8 行：若是**符合**的 ChannelHandler ：

  - 第 5 行：调用 ChannelHandler 的 `#bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise)` 方法，处理 bind 事件。

    - 😈 实际上，此时节点的数据类型为 DefaultChannelHandlerContext 类。若它被认为是 Outbound 节点，那么他的处理器的类型会是 **ChannelOutboundHandler** 。而 `io.netty.channel.ChannelOutboundHandler` 类似 ChannelOutboundInvoker ，定义了对每个 Outbound 事件的处理。代码如下：

      ```
      void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception;
      
      void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception;
      
      void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;
      
      void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;
      
      void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;
      
      void read(ChannelHandlerContext ctx) throws Exception;
      
      void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception;
      
      void flush(ChannelHandlerContext ctx) throws Exception;
      ```

      - 胖友自己对比下噢。

    - 如果节点的 `ChannelOutboundHandler#bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise)` 方法的实现，不调用 `AbstractChannelHandlerContext#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，就不会传播 Outbound 事件给下一个节点。**这就是 Outbound 事件的定义 A05** 。可能有点绕，我们来看下 Netty LoggingHandler 对该方法的实现代码：

      ```
      final class LoggingHandler implements ChannelInboundHandler, ChannelOutboundHandler {
      
          // ... 省略无关方法
          
          @Override
          public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
              // 打印日志
              log(Event.BIND, "localAddress=" + localAddress);
              // 传递 bind 事件，给下一个节点
              ctx.bind(localAddress, promise); // <1>
          }
      }
      ```

      - 如果把 `<1>` 处的代码去掉，bind 事件将不会传播给下一个节点！！！**一定要注意**。

    - 这块的逻辑非常重要，如果胖友觉得很绕，一定要自己多调试 + 调试 + 调试。

  - 第 7 行：如果发生异常，调用 `#notifyOutboundHandlerException(Throwable, Promise)` 方法，通知 Outbound 事件的传播，发生异常。详细解析，见 [《精尽 Netty 源码解析 —— ChannelPipeline（六）之异常事件的传播》](http://svip.iocoder.cn/Netty/ChannelPipeline-6-exception) 。

------

本小节的整个代码实现，**就是 Outbound 事件的定义 A06**的体现。而随着 Outbound 事件在节点不断从 pipeline 的尾部到头部的传播，最终会到达 HeadContext 节点。

# 5. HeadContext

`HeadContext#bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise)` 方法，代码如下：

```
@Override
public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
    unsafe.bind(localAddress, promise);
}
```

- 调用 `Unsafe#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，进行 bind 事件的处理。也就是说 Unsafe 是 **bind** 的处理着，**这符合 Outbound 事件的定义 A03** 。
- 而后续的逻辑，就是 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 的 [「3.13.2 doBind0」](http://svip.iocoder.cn/Netty/Pipeline-4-outbound/#) 小节，从 `Unsafe#bind(SocketAddress localAddress, ChannelPromise promise)` 方法，开始。
- 至此，整个 pipeline 的 Outbound 事件的传播结束。

# 6. 关于其他 Outbound 事件

本文暂时只分享了 **bind** 这个 Outbound 事件。剩余的其他事件，胖友可以自己进行调试和理解。例如：**connect** 事件，并且结合 [《精尽 Netty 源码分析 —— 启动（二）之客户端》](http://svip.iocoder.cn/Netty/bootstrap-2-client/)一文。

# 666. 彩蛋

*推荐阅读文章：

- 闪电侠 [《netty 源码分析之 pipeline(二)》](https://www.jianshu.com/p/087b7e9a27a2)*

# 精尽 Netty 源码解析 —— ChannelPipeline（五）之 Inbound 事件的传播



# 1. 概述

本文我们来分享，在 pipeline 中的 **Inbound 事件的传播**。我们先来回顾下 Inbound 事件的定义：

> 老艿艿：B01、B02 等等，是我们每条定义的编号。

- [x] B01：Inbound 事件是【通知】事件, 当某件事情已经就绪后, 通知上层.

  > 老艿艿：B01 = B02 + B03

- [x] B02：Inbound 事件发起者是 Unsafe

- [x] B03：Inbound 事件的处理者是 TailContext, 如果用户没有实现自定义的处理方法, 那么Inbound 事件默认的处理者是 TailContext, 并且其处理方法是空实现.

- [x] B04：Inbound 事件在 Pipeline 中传输方向是 `head`( 头 ) -> `tail`( 尾 )

- [x] B05：在 ChannelHandler 中处理事件时, 如果这个 Handler 不是最后一个 Handler, 则需要调用 `ctx.fireIN_EVT` (例如 `ctx.fireChannelActive` ) 将此事件继续传播下去. 如果不这样做, 那么此事件的传播会提前终止.

- [x] B06：Inbound 事件流: `Context.fireIN_EVT` -> `Connect.findContextInbound` -> `nextContext.invokeIN_EVT` -> `nextHandler.IN_EVT` -> `nextContext.fireIN_EVT`

Outbound 和 Inbound 事件十分的镜像，所以，接下来我们来跟着的代码，和 [《精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-4-inbound) 会非常相似。

# 2. ChannelInboundInvoker

在 `io.netty.channel.ChannelInboundInvoker` 接口中，定义了所有 Inbound 事件对应的方法：

```
ChannelInboundInvoker fireChannelRegistered();
ChannelInboundInvoker fireChannelUnregistered();

ChannelInboundInvoker fireChannelActive();
ChannelInboundInvoker fireChannelInactive();

ChannelInboundInvoker fireExceptionCaught(Throwable cause);

ChannelInboundInvoker fireUserEventTriggered(Object event);

ChannelInboundInvoker fireChannelRead(Object msg);
ChannelInboundInvoker fireChannelReadComplete();

ChannelInboundInvoker fireChannelWritabilityChanged();
```

而 ChannelInboundInvoker 的**部分**子类/接口如下图：

![类图](http://static2.iocoder.cn/images/Netty/2018_06_13/01.png)

- 我们可以看到类图，有 ChannelPipeline、AbstractChannelHandlerContext 都继承/实现了该接口。那这意味着什么呢？我们继续往下看。
- 相比来说，Channel 实现了 ChannelOutboundInvoker 接口，但是**不实现** ChannelInboundInvoker 接口。

在 [《精尽 Netty 源码解析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 中，我们可以看到 Inbound 事件的其中之一 **fireChannelActive** ，本文就以 **fireChannelActive** 的过程，作为示例。调用栈如下：

![调用栈](http://static2.iocoder.cn/images/Netty/2018_06_13/02.png)

- `AbstractUnsafe#bind(final SocketAddress localAddress, final ChannelPromise promise)` 方法，代码如下：

  ```
  @Override
  public final void bind(final SocketAddress localAddress, final ChannelPromise promise) {
      // 判断是否在 EventLoop 的线程中。
      assertEventLoop();
  
      // ... 省略部分代码
     
      // 记录 Channel 是否激活
      boolean wasActive = isActive();
  
      // 绑定 Channel 的端口
      doBind(localAddress);
  
      // 若 Channel 是新激活的，触发通知 Channel 已激活的事件。 
      if (!wasActive && isActive()) {
          invokeLater(new Runnable() {
              @Override
              public void run() {
                  pipeline.fireChannelActive(); // <1>
              }
          });
      }
  
      // 回调通知 promise 执行成功
      safeSetSuccess(promise);
  }
  ```

  - 在

     

    ```
    <1>
    ```

     

    处，调用

     

    ```
    ChannelPipeline#fireChannelActive()
    ```

     

    方法。

    - Unsafe 是 **fireChannelActive** 的发起者，**这符合 Inbound 事件的定义 B02** 。
    - 那么接口下，让我们看看 `ChannelPipeline#fireChannelActive()` 方法的具体实现。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#fireChannelActive()` 方法的实现，代码如下：

```
@Override
public final ChannelPipeline fireChannelActive() {
    AbstractChannelHandlerContext.invokeChannelActive(head);
    return this;
}
```

- 在方法内部，会调用

   

  ```
  AbstractChannelHandlerContext#invokeChannelActive(final AbstractChannelHandlerContext next)
  ```

   

  方法，而方法参数是

   

  ```
  head
  ```

   

  ，

  这符合 Inbound 事件的定义 B04

   

  。

  - 实际上，HeadContext 的该方法，继承自 AbstractChannelHandlerContext 抽象类，而 AbstractChannelHandlerContext 实现了 ChannelInboundInvoker 接口。*从这里可以看出，对于 ChannelInboundInvoker 接口方法的实现，ChannelPipeline 对它的实现，会调用 AbstractChannelHandlerContext 的对应方法*( 有一点绕，胖友理解下 )。

# 4. AbstractChannelHandlerContext#invokeChannelActive

`AbstractChannelHandlerContext#invokeChannelActive(final AbstractChannelHandlerContext next)` **静态**方法，代码如下：

```
 1: static void invokeChannelActive(final AbstractChannelHandlerContext next) {
 2:     // 获得下一个 Inbound 节点的执行器
 3:     EventExecutor executor = next.executor();
 4:     // 调用下一个 Inbound 节点的 Channel active 方法
 5:     if (executor.inEventLoop()) {
 6:         next.invokeChannelActive();
 7:     } else {
 8:         executor.execute(new Runnable() {
 9:             @Override
10:             public void run() {
11:                 next.invokeChannelActive();
12:             }
13:         });
14:     }
15: }
```

- 方法参数 `next` ，下一个 Inbound 节点。

- 第 3 行：调用 `AbstractChannelHandlerContext#executor()` 方法，获得下一个 Inbound 节点的执行器。

- 第 4 至 14 行：调用 `AbstractChannelHandlerContext#invokeChannelActive()` 方法，调用下一个 Inbound 节点的 Channel active 方法。

  - 在 [「3. DefaultChannelPipeline」](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 中，我们可以看到传递的**第一个** `next` 方法参数为 `head`( HeadContext ) 节点。

  - 代码如下：

    ```
     1: private void invokeChannelActive() {
     2:     if (invokeHandler()) { // 判断是否符合的 ChannelHandler
     3:         try {
     4:             // 调用该 ChannelHandler 的 Channel active 方法
     5:             ((ChannelInboundHandler) handler()).channelActive(this);
     6:         } catch (Throwable t) {
     7:             notifyHandlerException(t);  // 通知 Inbound 事件的传播，发生异常
     8:         }
     9:     } else {
    10:         // 跳过，传播 Inbound 事件给下一个节点
    11:         fireChannelActive();
    12:     }
    13: }
    ```

    - 第 2 行：调用 `#invokeHandler()` 方法，判断是否符合的 ChannelHandler 。

    - 第 9 至 12 行：若是**不符合**的 ChannelHandler ，则**跳过**该节点，调用 `AbstractChannelHandlerContext#fireChannelActive(` 方法，传播 Inbound 事件给下一个节点。详细解析，见 [「6. AbstractChannelHandlerContext#fireChannelActive」](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 。

    - 第 2 至 8 行：若是**符合**的 ChannelHandler ：

      - 第 5 行：调用 ChannelHandler 的 `#channelActive(ChannelHandlerContext ctx)` 方法，处理 Channel active 事件。

        - 😈 实际上，此时节点的数据类型为 DefaultChannelHandlerContext 类。若它被认为是 Inbound 节点，那么他的处理器的类型会是 **ChannelInboundHandler** 。而 `io.netty.channel.ChannelInboundHandler` 类似 ChannelInboundInvoker ，定义了对每个 Inbound 事件的处理。代码如下：

          ```
          void channelRegistered(ChannelHandlerContext ctx) throws Exception;
          void channelUnregistered(ChannelHandlerContext ctx) throws Exception;
          
          void channelActive(ChannelHandlerContext ctx) throws Exception;
          void channelInactive(ChannelHandlerContext ctx) throws Exception;
          
          void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception;
          
          void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception;
          void channelReadComplete(ChannelHandlerContext ctx) throws Exception;
          
          void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception;
           
          @Override
          @SuppressWarnings("deprecation")
          void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception; // 不属于 Inbound 事件
          ```

          - 胖友自己对比下噢。

        - 如果节点的 `ChannelInboundHandler#channelActive(ChannelHandlerContext ctx` 方法的实现，不调用 `AbstractChannelHandlerContext#fireChannelActive()`方法，就不会传播 Inbound 事件给下一个节点。**这就是 Inbound 事件的定义 B05** 。可能有点绕，我们来看下 Netty LoggingHandler 对该方法的实现代码：

          ```
          final class LoggingHandler implements ChannelInboundHandler, ChannelOutboundHandler {
          
              // ... 省略无关方法
              
              @Override
              public void channelActive(ChannelHandlerContext ctx) throws Exception {
                  // 打印日志
                  if (logger.isEnabled(internalLevel)) {
                      logger.log(internalLevel, format(ctx, "ACTIVE"));
                  }
                  // 传递 Channel active 事件，给下一个节点
                  ctx.fireChannelActive(); // <1>
              }
          }
          ```

          - 如果把 `<1>` 处的代码去掉，Channel active 事件 事件将不会传播给下一个节点！！！**一定要注意**。

        - 这块的逻辑非常重要，如果胖友觉得很绕，一定要自己多调试 + 调试 + 调试。

      - 第 7 行：如果发生异常，调用 `#notifyHandlerException(Throwable)` 方法，通知 Inbound 事件的传播，发生异常。详细解析，见 [《精尽 Netty 源码解析 —— ChannelPipeline（六）之异常事件的传播》](http://svip.iocoder.cn/Netty/ChannelPipeline-6-exception) 。

# 5. HeadContext

`HeadContext#invokeChannelActive()` 方法，代码如下：

```
@Override
public void channelActive(ChannelHandlerContext ctx) throws Exception {
    // 传播 Channel active 事件给下一个 Inbound 节点 <1>
    ctx.fireChannelActive();

    // 执行 read 逻辑 <2>
    readIfIsAutoRead();
}
```

- `<1>` 处，调用 `AbstractChannelHandlerContext#fireChannelActive()` 方法，传播 Channel active 事件给下一个 Inbound 节点。详细解析，见 [「6. AbstractChannelHandlerContext」](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 中。

- `<2>` 处，调用 `HeadContext#readIfIsAutoRead()` 方法，执行 read 逻辑。代码如下：

  ```
  // HeadContext.java
  private void readIfIsAutoRead() {
      if (channel.config().isAutoRead()) { 
          channel.read();
      }
  }
  
  // AbstractChannel.java
  @Override
  public Channel read() {
      pipeline.read();
      return this;
  }
  ```

  - 该方法内部，会调用 `Channel#read()` 方法，而后通过 pipeline 传递该 **read** OutBound 事件，最终调用 `HeadContext#read()` 方法，代码如下：

    ```
    @Override
    public void read(ChannelHandlerContext ctx) {
        unsafe.beginRead();
    }
    ```

    - 后续的逻辑，便是 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 的 [3.13.3 beginRead](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 小节，胖友可以自己再去回顾下。

  - 这里说的是 **OutBound** 事件，不是本文的 InBound 事件。所以，胖友不要搞混哈。只能说是对 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 的 [3.13.3 beginRead](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 小节的补充。

# 6. AbstractChannelHandlerContext#fireChannelActive

`AbstractChannelHandlerContext#fireChannelActive()` 方法，代码如下：

```
@Override
public ChannelHandlerContext fireChannelActive() {
    // 获得下一个 Inbound 节点的执行器
    // 调用下一个 Inbound 节点的 Channel active 方法
    invokeChannelActive(findContextInbound());
    return this;
}
```

- 【重要】调用 `AbstractChannelHandlerContext#findContextInbound()` 方法，获得下一个 Inbound 节点的执行器。代码如下：

  ```
  private AbstractChannelHandlerContext findContextInbound() {
      // 循环，向后获得一个 Inbound 节点
      AbstractChannelHandlerContext ctx = this;
      do {
          ctx = ctx.next;
      } while (!ctx.inbound);
      return ctx;
  }
  ```

  - 循环，**向后**获得一个 Inbound 节点。
  - 循环，**向后**获得一个 Inbound 节点。
  - 循环，**向后**获得一个 Inbound 节点。
  - 😈 重要的事情说三遍，对于 Inbound 事件的传播，是从 pipeline 的头部到尾部，**这符合 Inbound 事件的定义 B04** 。

- 调用 `AbstractChannelHandlerContext#invokeChannelActive(AbstractChannelHandlerContext)` **静态**方法，调用下一个 Inbound 节点的 Channel active 方法。即，又回到 [「4. AbstractChannelHandlerContext#invokeChannelActive」](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/#) 的开头。

------

本小节的整个代码实现，**就是 Inbound 事件的定义 B06** 的体现。而随着 Inbound 事件在节点不断从 pipeline 的头部到尾部的传播，最终会到达 TailContext 节点。

# 7. TailContext

`TailContext#channelActive(ChannelHandlerContext ctx)` 方法，代码如下：

```
@Override
public void channelActive(ChannelHandlerContext ctx) throws Exception {
    onUnhandledInboundChannelActive();
}

```

- 在方法内部，会调用 `DefaultChannelPipeline#onUnhandledInboundChannelActive()` 方法，代码如下：

  ```
  /**
   * Called once the {@link ChannelInboundHandler#channelActive(ChannelHandlerContext)}event hit
   * the end of the {@link ChannelPipeline}.
   */
  protected void onUnhandledInboundChannelActive() {
  }
  
  ```

  - 该方法是个**空**方法，**这符合 Inbound 事件的定义 B03** 。
  - 至此，整个 pipeline 的 Inbound 事件的传播结束。

# 8. 关于其他 Inbound 事件

本文暂时只分享了 **firecChannelActive** 这个 Inbound 事件。剩余的其他事件，胖友可以自己进行调试和理解。例如：**fireChannelRegistered** 事件，并且结合 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 一文。

# 666. 彩蛋

推荐阅读文章：

- 闪电侠 [《netty 源码分析之 pipeline(二)》](https://www.jianshu.com/p/087b7e9a27a2)

感觉上来说，Inbound 事件的传播，比起 Outbound 事件的传播，会相对“绕”一点点。简化来说，实际大概是如下：

```
Unsafe 开始 => DefaultChannelPipeline#fireChannelActive

=> HeadContext#invokeChannelActive => DefaultChannelHandlerContext01#fireChannelActive

=> DefaultChannelHandlerContext01#invokeChannelActive => DefaultChannelHandlerContext02#fireChannelActive
...
=> DefaultChannelHandlerContext99#fireChannelActive => TailContext#fireChannelActive

=> TailContext#invokeChannelActive => 结束

```

笔者觉得可能解释的也有点“绕”，如果不理解或者有地方写的有误解，欢迎来叨叨，以便我们能一起优化这篇文章。

# 精尽 Netty 源码解析 —— ChannelPipeline（六）之异常事件的传播



# 1. 概述

在 [《精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-4-outbound/) 和 [《精尽 Netty 源码解析 —— ChannelPipeline（五）之 Inbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/) 中，我们看到 Outbound 和 Inbound 事件在 pipeline 中的传播逻辑。但是，无可避免，传播的过程中，可能会发生异常，那是怎么处理的呢？

本文，我们就来分享分享这块。

# 2. notifyOutboundHandlerException

我们以 Outbound 事件中的 **bind** 举例子，代码如下：

```
// AbstractChannelHandlerContext.java

private void invokeBind(SocketAddress localAddress, ChannelPromise promise) {
    if (invokeHandler()) { // 判断是否符合的 ChannelHandler
        try {
            // 调用该 ChannelHandler 的 bind 方法 <1>
            ((ChannelOutboundHandler) handler()).bind(this, localAddress, promise);
        } catch (Throwable t) {
            notifyOutboundHandlerException(t, promise); // 通知 Outbound 事件的传播，发生异常 <2>
        }
    } else {
        // 跳过，传播 Outbound 事件给下一个节点
        bind(localAddress, promise);
    }
}
```

- 在 `<1>` 处，调用 `ChannelOutboundHandler#bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise)` 方法**发生异常**时，会在 `<2>` 处调用 `AbstractChannelHandlerContext#notifyOutboundHandlerException(Throwable cause, ChannelPromise promise)` 方法，通知 Outbound 事件的传播，发生异常。
- 其他 Outbound 事件，大体的代码也是和 `#invokeBind(SocketAddress localAddress, ChannelPromise promise)` 是一致的。如下图所示：![类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554345630561.png)

------

`AbstractChannelHandlerContext#notifyOutboundHandlerException(Throwable cause, ChannelPromise promise)` 方法，通知 Outbound 事件的传播，发生异常。代码如下：

```
private static void notifyOutboundHandlerException(Throwable cause, ChannelPromise promise) {
    // Only log if the given promise is not of type VoidChannelPromise as tryFailure(...) is expected to return
    // false.
    PromiseNotificationUtil.tryFailure(promise, cause, promise instanceof VoidChannelPromise ? null : logger);
}
```

- 在方法内部，会调用 `PromiseNotificationUtil#tryFailure(Promise<?> p, Throwable cause, InternalLogger logger)` 方法，通知 bind 事件对应的 Promise 对应的监听者们。代码如下：

  ```
  public static void tryFailure(Promise<?> p, Throwable cause, InternalLogger logger) {
      if (!p.tryFailure(cause) && logger != null) {
          Throwable err = p.cause();
          if (err == null) {
              logger.warn("Failed to mark a promise as failure because it has succeeded already: {}", p, cause);
          } else {
              logger.warn(
                      "Failed to mark a promise as failure because it has failed already: {}, unnotified cause: {}",
                      p, ThrowableUtil.stackTraceToString(err), cause);
          }
      }
  }
  ```

  - 以 bind 事件来举一个监听器的例子。代码如下：

    ```
    ChannelFuture f = b.bind(PORT).addListener(new ChannelFutureListener() { // <1> 监听器就是我！
        @Override
        public void operationComplete(ChannelFuture future) throws Exception {
            System.out.println("异常：" + future.casue());
        }
    }).sync();
    ```

    - `<1>` 处的监听器，就是示例。当发生异常时，就会通知该监听器，对该异常做进一步**自定义**的处理。**也就是说，该异常不会在 pipeline 中传播**。

  - 我们再来看看怎么通知监听器的源码实现。调用 `DefaultPromise#tryFailure(Throwable cause)` 方法，通知 Promise 的监听器们，发生了异常。代码如下：

    ```
    @Override
    public boolean tryFailure(Throwable cause) {
        if (setFailure0(cause)) { // 设置 Promise 的结果
            // 通知监听器
            notifyListeners();
            // 返回成功
            return true;
        }
        // 返回失败
        return false;
    }
    ```

    - 若 `DefaultPromise#setFailure0(Throwable cause)` 方法，设置 Promise 的结果为方法传入的异常。但是有可能会传递失败，例如说，Promise 已经被设置了结果。
    - 如果该方法返回 `false` 通知 Promise 失败，那么 `PromiseNotificationUtil#tryFailure(Promise<?> p, Throwable cause, InternalLogger logger)` 方法的后续，就会使用 `logger` 打印错误日志。

# 3. notifyHandlerException

我们以 Inbound 事件中的 **fireChannelActive** 举例子，代码如下：

```
private void invokeChannelActive() {
    if (invokeHandler()) { // 判断是否符合的 ChannelHandler
        try {
            // 调用该 ChannelHandler 的 Channel active 方法 <1>
            ((ChannelInboundHandler) handler()).channelActive(this);
        } catch (Throwable t) {
            notifyHandlerException(t);  // 通知 Inbound 事件的传播，发生异常 <2>
        }
    } else {
        // 跳过，传播 Inbound 事件给下一个节点
        fireChannelActive();
    }
}
```

- 在 `<1>` 处，调用 `ChannelInboundHandler#channelActive(ChannelHandlerContext ctx)` 方法**发生异常**时，会在 `<2>` 处调用 `AbstractChannelHandlerContext#notifyHandlerException(Throwable cause)` 方法，通知 Inbound 事件的传播，发生异常。

- 其他 Inbound 事件，大体的代码也是和

   

  ```
  #invokeChannelActive()
  ```

   

  是一致的。如下图所示：

  

  - 😈 **注意，笔者在写的时候，突然发现 Outbound 事件中的 read 和 flush 的异常处理方式和 Inbound 事件是一样的**。
  - 😈 **注意，笔者在写的时候，突然发现 Outbound 事件中的 read 和 flush 的异常处理方式和 Inbound 事件是一样的**。
  - 😈 **注意，笔者在写的时候，突然发现 Outbound 事件中的 read 和 flush 的异常处理方式和 Inbound 事件是一样的**。

------

`AbstractChannelHandlerContext#notifyHandlerException(Throwable cause)` 方法，通知 Inbound 事件的传播，发生异常。代码如下：

```
private void notifyHandlerException(Throwable cause) {
    // <1> 如果是在 `ChannelHandler#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法中，仅打印错误日志。否则会形成死循环。
    if (inExceptionCaught(cause)) {
        if (logger.isWarnEnabled()) {
            logger.warn(
                    "An exception was thrown by a user handler " +
                            "while handling an exceptionCaught event", cause);
        }
        return;
    }

    // <2> 在 pipeline 中，传播 Exception Caught 事件
    invokeExceptionCaught(cause);
}
```

- `<1>` 处，调用 `AbstractChannelHandlerContext#inExceptionCaught(Throwable cause)` 方法，如果是在 `ChannelHandler#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法中，**发生异常**，仅打印错误日志，**并 return 返回** 。否则会形成死循环。代码如下：

  ```
  private static boolean inExceptionCaught(Throwable cause) {
      do {
          StackTraceElement[] trace = cause.getStackTrace();
          if (trace != null) {
              for (StackTraceElement t : trace) { // 循环 StackTraceElement
                  if (t == null) {
                      break;
                  }
                  if ("exceptionCaught".equals(t.getMethodName())) { // 通过方法名判断
                      return true;
                  }
              }
          }
          cause = cause.getCause();
      } while (cause != null); // 循环异常的 cause() ，直到到没有
      
      return false;
  }
  ```

  - 通过 StackTraceElement 的方法名来判断，是不是 `ChannelHandler#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法。

- `<2>` 处，调用 `AbstractChannelHandlerContext#invokeExceptionCaught(Throwable cause)` 方法，在 pipeline 中，传递 Exception Caught 事件。在下文中，我们会看到，和 [《精尽 Netty 源码解析 —— ChannelPipeline（五）之 Inbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/) 的逻辑( `AbstractChannelHandlerContext#invokeChannelActive()` )是**一致**的。

  - 比较特殊的是，Exception Caught 事件在 pipeline 的起始节点，不是 `head` 头节点，而是**发生异常的当前节点开始**。怎么理解好呢？对于在 pipeline 上传播的 Inbound **xxx** 事件，在发生异常后，转化成 **Exception Caught** 事件，继续从当前节点，继续向下传播。

  - 如果 **Exception Caught** 事件在 pipeline 中的传播过程中，一直没有处理掉该异常的节点，最终会到达尾节点 `tail` ，它对 `#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法的实现，代码如下：

    ```
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        onUnhandledInboundException(cause);
    }
    ```

    - 在方法内部，会调用 `DefaultChannelPipeline#onUnhandledInboundException(Throwable cause)` 方法，代码如下：

      ```
      /**
       * Called once a {@link Throwable} hit the end of the {@link ChannelPipeline} without been handled by the user
       * in {@link ChannelHandler#exceptionCaught(ChannelHandlerContext, Throwable)}.
       */
      protected void onUnhandledInboundException(Throwable cause) {
          try {
              logger.warn(
                      "An exceptionCaught() event was fired, and it reached at the tail of the pipeline. " +
                              "It usually means the last handler in the pipeline did not handle the exception.",
                      cause);
          } finally {
              ReferenceCountUtil.release(cause);
          }
      }
      ```

      - 打印**告警**日志，并调用 `ReferenceCountUtil#release(Throwable)` 方法，释放需要释放的资源。

      - 从英文注释中，我们也可以看到，这种情况出现在**使用者**未定义合适的 ChannelHandler 处理这种异常，所以对于这种情况下，`tail` 节点只好打印**告警**日志。

      - 实际使用时，笔者建议胖友一定要定义 ExceptionHandler ，能够处理掉所有的异常，而不要使用到 `tail` 节点的异常处理。😈

      - 好基友【闪电侠】对尾节点 `tail` 做了很赞的总结

        > 总结一下，tail 节点的作用就是结束事件传播，并且对一些重要的事件做一些善意提醒

# 666. 彩蛋

推荐阅读文章：

- 闪电侠 [《netty 源码分析之 pipeline(二)》](https://www.jianshu.com/p/087b7e9a27a2)

# 精尽 Netty 源码解析 —— Channel（一）之简介



# 1. 概述

在前面的文章中，我们已经不断看到 Netty Channel 的身影，例如：

- 在 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 中，我们看了服务端 NioServerSocketChannel **对象创建**的过程。
- 在 [《精尽 Netty 源码分析 —— 启动（二）之客户端》](http://svip.iocoder.cn/Netty/bootstrap-2-client/) 中，我们看了客户端 NioSocketChannel **对象创建**的过程。

但是，考虑到本小节的后续文章，我们还是需要这样一篇文章，整体性的再看一次 Channel 的面貌。

# 2. Channel

`io.netty.channel.Channel` ，实现 AttributeMap、ChannelOutboundInvoker、Comparable 接口，Netty Channel 接口。

在 [《精尽 Netty 源码分析 —— Netty 简介（一）之项目结构》](http://svip.iocoder.cn/Netty/intro-1/) 中，我们对 Channel 的组件定义如下：

> Channel 是 Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 之外，还包括了 Netty 框架相关的一些功能，如获取该 Channel 的 EventLoop 。
>
> 在传统的网络编程中，作为核心类的 Socket ，它对程序员来说并不是那么友好，直接使用其成本还是稍微高了点。而 Netty 的 Channel 则提供的一系列的 API ，它大大降低了直接与 Socket 进行操作的复杂性。而相对于原生 NIO 的 Channel，Netty 的 Channel 具有如下优势( 摘自《Netty权威指南( 第二版 )》) ：
>
> - 在 Channel 接口层，采用 Facade 模式进行统一封装，将网络 I/O 操作、网络 I/O 相关联的其他操作封装起来，统一对外提供。
> - Channel 接口的定义尽量大而全，为 SocketChannel 和 ServerSocketChannel 提供统一的视图，由不同子类实现不同的功能，公共功能在抽象父类中实现，最大程度地实现功能和接口的重用。
> - 具体实现采用聚合而非包含的方式，将相关的功能类聚合在 Channel 中，由 Channel 统一负责和调度，功能实现更加灵活。

## 2.1 基础查询

```
/**
 * Returns the globally unique identifier of this {@link Channel}.
 *
 * Channel 的编号
 */
ChannelId id();

/**
 * Return the {@link EventLoop} this {@link Channel} was registered to.
 *
 * Channel 注册到的 EventLoop
 */
EventLoop eventLoop();

/**
 * Returns the parent of this channel.
 *
 * 父 Channel 对象
 *
 * @return the parent channel.
 *         {@code null} if this channel does not have a parent channel.
 */
Channel parent();

/**
 * Returns the configuration of this channel.
 *
 * Channel 配置参数
 */
ChannelConfig config();

/**
 * Returns an <em>internal-use-only</em> object that provides unsafe operations.
 *
 * Unsafe 对象
 */
Unsafe unsafe();

/**
 * Return the assigned {@link ChannelPipeline}.
 *
 * ChannelPipeline 对象，用于处理 Inbound 和 Outbound 事件的处理
 */
ChannelPipeline pipeline();

/**
 * Return the assigned {@link ByteBufAllocator} which will be used to allocate {@link ByteBuf}s.
 *
 * ByteBuf 分配器
 */
ByteBufAllocator alloc();

/**
 * Returns the local address where this channel is bound to.  The returned
 * {@link SocketAddress} is supposed to be down-cast into more concrete
 * type such as {@link InetSocketAddress} to retrieve the detailed
 * information.
 *
 * 本地地址
 *
 * @return the local address of this channel.
 *         {@code null} if this channel is not bound.
 */
SocketAddress localAddress();
/**
 * Returns the remote address where this channel is connected to.  The
 * returned {@link SocketAddress} is supposed to be down-cast into more
 * concrete type such as {@link InetSocketAddress} to retrieve the detailed
 * information.
 *
 * 远端地址
 *
 * @return the remote address of this channel.
 *         {@code null} if this channel is not connected.
 *         If this channel is not connected but it can receive messages
 *         from arbitrary remote addresses (e.g. {@link DatagramChannel},
 *         use {@link DatagramPacket#recipient()} to determine
 *         the origination of the received message as this method will
 *         return {@code null}.
 */
SocketAddress remoteAddress();
```

- 自身基本信息有 `#id()`、`#parent()`、`#config()`、`#localAddress()`、`#remoteAddress()` 方法。
- 每个 Channel 都有的核心组件有 `#eventLoop()`、`#unsafe()`、`#pipeline()`、`#alloc()` 方法。

## 2.2 状态查询

```
/**
 * Returns {@code true} if the {@link Channel} is open and may get active later
 *
 * Channel 是否打开。
 *
 * true 表示 Channel 可用
 * false 表示 Channel 已关闭，不可用
 */
boolean isOpen();

/**
 * Returns {@code true} if the {@link Channel} is registered with an {@link EventLoop}.
 *
 * Channel 是否注册
 *
 * true 表示 Channel 已注册到 EventLoop 上
 * false 表示 Channel 未注册到 EventLoop 上
 */
boolean isRegistered();

/**
 * Return {@code true} if the {@link Channel} is active and so connected.
 *
 * Channel 是否激活
 *
 * 对于服务端 ServerSocketChannel ，true 表示 Channel 已经绑定到端口上，可提供服务
 * 对于客户端 SocketChannel ，true 表示 Channel 连接到远程服务器
 */
boolean isActive();

/**
 * Returns {@code true} if and only if the I/O thread will perform the
 * requested write operation immediately.  Any write requests made when
 * this method returns {@code false} are queued until the I/O thread is
 * ready to process the queued write requests.
 *
 * Channel 是否可写
 *
 * 当 Channel 的写缓存区 outbound 非 null 且可写时，返回 true
 */
boolean isWritable();
/**
 * 获得距离不可写还有多少字节数
 * 
 * Get how many bytes can be written until {@link #isWritable()} returns {@code false}.
 * This quantity will always be non-negative. If {@link #isWritable()} is {@code false} then 0.
 */
long bytesBeforeUnwritable();
/**
 * 获得距离可写还要多少字节数
 * 
 * Get how many bytes must be drained from underlying buffers until {@link #isWritable()} returns {@code true}.
 * This quantity will always be non-negative. If {@link #isWritable()} is {@code true} then 0.
 */
long bytesBeforeWritable();
```

一个**正常结束**的 Channel 状态转移有**两**种情况：

- 服务端用于绑定( bind )的 Channel 、或者客户端发起连接( connect )的 Channel 。

  ```
  REGISTERED -> CONNECT/BIND -> ACTIVE -> CLOSE -> INACTIVE -> UNREGISTERED
  ```

- 服务端接受( accept )客户端的 Channel 。

  ```
  REGISTERED -> ACTIVE -> CLOSE -> INACTIVE -> UNREGISTERED
  ```

一个**异常关闭**的 Channel 状态转移不符合上面的。

## 2.3 IO 操作

```
@Override
Channel read();

@Override
Channel flush();
```

- 这两个方法，继承自 ChannelOutboundInvoker 接口。实际还有如下几个：

  ```
  ChannelFuture bind(SocketAddress localAddress);
  ChannelFuture connect(SocketAddress remoteAddress);
  ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress);
  ChannelFuture disconnect();
  ChannelFuture close();
  ChannelFuture deregister();
  ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise);
  ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise);
  ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise);
  ChannelFuture disconnect(ChannelPromise promise);
  ChannelFuture close(ChannelPromise promise);
  ChannelFuture deregister(ChannelPromise promise);
  ChannelOutboundInvoker read();
  ChannelFuture write(Object msg);
  ChannelFuture write(Object msg, ChannelPromise promise);
  ChannelOutboundInvoker flush();
  ChannelFuture writeAndFlush(Object msg, ChannelPromise promise);
  ChannelFuture writeAndFlush(Object msg);
  ```

- 对比下来，我们会发现 Channel 重写 ChannelOutboundInvoker 这两个接口的原因是：将返回值从 ChannelOutboundInvoker 修改成 Channel 。

- 我们看到除了 `#read()` 和 `#flush()` 方法，其它方法的返回值的类型都是 ChannelFuture ，这表明这些操作是**异步** IO 的过程。

## 2.4 异步结果 Future

```
/**
 * Returns the {@link ChannelFuture} which will be notified when this
 * channel is closed.  This method always returns the same future instance.
 *
 * Channel 关闭的 Future 对象
 */
ChannelFuture closeFuture();
```

- 除了自定义的 `#closeFuture()` 方法，也从 ChannelOutboundInvoker 接口继承了几个接口方法：

  ```
  ChannelPromise newPromise();
  ChannelProgressivePromise newProgressivePromise();
  
  ChannelFuture newSucceededFuture();
  ChannelFuture newFailedFuture(Throwable cause);
  
  ChannelPromise voidPromise();
  ```

  - 通过这些接口方法，可创建或获得和该 Channel 相关的 Future / Promise 对象。

## 2.5 类图

Channel 的子接口和实现类如下图：

![Channel 的子接口和实现类](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/01-1554345823017.png)

- 本图包含了 NIO、OIO、Local、Embedded 四种 Channel 实现类。说明如下：![Channel 四种 Channel 实现类的说明](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/02-1554345823029.png)
- 本系列仅分享 NIO 部分，所以裁剪类图如下：![NIO Channel 类图](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/03-1554345823044.png)

# 3. Unsafe

Unsafe **接口**，定义在在 `io.netty.channel.Channel` 内部，和 Channel 的操作**紧密结合**，下文我们将看到。

Unsafe 直译中文为“不安全”，就是告诉我们，**无需**且**不必要**在我们使用 Netty 的代码中，**不能直接**调用 Unsafe 相关的方法。Netty 注释说明如下：

```
/**
 * <em>Unsafe</em> operations that should <em>never</em> be called from user-code. 
 * 
 * These methods are only provided to implement the actual transport, and must be invoked from an I/O thread except for the
 * following methods:
 * <ul>
 *   <li>{@link #localAddress()}</li>
 *   <li>{@link #remoteAddress()}</li>
 *   <li>{@link #closeForcibly()}</li>
 *   <li>{@link #register(EventLoop, ChannelPromise)}</li>
 *   <li>{@link #deregister(ChannelPromise)}</li>
 *   <li>{@link #voidPromise()}</li>
 * </ul>
 */
```

😈 当然，对于我们想要了解 Netty 内部实现的胖友，那必须开扒它的代码实现落。因为它和 Channel 密切相关，所以我们也对它的接口做下分类。

## 3.1 基础查询

```
/**
 * Return the assigned {@link RecvByteBufAllocator.Handle} which will be used to allocate {@link ByteBuf}'s when
 * receiving data.
 *
 * ByteBuf 分配器的处理器
 */
RecvByteBufAllocator.Handle recvBufAllocHandle();

/**
 * Return the {@link SocketAddress} to which is bound local or
 * {@code null} if none.
 *
 * 本地地址
 */
SocketAddress localAddress();

/**
 * Return the {@link SocketAddress} to which is bound remote or
 * {@code null} if none is bound yet.
 *
 * 远端地址
 */
SocketAddress remoteAddress();
```

## 3.2 状态查询

无 😈

## 3.3 IO 操作

```
void register(EventLoop eventLoop, ChannelPromise promise);
void bind(SocketAddress localAddress, ChannelPromise promise);
void connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise);
void disconnect(ChannelPromise promise);
void close(ChannelPromise promise);
void closeForcibly();
void deregister(ChannelPromise promise);
void beginRead();
void write(Object msg, ChannelPromise promise);
void flush();

/**
 * Returns the {@link ChannelOutboundBuffer} of the {@link Channel} where the pending write requests are stored.
 */
ChannelOutboundBuffer outboundBuffer();
```

## 3.4 异步结果 Future

```
/**
 * Return a special ChannelPromise which can be reused and passed to the operations in {@link Unsafe}.
 * It will never be notified of a success or error and so is only a placeholder for operations
 * that take a {@link ChannelPromise} as argument but for which you not want to get notified.
 */
ChannelPromise voidPromise();
```

## 3.5 类图

Unsafe 的子接口和实现类如下图：

![Unsafe 的子接口和实现类](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/04-1554345823060.png)

- 已经经过裁剪，仅保留 NIO Channel 相关的 Unsafe 的子接口和实现类部分。
- 我们会发现，对于 Channel 和 Unsafe 来说，类名中包含 Byte 是属于客户端的，Message 是属于服务端的。

# 4. ChanelId

`io.netty.channel.ChannelId` 实现 Serializable、Comparable 接口，Channel 编号接口。代码如下：

```
public interface ChannelId extends Serializable, Comparable<ChannelId> {

    /**
     * Returns the short but globally non-unique string representation of the {@link ChannelId}.
     *
     * 全局非唯一
     */
    String asShortText();

    /**
     * Returns the long yet globally unique string representation of the {@link ChannelId}.
     *
     * 全局唯一
     */
    String asLongText();

}
```

- `#asShortText()` 方法，返回的编号，短，但是全局非唯一。
- `#asLongText()` 方法，返回的编号，长，但是全局唯一。

ChanelId 的**默认**实现类为 `io.netty.channel.DefaultChannelId` ，我们主要看看它是如何生成 Channel 的**两种**编号的。代码如下：

```
@Override
public String asShortText() {
    String shortValue = this.shortValue;
    if (shortValue == null) {
        this.shortValue = shortValue = ByteBufUtil.hexDump(data, data.length - RANDOM_LEN, RANDOM_LEN);
    }
    return shortValue;
}

@Override
public String asLongText() {
    String longValue = this.longValue;
    if (longValue == null) {
        this.longValue = longValue = newLongValue();
    }
    return longValue;
}
```

- 对于 `#asShortText()` 方法，仅使用最后 4 字节的随机数字，并转换成 16 进制的数字字符串。也因此，短，但是全局非唯一。

- 对于 `#asLongText()` 方法，通过调用 `#newLongValue()` 方法生成。代码如下：

  ```
  private String newLongValue() {
      StringBuilder buf = new StringBuilder(2 * data.length + 5); // + 5 的原因是有 5 个 '-'
      int i = 0;
      i = appendHexDumpField(buf, i, MACHINE_ID.length); // MAC 地址。
      i = appendHexDumpField(buf, i, PROCESS_ID_LEN); // 进程 ID 。4 字节。
      i = appendHexDumpField(buf, i, SEQUENCE_LEN); // 32 位数字，顺序增长。4 字节。
      i = appendHexDumpField(buf, i, TIMESTAMP_LEN); // 时间戳。8 字节。
      i = appendHexDumpField(buf, i, RANDOM_LEN); // 32 位数字，随机。4 字节。
      assert i == data.length;
      return buf.substring(0, buf.length() - 1);
  }
  
  private int appendHexDumpField(StringBuilder buf, int i, int length) {
      buf.append(ByteBufUtil.hexDump(data, i, length));
      buf.append('-');
      i += length;
      return i;
  }
  ```

  - 具体的生成规则，见代码。最终也是 16 进制的数字。也因此，长，但是全局唯一。

# 5. ChannelConfig

`io.netty.channel.ChannelConfig` ，Channel 配置接口。代码如下：

```
Map<ChannelOption<?>, Object> getOptions();
<T> T getOption(ChannelOption<T> option);
boolean setOptions(Map<ChannelOption<?>, ?> options);
<T> boolean setOption(ChannelOption<T> option, T value);

int getConnectTimeoutMillis();
ChannelConfig setConnectTimeoutMillis(int connectTimeoutMillis);

@Deprecated
int getMaxMessagesPerRead();
@Deprecated
ChannelConfig setMaxMessagesPerRead(int maxMessagesPerRead);

int getWriteSpinCount();
ChannelConfig setWriteSpinCount(int writeSpinCount);

ByteBufAllocator getAllocator();
ChannelConfig setAllocator(ByteBufAllocator allocator);

<T extends RecvByteBufAllocator> T getRecvByteBufAllocator();
ChannelConfig setRecvByteBufAllocator(RecvByteBufAllocator allocator);

boolean isAutoRead();
ChannelConfig setAutoRead(boolean autoRead);

boolean isAutoClose();
ChannelConfig setAutoClose(boolean autoClose);

int getWriteBufferHighWaterMark();
ChannelConfig setWriteBufferHighWaterMark(int writeBufferHighWaterMark);

int getWriteBufferLowWaterMark();
ChannelConfig setWriteBufferLowWaterMark(int writeBufferLowWaterMark);

MessageSizeEstimator getMessageSizeEstimator();
ChannelConfig setMessageSizeEstimator(MessageSizeEstimator estimator);

WriteBufferWaterMark getWriteBufferWaterMark();
ChannelConfig setWriteBufferWaterMark(WriteBufferWaterMark writeBufferWaterMark);
```

- 调用 `#setOption(ChannelOption<T> option, T value)` 方法时，会调用相应的 `#setXXX(...)` 方法。代码如下：

  ```
  // DefaultChannelConfig.java
  
  @Override
  @SuppressWarnings("deprecation")
  public <T> boolean setOption(ChannelOption<T> option, T value) {
      validate(option, value);
  
      if (option == CONNECT_TIMEOUT_MILLIS) {
          setConnectTimeoutMillis((Integer) value);
      } else if (option == MAX_MESSAGES_PER_READ) {
          setMaxMessagesPerRead((Integer) value);
      } else if (option == WRITE_SPIN_COUNT) {
          setWriteSpinCount((Integer) value);
      } else if (option == ALLOCATOR) {
          setAllocator((ByteBufAllocator) value);
      } else if (option == RCVBUF_ALLOCATOR) {
          setRecvByteBufAllocator((RecvByteBufAllocator) value);
      } else if (option == AUTO_READ) {
          setAutoRead((Boolean) value);
      } else if (option == AUTO_CLOSE) {
          setAutoClose((Boolean) value);
      } else if (option == WRITE_BUFFER_HIGH_WATER_MARK) {
          setWriteBufferHighWaterMark((Integer) value);
      } else if (option == WRITE_BUFFER_LOW_WATER_MARK) {
          setWriteBufferLowWaterMark((Integer) value);
      } else if (option == WRITE_BUFFER_WATER_MARK) {
          setWriteBufferWaterMark((WriteBufferWaterMark) value);
      } else if (option == MESSAGE_SIZE_ESTIMATOR) {
          setMessageSizeEstimator((MessageSizeEstimator) value);
      } else if (option == SINGLE_EVENTEXECUTOR_PER_GROUP) {
          setPinEventExecutorPerGroup((Boolean) value);
      } else {
          return false;
      }
  }
  
  ```

- ChannelConfig 的配置项 `io.netty.channel.ChannelOption` 很多，胖友可以看下 [《Netty：option 和 childOption 参数设置说明》](https://www.jianshu.com/p/0bff7c020af2) ，了解感兴趣的配置项。

## 5.1 类图

ChannelConfig 的子接口和实现类如下图：

![ChannelConfig 的子接口和实现类](D:/onedrive/OneDrive%20-%205TB/files/md/%E8%8A%8B%E9%81%93%E6%BA%90%E7%A0%81/Netty/05-1554345823080.png)

- 已经经过裁剪，仅保留 NIO Channel 相关的 ChannelConfig 的子接口和实现类部分。

# 666. 彩蛋

正如文头所说，在前面的文章中，我们已经不断看到 Netty Channel 的身影，例如：

- 在 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 中，我们看了服务端 NioServerSocketChannel **bind** 的过程。
- 在 [《精尽 Netty 源码分析 —— 启动（二）之客户端》](http://svip.iocoder.cn/Netty/bootstrap-2-client/) 中，我们看了客户端 NioSocketChannel **connect** 的过程。

在后续的文章中，我们会分享 Netty NIO Channel 的其他操作，😈 一篇一个操作。

------

推荐阅读文章：

- Hypercube [《自顶向下深入分析 Netty（六）–Channel总述》](https://www.jianshu.com/p/fffc18d33159)

# 精尽 Netty 源码解析 —— Channel（二）之 accept 操作



# 1. 概述

本文分享 Netty NIO 服务端 NioServerSocketChannel 接受( **accept** )客户端连接的过程。简单来说：

1. 服务端 NioServerSocketChannel 的 boss EventLoop 线程轮询是否有新的客户端连接接入。
2. 当轮询到有新的连接接入，封装连入的客户端的 SocketChannel 为 Netty NioSocketChannel 对象。
3. 选择一个服务端 NioServerSocketChannel 的 worker EventLoop ，将客户端的 NioSocketChannel 注册到其上。并且，注册客户端的 NioSocketChannel 的读事件，开始轮询该客户端是否有数据写入。

下面，让我们来看看具体的代码实现。

# 2. NioMessageUnsafe#read

> 老艿艿：有点不知道怎么取标题好，直接用方法名吧。

在 NioEventLoop 的 `#processSelectedKey(SelectionKey k, AbstractNioChannel ch)` 方法中，我们会看到这样一段代码：

```
// SelectionKey.OP_READ 或 SelectionKey.OP_ACCEPT 就绪
// readyOps == 0 是对 JDK Bug 的处理，防止空的死循环
// Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead
// to a spin loop
if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {
    unsafe.read();
}
```

- 当 `(readyOps & SelectionKey.OP_ACCEPT) != 0` 时，这就是服务端 NioServerSocketChannel 的 boss EventLoop 线程**轮询到**有新的客户端连接接入。
- 然后，调用 `NioMessageUnsafe#read()` 方法，“读取”( 😈 这个抽象很灵性 )新的客户端连接连入。

------

`NioMessageUnsafe#read()` 方法，代码如下：

```
 1: private final class NioMessageUnsafe extends AbstractNioUnsafe {
 2: 
 3:     /**
 4:      * 新读取的客户端连接数组
 5:      */
 6:     private final List<Object> readBuf = new ArrayList<Object>();
 7: 
 8:     @SuppressWarnings("Duplicates")
 9:     @Override
10:     public void read() {
11:         assert eventLoop().inEventLoop();
12:         final ChannelConfig config = config();
13:         final ChannelPipeline pipeline = pipeline();
14:         // 获得 RecvByteBufAllocator.Handle 对象
15:         final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle();
16:         // 重置 RecvByteBufAllocator.Handle 对象
17:         allocHandle.reset(config);
18: 
19:         boolean closed = false;
20:         Throwable exception = null;
21:         try {
22:             try {
23:                 do {
24:                     // 读取客户端的连接到 readBuf 中
25:                     int localRead = doReadMessages(readBuf);
26:                     // 无可读取的客户端的连接，结束
27:                     if (localRead == 0) {
28:                         break;
29:                     }
30:                     // 读取出错
31:                     if (localRead < 0) {
32:                         closed = true; // 标记关闭
33:                         break;
34:                     }
35: 
36:                     // 读取消息数量 + localRead
37:                     allocHandle.incMessagesRead(localRead);
38:                 } while (allocHandle.continueReading()); // 循环判断是否继续读取
39:             } catch (Throwable t) {
40:                 // 记录异常
41:                 exception = t;
42:             }
43: 
44:             // 循环 readBuf 数组，触发 Channel read 事件到 pipeline 中。
45:             int size = readBuf.size();
46:             for (int i = 0; i < size; i ++) {
47:                 // TODO 芋艿
48:                 readPending = false;
49:                 // 在内部，会通过 ServerBootstrapAcceptor ，将客户端的 Netty NioSocketChannel 注册到 EventLoop 上
50:                 pipeline.fireChannelRead(readBuf.get(i));
51:             }
52:             // 清空 readBuf 数组
53:             readBuf.clear();
54:             // 读取完成
55:             allocHandle.readComplete();
56:             // 触发 Channel readComplete 事件到 pipeline 中。
57:             pipeline.fireChannelReadComplete();
58: 
59:             // 发生异常
60:             if (exception != null) {
61:                 // 判断是否要关闭 TODO 芋艿
62:                 closed = closeOnReadError(exception);
63: 
64:                 // 触发 exceptionCaught 事件到 pipeline 中。
65:                 pipeline.fireExceptionCaught(exception);
66:             }
67: 
68:             if (closed) {
69:                 // TODO 芋艿
70:                 inputShutdown = true;
71:                 // TODO 芋艿
72:                 if (isOpen()) {
73:                     close(voidPromise());
74:                 }
75:             }
76:         } finally {
77:             // Check if there is a readPending which was not processed yet.
78:             // This could be for two reasons:
79:             // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method
80:             // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method
81:             //
82:             // See https://github.com/netty/netty/issues/2254
83:             // TODO 芋艿
84:             if (!readPending && !config.isAutoRead()) {
85:                 removeReadOp();
86:             }
87:         }
88:     }
89: }
```

- 😈 NioMessageUnsafe 只有一个 `#read()` 方法，而该方法，“读取”新的客户端连接连入。

- 第 15 行：调用 `Unsafe#recvBufAllocHandle()` 方法，获得 获得 RecvByteBufAllocator.Handle 对象。默认情况下，返回的是 AdaptiveRecvByteBufAllocator.HandleImpl 对象。关于它的内容，我们放在 ByteBuf 相关的文章，详细解析。

  - 第 17 行：调用 `DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle#reset(ChannelConfig)` 方法，重置 RecvByteBufAllocator.Handle 对象。代码如下：

    ```
    @Override
    public void reset(ChannelConfig config) {
        this.config = config; // 重置 ChannelConfig 对象
        maxMessagePerRead = maxMessagesPerRead(); // 重置 maxMessagePerRead 属性
        totalMessages = totalBytesRead = 0; // 重置 totalMessages 和 totalBytesRead 属性
    }
    ```

    - 注意，AdaptiveRecvByteBufAllocator.HandleImpl 继承 DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle 抽象类。

- 第 22 至 42 行：**while 循环** “读取”新的客户端连接连入。

  - 第 25 行： 调用 `NioServerSocketChannel#doReadMessages(List<Object> buf)` 方法，读取客户端的连接到 `readBuf` 中。详细解析，胖友先跳到 [「3. AbstractNioMessageChannel#doReadMessages」](http://svip.iocoder.cn/Netty/Channel-2-accept/#) 中，看完记得回到此处。

  - 第 25 至 29 行：无可读取的客户端的连接，结束循环。

  - 第 30 至 34 行：读取出错，**标记关闭服务端**，并结束循环。目前我们看到 `NioServerSocketChannel#doReadMessages(List<Object> buf)` 方法的实现，返回的结果只会存在 0 和 1 ，也就是说不会出现这种情况。笔者又去翻了别的实现类，例如 `NioDatagramChannel#doReadMessages(List<Object> buf)` 方法，在发生异常时，会返回 -1 。

  - 第 37 行：调用 `AdaptiveRecvByteBufAllocator.HandleImpl#incMessagesRead(int amt)` 方法，读取消息( 客户端 )数量 + `localRead` 。代码如下：

    ```
    @Override
    public final void incMessagesRead(int amt) {
        totalMessages += amt;
    }
    ```

    - 对于 AdaptiveRecvByteBufAllocator.HandleImpl 来说，考虑到**抽象**的需要，所以统一使用“消息”的说法。

  - 第 38 行：调用 `AdaptiveRecvByteBufAllocator.HandleImpl#incMessagesRead(int amt)#continueReading()` 方法，判断是否循环是否继续，读取( 接受 )新的客户端连接。代码如下：

    ```
    // AdaptiveRecvByteBufAllocator.HandleImpl.java
    @Override
    public boolean continueReading() {
        return continueReading(defaultMaybeMoreSupplier);
    }
    
    // DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle.java
    @Override
    public boolean continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier) {
        return config.isAutoRead() &&
               (!respectMaybeMoreData || maybeMoreDataSupplier.get()) &&
               totalMessages < maxMessagePerRead &&
               totalBytesRead > 0; // <1>
    }
    ```

    - 因为 `<1>` 处，此时 `totalBytesRead` 等于 0 ，所以会返回 **false** 。因此，循环会结束。也因此，对于 NioServerSocketChannel 来说，**每次只接受一个新的客户端连接**。😈 当然，因为服务端 NioServerSocketChannel 对 `Selectionkey.OP_ACCEPT` 事件感兴趣，所以**后续的新的客户端连接还是会被接受的**。

  - 第 39 至 42 行：读取过程中发生异常，记录该异常到 `exception` 中，同时结束循环。

- 第 44 至 51 行：循环`readBuf`数组，触发 Channel read 事件到 pipeline 中。

  - 第 48 行：TODO 芋艿 细节
  - 第 50 行：调用`ChannelPipeline#fireChannelRead(Object msg)`方法，触发 Channel read 事件到 pipeline 中。
    - **注意**，传入的方法参数是新接受的客户端 NioSocketChannel 连接。
    - 在内部，会通过 ServerBootstrapAcceptor ，将客户端的 Netty NioSocketChannel 注册到 EventLoop 上。详细解析，胖友先跳到 [「4. ServerBootstrapAcceptor」](http://svip.iocoder.cn/Netty/Channel-2-accept/#) 中，看完记得回到此处。

- 第 53 行：清空 `readBuf` 数组。

- 第 55 行：调用 `RecvByteBufAllocator.Handle#readComplete()` 方法，读取完成。暂无重要的逻辑，不详细解析。

- 第 57 行：调用 `ChannelPipeline#fireChannelReadComplete()` 方法，触发 Channel readComplete 事件到 pipeline 中。

  - *如果有需要，胖友可以自定义处理器，处理该事件。一般情况下，不需要*。

  - 如果没有自定义 ChannelHandler 进行处理，最终会被 pipeline 中的尾节点 TailContext 所处理。代码如下：

    ```
    // TailContext.java
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        onUnhandledInboundChannelReadComplete();
    }
    
    // DefaultChannelPipeline.java
    protected void onUnhandledInboundChannelReadComplete() {
    }
    ```

    - 具体的调用是**空方法**。

- 第 60 至 66 行：`exception`非空，说明在接受连接过程中发生异常。

  - 第 62 行：TODO 芋艿 细节
  - 第 65 行： 调用`ChannelPipeline#fireExceptionCaught(Throwable)`方法，触发 exceptionCaught 事件到 pipeline 中。
    - 默认情况下，会使用 ServerBootstrapAcceptor 处理该事件。详细解析，见 [「4.3 exceptionCaught」](http://svip.iocoder.cn/Netty/Channel-2-accept/#) 。
    - *如果有需要，胖友可以自定义处理器，处理该事件。一般情况下，不需要*。

- 第 68 至 75 行：TODO 芋艿 细节

- 第 76 至 87 行：TODO 芋艿 细节

# 3. AbstractNioMessageChannel#doReadMessages

`doReadMessages(List<Object> buf)` **抽象**方法，读取客户端的连接到方法参数 `buf` 中。它是一个**抽象**方法，定义在 AbstractNioMessageChannel 抽象类中。代码如下：

```
/**
 * Read messages into the given array and return the amount which was read.
 */
protected abstract int doReadMessages(List<Object> buf) throws Exception;
```

- 返回值为读取到的数量。

NioServerSocketChannel 对该方法的实现代码如下：

```
  1: @Override
  2: protected int doReadMessages(List<Object> buf) throws Exception {
  3:     // 接受客户端连接
  4:     SocketChannel ch = SocketUtils.accept(javaChannel());
  5: 
  6:     try {
  7:         // 创建 Netty NioSocketChannel 对象
  8:         if (ch != null) {
  9:             buf.add(new NioSocketChannel(this, ch));
 10:             return 1;
 11:         }
 12:     } catch (Throwable t) {
 13:         logger.warn("Failed to create a new channel from an accepted socket.", t);
 14:         // 发生异常，关闭客户端的 SocketChannel 连接
 15:         try {
 16:             ch.close();
 17:         } catch (Throwable t2) {
 18:             logger.warn("Failed to close a socket.", t2);
 19:         }
 20:     }
 21: 
 22:     return 0;
 23: }
 
 @Override
protected ServerSocketChannel javaChannel() {
    return (ServerSocketChannel) super.javaChannel();
}
```

- 第 4 行：调用 `SocketUtils#accept(ServerSocketChannel serverSocketChannel)` 方法，接受客户端连接。代码如下：

  ```
  public static SocketChannel accept(final ServerSocketChannel serverSocketChannel) throws IOException {
      try {
          return AccessController.doPrivileged(new PrivilegedExceptionAction<SocketChannel>() {
              @Override
              public SocketChannel run() throws IOException {
                  return serverSocketChannel.accept(); // <1>
              }
          });
      } catch (PrivilegedActionException e) {
          throw (IOException) e.getCause();
      }
  }
  ```

  - 重点是看 `<1>` 处，调用 `ServerSocketChannel#accept()` 方法，接受客户端连接。

- 第 9 行：基于客户端的 NIO ServerSocket ，创建 Netty NioSocketChannel 对象。整个过程，就是[《精尽 Netty 源码分析 —— 启动（二）之客户端》](http://svip.iocoder.cn/Netty/bootstrap-2-client/)的 [「3.7.1 创建 Channel 对象」](http://svip.iocoder.cn/Netty/Channel-2-accept/#)小节。

  - 第 10 行：返回 1 ，表示成功接受了 1 个新的客户端连接。

- 第 12 至 20 行：发生异常，关闭客户端的 SocketChannel 连接，并打印**告警**日志。

  - 第 22 行：返回 0 ，表示成功接受 0 个新的客户端连接。

# 4. ServerBootstrapAcceptor

ServerBootstrapAcceptor ，继承 ChannelInboundHandlerAdapter 类，服务器接收器( acceptor )，负责将接受的客户端的 NioSocketChannel 注册到 EventLoop 中。

另外，从继承的是 ChannelInboundHandlerAdapter 类，可以看出它是 Inbound 事件处理器。

## 4.1 构造方法

在服务端的启动过程中，我们看到 ServerBootstrapAcceptor 注册到服务端的 NioServerSocketChannel 的 pipeline 的尾部，代码如下：

```
// 记录当前的属性
final EventLoopGroup currentChildGroup = childGroup;
final ChannelHandler currentChildHandler = childHandler;
final Entry<ChannelOption<?>, Object>[] currentChildOptions;
final Entry<AttributeKey<?>, Object>[] currentChildAttrs;
synchronized (childOptions) {
    currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0));
}
synchronized (childAttrs) {
    currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0));
}

// 添加 ChannelInitializer 对象到 pipeline 中，用于后续初始化 ChannelHandler 到 pipeline 中。
p.addLast(new ChannelInitializer<Channel>() {

    @Override
    public void initChannel(final Channel ch) throws Exception {
        final ChannelPipeline pipeline = ch.pipeline();

        // 添加配置的 ChannelHandler 到 pipeline 中。
        ChannelHandler handler = config.handler();
        if (handler != null) {
            pipeline.addLast(handler);
        }

        // 添加 ServerBootstrapAcceptor 到 pipeline 中。
        // 使用 EventLoop 执行的原因，参见 https://github.com/lightningMan/netty/commit/4638df20628a8987c8709f0f8e5f3679a914ce1a
        ch.eventLoop().execute(new Runnable() {
            @Override
            public void run() {
                pipeline.addLast(new ServerBootstrapAcceptor(
                        ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); // <1>
            }
        });
    }

});
```

- 即 `<1>` 处。也是在此处，创建了 ServerBootstrapAcceptor 对象。代码如下：

  ```
  private final EventLoopGroup childGroup;
  private final ChannelHandler childHandler;
  private final Entry<ChannelOption<?>, Object>[] childOptions;
  private final Entry<AttributeKey<?>, Object>[] childAttrs;
  /**
   * 自动恢复接受客户端连接的任务
   */
  private final Runnable enableAutoReadTask;
  
  ServerBootstrapAcceptor(
          final Channel channel, EventLoopGroup childGroup, ChannelHandler childHandler,
          Entry<ChannelOption<?>, Object>[] childOptions, Entry<AttributeKey<?>, Object>[] childAttrs) {
      this.childGroup = childGroup;
      this.childHandler = childHandler;
      this.childOptions = childOptions;
      this.childAttrs = childAttrs;
  
      // Task which is scheduled to re-enable auto-read.
      // It's important to create this Runnable before we try to submit it as otherwise the URLClassLoader may
      // not be able to load the class because of the file limit it already reached.
      //
      // See https://github.com/netty/netty/issues/1328
      enableAutoReadTask = new Runnable() { // <2>
          @Override
          public void run() {
              channel.config().setAutoRead(true);
          }
      };
  }
  ```

  - `enableAutoReadTask` 属性，自动恢复接受客户端连接的任务，在 `<2>` 处初始化。具体的使用，我们在 [「4.3 exceptionCaught」](http://svip.iocoder.cn/Netty/Channel-2-accept/#) 中，详细解析。

## 4.2 channelRead

`#channelRead(ChannelHandlerContext ctx, Object msg)` 方法，将接受的客户端的 NioSocketChannel 注册到 EventLoop 中。代码如下：

```
 1: @Override
 2: public void channelRead(ChannelHandlerContext ctx, Object msg) {
 3:     // 老艿艿：如下的注释，先暂时认为是接受的客户端的 NioSocketChannel
 4: 
 5:     // 接受的客户端的 NioSocketChannel 对象
 6:     final Channel child = (Channel) msg;
 7:     // 添加 NioSocketChannel 的处理器
 8:     child.pipeline().addLast(childHandler);
 9:     // 设置 NioSocketChannel 的配置项
10:     setChannelOptions(child, childOptions, logger);
11:     // 设置 NioSocketChannel 的属性
12:     for (Entry<AttributeKey<?>, Object> e: childAttrs) {
13:         child.attr((AttributeKey<Object>) e.getKey()).set(e.getValue());
14:     }
15: 
16:     try {
17:         // 注册客户端的 NioSocketChannel 到 work EventLoop 中。
18:         childGroup.register(child).addListener(new ChannelFutureListener() {
19: 
20:             @Override
21:             public void operationComplete(ChannelFuture future) throws Exception {
22:                 // 注册失败，关闭客户端的 NioSocketChannel
23:                 if (!future.isSuccess()) {
24:                     forceClose(child, future.cause());
25:                 }
26:             }
27: 
28:         });
29:     } catch (Throwable t) {
30:         // 发生异常，强制关闭客户端的 NioSocketChannel
31:         forceClose(child, t);
32:     }
33: }
```

- 为了方便描述，我们统一认为接受的客户端连接为 NioSocketChannel 对象。

- 第 6 行：接受的客户端的 NioSocketChannel 对象。

  - 第 8 行：调用 `ChannelPipeline#addLast(childHandler)` 方法，将配置的子 Channel 的处理器，添加到 NioSocketChannel 中。
  - 第 10 至 14 行：设置 NioSocketChannel 的配置项、属性。

- 第 17 至 28 行：调用 `EventLoopGroup#register(Channel channel)` 方法，将客户端的 NioSocketChannel 对象，从 worker EventLoopGroup 中选择一个 EventLoop ，注册到其上。

  - 后续的逻辑，就和 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 的注册逻辑**基本一致**( 虽然说，文章写的是 NioServerSocketChannel 的注册逻辑 )。

  - 在注册完成之后，该 worker EventLoop 就会开始轮询该客户端是否有数据写入。

  - 第 18 至 28 行：添加监听器，如果注册失败，则调用 `#forceClose(Channel child, Throwable t)` 方法，强制关闭客户端的 NioSocketChannel 连接。代码如下：

    ```
    private static void forceClose(Channel child, Throwable t) {
        child.unsafe().closeForcibly();
        logger.warn("Failed to register an accepted channel: {}", child, t);
    }
    ```

    - 在该方法内部，会调用 `Unsafe#closeForcibly()` 方法，强制关闭客户端的 NioSocketChannel 。

  - 第 29 至 32 行：发生异常，则调用 `#forceClose(Channel child, Throwable t)` 方法，强制关闭客户端的 NioSocketChannel 连接。

## 4.3 exceptionCaught

`#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法，当捕获到异常时，**暂停 1 秒**，不再接受新的客户端连接；而后，再恢复接受新的客户端连接。代码如下：

```
 1: @Override
 2: public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
 3:     final ChannelConfig config = ctx.channel().config();
 4:     if (config.isAutoRead()) {
 5:         // 关闭接受新的客户端连接
 6:         // stop accept new connections for 1 second to allow the channel to recover
 7:         // See https://github.com/netty/netty/issues/1328
 8:         config.setAutoRead(false);
 9:         // 发起 1 秒的延迟任务，恢复重启开启接受新的客户端连接
10:         ctx.channel().eventLoop().schedule(enableAutoReadTask, 1, TimeUnit.SECONDS);
11:     }
12: 
13:     // 继续传播 exceptionCaught 给下一个节点
14:     // still let the exceptionCaught event flow through the pipeline to give the user
15:     // a chance to do something with it
16:     ctx.fireExceptionCaught(cause);
17: }
```

- 第 8 行：调用 `ChannelConfig#setAutoRead(false)` 方法，关闭接受新的客户端连接。代码如下：

  ```
  // DefaultChannelConfig.java
  /**
   * {@link #autoRead} 的原子更新器
   */
  private static final AtomicIntegerFieldUpdater<DefaultChannelConfig> AUTOREAD_UPDATER = AtomicIntegerFieldUpdater.newUpdater(DefaultChannelConfig.class, "autoRead");
  /**
   * 是否开启自动读取的开关
   *
   * 1 - 开启
   * 0 - 关闭
   */
  @SuppressWarnings("FieldMayBeFinal")
  private volatile int autoRead = 1;
  
  @Override
  public ChannelConfig setAutoRead(boolean autoRead) {
      // 原子更新，并且获得更新前的值 <1>
      boolean oldAutoRead = AUTOREAD_UPDATER.getAndSet(this, autoRead ? 1 : 0) == 1;
      // 发起读取 <2.1>
      if (autoRead && !oldAutoRead) {
          channel.read();
      // 关闭读取 <2.2>
      } else if (!autoRead && oldAutoRead) {
          autoReadCleared();
      }
      return this;
  }
  ```

  - `autoRead`字段，是否开启自动读取的开关。😈 笔者原本以为是个`boolean`类型，是不是胖友也是。其中，1 表示开启，0 表示关闭。

    - `AUTOREAD_UPDATER` 静态变量，对 `autoRead` 字段的原子更新器。

  - `<1>` 处，使用 `AUTOREAD_UPDATER` 更新 `autoRead` 字段，并获得更新前的值。为什么需要获取更新前的值呢？在后续的 `<2.1>` 和 `<2.2>` 中，当 `autoRead` 有变化时候，才进行后续的逻辑。

  - 😈 下面的逻辑，我们按照 `channel` 的类型为 NioServerSocketChannel 来分享。

  - `<2.1>` 处，`autoRead && !oldAutoRead` 返回 `true` ，意味着恢复重启开启接受新的客户端连接。所以调用 `NioServerSocketChannel#read()` 方法，后续的逻辑，就是 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server/) 的 [「3.13.3 beginRead」](http://svip.iocoder.cn/Netty/Channel-2-accept/#) 的逻辑。

  - `<2.2>` 处，`!autoRead && oldAutoRead` 返回 `false` ，意味着关闭接受新的客户端连接。所以调用 `#autoReadCleared()` 方法，移除对 `SelectionKey.OP_ACCEPT` 事件的感兴趣。

    ```
    // NioServerSocketChannel.java
    
    @Override
    protected void autoReadCleared() {
        clearReadPending();
    }
    ```

    - 在方法内部，会调用 `#clearReadPending()` 方法，代码如下：

      ```
      protected final void clearReadPending() {
          if (isRegistered()) {
              EventLoop eventLoop = eventLoop();
              if (eventLoop.inEventLoop()) {
                  clearReadPending0();
              } else {
                  eventLoop.execute(clearReadPendingRunnable);
              }
          } else {
              // Best effort if we are not registered yet clear readPending. This happens during channel initialization.
              // NB: We only set the boolean field instead of calling clearReadPending0(), because the SelectionKey is
              // not set yet so it would produce an assertion failure.
              readPending = false;
          }
      }
      
      private final Runnable clearReadPendingRunnable = new Runnable() {
          @Override
          public void run() {
              clearReadPending0();
          }
      };
      
      private void clearReadPending0() {
          // TODO 芋艿
          readPending = false;
          // 移除对“读”事件的感兴趣。
          ((AbstractNioUnsafe) unsafe()).removeReadOp();
      }
      
      ```

      - 最终的结果，是在 EventLoop 的线程中，调用 `AbstractNioUnsafe#clearReadPending0()` 方法，移除对“**读**”事件的感兴趣( 对于 NioServerSocketChannel 的 “**读**“事件就是 `SelectionKey.OP_ACCEPT` )。代码如下：

        ```
        // AbstractNioUnsafe.java
        
        protected final void removeReadOp() {
            SelectionKey key = selectionKey();
            // 忽略，如果 SelectionKey 不合法，例如已经取消
            // Check first if the key is still valid as it may be canceled as part of the deregistration
            // from the EventLoop
            // See https://github.com/netty/netty/issues/2104
            if (!key.isValid()) {
                return;
            }
            // 移除对“读”事件的感兴趣。
            int interestOps = key.interestOps();
            if ((interestOps & readInterestOp) != 0) {
                // only remove readInterestOp if needed
                key.interestOps(interestOps & ~readInterestOp);
            }
        }
        
        ```

        - 通过取反求并，后调用 `SelectionKey#interestOps(interestOps)` 方法，**仅**移除对“读”事件的感兴趣。
        - 😈 整个过程的调用链，有丢丢长，胖友可以回看，或者多多调试。

- 第 10 行：调用 `EventLoop#schedule(Runnable command, long delay, TimeUnit unit)` 方法，发起 1 秒的延迟任务，恢复重启开启接受新的客户端连接。该定时任务会调用 `ChannelConfig#setAutoRead(true)` 方法，即对应 `<2.1>` 情况。

- 第 16 行：调用 `ChannelHandlerContext#fireExceptionCaught(cause)` 方法，继续传播 exceptionCaught 给下一个节点。具体的原因，可看英文注释。

# 666. 彩蛋

推荐阅读文章：

- 闪电侠 [《netty 源码分析之新连接接入全解析》](https://www.jianshu.com/p/0242b1d4dd21)
- 占小狼 [《Netty 源码分析之 accept 过程》](https://www.jianshu.com/p/ffc6fd82e32b)

# 精尽 Netty 源码解析 —— Channel（三）之 read 操作



# 1. 概述

本文分享 Netty NIO 服务端读取( **read** )来自客户端数据的过程、和 Netty NIO 客户端接收( **read** )来自服务端数据的结果。实际上，这两者的实现逻辑是一致的：

- 客户端就不用说了，自身就使用了 Netty NioSocketChannel 。
- 服务端在接受客户端连接请求后，会创建客户端对应的 Netty NioSocketChannel 。

因此，我们统一叫做 NioSocketChannel 读取( **read** )对端的数据的过程。

------

NioSocketChannel 读取( **read** )对端的数据的过程，简单来说：

1. NioSocketChannel 所在的 EventLoop 线程轮询是否有新的数据写入。
2. 当轮询到有新的数据写入，NioSocketChannel 读取数据，并提交到 pipeline 中进行处理。

比较简单，和 [《精尽 Netty 源码解析 —— Channel（二）之 accept 操作》](http://svip.iocoder.cn/Netty/Channel-2-accept) 有几分相似。或者我们可以说：

- NioServerSocketChannel 读取新的连接。
- NioSocketChannel 读取新的数据。

# 2. NioByteUnsafe#read

NioByteUnsafe ，实现 AbstractNioUnsafe 抽象类，AbstractNioByteChannel 的 Unsafe 实现类。代码如下：

```
protected class NioByteUnsafe extends AbstractNioUnsafe {

    public final void read() { /** 省略内部实现 **/ }

    private void handleReadException(ChannelPipeline pipeline, ByteBuf byteBuf, Throwable cause, boolean close, RecvByteBufAllocator.Handle allocHandle) { /** 省略内部实现 **/ }

    private void closeOnRead(ChannelPipeline pipeline) { /** 省略内部实现 **/ }

}
```

- 一共有 3 个方法。但是实现上，入口为 `#read()` 方法，而另外 2 个方法被它所调用。所以，我们赶紧开始 `#read()` 方法的理解吧。

## 2.1 read

在 NioEventLoop 的 `#processSelectedKey(SelectionKey k, AbstractNioChannel ch)` 方法中，我们会看到这样一段代码：

```
// SelectionKey.OP_READ 或 SelectionKey.OP_ACCEPT 就绪
// readyOps == 0 是对 JDK Bug 的处理，防止空的死循环
// Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead
// to a spin loop
if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {
    unsafe.read();
}
```

- 当 `(readyOps & SelectionKey.OP_READ) != 0` 时，这就是 NioSocketChannel 所在的 EventLoop 的线程**轮询到**有新的数据写入。
- 然后，调用 `NioByteUnsafe#read()` 方法，读取新的写入数据。

------

`NioByteUnsafe#read()` 方法，读取新的写入数据。代码如下：

```
 1: @Override
 2: @SuppressWarnings("Duplicates")
 3: public final void read() {
 4:     final ChannelConfig config = config();
 5:     // 若 inputClosedSeenErrorOnRead = true ，移除对 SelectionKey.OP_READ 事件的感兴趣。
 6:     if (shouldBreakReadReady(config)) {
 7:         clearReadPending();
 8:         return;
 9:     }
10:     final ChannelPipeline pipeline = pipeline();
11:     final ByteBufAllocator allocator = config.getAllocator();
12:     // 获得 RecvByteBufAllocator.Handle 对象
13:     final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle();
14:     // 重置 RecvByteBufAllocator.Handle 对象
15:     allocHandle.reset(config);
16: 
17:     ByteBuf byteBuf = null;
18:     boolean close = false; // 是否关闭连接
19:     try {
20:         do {
21:             // 申请 ByteBuf 对象
22:             byteBuf = allocHandle.allocate(allocator);
23:             // 读取数据
24:             // 设置最后读取字节数
25:             allocHandle.lastBytesRead(doReadBytes(byteBuf));
26:             // <1> 未读取到数据
27:             if (allocHandle.lastBytesRead() <= 0) {
28:                 // 释放 ByteBuf 对象
29:                 // nothing was read. release the buffer.
30:                 byteBuf.release();
31:                 // 置空 ByteBuf 对象
32:                 byteBuf = null;
33:                 // 如果最后读取的字节为小于 0 ，说明对端已经关闭
34:                 close = allocHandle.lastBytesRead() < 0;
35:                 // TODO
36:                 if (close) {
37:                     // There is nothing left to read as we received an EOF.
38:                     readPending = false;
39:                 }
40:                 // 结束循环
41:                 break;
42:             }
43: 
44:             // <2> 读取到数据
45: 
46:             // 读取消息数量 + localRead
47:             allocHandle.incMessagesRead(1);
48:             // TODO 芋艿 readPending
49:             readPending = false;
50:             // 触发 Channel read 事件到 pipeline 中。 TODO
51:             pipeline.fireChannelRead(byteBuf);
52:             // 置空 ByteBuf 对象
53:             byteBuf = null;
54:         } while (allocHandle.continueReading()); // 循环判断是否继续读取
55: 
56:         // 读取完成
57:         allocHandle.readComplete();
58:         // 触发 Channel readComplete 事件到 pipeline 中。
59:         pipeline.fireChannelReadComplete();
60: 
61:         // 关闭客户端的连接
62:         if (close) {
63:             closeOnRead(pipeline);
64:         }
65:     } catch (Throwable t) {
66:         handleReadException(pipeline, byteBuf, t, close, allocHandle);
67:     } finally {
68:         // TODO 芋艿 readPending
69:         // Check if there is a readPending which was not processed yet.
70:         // This could be for two reasons:
71:         // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method
72:         // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method
73:         //
74:         // See https://github.com/netty/netty/issues/2254
75:         if (!readPending && !config.isAutoRead()) {
76:             removeReadOp();
77:         }
78:     }
79: }
```

- 第 5 至 9 行：若 inputClosedSeenErrorOnRead = true ，移除对 SelectionKey.OP_READ 事件的感兴趣。详细解析，见 [《精尽 Netty 源码解析 —— Channel（七）之 close 操作》](http://svip.iocoder.cn/Netty/Channel-7-close/) 的 [「5. 服务端处理客户端主动关闭连接」](http://svip.iocoder.cn/Netty/Channel-3-read/#) 小节。

- 第 12 至 15 行：获得 RecvByteBufAllocator.Handle 对象，并重置它。这里的逻辑，和 `NioMessageUnsafe#read()` 方法的【第 14 至 17 行】的代码是一致的。相关的解析，见 [《精尽 Netty 源码解析 —— Channel（二）之 accept 操作》](http://svip.iocoder.cn/Netty/Channel-2-accept) 。

- 第 20 至 64 行：**while 循环** 读取新的写入数据。

  - 第 22 行：调用 `RecvByteBufAllocator.Handle#allocate(ByteBufAllocator allocator)` 方法，申请 ByteBuf 对象。关于它的内容，我们放在 ByteBuf 相关的文章，详细解析。

  - 第 25 行：调用 `AbstractNioByteChannel#doReadBytes(ByteBuf buf)` 方法，读取数据。详细解析，胖友先跳到 [「3. AbstractNioMessageChannel#doReadMessages」](http://svip.iocoder.cn/Netty/Channel-3-read/#) 中，看完记得回到此处。

  - 第 25 行：调用 `RecvByteBufAllocator.Handle#lastBytesRead(int bytes)` 方法，设置**最后**读取字节数。代码如下：

    ```
    // AdaptiveRecvByteBufAllocator.HandleImpl.java
    @Override
    public void lastBytesRead(int bytes) {
        // If we read as much as we asked for we should check if we need to ramp up the size of our next guess.
        // This helps adjust more quickly when large amounts of data is pending and can avoid going back to
        // the selector to check for more data. Going back to the selector can add significant latency for large
        // data transfers.
        if (bytes == attemptedBytesRead()) {
            record(bytes);
        }
        super.lastBytesRead(bytes);
    }
    
    // DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle.java
    @Override
    public void lastBytesRead(int bytes) {
        lastBytesRead = bytes; // 设置最后一次读取字节数 <1>
        if (bytes > 0) {
            totalBytesRead += bytes; // 总共读取字节数
        }
    }
    ```

    - 代码比较多，我们只看重点，当然也不细讲。
    - 在 `<1>` 处，设置最后一次读取字节数。

  - 读取有，有两种结果，**是**/**否**读取到数据。

  - `<1>` **未**读取到数据，即 `allocHandle.lastBytesRead() <= 0` 。

  - 第 30 行：调用`ByteBuf#release()`方法，释放 ByteBuf 对象。

    - 第 32 行：置空 ByteBuf 对象。

  - 第 34 行：如果最后读取的字节为小于 0 ，说明对端已经关闭。

  - 第 35 至 39 行：TODO 芋艿 细节

  - 第 41 行：`break` 结束循环。

  - `<2>` **有**读取到数据，即 `allocHandle.lastBytesRead() > 0` 。

  - 第 47 行：调用 `AdaptiveRecvByteBufAllocator.HandleImpl#incMessagesRead(int amt)` 方法，读取消息( 客户端 )数量 + `localRead = 1` 。

  - 第 49 行：TODO 芋艿 readPending

  - 第 51 行：调用 `ChannelPipeline#fireChannelRead(Object msg)` 方法，触发 Channel read 事件到 pipeline 中。

    - **注意**，一般情况下，我们会在自己的 Netty 应用程序中，自定义 ChannelHandler 处理读取到的数据。😈 当然，此时读取的数据，大多数情况下是需要在解码( Decode )。关于这一块，在后续关于 Codec ( 编解码 )的文章中，详细解析。

    - 如果没有自定义 ChannelHandler 进行处理，最终会被 pipeline 中的尾节点 TailContext 所处理。代码如下：

      ```
      // TailContext.java
      @Override
      public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
          onUnhandledInboundMessage(msg);
      }
      
      // DefaultChannelPipeline.java
      protected void onUnhandledInboundMessage(Object msg) {
          try {
              logger.debug("Discarded inbound message {} that reached at the tail of the pipeline. " + "Please check your pipeline configuration.", msg);
          } finally {
              ReferenceCountUtil.release(msg);
          }
      }
      ```

      - 最终也会**释放** ByteBuf 对象。这就是为什么【第 53 行】的代码，只去置空 ByteBuf 对象，而不用再去释放的原因。

  - 第 53 行：置空 ByteBuf 对象。

  - 第 54 行：调用 `AdaptiveRecvByteBufAllocator.HandleImpl#incMessagesRead(int amt)#continueReading()` 方法，判断是否循环是否继续，读取新的数据。代码如下：

    ```
    // DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle.java
    private final UncheckedBooleanSupplier defaultMaybeMoreSupplier = new UncheckedBooleanSupplier() {
        @Override
        public boolean get() {
            return attemptedBytesRead == lastBytesRead; // 最后读取的字节数，是否等于，最大可写入的字节数
        }
    };
    
    @Override
    public boolean continueReading() {
        return continueReading(defaultMaybeMoreSupplier);
    }
    
    @Override
    public boolean continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier) {
        return config.isAutoRead() &&
               (!respectMaybeMoreData || maybeMoreDataSupplier.get()) && // <1>
               totalMessages < maxMessagePerRead &&
               totalBytesRead > 0;
    }
    ```

    - 一般情况下，最后读取的字节数，**不等于**最大可写入的字节数，即 `<1>` 处的代码 `UncheckedBooleanSupplier#get()` 返回 `false` ，则不再进行数据读取。因为 😈 也没有数据可以读取啦。

- 第 57 行：调用 `RecvByteBufAllocator.Handle#readComplete()` 方法，读取完成。暂无重要的逻辑，不详细解析。

- 第 59 行：调用 `ChannelPipeline#fireChannelReadComplete()` 方法，触发 Channel readComplete 事件到 pipeline 中。

  - *如果有需要，胖友可以自定义处理器，处理该事件。一般情况下，不需要*。

  - 如果没有自定义 ChannelHandler 进行处理，最终会被 pipeline 中的尾节点 TailContext 所处理。代码如下：

    ```
    // TailContext.java
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        onUnhandledInboundChannelReadComplete();
    }
    
    // DefaultChannelPipeline.java
    protected void onUnhandledInboundChannelReadComplete() {
    }
    ```

    - 具体的调用是**空方法**。

- 第 61 至 64 行：关闭客户端的连接。详细解析，见 [《精尽 Netty 源码解析 —— Channel（七）之 close 操作》](http://svip.iocoder.cn/Netty/Channel-7-close/) 的 [「5. 服务端处理客户端主动关闭连接」](http://svip.iocoder.cn/Netty/Channel-3-read/#) 小节。

- 第 65 至 66 行：当发生异常时，调用 `#handleReadException(hannelPipeline pipeline, ByteBuf byteBuf, Throwable cause, boolean close, RecvByteBufAllocator.Handle allocHandle)` 方法，处理异常。详细解析，见 [「2.2 handleReadException」](http://svip.iocoder.cn/Netty/Channel-3-read/#) 中。

- 第 67 至 78 行：TODO 芋艿 细节

## 2.2 handleReadException

`#handleReadException(hannelPipeline pipeline, ByteBuf byteBuf, Throwable cause, boolean close, RecvByteBufAllocator.Handle allocHandle)` 方法，处理异常。代码如下：

```
 1: private void handleReadException(ChannelPipeline pipeline, ByteBuf byteBuf, Throwable cause, boolean close, RecvByteBufAllocator.Handle allocHandle) {
 2:     if (byteBuf != null) {
 3:         if (byteBuf.isReadable()) {
 4:             // TODO 芋艿 细节
 5:             readPending = false;
 6:             // 触发 Channel read 事件到 pipeline 中。
 7:             pipeline.fireChannelRead(byteBuf);
 8:         } else {
 9:             // 释放 ByteBuf 对象
10:             byteBuf.release();
11:         }
12:     }
13:     // 读取完成
14:     allocHandle.readComplete();
15:     // 触发 Channel readComplete 事件到 pipeline 中。
16:     pipeline.fireChannelReadComplete();
17:     // 触发 exceptionCaught 事件到 pipeline 中。
18:     pipeline.fireExceptionCaught(cause);
19:     // // TODO 芋艿 细节
20:     if (close || cause instanceof IOException) {
21:         closeOnRead(pipeline);
22:     }
23: }
```

- 第 2 行：`byteBuf` 非空，说明在发生异常之前，至少申请 ByteBuf 对象是**成功**的。

  - 第 3 行：调用 `ByteBuf#isReadable()` 方法，判断 ByteBuf 对象是否可读，即剩余可读的字节数据。

    - 该方法的英文注释如下：

      ```
      /**
       * Returns {@code true}
       * if and only if {@code (this.writerIndex - this.readerIndex)} is greater
       * than {@code 0}.
       */
      public abstract boolean isReadable();
      ```

      - 即 `this.writerIndex - this.readerIndex > 0` 。

    - 第 5 行：TODO 芋艿 细节

    - 第 7 行：调用 `ChannelPipeline#fireChannelRead(Object msg)` 方法，触发 Channel read 事件到 pipeline 中。

  - 第 8 至 11 行：ByteBuf 对象不可读，所以调用 `ByteBuf#release()` 方法，释放 ByteBuf 对象。

- 第 14 行：调用 `RecvByteBufAllocator.Handle#readComplete()` 方法，读取完成。暂无重要的逻辑，不详细解析。

- 第 16 行：调用 `ChannelPipeline#fireChannelReadComplete()` 方法，触发 Channel readComplete 事件到 pipeline 中。

- 第 18 行：调用 `ChannelPipeline#fireExceptionCaught(Throwable)` 方法，触发 exceptionCaught 事件到 pipeline 中。

  - **注意**，一般情况下，我们会在自己的 Netty 应用程序中，自定义 ChannelHandler 处理异常。

  - 如果没有自定义 ChannelHandler 进行处理，最终会被 pipeline 中的尾节点 TailContext 所处理。代码如下：

    ```
    // TailContext.java
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        onUnhandledInboundException(cause);
    }
    
    // DefaultChannelPipeline.java
    protected void onUnhandledInboundException(Throwable cause) {
        try {
            logger.warn("An exceptionCaught() event was fired, and it reached at the tail of the pipeline. " +
                            "It usually means the last handler in the pipeline did not handle the exception.",
                    cause);
        } finally {
            ReferenceCountUtil.release(cause);
        }
    }
    ```

    - 打印**告警**日志。
    - 调用 `ReferenceCountUtil#release(Object msg)` 方法，释放和异常相关的资源。

- 第 19 至 22 行：TODO 芋艿，细节

## 2.3 closeOnRead

TODO 芋艿，细节

# 3. AbstractNioByteChannel#doReadBytes

`doReadBytes(ByteBuf buf)` **抽象**方法，读取写入的数据到方法参数 `buf` 中。它是一个**抽象**方法，定义在 AbstractNioByteChannel 抽象类中。代码如下：

```
/**
 * Read bytes into the given {@link ByteBuf} and return the amount.
 */
protected abstract int doReadBytes(ByteBuf buf) throws Exception;
```

- 返回值为读取到的字节数。
- **当返回值小于 0 时，表示对端已经关闭**。

NioSocketChannel 对该方法的实现代码如下：

```
1: @Override
2: protected int doReadBytes(ByteBuf byteBuf) throws Exception {
3:     // 获得 RecvByteBufAllocator.Handle 对象
4:     final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle();
5:     // 设置最大可读取字节数量。因为 ByteBuf 目前最大写入的大小为 byteBuf.writableBytes()
6:     allocHandle.attemptedBytesRead(byteBuf.writableBytes());
7:     // 读取数据到 ByteBuf 中
8:     return byteBuf.writeBytes(javaChannel(), allocHandle.attemptedBytesRead());
9: }
```

- 第 4 行：获得 RecvByteBufAllocator.Handle 对象。

  - 第 6 行：设置最大可读取字节数量。因为 ByteBuf 对象**目前**最大可写入的大小为 `ByteBuf#writableBytes()` 的长度。

- 第 8 行：调用 `ByteBuf#writeBytes(ScatteringByteChannel in, int length)` 方法，读取数据到 ByteBuf 对象中。因为 ByteBuf 有多种实现，我们以默认的 PooledUnsafeDirectByteBuf 举例子。代码如下：

  ```
  // AbstractByteBuf.java
  @Override
  public int writeBytes(ScatteringByteChannel in, int length) throws IOException {
      ensureWritable(length);
      int writtenBytes = setBytes(writerIndex, in, length); // <1>
      if (writtenBytes > 0) { // <3>
          writerIndex += writtenBytes;
      }
      return writtenBytes;
  }
  
  // PooledUnsafeDirectByteBuf.java
  @Override
  public int setBytes(int index, ScatteringByteChannel in, int length) throws IOException {
      checkIndex(index, length);
      ByteBuffer tmpBuf = internalNioBuffer();
      index = idx(index);
      tmpBuf.clear().position(index).limit(index + length);
      try {
          return in.read(tmpBuf); // <2>
      } catch (ClosedChannelException ignored) {
          return -1;
      }
  }
  ```

  - 代码比较多，我们只看重点，当然也不细讲。还是那句话，关于 ByteBuf 的内容，我们在 ByteBuf 相关的文章详细解析。
  - 在 `<1>` 处，会调用 `#setBytes(int index, ScatteringByteChannel in, int length)` 方法。
  - 在`<2>`处，会调用 Java NIO 的`ScatteringByteChannel#read(ByteBuffer)`方法，读取**数据**到临时的 Java NIO ByteBuffer 中。
    - 在对端未断开时，返回的是读取数据的**字节数**。
    - 在对端已断开时，返回 `-1` ，表示断开。这也是为什么 `<3>` 处做了 `writtenBytes > 0` 的判断的原因。

# 666. 彩蛋

推荐阅读文章：

- 闪电侠 [《深入浅出 Netty read》](https://www.jianshu.com/p/6b48196b5043)
- Hypercube [《自顶向下深入分析Netty（六）– Channel源码实现》](https://www.jianshu.com/p/9258af254e1d)

# Channel（四）之 write 操作



# 1. 概述

本文分享 Netty NioSocketChannel **写入**对端数据的过程。和**写入**相关的，在 Netty Channel 有三种 API 方法：

```java
ChannelFuture write(Object msg)
ChannelFuture write(Object msg, ChannelPromise promise);

ChannelOutboundInvoker flush();

ChannelFuture writeAndFlush(Object msg);
ChannelFuture writeAndFlush(Object msg, ChannelPromise promise);
```

原生的 Java NIO SocketChannel 只有一种 write 方法，将数据写到对端。而 Netty Channel 竟然有三种方法，我们来一个个看看：

- write 方法：将数据写到

  内存队列

  中。

  - 也就是说，此时数据**并没有**写入到对端。

- flush 方法：刷新

  内存队列

  ，将其中的数据写入到对端。

  - 也就是说，此时数据才**真正**写到对端。

- writeAndFlush 方法：write + flush 的组合，将数据写到内存队列后，立即刷新

  内存队列

  ，又将其中的数据写入到对端。

  - 也就是说，此时数据**已经**写到对端。

严格来说，上述的描述不是完全准确。因为 Netty Channel 的 `#write(Object msg, ...)` 和 `#writeAndFlush(Object msg, ...)` 方法，是**异步写入**的过程，需要通过监听返回的 ChannelFuture 来确实是真正写入。例如：

```
// 方式一：异步监听
channel.write(msg).addListener(new ChannelFutureListener() {
                
    @Override
    public void operationComplete(ChannelFuture future) throws Exception {
        // ... 相关逻辑，例如是否成功？    
    }
    
});

// 方式二：同步异步写入结果
channel.write(msg).sync();
```

- 所以，胖友实际在使用时，一定要注意。😈 如果感兴趣，可以看看 Dubbo 和 Motan 等等 RPC 框架是怎么使用这个 API 方法的。
- 😈 **有一点一定非常肯定要注意**，`#write(Object msg, ...)` 方法返回的 Promise 对象，只有在数据真正被 `#flush()` 方法调用执行完成后，才会被回调通知。如果胖友不理解，请自己测试一下。

------

考虑到 Netty NioSocketChannel **写入**对端数据的代码太多，所以笔者拆成 write 和 flush 相关的两篇文章。所以，本文当然是 write 相关的文章。当然，这两个操作相关性很高，所以本文也会包括 flush 部分的内容。

# 2. AbstractChannel

AbstractChannel 对 `#write(Object msg, ...)` 方法的实现，代码如下：

```
@Override
public ChannelFuture write(Object msg) {
    return pipeline.write(msg);
}

@Override
public ChannelFuture write(Object msg, ChannelPromise promise) {
    return pipeline.write(msg, promise);
}
```

- 在方法内部，会调用对应的

   

  ```
  ChannelPipeline#write(Object msg, ...)
  ```

   

  方法，将 write 事件在 pipeline 上传播。详细解析，见

   

  「3. DefaultChannelPipeline」

   

  。

  - 最终会传播 write 事件到 `head` 节点，将数据写入到内存队列中。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#write(Object msg, ...)` 方法，代码如下：

```
@Override
public final ChannelFuture write(Object msg) {
    return tail.write(msg);
}

@Override
public final ChannelFuture write(Object msg, ChannelPromise promise) {
    return tail.write(msg, promise);
}
```

- 在方法内部，会调用 `TailContext#write(Object msg, ...)` 方法，将 write 事件在 pipeline 中，从尾节点向头节点传播。详细解析，见 [「4. TailContext」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 。

# 4. TailContext

TailContext 对 `TailContext#write(Object msg, ...)` 方法的实现，是从 AbstractChannelHandlerContext 抽象类继承，代码如下：

```
 1: @Override
 2: public ChannelFuture write(Object msg) {
 3:     return write(msg, newPromise());
 4: }
 5: 
 6: @Override
 7: public ChannelFuture write(final Object msg, final ChannelPromise promise) {
 8:     // 消息( 数据 )为空，抛出异常
 9:     if (msg == null) {
10:         throw new NullPointerException("msg");
11:     }
12: 
13:     try {
14:         // 判断是否为合法的 Promise 对象
15:         if (isNotValidPromise(promise, true)) {
16:             // 释放消息( 数据 )相关的资源
17:             ReferenceCountUtil.release(msg);
18:             // cancelled
19:             return promise;
20:         }
21:     } catch (RuntimeException e) {
22:         // 发生异常，释放消息( 数据 )相关的资源
23:         ReferenceCountUtil.release(msg);
24:         throw e;
25:     }
26: 
27:     // 写入消息( 数据 )到内存队列
28:     write(msg, false, promise);
29:     return promise;
30: }
```

- 在【第 2 行】的代码，我们可以看到，`#write(Object msg)` 方法，会调用 `#write(Object msg, ChannelPromise promise)` 方法。

  - 缺少的 `promise` 方法参数，通过调用 `#newPromise()` 方法，进行创建 Promise 对象，代码如下：

    ```
    @Override
    public ChannelPromise newPromise() {
        return new DefaultChannelPromise(channel(), executor());
    }
    ```

    - 返回 DefaultChannelPromise 对象。

  - 在【第 29 行】的代码，返回的结果就是传入的 `promise` 对象。

- 第 8 至 11 行：若消息( 消息 )为空，抛出异常。

- 第 15 行：调用

   

  ```
  #isNotValidPromise(promise, true)
  ```

   

  方法，判断是否为

  不合法

  的 Promise 对象。该方法，在

   

  《精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播》

   

  中已经详细解析。

  - 第 17 行：调用 `ReferenceCountUtil#release(msg)` 方法，释放释放消息( 数据 )相关的资源。
  - 第 19 行：返回 `promise` 对象。一般情况下，出现这种情况是 `promise` 已经被取消，所以不再有必要写入数据。或者说，**写入数据的操作被取消**。
  - 第 21 至 25 行：若发生异常， 调用 `ReferenceCountUtil#release(msg)` 方法，释放释放消息( 数据 )相关的资源。最终，会抛出该异常。

- 第 28 行：调用 `#write(Object msg, boolean flush, ChannelPromise promise)` 方法，写入消息( 数据 )到内存队列。代码如下：

  ```
   1: private void write(Object msg, boolean flush, ChannelPromise promise) {
   2:     // 获得下一个 Outbound 节点
   3:     AbstractChannelHandlerContext next = findContextOutbound();
   4:     // 记录 Record 记录
   5:     final Object m = pipeline.touch(msg, next);
   6:     EventExecutor executor = next.executor();
   7:     // 在 EventLoop 的线程中
   8:     if (executor.inEventLoop()) {
   9:         // 执行 writeAndFlush 事件到下一个节点
  10:         if (flush) {
  11:             next.invokeWriteAndFlush(m, promise);
  12:         // 执行 write 事件到下一个节点
  13:         } else {
  14:             next.invokeWrite(m, promise);
  15:         }
  16:     } else {
  17:         AbstractWriteTask task;
  18:         // 创建 writeAndFlush 任务
  19:         if (flush) {
  20:             task = WriteAndFlushTask.newInstance(next, m, promise);
  21:         // 创建 write 任务
  22:         }  else {
  23:             task = WriteTask.newInstance(next, m, promise);
  24:         }
  25:         // 提交到 EventLoop 的线程中，执行该任务
  26:         safeExecute(executor, task, promise, m);
  27:     }
  28: }
  ```

  - 方法参数 `flush` 为 `true` 时，该方法执行的是 write + flush 的组合操作，即将数据写到内存队列后，立即刷新**内存队列**，又将其中的数据写入到对端。

  - 第 3 行：调用 `#findContextOutbound()` 方法，获得**下一个** Outbound 节点。

  - 第 5 行：调用 `DefaultChannelPipeline#touch(Object msg, AbstractChannelHandlerContext next)` 方法，记录 Record 记录。代码如下：

    ```
    // DefaultChannelPipeline.java
    final Object touch(Object msg, AbstractChannelHandlerContext next) {
        return touch ? ReferenceCountUtil.touch(msg, next) : msg;
    }
    
    // ReferenceCountUtil.java
    /**
     * Tries to call {@link ReferenceCounted#touch(Object)} if the specified message implements
     * {@link ReferenceCounted}.  If the specified message doesn't implement {@link ReferenceCounted},
     * this method does nothing.
     */
    @SuppressWarnings("unchecked")
    public static <T> T touch(T msg, Object hint) {
        if (msg instanceof ReferenceCounted) {
            return (T) ((ReferenceCounted) msg).touch(hint);
        }
        return msg;
    }
    ```

    - 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（三）内存泄露检测》](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/) 。

  - 第 7 行：**在** EventLoop 的线程中。

    - 第 10 至 11 行：如果 `flush = true` 时，调用 `AbstractChannelHandlerContext#invokeWriteAndFlush()` 方法，执行 writeAndFlush 事件到下一个节点。
    - 第 12 至 15 行：如果 `flush = false` 时，调用 `AbstractChannelHandlerContext#invokeWrite()` 方法，执行 write 事件到下一个节点。
    - 后续的逻辑，和 [《精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-4-outbound/) 分享的 **bind** 事件在 pipeline 中的传播是**基本一致**的。
    - 随着 write 或 writeAndFlush **事件**不断的向下一个节点传播，最终会到达 HeadContext 节点。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 。

  - 第 16 行：

    不在

     

    EventLoop 的线程中。

    - 第 19 至 20 行：如果 `flush = true` 时，创建 WriteAndFlushTask 任务。
    - 第 21 至 24 行：如果 `flush = false` 时，创建 WriteTask 任务。
    - 第 26 行：调用 `#safeExecute(executor, task, promise, m)` 方法，提交到 EventLoop 的线程中，执行该任务。从而实现，**在** EventLoop 的线程中，执行 writeAndFlush 或 write 事件到下一个节点。详细解析，见 [「7. AbstractWriteTask」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 中。

- 第 29 行：返回 `promise` 对象。

# 5. HeadContext

在 pipeline 中，write 事件最终会到达 HeadContext 节点。而 HeadContext 的 `#write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，会处理该事件，代码如下：

```
@Override
public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
    unsafe.write(msg, promise);
}
```

- 在方法内部，会调用 `AbstractUnsafe#write(Object msg, ChannelPromise promise)` 方法，将数据写到**内存队列**中。详细解析，见 [「6. AbstractUnsafe」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 。

# 6. AbstractUnsafe

`AbstractUnsafe#write(Object msg, ChannelPromise promise)` 方法，将数据写到**内存队列**中。代码如下：

```
/**
 * 内存队列
 */
private volatile ChannelOutboundBuffer outboundBuffer = new ChannelOutboundBuffer(AbstractChannel.this);

  1: @Override
  2: public final void write(Object msg, ChannelPromise promise) {
  3:     assertEventLoop();
  4: 
  5:     ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
  6:     // 内存队列为空
  7:     if (outboundBuffer == null) {
  8:         // 内存队列为空，一般是 Channel 已经关闭，所以通知 Promise 异常结果
  9:         // If the outboundBuffer is null we know the channel was closed and so
 10:         // need to fail the future right away. If it is not null the handling of the rest
 11:         // will be done in flush0()
 12:         // See https://github.com/netty/netty/issues/2362
 13:         safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);
 14:         // 释放消息( 对象 )相关的资源
 15:         // release message now to prevent resource-leak
 16:         ReferenceCountUtil.release(msg);
 17:         return;
 18:     }
 19: 
 20:     int size;
 21:     try {
 22:         // 过滤写入的消息( 数据 )
 23:         msg = filterOutboundMessage(msg);
 24:         // 计算消息的长度
 25:         size = pipeline.estimatorHandle().size(msg);
 26:         if (size < 0) {
 27:             size = 0;
 28:         }
 29:     } catch (Throwable t) {
 30:         // 通知 Promise 异常结果
 31:         safeSetFailure(promise, t);
 32:         // 释放消息( 对象 )相关的资源
 33:         ReferenceCountUtil.release(msg);
 34:         return;
 35:     }
 36: 
 37:     // 写入消息( 数据 )到内存队列
 38:     outboundBuffer.addMessage(msg, size, promise);
 39: }
```

- `outboundBuffer` 属性，内存队列，用于缓存写入的数据( 消息 )。

- 第 7 行：内存队列为空，一般是 Channel

   

  已经关闭

  。

  - 调用 `#safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION)` 方法，通知 Promise 异常结果。
  - 第 16 行：调用 `ReferenceCountUtil#release(msg)` 方法，释放释放消息( 数据 )相关的资源。
  - 第 17 行：`return` ，结束执行。

- 第 23 行：调用 `AbstractNioByteChannel#filterOutboundMessage(msg)` 方法，过滤写入的消息( 数据 )。代码如下：

  ```
  // AbstractNioByteChannel.java
  
  @Override
  protected final Object filterOutboundMessage(Object msg) {
      // <1> ByteBuf 的情况
      if (msg instanceof ByteBuf) {
          ByteBuf buf = (ByteBuf) msg;
          // 已经是内存 ByteBuf
          if (buf.isDirect()) {
              return msg;
          }
  
          // 非内存 ByteBuf ，需要进行创建封装
          return newDirectBuffer(buf);
      }
  
      // <2> FileRegion 的情况
      if (msg instanceof FileRegion) {
          return msg;
      }
  
      // <3> 不支持其他类型
      throw new UnsupportedOperationException("unsupported message type: " + StringUtil.simpleClassName(msg) + EXPECTED_TYPES);
  }
  ```

  - `<1>` 处，消息( 数据 )是 ByteBuf 类型，如果是非 Direct ByteBuf 对象，需要调用 `#newDirectBuffer(ByteBuf)` 方法，复制封装成 Direct ByteBuf 对象。原因是：在使用 Socket 传递数据时性能很好，由于数据直接在内存中，不存在从 JVM 拷贝数据到直接缓冲区的过程，性能好。( 来自 [《[netty核心类\]–缓冲区ByteBuf》](https://blog.csdn.net/u010853261/article/details/53690780) )
  - `<2>` 处，消息( 数据 )是 FileRegion 类型，直接返回。
  - `<3>` 处，不支持其他数据类型。

- 第 24 至 28 行：计算消息的长度。

- 第 29 行：若发生异常时：

  - 第 31 行：调用 `#safeSetFailure(promise, Throwable t)` 方法，通知 Promise 异常结果。
  - 第 33 行：调用 `ReferenceCountUtil#release(msg)` 方法，释放释放消息( 数据 )相关的资源。
  - 第 34 行：`return` ，结束执行。

- 第 38 行：调用 `ChannelOutboundBuffer#addMessage(msg, size, promise)` 方法，写入消息( 数据 )到内存队列。关于 ChannelOutboundBuffer ，我们在 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush) 中，详细解析。

😈 至此，write 操作，将数据写到**内存队列**中的过程。
🙂 当然，想要写入数据到对端的过程，还是需要看完 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush) 一文。

# 7. AbstractWriteTask

AbstractWriteTask ，实现 Runnable 接口，写入任务**抽象类**。它有两个子类实现：

- WriteTask ，write 任务实现类。
- WriteAndFlushTask ，write + flush 任务实现类。

它们都是 AbstractChannelHandlerContext 的内部静态类。那么让我们先来 AbstractWriteTask 的代码。

## 7.1 构造方法

```
/**
 * 提交任务时，是否计算 AbstractWriteTask 对象的自身占用内存大小
 */
private static final boolean ESTIMATE_TASK_SIZE_ON_SUBMIT = SystemPropertyUtil.getBoolean("io.netty.transport.estimateSizeOnSubmit", true);

/**
 * 每个 AbstractWriteTask 对象自身占用内存的大小。
 */
// Assuming a 64-bit JVM, 16 bytes object header, 3 reference fields and one int field, plus alignment
private static final int WRITE_TASK_OVERHEAD = SystemPropertyUtil.getInt("io.netty.transport.writeTaskSizeOverhead", 48);

private final Recycler.Handle<AbstractWriteTask> handle;
/**
 * pipeline 中的节点
 */
private AbstractChannelHandlerContext ctx;
/**
 * 消息( 数据 )
 */
private Object msg;
/**
 * Promise 对象
 */
private ChannelPromise promise;
/**
 * 对象大小
 */
private int size;

@SuppressWarnings("unchecked")
private AbstractWriteTask(Recycler.Handle<? extends AbstractWriteTask> handle) {
    this.handle = (Recycler.Handle<AbstractWriteTask>) handle;
}
```

- 每个字段，看代码注释。

- `ESTIMATE_TASK_SIZE_ON_SUBMIT` **静态**字段，提交任务时，是否计算 AbstractWriteTask 对象的自身占用内存大小。

- ```
  WRITE_TASK_OVERHEAD
  ```

   

  静态

  字段，每个 AbstractWriteTask 对象自身占用内存的大小。为什么占用的 48 字节呢？

  - `- 16 bytes object header` ，对象头，16 字节。
  - `- 3 reference fields` ，3 个**对象引用**字段，3 * 8 = 24 字节。
  - `- 1 int fields` ，1 个 `int` 字段，4 字节。
  - `padding` ，补齐 8 字节的整数倍，因此 4 字节。
  - 因此，合计 48 字节( 64 位的 JVM 虚拟机，并且不考虑压缩 )。
  - 如果不理解的胖友，可以看看 [《JVM中 对象的内存布局 以及 实例分析》](https://www.jianshu.com/p/12a3c97dc2b7) 。

- `handle` 字段，Recycler 处理器。而 Recycler 是 Netty 用来实现对象池的工具类。在网络通信中，写入是非常频繁的操作，因此通过 Recycler 重用 AbstractWriteTask 对象，减少对象的频繁创建，降低 GC 压力，提升性能。

## 7.2 init

`#init(AbstractWriteTask task, AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，初始化 AbstractWriteTask 对象。代码如下：

```
protected static void init(AbstractWriteTask task, AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
    task.ctx = ctx;
    task.msg = msg;
    task.promise = promise;
    // 计算 AbstractWriteTask 对象大小 <1>
    if (ESTIMATE_TASK_SIZE_ON_SUBMIT) {
        task.size = ctx.pipeline.estimatorHandle().size(msg) + WRITE_TASK_OVERHEAD;
        // 增加 ChannelOutboundBuffer 的 totalPendingSize 属性  <2>
        ctx.pipeline.incrementPendingOutboundBytes(task.size);
    } else {
        task.size = 0;
    }
}
```

- 在下文中，我们会看到 AbstractWriteTask 对象是从 Recycler 中获取，所以获取完成后，需要通过该方法，初始化该对象的属性。

- `<1>` 处，计算 AbstractWriteTask 对象大小。并且在 `<2>` 处，调用 `ChannelPipeline#incrementPendingOutboundBytes(long size)` 方法，增加 ChannelOutboundBuffer 的 `totalPendingSize` 属性。代码如下：

  ```
  // DefaultChannelPipeline.java
  @UnstableApi
  protected void incrementPendingOutboundBytes(long size) {
      ChannelOutboundBuffer buffer = channel.unsafe().outboundBuffer();
      if (buffer != null) {
          buffer.incrementPendingOutboundBytes(size);
      }
  }
  
  ```

  - 内部，会调用 `ChannelOutboundBuffer#incrementPendingOutboundBytes(long size)` 方法，增加 ChannelOutboundBuffer 的 `totalPendingSize` 属性。详细解析，见 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush) 的 [「10.1 incrementPendingOutboundBytes」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 小节。

## 7.3 run

`#run()` **实现**方法，

```
 1: @Override
 2: public final void run() {
 3:     try {
 4:         // 减少 ChannelOutboundBuffer 的 totalPendingSize 属性 <1>
 5:         // Check for null as it may be set to null if the channel is closed already
 6:         if (ESTIMATE_TASK_SIZE_ON_SUBMIT) {
 7:             ctx.pipeline.decrementPendingOutboundBytes(size);
 8:         }
 9:         // 执行 write 事件到下一个节点
10:         write(ctx, msg, promise);
11:     } finally {
12:         // 置空，help gc
13:         // Set to null so the GC can collect them directly
14:         ctx = null;
15:         msg = null;
16:         promise = null;
17:         // 回收对象
18:         handle.recycle(this);
19:     }
20: }

```

- 在 `<1>` 处， 调用 `ChannelPipeline#decrementPendingOutboundBytes(long size)` 方法，减少 ChannelOutboundBuffer 的 `totalPendingSize` 属性。代码如下：

  ```
  @UnstableApi
  protected void decrementPendingOutboundBytes(long size) {
      ChannelOutboundBuffer buffer = channel.unsafe().outboundBuffer();
      if (buffer != null) {
          buffer.decrementPendingOutboundBytes(size);
      }
  }
  
  ```

  - 内部，会调用 `ChannelOutboundBuffer#decrementPendingOutboundBytes(long size)` 方法，减少 ChannelOutboundBuffer 的 `totalPendingSize` 属性。详细解析，见 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush) 的 [「10.2 decrementPendingOutboundBytes」](http://svip.iocoder.cn/Netty/Channel-4-write/#) 小节。

- 第 10 行：调用 `#write(ctx, msg, promise)` 方法，执行 write 事件到下一个节点。代码如下：

  ```
  protected void write(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
      ctx.invokeWrite(msg, promise);
  }
  
  ```

- 第 11 至 19 行：置空 AbstractWriteTask 对象，并调用 `Recycler.Handle#recycle(this)` 方法，回收该对象。

## 7.4 WriteTask

WriteTask ，实现 SingleThreadEventLoop.NonWakeupRunnable 接口，继承 AbstractWriteTask 抽象类，write 任务实现类。

**为什么会实现 SingleThreadEventLoop.NonWakeupRunnable 接口呢**？write 操作，仅仅将数据写到**内存队列**中，无需唤醒 EventLoop ，从而提升性能。关于 SingleThreadEventLoop.NonWakeupRunnable 接口，在 [《精尽 Netty 源码解析 —— EventLoop（三）之 EventLoop 初始化》](http://svip.iocoder.cn/Netty/EventLoop-3-EventLoop-init) 有详细解析。

### 7.4.1 newInstance

`#newInstance(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，创建 WriteTask 对象。代码如下：

```
private static final Recycler<WriteTask> RECYCLER = new Recycler<WriteTask>() {

    @Override
    protected WriteTask newObject(Handle<WriteTask> handle) {
        return new WriteTask(handle); // 创建 WriteTask 对象
    }

};

private static WriteTask newInstance(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
    // 从 Recycler 的对象池中获得 WriteTask 对象
    WriteTask task = RECYCLER.get();
    // 初始化 WriteTask 对象的属性
    init(task, ctx, msg, promise);
    return task;
}

```

### 7.4.2 构造方法

```
private WriteTask(Recycler.Handle<WriteTask> handle) {
    super(handle);
}

```

### 7.4.3 write

WriteTask 无需实现 `#write(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，直接**重用**父类该方法即可。

## 7.5 WriteAndFlushTask

WriteAndFlushTask ，继承 WriteAndFlushTask 抽象类，write + flush 任务实现类。

### 7.5.1 newInstance

`#newInstance(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，创建 WriteAndFlushTask 对象。代码如下：

```
private static final Recycler<WriteAndFlushTask> RECYCLER = new Recycler<WriteAndFlushTask>() {

    @Override
    protected WriteAndFlushTask newObject(Handle<WriteAndFlushTask> handle) {
        return new WriteAndFlushTask(handle); // 创建 WriteAndFlushTask 对象
    }

};

private static WriteAndFlushTask newInstance(AbstractChannelHandlerContext ctx, Object msg,  ChannelPromise promise) {
    // 从 Recycler 的对象池中获得 WriteTask 对象
    WriteAndFlushTask task = RECYCLER.get();
    // 初始化 WriteTask 对象的属性
    init(task, ctx, msg, promise);
    return task;
}

```

### 7.5.2 构造方法

```
private WriteAndFlushTask(Recycler.Handle<WriteAndFlushTask> handle) {
    super(handle);
}

```

### 7.5.3 write

`#write(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，在父类的该方法的基础上，增加执行 **flush** 事件到下一个节点。代码如下：

```
@Override
public void write(AbstractChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
    // 执行 write 事件到下一个节点
    super.write(ctx, msg, promise);
    // 执行 flush 事件到下一个节点
    ctx.invokeFlush();
}

```

# 666. 彩蛋

最后，我们来看一个真的彩蛋，嘿嘿嘿。

在一些 ChannelHandler 里，我们想要写入数据到对端，可以有两种写法，代码如下：

```
@Override
public void channelRead(ChannelHandlerContext ctx, Object msg) {
    ctx.write(msg); // <1>
    ctx.channel().write(msg); // <2>
}

```

这两者有什么异同呢？

- `<2>` 种，实际就是本文所描述的，将 write 事件，从 pipeline 的 `tail` 节点到 `head` 节点的过程。
- `<1>` 种，和 `<2>` 种**不同**，将 write 事件，从当前的 `ctx` 节点的**下一个**节点到 `head` 节点的过程。
- 为什么呢？胖友自己调试理解下。😁😁😁

------

推荐阅读文章：

- 占小狼 [《深入浅出Netty write》](https://www.jianshu.com/p/1ad424c53e80)
- 闪电侠 [《netty 源码分析之 writeAndFlush 全解析》](https://www.jianshu.com/p/feaeaab2ce56)

# Channel（五）之 flush 操作



# 1. 概述

本文接 [《精尽 Netty 源码解析 —— Channel（四）之 write 操作》](http://svip.iocoder.cn/Netty/Channel-4-write/) ，分享 Netty Channel 的 `#flush()` 方法，刷新**内存队列**，将其中的数据写入到对端。

在本文中，我们会发现，`#flush()` 方法和 `#write(Object msg, ...)` **正常**情况下，经历的流程是**差不多**的，例如在 pipeline 中对事件的传播，从 `tail` 节点传播到 `head` 节点，最终交由 Unsafe 处理，而差异点就是 Unsafe 的处理方式**不同**：

- write 方法：将数据写到**内存队列**中。
- flush 方法：刷新**内存队列**，将其中的数据写入到对端。

当然，上述描述仅仅指的是**正常**情况下，在**异常**情况下会有所不同。我们知道，Channel 大多数情况下是**可写**的，所以不需要专门去注册 `SelectionKey.OP_WRITE` 事件。所以在 Netty 的实现中，默认 Channel 是**可写**的，当写入失败的时候，再去注册 `SelectionKey.OP_WRITE` 事件。这意味着什么呢？在 `#flush()` 方法中，如果写入数据到 Channel 失败，会通过注册 `SelectionKey.OP_WRITE` 事件，然后在轮询到 Channel **可写** 时，再“回调” `#forceFlush()` 方法。

是不是非常巧妙？！让我直奔代码，大口吃肉，潇洒撸码。

> 下文的 [「2.」](http://svip.iocoder.cn/Netty/Channel-5-flush/#)、[「3.」](http://svip.iocoder.cn/Netty/Channel-5-flush/#)、[「4.」](http://svip.iocoder.cn/Netty/Channel-5-flush/#)、[「5.」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 和 [《精尽 Netty 源码解析 —— Channel（四）之 write 操作》](http://svip.iocoder.cn/Netty/Channel-4-write) 非常**类似**，所以胖友可以快速浏览。真正的**差异**，从 [「6.」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 开始。

# 2. AbstractChannel

AbstractChannel 对 `#flush()` 方法的实现，代码如下：

```
@Override
public Channel flush() {
    pipeline.flush();
    return this;
}
```

- 在方法内部，会调用对应的

   

  ```
  ChannelPipeline#flush()
  ```

   

  方法，将 flush 事件在 pipeline 上传播。详细解析，见

   

  「3. DefaultChannelPipeline」

   

  。

  - 最终会传播 flush 事件到 `head` 节点，刷新**内存队列**，将其中的数据写入到对端。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#flush()` 方法，代码如下：

```
@Override
public final ChannelPipeline flush() {
    tail.flush();
    return this;
}
```

- 在方法内部，会调用 `TailContext#flush()` 方法，将 flush 事件在 pipeline 中，从尾节点向头节点传播。详细解析，见 [「4. TailContext」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

# 4. TailContext

TailContext 对 `TailContext#flush()` 方法的实现，是从 AbstractChannelHandlerContext 抽象类继承，代码如下：

```
 1: @Override
 2: public ChannelHandlerContext flush() {
 3:     // 获得下一个 Outbound 节点
 4:     final AbstractChannelHandlerContext next = findContextOutbound();
 5:     EventExecutor executor = next.executor();
 6:     // 在 EventLoop 的线程中
 7:     if (executor.inEventLoop()) {
 8:         // 执行 flush 事件到下一个节点
 9:         next.invokeFlush();
10:     // 不在 EventLoop 的线程中
11:     } else {
12:         // 创建 flush 任务
13:         Runnable task = next.invokeFlushTask;
14:         if (task == null) {
15:             next.invokeFlushTask = task = new Runnable() {
16:                 @Override
17:                 public void run() {
18:                     next.invokeFlush();
19:                 }
20:             };
21:         }
22:         // 提交到 EventLoop 的线程中，执行该任务
23:         safeExecute(executor, task, channel().voidPromise(), null);
24:     }
25: 
26:     return this;
27: }
```

- 第 4 行：调用 `#findContextOutbound()` 方法，获得**下一个** Outbound 节点。

- 第 7 行：

  在

   

  EventLoop 的线程中。

  - 第 12 至 15 行：调用 `AbstractChannelHandlerContext#invokeFlush()()` 方法，执行 flush 事件到下一个节点。
  - 后续的逻辑，和 [《精尽 Netty 源码解析 —— ChannelPipeline（四）之 Outbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-4-outbound/) 分享的 **bind** 事件在 pipeline 中的传播是**基本一致**的。
  - 随着 flush **事件**不断的向下一个节点传播，最终会到达 HeadContext 节点。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- 第 16 行：

  不在

   

  EventLoop 的线程中。

  - 第 12 至 21 行：创建 flush 任务。该任务的内部的调用【第 18 行】的代码，和【第 9 行】的代码是**一致**的。
  - 第 23 行：调用 `#safeExecute(executor, task, promise, m)` 方法，提交到 EventLoop 的线程中，执行该任务。从而实现，**在** EventLoop 的线程中，执行 flush 事件到下一个节点。

# 5. HeadContext

在 pipeline 中，flush 事件最终会到达 HeadContext 节点。而 HeadContext 的 `#flush()` 方法，会处理该事件，代码如下：

```
@Override
public void flush(ChannelHandlerContext ctx) throws Exception {
    unsafe.flush();
}
```

- 在方法内部，会调用 `AbstractUnsafe#flush()` 方法，刷新**内存队列**，将其中的数据写入到对端。详细解析，见 [「6. AbstractUnsafe」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

# 6. AbstractUnsafe

`AbstractUnsafe#flush()` 方法，刷新**内存队列**，将其中的数据写入到对端。代码如下：

```
 1: @Override
 2: public final void flush() {
 3:     assertEventLoop();
 4: 
 5:     // 内存队列为 null ，一般是 Channel 已经关闭，所以直接返回。
 6:     ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
 7:     if (outboundBuffer == null) {
 8:         return;
 9:     }
10: 
11:     // 标记内存队列开始 flush
12:     outboundBuffer.addFlush();
13:     // 执行 flush
14:     flush0();
15: }
```

- 第 5 至 9 行：内存队列为 `null` ，一般是 Channel **已经关闭**，所以直接返回。

- 第 12 行：调用 `ChannelOutboundBuffer#addFlush()` 方法，标记内存队列开始 **flush** 。详细解析，见 [「8.4 addFlush」](http://svip.iocoder.cn/Netty/Channel-5-flush/#)。

- 第 14 行：调用 `#flush0()` 方法，执行 flush 操作。代码如下：

  ```
  /**
   * 是否正在 flush 中，即正在调用 {@link #flush0()} 中
   */
  private boolean inFlush0;
  
    1: @SuppressWarnings("deprecation")
    2: protected void flush0() {
    3:     // 正在 flush 中，所以直接返回。
    4:     if (inFlush0) {
    5:         // Avoid re-entrance
    6:         return;
    7:     }
    8: 
    9:     // 内存队列为 null ，一般是 Channel 已经关闭，所以直接返回。
   10:     // 内存队列为空，无需 flush ，所以直接返回
   11:     final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
   12:     if (outboundBuffer == null || outboundBuffer.isEmpty()) {
   13:         return;
   14:     }
   15: 
   16:     // 标记正在 flush 中。
   17:     inFlush0 = true;
   18: 
   19:     // 若未激活，通知 flush 失败
   20:     // Mark all pending write requests as failure if the channel is inactive.
   21:     if (!isActive()) {
   22:         try {
   23:             if (isOpen()) {
   24:                 outboundBuffer.failFlushed(FLUSH0_NOT_YET_CONNECTED_EXCEPTION, true);
   25:             } else {
   26:                 // Do not trigger channelWritabilityChanged because the channel is closed already.
   27:                 outboundBuffer.failFlushed(FLUSH0_CLOSED_CHANNEL_EXCEPTION, false);
   28:             }
   29:         } finally {
   30:             // 标记不在 flush 中。
   31:             inFlush0 = false;
   32:         }
   33:         return;
   34:     }
   35: 
   36:     // 执行真正的写入到对端
   37:     try {
   38:         doWrite(outboundBuffer);
   39:     } catch (Throwable t) {
   40:         // TODO 芋艿 细节
   41:         if (t instanceof IOException && config().isAutoClose()) {
   42:             /**
   43:              * Just call {@link #close(ChannelPromise, Throwable, boolean)} here which will take care of
   44:              * failing all flushed messages and also ensure the actual close of the underlying transport
   45:              * will happen before the promises are notified.
   46:              *
   47:              * This is needed as otherwise {@link #isActive()} , {@link #isOpen()} and {@link #isWritable()}
   48:              * may still return {@code true} even if the channel should be closed as result of the exception.
   49:              */
   50:             close(voidPromise(), t, FLUSH0_CLOSED_CHANNEL_EXCEPTION, false);
   51:         } else {
   52:             try {
   53:                 shutdownOutput(voidPromise(), t);
   54:             } catch (Throwable t2) {
   55:                 close(voidPromise(), t2, FLUSH0_CLOSED_CHANNEL_EXCEPTION, false);
   56:             }
   57:         }
   58:     } finally {
   59:         // 标记不在 flush 中。
   60:         inFlush0 = false;
   61:     }
   62: }
  ```

  - `inFlush0` 字段，是否正在 flush 中，即正在调用 `#flush0()` 中。

  - 第 3 至 7 行：正在 flush 中，所以直接返回。

  - 第 9 至 14 行：

    - `outboundBuffer == null` ，内存队列为 `null` ，一般是 Channel 已经**关闭**，所以直接返回。
    - `outboundBuffer.isEmpty()` ，内存队列为空，无需 flush ，所以直接返回。

  - 第 17 行：设置 `inFlush0` 为 `true` ，表示正在 flush 中。

  - 第 19 至 34 行：调用

     

    ```
    #isActive()
    ```

     

    方法，发现 Channel

     

    未激活

    ，在根据 Channel

     

    是否打开

    ，调用

     

    ```
    ChannelOutboundBuffer#failFlushed(Throwable cause, boolean notify)
    ```

     

    方法，通知 flush 失败

    异常

    。详细解析，见

     

    「8.6 failFlushed」

     

    。

    - 第 29 至 33 行：最终，设置 `inFlush0` 为 `false` ，表示结束 flush 操作，最后 `return` 返回。

  - 第 38 行：调用

     

    ```
    AbstractChannel#doWrite(outboundBuffer)
    ```

     

    方法，

    执行真正的写入到对端

    。详细解析，见

     

    「7. NioSocketChannel」

     

    。

    - 第 39 至 57 行：TODO 芋艿 细节
    - 第 58 至 61 行：同【第 29 至 33】的代码和目的。

- 实际上，AbstractNioUnsafe **重写**了 `#flush0()` 方法，代码如下：

  ```
  @Override
  protected final void flush0() {
      // Flush immediately only when there's no pending flush.
      // If there's a pending flush operation, event loop will call forceFlush() later,
      // and thus there's no need to call it now.
      if (!isFlushPending()) {
          super.flush0();
      }
  }
  ```

  - 在执行父类 AbstractUnsafe 的 `#flush0()` 方法时，先调用 `AbstractNioUnsafe#isFlushPending()` 判断，是否已经处于 flush **准备**中。代码如下：

    ```
    private boolean isFlushPending() {
        SelectionKey selectionKey = selectionKey();
        return selectionKey.isValid() // 合法
                && (selectionKey.interestOps() & SelectionKey.OP_WRITE) != 0; // 对 SelectionKey.OP_WRITE 事件不感兴趣。
    }
    ```

    - 是不是有点懵 x ？在文初，我们提到：“所以在 Netty 的实现中，默认 Channel 是**可写**的，当写入失败的时候，再去注册 `SelectionKey.OP_WRITE` 事件。这意味着什么呢？在 `#flush()` 方法中，如果写入数据到 Channel 失败，会通过注册 `SelectionKey.OP_WRITE` 事件，然后在轮询到 Channel **可写** 时，再“回调” `#forceFlush()` 方法”。
    - 这就是这段代码的目的，如果处于对 `SelectionKey.OP_WRITE` 事件感兴趣，说明 Channel 此时是**不可写**的，那么调用父类 AbstractUnsafe 的 `#flush0()` 方法，**也没有意义**，所以就不调用。
    - 😈 逻辑上，略微有点复杂，胖友好好理解下。

# 7. NioSocketChannel

`AbstractChannel#doWrite(ChannelOutboundBuffer in)` **抽象**方法，**执行真正的写入到对端**。定义在 AbstractChannel **抽象**类中，代码如下：

```
/**
 * Flush the content of the given buffer to the remote peer.
 */
protected abstract void doWrite(ChannelOutboundBuffer in) throws Exception;
```

------

NioSocketChannel 对该**抽象**方法，实现代码如下：

```
 1: @Override
 2: protected void doWrite(ChannelOutboundBuffer in) throws Exception {
 3:     SocketChannel ch = javaChannel();
 4:     // 获得自旋写入次数
 5:     int writeSpinCount = config().getWriteSpinCount();
 6:     do {
 7:         // 内存队列为空，结束循环，直接返回
 8:         if (in.isEmpty()) {
 9:             // 取消对 SelectionKey.OP_WRITE 的感兴趣
10:             // All written so clear OP_WRITE
11:             clearOpWrite();
12:             // Directly return here so incompleteWrite(...) is not called.
13:             return;
14:         }
15: 
16:         // 获得每次写入的最大字节数
17:         // Ensure the pending writes are made of ByteBufs only.
18:         int maxBytesPerGatheringWrite = ((NioSocketChannelConfig) config).getMaxBytesPerGatheringWrite();
19:         // 从内存队列中，获得要写入的 ByteBuffer 数组
20:         ByteBuffer[] nioBuffers = in.nioBuffers(1024, maxBytesPerGatheringWrite);
21:         // 写入的 ByteBuffer 数组的个数
22:         int nioBufferCnt = in.nioBufferCount();
23: 
24:         // 写入 ByteBuffer 数组，到对端
25:         // Always us nioBuffers() to workaround data-corruption.
26:         // See https://github.com/netty/netty/issues/2761
27:         switch (nioBufferCnt) {
28:             case 0:
29:                 // 芋艿 TODO 1014 扣 doWrite0 的细节
30:                 // We have something else beside ByteBuffers to write so fallback to normal writes.
31:                 writeSpinCount -= doWrite0(in);
32:                 break;
33:             case 1: {
34:                 // Only one ByteBuf so use non-gathering write
35:                 // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need
36:                 // to check if the total size of all the buffers is non-zero.
37:                 ByteBuffer buffer = nioBuffers[0];
38:                 int attemptedBytes = buffer.remaining();
39:                 // 执行 NIO write 调用，写入单个 ByteBuffer 对象到对端
40:                 final int localWrittenBytes = ch.write(buffer);
41:                 // 写入字节小于等于 0 ，说明 NIO Channel 不可写，所以注册 SelectionKey.OP_WRITE ，等待 NIO Channel 可写，并返回以结束循环
42:                 if (localWrittenBytes <= 0) {
43:                     incompleteWrite(true);
44:                     return;
45:                 }
46:                 // TODO 芋艿 调整每次写入的最大字节数
47:                 adjustMaxBytesPerGatheringWrite(attemptedBytes, localWrittenBytes, maxBytesPerGatheringWrite);
48:                 // 从内存队列中，移除已经写入的数据( 消息 )
49:                 in.removeBytes(localWrittenBytes);
50:                 // 写入次数减一
51:                 --writeSpinCount;
52:                 break;
53:             }
54:             default: {
55:                 // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need
56:                 // to check if the total size of all the buffers is non-zero.
57:                 // We limit the max amount to int above so cast is safe
58:                 long attemptedBytes = in.nioBufferSize();
59:                 // 执行 NIO write 调用，写入多个 ByteBuffer 到对端
60:                 final long localWrittenBytes = ch.write(nioBuffers, 0, nioBufferCnt);
61:                 // 写入字节小于等于 0 ，说明 NIO Channel 不可写，所以注册 SelectionKey.OP_WRITE ，等待 NIO Channel 可写，并返回以结束循环
62:                 if (localWrittenBytes <= 0) {
63:                     incompleteWrite(true);
64:                     return;
65:                 }
66:                 // TODO 芋艿 调整每次写入的最大字节数
67:                 // Casting to int is safe because we limit the total amount of data in the nioBuffers to int above.
68:                 adjustMaxBytesPerGatheringWrite((int) attemptedBytes, (int) localWrittenBytes, maxBytesPerGatheringWrite);
69:                 // 从内存队列中，移除已经写入的数据( 消息 )
70:                 in.removeBytes(localWrittenBytes);
71:                 // 写入次数减一
72:                 --writeSpinCount;
73:                 break;
74:             }
75:         }
76:     } while (writeSpinCount > 0); // 循环自旋写入
77: 
78:     // 内存队列中的数据未完全写入，说明 NIO Channel 不可写，所以注册 SelectionKey.OP_WRITE ，等待 NIO Channel 可写
79:     incompleteWrite(writeSpinCount < 0);
80: }
```

- 第 3 行：调用 `#javaChannel()` 方法，获得 Java NIO **原生** SocketChannel 。

- 第 5 行：调用 `ChannelConfig#getWriteSpinCount()` 方法，获得**自旋**写入次数 N 。在【第 6 至 76 行】的代码，我们可以看到，不断**自旋**写入 N 次，直到完成写入结束。关于该配置项，官方注释如下：

  ```
  /**
   * Returns the maximum loop count for a write operation until {@link WritableByteChannel#write(ByteBuffer)} returns a non-zero value.
   * It is similar to what a spin lock is used for in concurrency programming.
   * It improves memory utilization and write throughput depending on the platform that JVM runs on.  The default value is {@code 16}.
   */
  int getWriteSpinCount();
  ```

  - 默认值为 `DefaultChannelConfig.writeSpinCount = 16` ，可配置修改，一般不需要。

- 第 6 至 76 行：不断**自旋**写入 N 次，直到完成写入结束。

- 第 8 行：调用 `ChannelOutboundBuffer#isEmpty()` 方法，内存队列为空，结束循环，直接返回。

  - 第 10 行：因为在 Channel **不可写**的时候，会注册 `SelectionKey.OP_WRITE` ，等待 NIO Channel 可写。而后会”回调” `#forceFlush()` 方法，该方法内部也会调用 `#doWrite(ChannelOutboundBuffer in)` 方法。所以在完成内部队列的数据向对端写入时候，需要调用 `#clearOpWrite()` 方法，代码如下：

    ```
    protected final void clearOpWrite() {
        final SelectionKey key = selectionKey();
        // Check first if the key is still valid as it may be canceled as part of the deregistration
        // from the EventLoop
        // See https://github.com/netty/netty/issues/2104
        if (!key.isValid()) { // 合法
            return;
        }
        final int interestOps = key.interestOps();
        // 若注册了 SelectionKey.OP_WRITE ，则进行取消
        if ((interestOps & SelectionKey.OP_WRITE) != 0) {
            key.interestOps(interestOps & ~SelectionKey.OP_WRITE);
        }
    }
    ```

    - 😈 胖友看下代码注释。

- 第 18 行：调用 `NioSocketChannelConfig#getMaxBytesPerGatheringWrite()` 方法，获得每次写入的最大字节数。// TODO 芋艿 调整每次写入的最大字节数

- 第 20 行：调用

   

  ```
  ChannelOutboundBuffer#nioBuffers(int maxCount, long maxBytes)
  
  ```

   

  方法，从内存队列中，获得要写入的 ByteBuffer 数组。

  注意

  ，如果内存队列中数据量很大，可能获得的仅仅是一部分数据。详细解析，见

   

  「8.5 nioBuffers」

   

  。

  - 第 22 行：获得写入的 ByteBuffer 数组的个数。为什么不直接调用数组的 `#length()` 方法呢？因为返回的 ByteBuffer 数组是**预先生成的数组缓存**，存在不断重用的情况，所以不能直接使用 `#length()` 方法，而是要调用 `ChannelOutboundBuffer#nioBufferCount()` 方法，获得写入的 ByteBuffer 数组的个数。详细解析，见 [「8.5 nioBuffers」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。
  - 后续根据 `nioBufferCnt` 的数值，分成**三种**情况。

- **(づ￣3￣)づ╭❤～ 第一种**，`nioBufferCnt = 0` 。

- 芋艿 TODO 1014 扣 doWrite0 的细节，应该是内部的数据为 FileRegion ，可以暂时无视，不影响本文理解。

- **(づ￣3￣)づ╭❤～ 第二种**，`nioBufferCnt = 1` 。

- 第 40 行：调用 Java **原生** `SocketChannel#write(ByteBuffer buffer)` 方法，执行 NIO write 调用，写入**单个** ByteBuffer 对象到对端。

- 第 42 行：写入字节小于等于 0 ，说明 NIO Channel **不可写**，所以注册 `SelectionKey.OP_WRITE` ，等待 NIO Channel **可写**，并返回以结束循环。

  - 第 43 行：调用 `AbstractNioByteChannel#incompleteWrite(true)` 方法，代码如下：

    ```
    protected final void incompleteWrite(boolean setOpWrite) {
        // Did not write completely.
        // true ，注册对 SelectionKey.OP_WRITE 事件感兴趣
        if (setOpWrite) {
            setOpWrite();
        // false ，取消对 SelectionKey.OP_WRITE 事件感兴趣
        } else {
            // It is possible that we have set the write OP, woken up by NIO because the socket is writable, and then
            // use our write quantum. In this case we no longer want to set the write OP because the socket is still
            // writable (as far as we know). We will find out next time we attempt to write if the socket is writable
            // and set the write OP if necessary.
            clearOpWrite();
    
            // Schedule flush again later so other tasks can be picked up in the meantime
            // 立即发起下一次 flush 任务
            eventLoop().execute(flushTask); // <1>
        }
    }
    
    ```

    - `setOpWrite` 为 `true` ，调用 `#setOpWrite()` 方法，注册对 `SelectionKey.OP_WRITE` 事件感兴趣。代码如下：

      ```
      protected final void setOpWrite() {
          final SelectionKey key = selectionKey();
          // Check first if the key is still valid as it may be canceled as part of the deregistration
          // from the EventLoop
          // See https://github.com/netty/netty/issues/2104
          if (!key.isValid()) { // 合法
              return;
          }
          final int interestOps = key.interestOps();
          // 注册 SelectionKey.OP_WRITE 事件的感兴趣
          if ((interestOps & SelectionKey.OP_WRITE) == 0) {
              key.interestOps(interestOps | SelectionKey.OP_WRITE);
          }
      }
      
      ```

      - 【第 43 行】的代码，就是这种情况。

    - `setOpWrite` 为 `false` ，调用 `#clearOpWrite()` 方法，取消对 SelectionKey.OP_WRITE 事件感兴趣。而后，在 `<1>` 处，立即发起下一次 flush 任务。

- 第 47 行：TODO 芋艿 调整每次写入的最大字节数

- 第 49 行：调用 `ChannelOutboundBuffer#removeBytes(long writtenBytes)` 方法啊，从内存队列中，移除已经写入的数据( 消息 )。详细解析，见 [「8.7 removeBytes」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- 第 51 行：写入次数减一。

- **(づ￣3￣)づ╭❤～ 第三种**，`nioBufferCnt > 1` 。和【第二种】基本相同，差别是在于【第 60 行】的代码，调用 Java **原生**`SocketChannel#write(ByteBuffer[] srcs, int offset, int length)` 方法，执行 NIO write 调用，写入**多个**ByteBuffer 对象到对端。😈 批量一次性写入，提升性能。

- =========== 结束 ===========

- 第 79 行：通过

   

  ```
  writeSpinCount < 0
  
  ```

   

  来判断，内存队列中的数据

  是否

  未完全写入。从目前逻辑看下来，笔者认为只会返回

   

  ```
  true
  
  ```

   

  ，即内存队列中的数据未完全写入，说明 NIO Channel 不可写，所以注册

   

  ```
  SelectionKey.OP_WRITE
  
  ```

   

  ，等待 NIO Channel 可写。因此，调用

   

  ```
  #incompleteWrite(true)
  
  ```

   

  方法。

  - 举个例子，最后一次写入，Channel 的缓冲区还剩下 10 字节可写，内存队列中剩余 90 字节，那么可以成功写入 10 字节，剩余 80 字节。😈 也就说，此时 Channel 不可写落。

## 7.1 乱入

> 老艿艿：临时插入下 AbstractNioByteChannel 和 AbstractNioMessageChannel 实现类对 `#doWrite(ChannelOutboundBuffer in)` 方法的实现。不感兴趣的胖友，可以直接跳过。

**AbstractNioByteChannel**

虽然，AbstractNioByteChannel 实现了 `#doWrite(ChannelOutboundBuffer in)` 方法，但是子类 NioSocketChannel 又覆盖实现了该方法，所以可以忽略 AbstractNioByteChannel 的实现方法了。

那么为什么 AbstractNioByteChannel 会实现了 `#doWrite(ChannelOutboundBuffer in)` 方法呢？因为 NioUdtByteConnectorChannel 和 NioUdtByteRendezvousChannel 会使用到该方法。但是，这两个类已经被**标记废弃**，因为：

```
transport udt is deprecated and so the user knows it will be removed in the future.

```

- 来自 Netty 官方提交的注释说明。

**AbstractNioMessageChannel**

虽然，AbstractNioMessageChannel 实现了 `#doWrite(ChannelOutboundBuffer in)` 方法，但是对于 NioServerSocketChannel 来说，暂时没有意义，因为：

```
@Override
protected boolean doWriteMessage(Object msg, ChannelOutboundBuffer in) throws Exception {
    throw new UnsupportedOperationException();
}

@Override
protected final Object filterOutboundMessage(Object msg) throws Exception {
    throw new UnsupportedOperationException();
}

```

- 两个方法，都是直接抛出 UnsupportedOperationException 异常。

那么为什么 AbstractNioMessageChannel 会实现了 `#doWrite(ChannelOutboundBuffer in)` 方法呢？因为 NioDatagramChannel 和 NioSctpChannel **等等**会使用到该方法。感兴趣的胖友，可以自己研究下。

# 8. ChannelOutboundBuffer

`io.netty.channel.ChannelOutboundBuffer` ，**内存队列**。

- 在 write 操作时，将数据写到 ChannelOutboundBuffer 中。
- 在 flush 操作时，将 ChannelOutboundBuffer 的数据写入到对端。

## 8.1 Entry

在 write 操作时，将数据写到 ChannelOutboundBuffer 中，都会产生一个 Entry 对象。代码如下：

```
/**
 * Recycler 对象，用于重用 Entry 对象
 */
private static final Recycler<Entry> RECYCLER = new Recycler<Entry>() {
    @Override
    protected Entry newObject(Handle<Entry> handle) {
        return new Entry(handle);
    }
};

/**
 * Recycler 处理器
 */
private final Handle<Entry> handle;
/**
 * 下一条 Entry
 */
Entry next;
/**
 * 消息（数据）
 */
Object msg;
/**
 * {@link #msg} 转化的 NIO ByteBuffer 数组
 */
ByteBuffer[] bufs;
/**
 * {@link #msg} 转化的 NIO ByteBuffer 对象
 */
ByteBuffer buf;
/**
 * Promise 对象
 */
ChannelPromise promise;
/**
 * 已写入的字节数
 */
long progress;
/**
 * 长度，可读字节数数。
 */
long total;
/**
 * 每个 Entry 预计占用的内存大小，计算方式为消息( {@link #msg} )的字节数 + Entry 对象自身占用内存的大小。
 */
int pendingSize;
/**
 * {@link #msg} 转化的 NIO ByteBuffer 的数量。
 *
 * 当 = 1 时，使用 {@link #buf}
 * 当 > 1 时，使用 {@link #bufs}
 */
int count = -1;
/**
 * 是否取消写入对端
 */
boolean cancelled;

private Entry(Handle<Entry> handle) {
    this.handle = handle;
}

```

- ```
  RECYCLER
  
  ```

   

  静态

  属性，用于

  重用

   

  Entry 对象。

  - `handle` 属性，Recycler 处理器，用于**回收** Entry 对象。

- `next` 属性，指向**下一条** Entry 。通过它，形成 ChannelOutboundBuffer 内部的链式存储**每条写入数据**的数据结构。

- `msg` 属性，写入的消息( 数据 )。

  - `promise` 属性，Promise 对象。当数据写入成功后，可以通过它回调通知结果。

  - `total` 属性，长度，可读字节数。通过 `#total(Object msg)` 方法来计算。代码如下：

    ```
    private static long total(Object msg) {
        if (msg instanceof ByteBuf) {
            return ((ByteBuf) msg).readableBytes();
        }
        if (msg instanceof FileRegion) {
            return ((FileRegion) msg).count();
        }
        if (msg instanceof ByteBufHolder) {
            return ((ByteBufHolder) msg).content().readableBytes();
        }
        return -1;
    }
    
    ```

    - 从这个方法，我们看到，`msg` 的类型，有 ByteBuf、FileRegion、ByteBufHolder 。

  - `process` 属性，已写入的字节数。详细解析，见 [「8.7.1 process」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- ```
  count
  
  ```

   

  属性，

  ```
  msg
  
  ```

   

  属性转化的 NIO ByteBuffer 的数量。

  - `bufs` 属性，当 `count > 0` 时使用，表示 `msg` 属性转化的 NIO ByteBuffer 数组。
  - `buf` 属性，当 `count = 0` 时使用，表示 `msg` 属性转化的 NIO ByteBuffer 对象。

- `cancelled` 属性，是否取消写入对端。

- `pendingSize` 属性，每个 Entry 预计占用的内存大小，计算方式为消息( `msg` )的字节数 + Entry 对象自身占用内存的大小。

### 8.1.1 newInstance

`#newInstance(Object msg, int size, long total, ChannelPromise promise)` **静态**方法，创建 Entry 对象。代码如下：

```
static Entry newInstance(Object msg, int size, long total, ChannelPromise promise) {
    // 通过 Recycler 重用对象
    Entry entry = RECYCLER.get();
    // 初始化属性
    entry.msg = msg;
    entry.pendingSize = size + CHANNEL_OUTBOUND_BUFFER_ENTRY_OVERHEAD;
    entry.total = total;
    entry.promise = promise;
    return entry;
}

```

- 通过 Recycler 来**重用** Entry 对象。

### 8.1.2 recycle

`#recycle()` 方法，**回收** Entry 对象，以为下次**重用**该对象。代码如下：

```
void recycle() {
    // 重置属性
    next = null;
    bufs = null;
    buf = null;
    msg = null;
    promise = null;
    progress = 0;
    total = 0;
    pendingSize = 0;
    count = -1;
    cancelled = false;
    // 回收 Entry 对象
    handle.recycle(this);
}

```

### 8.1.3 recycleAndGetNext

`#recycleAndGetNext()` 方法，获得下一个 Entry 对象，并**回收**当前 Entry 对象。代码如下：

```
Entry recycleAndGetNext() {
    // 获得下一个 Entry 对象
    Entry next = this.next;
    // 回收当前 Entry 对象
    recycle();
    // 返回下一个 Entry 对象
    return next;
}

```

### 8.1.4 cancel

`#cancel()` 方法，标记 Entry 对象，取消写入到对端。在 ChannelOutboundBuffer 里，Entry 数组是通过**链式**的方式进行组织，而当某个 Entry 对象( **节点** )如果需要取消写入到对端，是通过设置 `canceled = true` 来**标记删除**。代码如下：

```
int cancel() {
    if (!cancelled) {
        // 标记取消
        cancelled = true;
        int pSize = pendingSize;

        // 释放消息( 数据 )相关的资源
        // release message and replace with an empty buffer
        ReferenceCountUtil.safeRelease(msg);
        // 设置为空 ByteBuf
        msg = Unpooled.EMPTY_BUFFER;

        // 置空属性
        pendingSize = 0;
        total = 0;
        progress = 0;
        bufs = null;
        buf = null;

        // 返回 pSize
        return pSize;
    }
    return 0;
}

```

## 8.2 构造方法

```
/**
 * Entry 对象自身占用内存的大小
 */
// Assuming a 64-bit JVM:
//  - 16 bytes object header
//  - 8 reference fields
//  - 2 long fields
//  - 2 int fields
//  - 1 boolean field
//  - padding
static final int CHANNEL_OUTBOUND_BUFFER_ENTRY_OVERHEAD = SystemPropertyUtil.getInt("io.netty.transport.outboundBufferEntrySizeOverhead", 96);

private static final InternalLogger logger = InternalLoggerFactory.getInstance(ChannelOutboundBuffer.class);

/**
 * 线程对应的 ByteBuffer 数组缓存
 * 
 * 每次调用 {@link #nioBuffers(int, long)} 会重新生成
 */
private static final FastThreadLocal<ByteBuffer[]> NIO_BUFFERS = new FastThreadLocal<ByteBuffer[]>() {

    @Override
    protected ByteBuffer[] initialValue() throws Exception {
        return new ByteBuffer[1024];
    }

};

/**
 * Channel 对象
 */
private final Channel channel;

// Entry(flushedEntry) --> ... Entry(unflushedEntry) --> ... Entry(tailEntry)
//
/**
 * 第一个( 开始 ) flush Entry
 */
// The Entry that is the first in the linked-list structure that was flushed
private Entry flushedEntry;
/**
 * 第一个未 flush Entry
 */
// The Entry which is the first unflushed in the linked-list structure
private Entry unflushedEntry;
/**
 * 尾 Entry
 */
// The Entry which represents the tail of the buffer
private Entry tailEntry;
/**
 * 已 flush 但未写入对端的 Entry 数量
 *
 * {@link #addFlush()}
 *
 * The number of flushed entries that are not written yet
 */
private int flushed;

/**
 * {@link #NIO_BUFFERS} 数组大小
 */
private int nioBufferCount;
/**
 * {@link #NIO_BUFFERS} 字节数
 */
private long nioBufferSize;
/**
 * 正在通知 flush 失败中
 */
private boolean inFail;

/**
 * {@link #totalPendingSize} 的原子更新器
 */
private static final AtomicLongFieldUpdater<ChannelOutboundBuffer> TOTAL_PENDING_SIZE_UPDATER = AtomicLongFieldUpdater.newUpdater(ChannelOutboundBuffer.class, "totalPendingSize");
/**
 * 总共等待 flush 到对端的内存大小，通过 {@link Entry#pendingSize} 来合计。
 */
@SuppressWarnings("UnusedDeclaration")
private volatile long totalPendingSize;

/**
 * {@link #unwritable} 的原子更新器
 */
private static final AtomicIntegerFieldUpdater<ChannelOutboundBuffer> UNWRITABLE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(ChannelOutboundBuffer.class, "unwritable");
/**
 * 是否不可写
 */
@SuppressWarnings("UnusedDeclaration")
private volatile int unwritable;

/**
 * 触发 Channel 可写的改变的任务
 */
private volatile Runnable fireChannelWritabilityChangedTask;

ChannelOutboundBuffer(AbstractChannel channel) {
    this.channel = channel;
}

```

- `channel` 属性，所属的 Channel 对象。

- 链式结构

  - `flushedEntry` 属性，第一个( 开始 ) flush Entry 。
  - `unflushedEntry` 属性，第一个**未** flush Entry 。
  - `tailEntry` 属性，尾 Entry 。
  - `flushed` 属性， 已 flush 但未写入对端的 Entry 数量。
  - 指向关系是 `Entry(flushedEntry) --> ... Entry(unflushedEntry) --> ... Entry(tailEntry)` 。这样看，可能有点抽象，下文源码解析详细理解。

- ```
  NIO_BUFFERS
  
  ```

   

  静态

  属性，线程对应的 NIO ByteBuffer 数组缓存。在

   

  ```
  AbstractChannel#doWrite(ChannelOutboundBuffer)
  
  ```

   

  方法中，会调用

   

  ```
  ChannelOutbound#nioBuffers(int maxCount, long maxBytes)
  
  ```

   

  方法，初始化数组缓存。 详细解析，见

   

  「8.6 nioBuffers」

   

  中。

  - `nioBufferCount` 属性：NIO ByteBuffer 数组的**数组**大小。
  - `nioBufferSize` 属性：NIO ByteBuffer 数组的字**节**大小。

- `inFail` 属性，正在通知 flush 失败中。详细解析，见 [「8.8 failFlushed」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 中。

- ChannelOutboundBuffer 写入控制相关。😈 详细解析，见

   

  「10. ChannelOutboundBuffer」

   

  。

  - ```
    unwritable
    
    ```

     

    属性，是否不可写。

    - `UNWRITABLE_UPDATER` 静态属性，`unwritable` 属性的原子更新器。

  - ```
    totalPendingSize
    
    ```

     

    属性，所有 Entry 预计占用的内存大小，通过

     

    ```
    Entry.pendingSize
    
    ```

     

    来合计。

    - `TOTAL_PENDING_SIZE_UPDATER` 静态属性，`totalPendingSize` 属性的原子更新器。

  - `fireChannelWritabilityChangedTask` 属性，触发 Channel 可写的改变的**任务**。

  - ```
    CHANNEL_OUTBOUND_BUFFER_ENTRY_OVERHEAD
    
    ```

     

    静态

    属性，每个 Entry 对象自身占用内存的大小。为什么占用的 96 字节呢？

    - `- 16 bytes object header` ，对象头，16 字节。
    - `- 8 reference fields` ，实际是 6 个**对象引用**字段，6 * 8 = 48 字节。
    - `- 2 long fields` ，2 个 `long` 字段，2 * 8 = 16 字节。
    - `- 2 int fields` ，1 个 `int` 字段，2 * 4 = 8 字节。
    - `- 1 boolean field` ，1 个 `boolean` 字段，1 字节。
    - `padding` ，补齐 8 字节的整数倍，因此 7 字节。
    - 因此，合计 96 字节( 64 位的 JVM 虚拟机，并且不考虑压缩 )。
    - 如果不理解的胖友，可以看看 [《JVM中 对象的内存布局 以及 实例分析》](https://www.jianshu.com/p/12a3c97dc2b7) 。

## 8.3 addMessage

`#addMessage(Object msg, int size, ChannelPromise promise)` 方法，写入消息( 数据 )到内存队列。**注意**，`promise` 只有在真正完成写入到对端操作，才会进行通知。代码如下：

```
 1: /**
 2:  * Add given message to this {@link ChannelOutboundBuffer}. The given {@link ChannelPromise} will be notified once
 3:  * the message was written.
 4:  */
 5: public void addMessage(Object msg, int size, ChannelPromise promise) {
 6:     // 创建新 Entry 对象
 7:     Entry entry = Entry.newInstance(msg, size, total(msg), promise);
 8:     // 若 tailEntry 为空，将 flushedEntry 也设置为空。防御型编程，实际不会出现
 9:     if (tailEntry == null) {
10:         flushedEntry = null;
11:     // 若 tailEntry 非空，将原 tailEntry 指向新 Entry
12:     } else {
13:         Entry tail = tailEntry;
14:         tail.next = entry;
15:     }
16:     // 更新 tailEntry 为新 Entry
17:     tailEntry = entry;
18:     // 若 unflushedEntry 为空，更新为新 Entry
19:     if (unflushedEntry == null) {
20:         unflushedEntry = entry;
21:     }
22: 
23:     // 增加 totalPendingSize 计数
24:     // increment pending bytes after adding message to the unflushed arrays.
25:     // See https://github.com/netty/netty/issues/1619
26:     incrementPendingOutboundBytes(entry.pendingSize, false);
27: }

```

- 第 7 行：调用 `#newInstance(Object msg, int size, long total, ChannelPromise promise)` **静态**方法，创建 Entry 对象。

- 第 11 至 17 行：修改

  尾

  节点

   

  ```
  tailEntry
  
  ```

   

  为新的 Entry 节点。

  - 第 8 至 10 行：若 `tailEntry` 为空，将 `flushedEntry` 也设置为空。防御型编程，实际不会出现，胖友可以忽略。😈 当然，原因在 `#removeEntry(Entry e)` 方法。
  - 第 11 至 15 行：若 `tailEntry` 非空，将原 `tailEntry.next` 指向**新** Entry 。
  - 第 17 行：更新原 `tailEntry` 为新 Entry 。

- 第 18 至 21 行：若 `unflushedEntry` 为空，则更新为新 Entry ，此时相当于**首**节点。

- 第 23 至 26 行：`#incrementPendingOutboundBytes(long size, ...)` 方法，增加 `totalPendingSize` 计数。详细解析，见 [「10.1 incrementPendingOutboundBytes」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

------

可能有点抽象，我们来看看基友【闪电侠】对这块的解析：

> FROM 闪电侠 [《netty 源码分析之 writeAndFlush 全解析》](https://www.jianshu.com/p/feaeaab2ce56)
>
> 初次调用 `addMessage` 之后，各个指针的情况为
>
> ![img](http://static2.iocoder.cn/1ff7a5d2b08b9e6160dd92e74e68145f)
>
> `fushedEntry`指向空，`unFushedEntry`和 `tailEntry` 都指向新加入的节点
>
> 第二次调用 `addMessage` 之后，各个指针的情况为
>
> ![img](http://static2.iocoder.cn/1f939423f079ff491b90c8300e7ef3ea)
>
> 第 n 次调用 `addMessage`之后，各个指针的情况为
>
> ![img](http://static2.iocoder.cn/c0077b0dc86ecf1b791a99eeb9664fc3)
>
> 可以看到，调用 n 次 `addMessage` ，`flushedEntry` 指针一直指向 NULL ，表示现在还未有节点需要写出到 Socket 缓冲区，而`unFushedEntry` 之后有 n 个节点，表示当前还有n个节点尚未写出到 Socket 缓冲区中去

## 8.4 addFlush

`#addFlush()` 方法，标记内存队列每个 Entry 对象，开始 **flush** 。代码如下：

> 老艿艿：总觉得这个方法名取的有点奇怪，胖友可以直接看英文注释。😈 我“翻译”不好，哈哈哈。

```
 1: public void addFlush() {
 2:     // There is no need to process all entries if there was already a flush before and no new messages
 3:     // where added in the meantime.
 4:     //
 5:     // See https://github.com/netty/netty/issues/2577
 6:     Entry entry = unflushedEntry;
 7:     if (entry != null) {
 8:         // 若 flushedEntry 为空，赋值为 unflushedEntry ，用于记录第一个( 开始 ) flush 的 Entry 。
 9:         if (flushedEntry == null) {
10:             // there is no flushedEntry yet, so start with the entry
11:             flushedEntry = entry;
12:         }
13:         // 计算 flush 的数量，并设置每个 Entry 对应的 Promise 不可取消
14:         do {
15:             // 增加 flushed
16:             flushed ++;
17:             // 设置 Promise 不可取消
18:             if (!entry.promise.setUncancellable()) { // 设置失败
19:                 // 减少 totalPending 计数
20:                 // Was cancelled so make sure we free up memory and notify about the freed bytes
21:                 int pending = entry.cancel();
22:                 decrementPendingOutboundBytes(pending, false, true);
23:             }
24:             // 获得下一个 Entry
25:             entry = entry.next;
26:         } while (entry != null);
27: 
28:         // 设置 unflushedEntry 为空，表示所有都 flush
29:         // All flushed so reset unflushedEntry
30:         unflushedEntry = null;
31:     }
32: }

```

- 第 6 至 7 行：若 `unflushedEntry` 为空，说明每个 Entry 对象已经“标记” flush 。**注意**，“标记”的方式，不是通过 Entry 对象有一个 `flushed` 字段，而是 `flushedEntry` 属性，指向第一个( 开始 ) flush 的 Entry ，而 `unflushedEntry` 置空。

- 第 8 至 12 行：若 `flushedEntry` 为空，赋值为 `unflushedEntry` ，用于记录第一个( 开始 ) flush 的 Entry 。

- 第 13 至 26 行：计算需要 flush 的 Entry 数量，并设置每个 Entry 对应的 Promise

   

  不可取消

  。

  - 第 18 至 23 行：`#decrementPendingOutboundBytes(long size, ...)` 方法，减少 `totalPendingSize` 计数。

- 第 30 行：设置 `unflushedEntry` 为空。

------

可能有点抽象，我们来看看基友【闪电侠】对这块的解析：

> FROM 闪电侠 [《netty 源码分析之 writeAndFlush 全解析》](https://www.jianshu.com/p/feaeaab2ce56)
>
> 可以结合前面的图来看，首先拿到 `unflushedEntry` 指针，然后将 `flushedEntry` 指向 `unflushedEntry` 所指向的节点，调用完毕之后，三个指针的情况如下所示
>
> ![img](http://static2.iocoder.cn/ecb3df153a3df70464b524838b559232)

------

> 老艿艿：再次切回到老艿艿的频道，呼呼。

当一次需要从内存队列写到对端的数据量非常大，那么可能写着写着 Channel 的缓存区不够，导致 Channel 此时不可写。但是，这一轮 `#addFlush(...)` 标记的 Entry 对象并没有都写到对端。例如，准备写到对端的 Entry 的数量是 `flush = 10` 个，结果只写了 6 个，那么就剩下 `flush = 4` 。

但是的但是，`#addMessage(...)` 可能又不断写入新的消息( 数据 )到 ChannelOutboundBuffer 中。那会出现什么情况呢？会“分”成两段：

- `<1>` 段：自节点 `flushedEntry` 开始的 `flush` 个 Entry 节点，需要写入到对端。
- `<2>` 段：自节点 `unFlushedEntry` 开始的 Entry 节点，需要调用 `#addFlush()` 方法，添加到 `<1>` 段中。

这就很好的解释两个事情：

1. 为什么 `#addFlush()` 方法，命名是以 `"add"` 开头。
2. ChannelOutboundBuffer 的链式结构，为什么不是 `head` 和 `tail` **两个**节点，而是 `flushedEntry`、`unFlushedEntry`、`flushedEntry` **三个**节点。在此处，请允许老艿艿爆个粗口：真他 x 的巧妙啊。

### 8.4.1 size

`#size()` 方法，获得 `flushed` 属性。代码如下：

```
/**
 * Returns the number of flushed messages in this {@link ChannelOutboundBuffer}.
 */
public int size() {
    return flushed;
}

```

### 8.4.2 isEmpty

`#isEmpty()` 方法，是否为空。代码如下：

```
/**
 * Returns {@code true} if there are flushed messages in this {@link ChannelOutboundBuffer} or {@code false}
 * otherwise.
 */
public boolean isEmpty() {
    return flushed == 0;
}

```

## 8.5 current

`#current()` 方法，获得**当前**要写入对端的消息( 数据 )。代码如下：

```
/**
 * Return the current message to write or {@code null} if nothing was flushed before and so is ready to be written.
 */
public Object current() {
    Entry entry = flushedEntry;
    if (entry == null) {
        return null;
    }

    return entry.msg;
}

```

- 即，返回的是 `flushedEntry` 的消息( 数据 )。

## 8.6 nioBuffers

`#nioBuffers(int maxCount, long maxBytes)` 方法，获得当前要写入到对端的 NIO ByteBuffer 数组，并且获得的数组大小不得超过 `maxCount` ，字节数不得超过 `maxBytes` 。我们知道，在写入数据到 ChannelOutboundBuffer 时，一般使用的是 Netty ByteBuf 对象，但是写到 NIO SocketChannel 时，则必须使用 NIO ByteBuffer 对象，因此才有了这个方法。考虑到性能，这个方法里会使用到“**缓存**”，所以看起来会比较绕一丢丢。OK，开始看代码落：

```
/**
 * Returns an array of direct NIO buffers if the currently pending messages are made of {@link ByteBuf} only.
 * {@link #nioBufferCount()} and {@link #nioBufferSize()} will return the number of NIO buffers in the returned
 * array and the total number of readable bytes of the NIO buffers respectively.
 * <p>
 * Note that the returned array is reused and thus should not escape
 * {@link AbstractChannel#doWrite(ChannelOutboundBuffer)}.
 * Refer to {@link NioSocketChannel#doWrite(ChannelOutboundBuffer)} for an example.
 * </p>
 * @param maxCount The maximum amount of buffers that will be added to the return value.
 * @param maxBytes A hint toward the maximum number of bytes to include as part of the return value. Note that this
 *                 value maybe exceeded because we make a best effort to include at least 1 {@link ByteBuffer}
 *                 in the return value to ensure write progress is made.
 */
     
  1: public ByteBuffer[] nioBuffers(int maxCount, long maxBytes) {
  2:     assert maxCount > 0;
  3:     assert maxBytes > 0;
  4:     long nioBufferSize = 0;
  5:     int nioBufferCount = 0;
  6:     // 获得当前线程的 NIO ByteBuffer 数组缓存。
  7:     final InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();
  8:     ByteBuffer[] nioBuffers = NIO_BUFFERS.get(threadLocalMap);
  9:     // 从 flushedEntry 节点，开始向下遍历
 10:     Entry entry = flushedEntry;
 11:     while (isFlushedEntry(entry) && entry.msg instanceof ByteBuf) {
 12:         // 若 Entry 节点已经取消，忽略。
 13:         if (!entry.cancelled) {
 14:             ByteBuf buf = (ByteBuf) entry.msg;
 15:             // 获得消息( 数据 )开始读取位置
 16:             final int readerIndex = buf.readerIndex();
 17:             // 获得消息( 数据 )可读取的字节数
 18:             final int readableBytes = buf.writerIndex() - readerIndex;
 19: 
 20:             // 若无可读取的数据，忽略。
 21:             if (readableBytes > 0) {
 22:                 // 前半段，可读取的字节数，不能超过 maxBytes
 23:                 // 后半段，如果第一条数据，就已经超过 maxBytes ，那么只能“强行”读取，否则会出现一直无法读取的情况。
 24:                 if (maxBytes - readableBytes < nioBufferSize && nioBufferCount != 0) {
 25:                     // If the nioBufferSize + readableBytes will overflow maxBytes, and there is at least one entry
 26:                     // we stop populate the ByteBuffer array. This is done for 2 reasons:
 27:                     // 1. bsd/osx don't allow to write more bytes then Integer.MAX_VALUE with one writev(...) call
 28:                     // and so will return 'EINVAL', which will raise an IOException. On Linux it may work depending
 29:                     // on the architecture and kernel but to be safe we also enforce the limit here.
 30:                     // 2. There is no sense in putting more data in the array than is likely to be accepted by the
 31:                     // OS.
 32:                     //
 33:                     // See also:
 34:                     // - https://www.freebsd.org/cgi/man.cgi?query=write&sektion=2
 35:                     // - http://linux.die.net/man/2/writev
 36:                     break;
 37:                 }
 38:                 // 增加 nioBufferSize
 39:                 nioBufferSize += readableBytes;
 40:                 // 初始 Entry 节点的 NIO ByteBuffer 数量
 41:                 int count = entry.count;
 42:                 if (count == -1) {
 43:                     //noinspection ConstantValueVariableUse
 44:                     entry.count = count = buf.nioBufferCount();
 45:                 }
 46:                 // 如果超过 NIO ByteBuffer 数组的大小，进行扩容。
 47:                 int neededSpace = min(maxCount, nioBufferCount + count);
 48:                 if (neededSpace > nioBuffers.length) {
 49:                     nioBuffers = expandNioBufferArray(nioBuffers, neededSpace, nioBufferCount);
 50:                     NIO_BUFFERS.set(threadLocalMap, nioBuffers);
 51:                 }
 52:                 // 初始化 Entry 节点的 buf / bufs 属性
 53:                 if (count == 1) {
 54:                     ByteBuffer nioBuf = entry.buf;
 55:                     if (nioBuf == null) {
 56:                         // cache ByteBuffer as it may need to create a new ByteBuffer instance if its a
 57:                         // derived buffer
 58:                         entry.buf = nioBuf = buf.internalNioBuffer(readerIndex, readableBytes);
 59:                     }
 60:                     nioBuffers[nioBufferCount++] = nioBuf;
 61:                 } else {
 62:                     ByteBuffer[] nioBufs = entry.bufs;
 63:                     if (nioBufs == null) {
 64:                         // cached ByteBuffers as they may be expensive to create in terms
 65:                         // of Object allocation
 66:                         entry.bufs = nioBufs = buf.nioBuffers();
 67:                     }
 68:                     for (int i = 0; i < nioBufs.length && nioBufferCount < maxCount; ++i) {
 69:                         ByteBuffer nioBuf = nioBufs[i];
 70:                         if (nioBuf == null) {
 71:                             break;
 72:                         } else if (!nioBuf.hasRemaining()) {
 73:                             continue;
 74:                         }
 75:                         nioBuffers[nioBufferCount++] = nioBuf;
 76:                     }
 77:                 }
 78: 
 79:                 // 到达 maxCount 上限，结束循环。老艿艿的想法，这里最好改成 nioBufferCount >= maxCount ，是有可能会超过的
 80:                 if (nioBufferCount == maxCount) {
 81:                     break;
 82:                 }
 83:             }
 84:         }
 85: 
 86:         // 下一个 Entry节点
 87:         entry = entry.next;
 88:     }
 89: 
 90:     // 设置 nioBufferCount 和 nioBufferSize 属性
 91:     this.nioBufferCount = nioBufferCount;
 92:     this.nioBufferSize = nioBufferSize;
 93: 
 94:     return nioBuffers;
 95: }

```

- 第 4 至 5 行：初始 `nioBufferSize`、`nioBufferCount` 计数。

- 第 6 至 8 行：获得当前线程的 NIO ByteBuffer 数组缓存。

  - 关于 InternalThreadLocalMap 和 FastThreadLocal ，胖友可以暂时忽略，后续的文章，详细解析。

- 第 10 至 11 行：从 `flushedEntry` 节点，开始向下遍历。

  - 调用 `#isFlushedEntry(Entry entry)` 方法，判断是否为已经“标记”为 flush 的 Entry 节点。代码如下：

    ```
    private boolean isFlushedEntry(Entry e) {
        return e != null && e != unflushedEntry;
    }
    
    ```

    - `e != unflushedEntry` ，就是我们在 [「8.4 addFlush」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 最后部分讲的，思考下。

  - `entry.msg instanceof ByteBuf` ，消息( 数据 )类型为 ByteBuf 。实际上，`msg` 的类型也可能是 FileRegion 。如果 ChannelOutboundBuffer 里的消息都是 FileRegion 类型，那就会导致这个方法返回为**空** NIO ByteBuffer 数组。

- 第 13 行：若 Entry 节点已经取消，忽略。

- 第 14 至 18 行：获得消息( 数据 )开始读取位置和可读取的字节数。

  - 第 21 行：若无可读取的数据，忽略。

- 第 22 至 37 行：

  - 前半段 `maxBytes - readableBytes < nioBufferSize` ，当前 ByteBuf 可读取的字节数，不能超过 `maxBytes` 。这个比较好理解。
  - 后半段 `nioBufferCount != 0` ，如果**第一条**数据，就已经超过 `maxBytes` ，那么只能“强行”读取，否则会出现一直无法读取的情况( 因为不能跳过这条 😈 )。

- 第 39 行：增加 `nioBufferSize` 。

- 第 40 至 45 行：调用

   

  ```
  ByteBuf#nioBufferCount()
  
  ```

   

  方法，初始 Entry 节点的

   

  ```
  count
  
  ```

   

  属性( NIO ByteBuffer 数量)。

  - 使用 `count == -1` 的原因是，`Entry.count` 未初始化时，为 `-1` 。

- 第 47 至 51 行：如果超过 NIO ByteBuffer 数组的大小，调用 `#expandNioBufferArray(ByteBuffer[] array, int neededSpace, int size)` 方法，进行扩容。详细解析，见 [「8.6.1 expandNioBufferArray」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- 第 52 至 77 行：初始 Entry 节点的

   

  ```
  buf
  
  ```

   

  或

   

  ```
  bufs
  
  ```

   

  属性。

  - 当 `count = 1` 时，调用 `ByteBuf#internalNioBuffer(readerIndex, readableBytes)` 方法，获得 NIO ByteBuffer 对象。
  - 当 `count > 1` 时，调用 `ByteBuf#nioBuffers()` 方法，获得 NIO ByteBuffer 数组。
  - 通过 `nioBuffers[nioBufferCount++] = nioBuf` ，将 NIO ByteBuffer 赋值到结果数组 `nioBuffers` 中，并增加 `nioBufferCount` 。

- 第 79 至 82 行：到达 `maxCount` 上限，结束循环。老艿艿的想法，这里最好改成 `nioBufferCount >= maxCount` ，是有可能会超过的。

- 第 87 行：**下一个 Entry 节点**。

- 第 90 至 92 行：设置 ChannelOutboundBuffer 的 `nioBufferCount` 和 `nioBufferSize` 属性。

### 8.6.1 expandNioBufferArray

`#expandNioBufferArray(ByteBuffer[] array, int neededSpace, int size)` 方法，进行 NIO ByteBuff 数组的**扩容**。代码如下：

```
private static ByteBuffer[] expandNioBufferArray(ByteBuffer[] array, int neededSpace, int size) {
    // 计算扩容后的数组的大小，按照 2 倍计算
    int newCapacity = array.length;
    do {
        // double capacity until it is big enough
        // See https://github.com/netty/netty/issues/1890
        newCapacity <<= 1;

        if (newCapacity < 0) {
            throw new IllegalStateException();
        }

    } while (neededSpace > newCapacity);

    // 创建新的 ByteBuffer 数组
    ByteBuffer[] newArray = new ByteBuffer[newCapacity];

    // 复制老的 ByteBuffer 数组到新的 ByteBuffer 数组中
    System.arraycopy(array, 0, newArray, 0, size);

    return newArray;
}

```

- 代码比较简单，胖友自己看下注释。

### 8.6.2 nioBufferCount

`#nioBufferCount()` 方法，返回 `nioBufferCount` 属性。代码如下：

```
/**
 * Returns the number of {@link ByteBuffer} that can be written out of the {@link ByteBuffer} array that was
 * obtained via {@link #nioBuffers()}. This method <strong>MUST</strong> be called after {@link #nioBuffers()}
 * was called.
 */
public int nioBufferCount() {
    return nioBufferCount;
}

```

### 8.6.3 nioBufferSize

`#nioBufferSize()` 方法，返回 `nioBufferSize` 属性。代码如下：

```
/**
 * Returns the number of bytes that can be written out of the {@link ByteBuffer} array that was
 * obtained via {@link #nioBuffers()}. This method <strong>MUST</strong> be called after {@link #nioBuffers()}
 * was called.
 */
public long nioBufferSize() {
    return nioBufferSize;
}

```

## 8.7 removeBytes

`#removeBytes(long writtenBytes)` 方法，移除已经写入 `writtenBytes` 字节对应的 Entry 对象 / 对象们。代码如下：

```
 1: public void removeBytes(long writtenBytes) {
 2:     // 循环移除
 3:     for (;;) {
 4:         // 获得当前消息( 数据 )
 5:         Object msg = current();
 6:         if (!(msg instanceof ByteBuf)) {
 7:             assert writtenBytes == 0;
 8:             break;
 9:         }
10: 
11:         final ByteBuf buf = (ByteBuf) msg;
12:         // 获得消息( 数据 )开始读取位置
13:         final int readerIndex = buf.readerIndex();
14:         // 获得消息( 数据 )可读取的字节数
15:         final int readableBytes = buf.writerIndex() - readerIndex;
16: 
17:         // 当前消息( 数据 )已被写完到对端
18:         if (readableBytes <= writtenBytes) {
19:             if (writtenBytes != 0) {
20:                 // 处理当前消息的 Entry 的写入进度
21:                 progress(readableBytes);
22:                 // 减小 writtenBytes
23:                 writtenBytes -= readableBytes;
24:             }
25:             // 移除当前消息对应的 Entry
26:             remove();
27:         // 当前消息( 数据 )未被写完到对端
28:         } else { // readableBytes > writtenBytes
29:             if (writtenBytes != 0) {
30:                 // 标记当前消息的 ByteBuf 的读取位置
31:                 buf.readerIndex(readerIndex + (int) writtenBytes);
32:                 // 处理当前消息的 Entry 的写入进度
33:                 progress(writtenBytes);
34:             }
35:             break;
36:         }
37:     }
38: 
39:     // 清除 NIO ByteBuff 数组的缓存
40:     clearNioBuffers();
41: }

```

- 第 3 行：

  循环

  ，移除已经写入

   

  ```
  writtenBytes
  
  ```

   

  字节对应的 Entry 对象。

  - 第 5 行：调用 `#current()` 方法，获得当前消息( 数据 )。
  - 第 12 至 15 行：获得消息( 数据 )开始读取位置和可读取的字节数。
  - `<1>` 当前消息( 数据 )**已**被写完到对端。
  - 第 21 行：调用 `#progress(long amount)` 方法，处理当前消息的 Entry 的写入进度。详细解析，见 [「8.7.1 progress」](http://svip.iocoder.cn/Netty/Channel-5-flush/#)。
  - 第 23 行：减小 `writtenBytes` 。
  - 第 26 行：调用 `#remove()` 方法，移除当前消息对应的 Entry 对象。详细解析，见 [「8.7.2 remove」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。
  - `<2》` 当前消息( 数据 )**未**被写完到对端。
  - 第 31 行：调用 `ByteBuf#readerIndex(readerIndex)` 方法，标记当前消息的 ByteBuf 的**读取位置**。
  - 第 33 行：调用 `#progress(long amount)` 方法，处理当前消息的 Entry 的写入进度。
  - 第 35 行：`break` ，结束循环。

- 第 40 行：调用 `#clearNioBuffers()` 方法，**清除** NIO ByteBuff 数组的缓存。详细解析，见 [「8.7.4 clearNioBuffers」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

### 8.7.1 progress

`#progress(long amount)` 方法，处理当前消息的 Entry 的写入进度，主要是**通知** Promise 消息写入的进度。代码如下：

```
/**
 * Notify the {@link ChannelPromise} of the current message about writing progress.
 */
  1: public void progress(long amount) {
  2:     Entry e = flushedEntry;
  3:     assert e != null;
  4:     ChannelPromise p = e.promise;
  5:     if (p instanceof ChannelProgressivePromise) {
  6:         // 设置 Entry 对象的 progress 属性
  7:         long progress = e.progress + amount;
  8:         e.progress = progress;
  9:         // 通知 ChannelProgressivePromise 进度
 10:         ((ChannelProgressivePromise) p).tryProgress(progress, e.total);
 11:     }
 12: }

```

- 第 5 行：若 `promise` 的类型是 ChannelProgressivePromise 类型。
- 第 6 至 8 行：设置 Entry 对象的 `progress` 属性。
- 第 10 行：调用 `ChannelProgressivePromise#tryProgress(progress, total)` 方法，通知 ChannelProgressivePromise 进度。

### 8.7.2 remove

`#remove()` 方法，移除当前消息对应的 Entry 对象，并 Promise 通知成功。代码如下：

```
 1: public boolean remove() {
 2:     Entry e = flushedEntry;
 3:     if (e == null) {
 4:         // 清除 NIO ByteBuff 数组的缓存
 5:         clearNioBuffers();
 6:         return false;
 7:     }
 8:     Object msg = e.msg;
 9: 
10:     ChannelPromise promise = e.promise;
11:     int size = e.pendingSize;
12: 
13:     // 移除指定 Entry 对象
14:     removeEntry(e);
15: 
16:     if (!e.cancelled) {
17:         // 释放消息( 数据 )相关的资源
18:         // only release message, notify and decrement if it was not canceled before.
19:         ReferenceCountUtil.safeRelease(msg);
20:         // 通知 Promise 执行成功
21:         safeSuccess(promise);
22:         // 减少 totalPending 计数
23:         decrementPendingOutboundBytes(size, false, true);
24:     }
25: 
26:     // 回收 Entry 对象
27:     // recycle the entry
28:     e.recycle();
29: 
30:     return true;
31: }

```

- 第 14 行：调用 `#removeEntry(Entry e)` 方法，移除**指定** Entry 对象。详细解析，见 [「8.7.3 removeEntry」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- 第 16 行：若 Entry 已取消，则忽略。

- 第 19 行：`ReferenceCountUtil#safeRelease(msg)` 方法，释放消息( 数据 )相关的资源。

- 第 21 行：【**重要**】调用 `#safeSuccess(promise)` 方法，通知 Promise 执行成功。此处才是，真正触发 `Channel#write(...)` 或 `Channel#writeAndFlush(...)` 方法，返回的 Promise 的通知。`#safeSuccess(promise)` 方法的代码如下：

  ```
  private static void safeSuccess(ChannelPromise promise) {
      // Only log if the given promise is not of type VoidChannelPromise as trySuccess(...) is expected to return
      // false.
      PromiseNotificationUtil.trySuccess(promise, null, promise instanceof VoidChannelPromise ? null : logger);
  }
  
  ```

- 第 23 行：`#decrementPendingOutboundBytes(long size, ...)` 方法，减少 `totalPendingSize` 计数。

- 第 28 行：调用 `Entry#recycle()` 方法，**回收** Entry 对象。

### 8.7.3 removeEntry

`#removeEntry(Entry e)` 方法，移除**指定** Entry 对象。代码如下：

```
 1: private void removeEntry(Entry e) {
 2:     // 已移除完已 flush 的 Entry 节点，置空 flushedEntry、tailEntry、unflushedEntry 。
 3:     if (-- flushed == 0) {
 4:         // processed everything
 5:         flushedEntry = null;
 6:         if (e == tailEntry) {
 7:             tailEntry = null;
 8:             unflushedEntry = null;
 9:         }
10:     // 未移除完已 flush 的 Entry 节点，flushedEntry 指向下一个 Entry 对象
11:     } else {
12:         flushedEntry = e.next;
13:     }
14: }

```

- 第 3 至 9 行：**已**移除完已 flush 的**所有** Entry 节点，置空 `flushedEntry`、`tailEntry`、`unflushedEntry` 。
- 第 10 至 13 行：**未**移除完已 flush 的**所有** Entry 节点，`flushedEntry` 指向**下一个** Entry 对象。

### 8.7.4 clearNioBuffers

`#clearNioBuffers()` 方法，**清除** NIO ByteBuff 数组的缓存。代码如下：

```
// Clear all ByteBuffer from the array so these can be GC'ed.
// See https://github.com/netty/netty/issues/3837
private void clearNioBuffers() {
    int count = nioBufferCount;
    if (count > 0) {
        // 归零 nioBufferCount 。老艿艿觉得，应该把 nioBufferSize 也归零
        nioBufferCount = 0;
        // 置空 NIO ByteBuf 数组
        Arrays.fill(NIO_BUFFERS.get(), 0, count, null);
    }
}

```

- 代码比较简单，胖友自己看注释。主要目的是 help gc 。

## 8.8 failFlushed

`#failFlushed(Throwable cause, boolean notify)` 方法，写入数据到对端**失败**，进行后续的处理，详细看代码。代码如下：

```
 1: void failFlushed(Throwable cause, boolean notify) {
 2:     // 正在通知 flush 失败中，直接返回
 3:     // Make sure that this method does not reenter.  A listener added to the current promise can be notified by the
 4:     // current thread in the tryFailure() call of the loop below, and the listener can trigger another fail() call
 5:     // indirectly (usually by closing the channel.)
 6:     //
 7:     // See https://github.com/netty/netty/issues/1501
 8:     if (inFail) {
 9:         return;
10:     }
11: 
12:     try {
13:         // 标记正在通知 flush 失败中
14:         inFail = true;
15:         // 循环，移除所有已 flush 的 Entry 节点们
16:         for (;;) {
17:             if (!remove0(cause, notify)) {
18:                 break;
19:             }
20:         }
21:     } finally {
22:         // 标记不在通知 flush 失败中
23:         inFail = false;
24:     }
25: }

```

- 第 2 至 10 行：正在通知 flush 失败中，直接返回。
- 第 14 行：标记正在通知 flush 失败中，即 `inFail = true` 。
- 第 15 至 20 行：循环，调用 `#remove0(Throwable cause, boolean notifyWritability)` 方法，移除**所有**已 flush 的 Entry 节点们。详细解析，见 [「8. remove0」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 中。
- 第 21 至 24 行：标记不在通知 flush 失败中，即 `inFail = false` 。

### 8.8.1 remove0

`#remove0(Throwable cause, boolean notifyWritability)` 方法，移除当前消息对应的 Entry 对象，并 Promise 通知异常。代码如下：

```
 1: private boolean remove0(Throwable cause, boolean notifyWritability) {
 2:     Entry e = flushedEntry;
 3:     // 所有 flush 的 Entry 节点，都已经写到对端
 4:     if (e == null) {
 5:         // // 清除 NIO ByteBuff 数组的缓存
 6:         clearNioBuffers();
 7:         return false; // 没有后续的 flush 的 Entry 节点
 8:     }
 9:     Object msg = e.msg;
10: 
11:     ChannelPromise promise = e.promise;
12:     int size = e.pendingSize;
13: 
14:     removeEntry(e);
15: 
16:     if (!e.cancelled) {
17:         // 释放消息( 数据 )相关的资源
18:         // only release message, fail and decrement if it was not canceled before.
19:         ReferenceCountUtil.safeRelease(msg);
20:         // 通知 Promise 执行失败
21:         safeFail(promise, cause);
22:         // 减少 totalPendingSize 计数
23:         decrementPendingOutboundBytes(size, false, notifyWritability);
24:     }
25: 
26:     // 回收 Entry 对象
27:     // recycle the entry
28:     e.recycle();
29: 
30:     return true; // 还有后续的 flush 的 Entry 节点
31: }

```

- 第 3 至 8 行：若**所有** flush 的 Entry 节点，都已经写到对端，则调用 `#clearNioBuffers()` 方法，清除 NIO ByteBuff 数组的缓存。

- 第 14 行：调用 `#removeEntry(Entry e)` 方法，移除**指定** Entry 对象。详细解析，见 [「8.7.3 removeEntry」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

- 第 16 行：若 Entry 已取消，则忽略。

- 第 19 行：`ReferenceCountUtil#safeRelease(msg)` 方法，释放消息( 数据 )相关的资源。

- 第 21 行：【**重要**】调用 `#safeFail(promise)` 方法，通知 Promise 执行失败。此处才是，真正触发 `Channel#write(...)` 或 `Channel#writeAndFlush(...)` 方法，返回的 Promise 的通知。`#safeFail(promise)` 方法的代码如下：

  ```
  private static void safeFail(ChannelPromise promise, Throwable cause) {
      // Only log if the given promise is not of type VoidChannelPromise as tryFailure(...) is expected to return
      // false.
      PromiseNotificationUtil.tryFailure(promise, cause, promise instanceof VoidChannelPromise ? null : logger);
  }
  
  ```

- 第 23 行：调用 `#decrementPendingOutboundBytes(long size, ...)` 方法，减少 `totalPendingSize` 计数。

- 第 28 行：调用 `Entry#recycle()` 方法，**回收** Entry 对象。

## 8.9 forEachFlushedMessage

TODO 1015 forEachFlushedMessage 在 `netty-transport-native-poll` 和 `netty-transport-native-kqueue`中使用，在后续的文章解析。

## 8.10 close

`#close(...)` 方法，关闭 ChannelOutboundBuffer ，进行后续的处理，详细看代码。代码如下：

```
void close(ClosedChannelException cause) {
    close(cause, false);
}

  1: void close(final Throwable cause, final boolean allowChannelOpen) {
  2:     // 正在通知 flush 失败中
  3:     if (inFail) {
  4:         // 提交 EventLoop 的线程中，执行关闭
  5:         channel.eventLoop().execute(new Runnable() {
  6:             @Override
  7:             public void run() {
  8:                 close(cause, allowChannelOpen);
  9:             }
 10:         });
 11:         // 返回
 12:         return;
 13:     }
 14: 
 15:     // 标记正在通知 flush 失败中
 16:     inFail = true;
 17: 
 18:     if (!allowChannelOpen && channel.isOpen()) {
 19:         throw new IllegalStateException("close() must be invoked after the channel is closed.");
 20:     }
 21: 
 22:     if (!isEmpty()) {
 23:         throw new IllegalStateException("close() must be invoked after all flushed writes are handled.");
 24:     }
 25: 
 26:     // Release all unflushed messages.
 27:     try {
 28:         // 从 unflushedEntry 节点，开始向下遍历
 29:         Entry e = unflushedEntry;
 30:         while (e != null) {
 31:             // 减少 totalPendingSize
 32:             // Just decrease; do not trigger any events via decrementPendingOutboundBytes()
 33:             int size = e.pendingSize;
 34:             TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);
 35: 
 36:             if (!e.cancelled) {
 37:                 // 释放消息( 数据 )相关的资源
 38:                 ReferenceCountUtil.safeRelease(e.msg);
 39:                 // 通知 Promise 执行失败
 40:                 safeFail(e.promise, cause);
 41:             }
 42:             // 回收当前节点，并获得下一个 Entry 节点
 43:             e = e.recycleAndGetNext();
 44:         }
 45:     } finally {
 46:         // 标记在在通知 flush 失败中
 47:         inFail = false;
 48:     }
 49: 
 50:     // 清除 NIO ByteBuff 数组的缓存。
 51:     clearNioBuffers();
 52: }

```

- 第 3 行：正在通知 flush 失败中：

  - 第 5 至 10 行: 提交 EventLoop 的线程中，执行关闭。
  - 第 12 行：`return` 返回。

- 第 16 行：标记正在通知 flush 失败中，即 `inFail = true` 。

- 第 28 至 30 行：从

   

  ```
  unflushedEntry
  
  ```

   

  节点，开始向下遍历。

  - 第 31 至 34 行：减少 `totalPendingSize` 计数。
  - 第 36 行：若 Entry 已取消，则忽略。
  - 第 38 行：调用 `ReferenceCountUtil#safeRelease(msg)` 方法，释放消息( 数据 )相关的资源。
  - 第 40 行：【**重要**】调用 `#safeFail(promise)` 方法，通知 Promise 执行失败。此处才是，真正触发 `Channel#write(...)` 或 `Channel#writeAndFlush(...)` 方法，返回的 Promise 的通知。
  - 第 43 行：调用 `Entry#recycleAndGetNext()` 方法，回收当前节点，并获得下一个 Entry 节点。

- 第 45 至 48 行：标记不在通知 flush 失败中，即 `inFail = false` 。

- 第 51 行：调用 `#clearNioBuffers()` 方法，**清除** NIO ByteBuff 数组的缓存。

# 9. NioEventLoop

在上文 [「7. NioSocketChannel」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 中，在写入到 Channel 到对端，若 TCP 数据发送缓冲区**已满**，这将导致 Channel **不写可**，此时会注册对该 Channel 的 `SelectionKey.OP_WRITE` 事件感兴趣。从而实现，再在 Channel 可写后，进行**强制** flush 。这块的逻辑，在 `NioEventLoop#processSelectedKey(SelectionKey k, AbstractNioChannel ch)`中实现，代码如下：

```
// OP_WRITE 事件就绪
// Process OP_WRITE first as we may be able to write some queued buffers and so free memory.
if ((readyOps & SelectionKey.OP_WRITE) != 0) {
    // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write
    // 向 Channel 写入数据
    ch.unsafe().forceFlush();
}

```

- 通过 Selector 轮询到 Channel 的 `OP_WRITE` 就绪时，调用 `AbstractNioUnsafe#forceFlush()` 方法，强制 flush 。代码如下：

  ```
  // AbstractNioUnsafe.java
  @Override
  public final void forceFlush() {
      // directly call super.flush0() to force a flush now
      super.flush0();
  }
  
  ```

  - 后续的逻辑，又回到 [「6. AbstractUnsafe」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 小节的 `#flush0()` 流程。
  - 在完成强制 flush 之后，会取消对 `SelectionKey.OP_WRITE` 事件的感兴趣。

## 9.1 如何模拟

1. 配置服务端 ServerBootstrap 的启动参数如下：

   ```
   .childOption(ChannelOption.SO_SNDBUF, 5) // Socket 参数，TCP 数据发送缓冲区大小。
   
   ```

2. `telnet` 到启动的服务端，发送相对长的命令，例如 `"abcdefghijklmnopqrstuvw11321321321nhdkslk"` 。

# 10. ChannelOutboundBuffer 写入控制

当我们不断调用 `#addMessage(Object msg, int size, ChannelPromise promise)` 方法，添加消息到 ChannelOutboundBuffer 内存队列中，如果**不及时** flush 写到对端( 例如程序一直未调用 `Channel#flush()` 方法，或者对端接收数据比较慢导致 Channel 不可写 )，可能会导致 **OOM 内存溢出**。所以，在 ChannelOutboundBuffer 使用 `totalPendingSize` 属性，存储所有 Entry 预计占用的内存大小( `pendingSize` )。

- 在 `totalPendingSize` 大于高水位阀值时( `ChannelConfig.writeBufferHighWaterMark` ，默认值为 64 KB )，**关闭**写开关( `unwritable` )。详细解析，见 [「10.1 incrementPendingOutboundBytes」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。
- 在 `totalPendingSize` 小于低水位阀值时( `ChannelConfig.writeBufferLowWaterMark` ，默认值为 32 KB )，**打开**写开关( `unwritable` )。详细解析，见 [「10.2 decrementPendingOutboundBytes」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

该功能，对应 Github 提交为 [《Take memory overhead of ChannelOutboundBuffer / PendingWriteQueue into account》](https://github.com/netty/netty/commit/e3cb9935c0b63357e3d51867cffe624129e7e1dd) 。

## 10.1 incrementPendingOutboundBytes

`#incrementPendingOutboundBytes(long size, ...)` 方法，增加 `totalPendingSize` 计数。代码如下：

```
 1: /**
 2:  * Increment the pending bytes which will be written at some point.
 3:  * This method is thread-safe!
 4:  */
 5: void incrementPendingOutboundBytes(long size) {
 6:     incrementPendingOutboundBytes(size, true);
 7: }
 8: 
 9: private void incrementPendingOutboundBytes(long size, boolean invokeLater) {
10:     if (size == 0) {
11:         return;
12:     }
13: 
14:     // 增加 totalPendingSize 计数
15:     long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);
16:     // totalPendingSize 大于高水位阀值时，设置为不可写
17:     if (newWriteBufferSize > channel.config().getWriteBufferHighWaterMark()) {
18:         setUnwritable(invokeLater);
19:     }
20: }

```

- 第 15 行：增加 `totalPendingSize` 计数。

- 第 16 至 19 行：`totalPendingSize` 大于高水位阀值时，调用 `#setUnwritable(boolean invokeLater)` 方法，设置为不可写。代码如下：

  ```
   1: private void setUnwritable(boolean invokeLater) {
   2:     for (;;) {
   3:         final int oldValue = unwritable;
   4:         // 或位操作，修改第 0 位 bits 为 1
   5:         final int newValue = oldValue | 1;
   6:         // CAS 设置 unwritable 为新值
   7:         if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {
   8:             // 若之前可写，现在不可写，触发 Channel WritabilityChanged 事件到 pipeline 中。
   9:             if (oldValue == 0 && newValue != 0) {
  10:                 fireChannelWritabilityChanged(invokeLater);
  11:             }
  12:             break;
  13:         }
  14:     }
  15: }
  
  ```

  - 第 2 行：`for` 循环，直到 CAS 修改成功
  - 第 5 行：或位操作，修改第 0 位 bits 为 1 。😈 比较神奇的是，`unwritable` 的类型不是 `boolean` ，而是 `int` 类型。通过每个 bits ，来表示**哪种**类型不可写。感兴趣的胖友，可以看看 `io.netty.handler.traffic.AbstractTrafficShapingHandler` ，使用了第 1、2、3 bits 。
  - 第 7 行：CAS 设置 `unwritable` 为新值。
  - 第 8 至 11 行：若之前可写，现在不可写，调用 `#fireChannelWritabilityChanged(boolean invokeLater)` 方法，触发 Channel WritabilityChanged 事件到 pipeline 中。详细解析，见 [「10.3 fireChannelWritabilityChanged」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

### 10.1.1 bytesBeforeUnwritable

`#bytesBeforeUnwritable()` 方法，获得距离**不可写**还有多少字节数。代码如下：

```
public long bytesBeforeUnwritable() {
    long bytes = channel.config().getWriteBufferHighWaterMark() - totalPendingSize;
    // If bytes is negative we know we are not writable, but if bytes is non-negative we have to check writability.
    // Note that totalPendingSize and isWritable() use different volatile variables that are not synchronized
    // together. totalPendingSize will be updated before isWritable().
    if (bytes > 0) {
        return isWritable() ? bytes : 0; // 判断 #isWritable() 的原因是，可能已经被设置不可写
    }
    return 0;
}

```

- 基于**高水位**阀值来判断。

## 10.2 decrementPendingOutboundBytes

`#decrementPendingOutboundBytes(long size, ...)` 方法，减少 `totalPendingSize` 计数。代码如下：

```
 1: /**
 2:  * Decrement the pending bytes which will be written at some point.
 3:  * This method is thread-safe!
 4:  */
 5: void decrementPendingOutboundBytes(long size) {
 6:     decrementPendingOutboundBytes(size, true, true);
 7: }
 8: 
 9: private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) {
10:     if (size == 0) {
11:         return;
12:     }
13: 
14:     // 减少 totalPendingSize 计数
15:     long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);
16:     // totalPendingSize 小于低水位阀值时，设置为可写
17:     if (notifyWritability && newWriteBufferSize < channel.config().getWriteBufferLowWaterMark()) {
18:         setWritable(invokeLater);
19:     }
20: }

```

- 第 15 行：减少 `totalPendingSize` 计数。

- 第 16 至 19 行：`totalPendingSize` 小于低水位阀值时，调用 `#setWritable(boolean invokeLater)` 方法，设置为可写。代码如下：

  ```
   1: private void setWritable(boolean invokeLater) {
   2:     for (;;) {
   3:         final int oldValue = unwritable;
   4:         // 并位操作，修改第 0 位 bits 为 0
   5:         final int newValue = oldValue & ~1;
   6:         // CAS 设置 unwritable 为新值
   7:         if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {
   8:             // 若之前不可写，现在可写，触发 Channel WritabilityChanged 事件到 pipeline 中。
   9:             if (oldValue != 0 && newValue == 0) {
  10:                 fireChannelWritabilityChanged(invokeLater);
  11:             }
  12:             break;
  13:         }
  14:     }
  15: }
  
  ```

  - 第 2 行：`for` 循环，直到 CAS 修改成功
  - 第 5 行：并位操作，修改第 0 位 bits 为 0 。
  - 第 7 行：CAS 设置 `unwritable` 为新值。
  - 第 8 至 11 行：若之前可写，现在不可写，调用 `#fireChannelWritabilityChanged(boolean invokeLater)` 方法，触发 Channel WritabilityChanged 事件到 pipeline 中。详细解析，见 [「10.3 fireChannelWritabilityChanged」](http://svip.iocoder.cn/Netty/Channel-5-flush/#) 。

### 10.2.1 bytesBeforeWritable

`#bytesBeforeWritable()` 方法，获得距离**可写**还要多少字节数。代码如下：

```
/**
 * Get how many bytes must be drained from the underlying buffer until {@link #isWritable()} returns {@code true}.
 * This quantity will always be non-negative. If {@link #isWritable()} is {@code true} then 0.
 */
public long bytesBeforeWritable() {
    long bytes = totalPendingSize - channel.config().getWriteBufferLowWaterMark();
    // If bytes is negative we know we are writable, but if bytes is non-negative we have to check writability.
    // Note that totalPendingSize and isWritable() use different volatile variables that are not synchronized
    // together. totalPendingSize will be updated before isWritable().
    if (bytes > 0) {
        return isWritable() ? 0 : bytes; // 判断 #isWritable() 的原因是，可能已经被设置不可写
    }
    return 0;
}

```

- 基于**低水位**阀值来判断。

## 10.3 fireChannelWritabilityChanged

`#fireChannelWritabilityChanged(boolean invokeLater)` 方法，触发 Channel WritabilityChanged 事件到 pipeline 中。代码如下：

```
private void fireChannelWritabilityChanged(boolean invokeLater) {
    final ChannelPipeline pipeline = channel.pipeline();
    // 延迟执行，即提交 EventLoop 中触发 Channel WritabilityChanged 事件到 pipeline 中
    if (invokeLater) {
        Runnable task = fireChannelWritabilityChangedTask;
        if (task == null) {
            fireChannelWritabilityChangedTask = task = new Runnable() {
                @Override
                public void run() {
                    pipeline.fireChannelWritabilityChanged();
                }
            };
        }
        channel.eventLoop().execute(task);
    // 直接触发 Channel WritabilityChanged 事件到 pipeline 中
    } else {
        pipeline.fireChannelWritabilityChanged();
    }
}

```

- 根据 `invokeLater` 的值，分成两种方式，调用 `ChannelPipeline#fireChannelWritabilityChanged()` 方法，触发 Channel WritabilityChanged 事件到 pipeline 中。具体，胖友看下代码注释。

- 后续的流程，就是 [《精尽 Netty 源码解析 —— ChannelPipeline（五）之 Inbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-5-inbound/) 。

- 通过 Channel WritabilityChanged 事件，配合

   

  ```
  io.netty.handler.stream.ChunkedWriteHandler
  
  ```

   

  处理器，实现 ChannelOutboundBuffer 写入的控制，避免 OOM 。ChunkedWriteHandler 的具体代码实现，我们在后续的文章，详细解析。

  - 所以，有一点要注意，ChannelOutboundBuffer 的 `unwritable` 属性，仅仅作为一个是否不可写的**开关**，具体需要配合响应的 ChannelHandler 处理器，才能实现“不可写”的功能。

## 10.4 isWritable

`#isWritable()` 方法，是否可写。代码如下：

```
/**
 * Returns {@code true} if and only if {@linkplain #totalPendingWriteBytes() the total number of pending bytes} did
 * not exceed the write watermark of the {@link Channel} and
 * no {@linkplain #setUserDefinedWritability(int, boolean) user-defined writability flag} has been set to
 * {@code false}.
 */
public boolean isWritable() {
    return unwritable == 0;
}

```

- 如果 `unwritable` 大于 0 ，则表示不可写。😈 一定要注意！！！

### 10.4.1 getUserDefinedWritability

`#getUserDefinedWritability(int index)` 方法，获得指定 bits 是否可写。代码如下：

```
/**
 * Returns {@code true} if and only if the user-defined writability flag at the specified index is set to
 * {@code true}.
 */
public boolean getUserDefinedWritability(int index) {
    return (unwritable & writabilityMask(index)) == 0;
}

private static int writabilityMask(int index) {
    // 不能 < 1 ，因为第 0 bits 为 ChannelOutboundBuffer 自己使用
    // 不能 > 31 ，因为超过 int 的 bits 范围
    if (index < 1 || index > 31) {
        throw new IllegalArgumentException("index: " + index + " (expected: 1~31)");
    }
    return 1 << index;
}

```

- 为什么方法名字上会带有 `"UserDefined"` 呢？因为 `index` 不能使用 0 ，表示只允许使用用户定义( `"UserDefined"` ) bits 位，即 `[1, 31]` 。

### 10.4.2 setUserDefinedWritability

`#setUserDefinedWritability(int index, boolean writable)` 方法，设置指定 bits 是否可写。代码如下：

```
/**
 * Sets a user-defined writability flag at the specified index.
 */
public void setUserDefinedWritability(int index, boolean writable) {
    // 设置可写
    if (writable) {
        setUserDefinedWritability(index);
    // 设置不可写
    } else {
        clearUserDefinedWritability(index);
    }
}

private void setUserDefinedWritability(int index) {
    final int mask = ~writabilityMask(index);
    for (;;) {
        final int oldValue = unwritable;
        final int newValue = oldValue & mask;
        // CAS 设置 unwritable 为新值
        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {
            // 若之前不可写，现在可写，触发 Channel WritabilityChanged 事件到 pipeline 中。
            if (oldValue != 0 && newValue == 0) {
                fireChannelWritabilityChanged(true);
            }
            break;
        }
    }
}

private void clearUserDefinedWritability(int index) {
    final int mask = writabilityMask(index);
    for (;;) {
        final int oldValue = unwritable;
        final int newValue = oldValue | mask;
        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {
            // 若之前可写，现在不可写，触发 Channel WritabilityChanged 事件到 pipeline 中。
            if (oldValue == 0 && newValue != 0) {
                fireChannelWritabilityChanged(true);
            }
            break;
        }
    }
}

```

- 代码比较简单，胖友自己看噢。

# 666. 彩蛋

比想象中，长的多的多的一篇文章。总的来说，绝大部分细节，都已经扣到，美滋滋。如果有解释不够清晰或错误的细节，一起多多沟通呀。

写完这篇，我简直疯了。。。。

推荐阅读文章：

- 莫那一鲁道 [《Netty 出站缓冲区 ChannelOutboundBuffer 源码解析（isWritable 属性的重要性）》](https://www.jianshu.com/p/311425d1c72f)
- tomas家的小拨浪鼓 [《Netty 源码解析 ——— writeAndFlush流程分析》](https://www.jianshu.com/p/a3443cacd081)
- 闪电侠 [《netty 源码分析之 writeAndFlush 全解析》](https://www.jianshu.com/p/feaeaab2ce56)
- 占小狼 [《深入浅出 Netty write》](https://www.jianshu.com/p/1ad424c53e80)
- Hypercube [《自顶向下深入分析Netty（六）–Channel源码实现》](https://www.jianshu.com/p/9258af254e1d)

# Channel（六）之 writeAndFlush 操作



# 1. 概述

本文接 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush/) ，分享 Netty Channel 的 `#writeAndFlush(Object msg, ...)` 方法，write + flush 的组合，将数据写到内存队列后，立即刷新**内存队列**，又将其中的数据写入到对端。

😈 本来是不准备写这篇的，因为内容主要是 [《精尽 Netty 源码解析 —— Channel（四）之 write 操作》](http://svip.iocoder.cn/Netty/Channel-4-write/) 和 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush/) 的组合。但是，考虑到内容的完整性，于是乎就稍微水更下下。

# 2. AbstractChannel

AbstractChannel 对 `#writeAndFlush(Object msg, ...)` 方法的实现，代码如下：

```java
@Override
public ChannelFuture writeAndFlush(Object msg) {
    return pipeline.writeAndFlush(msg);
}

@Override
public ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) {
    return pipeline.writeAndFlush(msg, promise);
}
```

- 在方法内部，会调用对应的`ChannelPipeline#write(Object msg, ...)`方法，将 write 和 flush**两个**事件在 pipeline 上传播。详细解析，见「3. DefaultChannelPipeline」。
  - 最终会传播 write 事件到 `head` 节点，将数据写入到内存队列中。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 。
  - 最终会传播 flush 事件到 `head` 节点，刷新**内存队列**，将其中的数据写入到对端。详细解析，见 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#writeAndFlush(Object msg, ...)` 方法，代码如下：

```java
@Override
public final ChannelFuture write(Object msg) {
    return tail.writeAndFlush(msg);
}

@Override
public final ChannelFuture write(Object msg, ChannelPromise promise) {
    return tail.writeAndFlush(msg, promise);
}
```

- 在方法内部，会调用 `TailContext#writeAndFlush(Object msg, ...)` 方法，将 write 和 flush **两个**事件在 pipeline 中，从尾节点向头节点传播。详细解析，见 [「4. TailContext」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 。

# 4. TailContext

TailContext 对 `TailContext#writeAndFlush(Object msg, ...)` 方法的实现，是从 AbstractChannelHandlerContext 抽象类继承，代码如下：

```java
@Override
public ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) {
    if (msg == null) {
        throw new NullPointerException("msg");
    }

    // 判断是否为合法的 Promise 对象
    if (isNotValidPromise(promise, true)) {
        // 释放消息( 数据 )相关的资源
        ReferenceCountUtil.release(msg);
        // cancelled
        return promise;
    }

    // 写入消息( 数据 )到内存队列
    write(msg, true, promise); // <1>

    return promise;
}
```

- 这个方法，和我们在 [《精尽 Netty 源码解析 —— Channel（四）之 write 操作》](http://svip.iocoder.cn/Netty/Channel-4-write/) 的 [「4. TailContext」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 的小节，`TailContext#write(Object msg, ...)` 方法，基本类似，差异在于 `<1>` 处，调用 `#write(Object msg, boolean flush, ChannelPromise promise)` 方法，传入的 `flush = true` 方法参数，表示 write 操作的同时，**后续**需要执行 flush 操作。代码如下：

  ```java
  private void write(Object msg, boolean flush, ChannelPromise promise) {
      // 获得下一个 Outbound 节点
      AbstractChannelHandlerContext next = findContextOutbound();
      // 简化代码 😈
      // 执行 write + flush 操作
      next.invokeWriteAndFlush(m, promise);
  }
  
  private void invokeWriteAndFlush(Object msg, ChannelPromise promise) {
      if (invokeHandler()) {
          // 执行 write 事件到下一个节点
          invokeWrite0(msg, promise);
          // 执行 flush 事件到下一个节点
          invokeFlush0();
      } else {
          writeAndFlush(msg, promise);
      }
  }
  ```

  - 在后面，就是 [《精尽 Netty 源码解析 —— Channel（四）之 write 操作》](http://svip.iocoder.cn/Netty/Channel-4-write/) 的 [「5. HeadContext」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 的小节及其后续的小节。
  - 再在后面，就是 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush/) 。

# 666. 彩蛋

😈 真的是水更，哈哈哈哈。

推荐阅读文章：

- 闪电侠 [《netty 源码分析之 writeAndFlush 全解析》](https://www.jianshu.com/p/feaeaab2ce56) 的 [「writeAndFlush: 写队列并刷新」](http://svip.iocoder.cn/Netty/Channel-6-writeAndFlush/#) 小节。

# Channel（七）之 close 操作



# 1. 概述

本文分享 Netty NIO Channel 关闭( **close** )操作的过程，分成客户端和服务端 Channel **两种**关闭：

- 客户端 NioSocketChannel
  - 客户端关闭 NioSocketChannel ，断开和服务端的连接。
  - 服务端关闭 NioSocketChannel ，断开和客户端的连接。
- 服务端 NioServerSocketChannel
  - 服务端关闭 NioServerSocketChannel ，取消端口绑定，关闭服务。

上面的关闭，可能是客户端/服务端主动关闭，也可能是异常关闭。

- 关于 NioSocketChannel 的关闭，在 [「2. NioSocketChannel」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 详细解析。
- 关于 NioServerSocketChannel 的关闭，在 [「3. NioSocketChannel」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 详细解析。

# 2. NioSocketChannel

通过 `NioSocketChannel#close()` 方法，应用程序里可以主动关闭 NioSocketChannel 通道。代码如下：

```java
// AbstractChannel.java
@Override
public ChannelFuture close() {
    return pipeline.close();
}
```

- NioSocketChannel 继承 AbstractChannel 抽象类，所以 `#close()` 方法实际是 AbstractChannel 实现的。

- 在方法内部，会调用对应的 `ChannelPipeline#close()` 方法，将 close 事件在 pipeline 上传播。而 close 事件属于 Outbound 事件，所以会从 `tail` 节点开始，最终传播到 `head` 节点，使用 Unsafe 进行关闭。代码如下：

  ```java
  // DefaultChannelPipeline.java
  @Override
  public final ChannelFuture close() {
      return tail.close();
  }
  
  // TailContext.java
  @Override // FROM AbstractChannelHandlerContext.java 。因为 TailContext 继承 AbstractChannelHandlerContext 抽象类，该方法是它实现的。
  public ChannelFuture close() {
      return close(newPromise());
  }
  
  // HeadContext.java
  @Override
  public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
      unsafe.close(promise);
  }
  ```

## 2.1 AbstractUnsafe#close

`AbstractUnsafe#close()` 方法，关闭 Channel 。代码如下：

```java
@Override
public final void close(final ChannelPromise promise) {
    assertEventLoop();

    // 关闭
    close(promise, CLOSE_CLOSED_CHANNEL_EXCEPTION, CLOSE_CLOSED_CHANNEL_EXCEPTION, false);
}

  1: private void close(final ChannelPromise promise, final Throwable cause, final ClosedChannelException closeCause, final boolean notify) {
  2:     // 设置 Promise 不可取消
  3:     if (!promise.setUncancellable()) {
  4:         return;
  5:     }
  6: 
  7:     // 若关闭已经标记初始化
  8:     if (closeInitiated) {
  9:         // 关闭已经完成，直接通知 Promise 对象
 10:         if (closeFuture.isDone()) {
 11:             // Closed already.
 12:             safeSetSuccess(promise);
 13:         // 关闭未完成，通过监听器通知 Promise 对象
 14:         } else if (!(promise instanceof VoidChannelPromise)) { // Only needed if no VoidChannelPromise.
 15:             // This means close() was called before so we just register a listener and return
 16:             closeFuture.addListener(new ChannelFutureListener() {
 17:                 @Override
 18:                 public void operationComplete(ChannelFuture future) throws Exception {
 19:                     promise.setSuccess();
 20:                 }
 21:             });
 22:         }
 23:         return;
 24:     }
 25: 
 26:     // 标记关闭已经初始化
 27:     closeInitiated = true;
 28: 
 29:     // 获得 Channel 是否激活
 30:     final boolean wasActive = isActive();
 31:     // 标记 outboundBuffer 为空
 32:     final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
 33:     this.outboundBuffer = null; // Disallow adding any messages and flushes to outboundBuffer.
 34:     // 执行准备关闭
 35:     Executor closeExecutor = prepareToClose();
 36:     // 若 closeExecutor 非空
 37:     if (closeExecutor != null) {
 38:         closeExecutor.execute(new Runnable() {
 39:             @Override
 40:             public void run() {
 41:                 try {
 42:                     // 在 closeExecutor 中，执行关闭
 43:                     // Execute the close.
 44:                     doClose0(promise);
 45:                 } finally {
 46:                     // 在 EventLoop 中，执行
 47:                     // Call invokeLater so closeAndDeregister is executed in the EventLoop again!
 48:                     invokeLater(new Runnable() {
 49:                         @Override
 50:                         public void run() {
 51:                             if (outboundBuffer != null) {
 52:                                 // 写入数据( 消息 )到对端失败，通知相应数据对应的 Promise 失败。
 53:                                 // Fail all the queued messages
 54:                                 outboundBuffer.failFlushed(cause, notify);
 55:                                 // 关闭内存队列
 56:                                 outboundBuffer.close(closeCause);
 57:                             }
 58:                             // 执行取消注册，并触发 Channel Inactive 事件到 pipeline 中
 59:                             fireChannelInactiveAndDeregister(wasActive);
 60:                         }
 61:                     });
 62:                 }
 63:             }
 64:         });
 65:     // 若 closeExecutor 为空
 66:     } else {
 67:         try {
 68:             // 执行关闭
 69:             // Close the channel and fail the queued messages in all cases.
 70:             doClose0(promise);
 71:         } finally {
 72:             if (outboundBuffer != null) {
 73:                 // 写入数据( 消息 )到对端失败，通知相应数据对应的 Promise 失败。
 74:                 // Fail all the queued messages.
 75:                 outboundBuffer.failFlushed(cause, notify);
 76:                 // 关闭内存队列
 77:                 outboundBuffer.close(closeCause);
 78:             }
 79:         }
 80:         // 正在 flush 中，在 EventLoop 中执行执行取消注册，并触发 Channel Inactive 事件到 pipeline 中
 81:         if (inFlush0) {
 82:             invokeLater(new Runnable() {
 83:                 @Override
 84:                 public void run() {
 85:                     fireChannelInactiveAndDeregister(wasActive);
 86:                 }
 87:             });
 88:         // 不在 flush 中，直接执行执行取消注册，并触发 Channel Inactive 事件到 pipeline 中
 89:         } else {
 90:             fireChannelInactiveAndDeregister(wasActive);
 91:         }
 92:     }
 93: }
```

- 方法参数 `cause`、`closeCause` ，关闭的“原因”。对于 **close** 操作来说，无论是正常关闭，还是异常关闭，通过使用 **Exception** 来表示**来源**。在 AbstractChannel 类中，枚举了所有来源：

  ```
  // AbstractChannel.java
  private static final ClosedChannelException FLUSH0_CLOSED_CHANNEL_EXCEPTION = ThrowableUtil.unknownStackTrace(
          new ClosedChannelException(), AbstractUnsafe.class, "flush0()");
  private static final ClosedChannelException ENSURE_OPEN_CLOSED_CHANNEL_EXCEPTION = ThrowableUtil.unknownStackTrace(
          new ClosedChannelException(), AbstractUnsafe.class, "ensureOpen(...)");
  private static final ClosedChannelException CLOSE_CLOSED_CHANNEL_EXCEPTION = ThrowableUtil.unknownStackTrace(
          new ClosedChannelException(), AbstractUnsafe.class, "close(...)");
  private static final ClosedChannelException WRITE_CLOSED_CHANNEL_EXCEPTION = ThrowableUtil.unknownStackTrace(
          new ClosedChannelException(), AbstractUnsafe.class, "write(...)");
  private static final NotYetConnectedException FLUSH0_NOT_YET_CONNECTED_EXCEPTION = ThrowableUtil.unknownStackTrace(
          new NotYetConnectedException(), AbstractUnsafe.class, "flush0()");
  ```

- 第 2 至 5 行：调用 `ChannelPromise#setUncancellable()` 方法，设置 Promise 不可取消。

- 第 8 行：若

   

  ```
  AbstractChannel.closeInitiated
  ```

   

  为

   

  ```
  true
  ```

   

  时，表示关闭已经标记初始化，此时

  可能

  已经关闭完成。

  - 第 10 至 12 行：关闭**已经**完成，直接通知 Promise 对象。
  - 第 13 至 22 行：关闭**并未**完成，通过监听器回调通知 Promise 对象。
  - 第 23 行：`return` 结束。
  - 第 27 行：标记关闭已经初始化。

- 第 30 行：调用 `#isActive()` 方法， 获得 Channel 是否激活。

- 第 31 至 33 行：标记内存队列 `outboundBuffer` 为空。

- 第 35 行：调用 `#prepareToClose()` 方法，执行准备关闭。详细解析，胖友先跳到 [「2.2 NioSocketChannelUnsafe#prepareToClose」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 中。

- 第 37 行：若

   

  ```
  closeExecutor
  ```

   

  非空，在

   

  「2.2 NioSocketChannelUnsafe#prepareToClose」

   

  中，我们已经看到如果开启

   

  ```
  SO_LINGER
  ```

   

  功能，会返回

   

  ```
  GlobalEventExecutor.INSTANCE
  ```

   

  对象。

  - 第 38 至 44 行：提交任务到 `closeExecutor` 中，**在它的线程中**，执行 `#doClose0(promise)` 方法，执行关闭。为什么要在“在它的线程中”中？回答不出来的胖友，再好好重新看下 [「2.2 NioSocketChannelUnsafe#prepareToClose」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 小节。
  - 第 46 至 61 行：提交任务到 Channel 所在的 EventLoop 中，执行后续的任务。
  - 整体的逻辑和代码，和【第 66 至 91 行】的代码是**基本**一致。

- 第 66 行：若

   

  ```
  closeExecutor
  ```

   

  为空。

  - 第 70 行：调用 `#doClose0(promise)` 方法，执行**真正的**关闭。详细解析，胖友先跳到 [「2.4 doClose0」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 中。

  - 第 75 行：调用 `ChannelOutboundBuffer#failFlushed(Throwable cause, boolean notify)` 方法，写入数据( 消息 )到对端失败，通知相应数据对应的 Promise 失败。详细解析，见 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush/) 。

  - 第 77 行：调用 `ChannelOutboundBuffer#close(Throwable cause)` 方法，关闭内存队列。详细解析，见 [《精尽 Netty 源码解析 —— Channel（五）之 flush 操作》](http://svip.iocoder.cn/Netty/Channel-5-flush/) 。

  - 第 81 行：若

     

    ```
    inFlush0
    ```

     

    为

     

    ```
    true
    ```

     

    ，

    正在

     

    flush 中，

    在 EventLoop 中的线程中

    ，调用

     

    ```
    #fireChannelInactiveAndDeregister(boolean wasActive)
    ```

     

    方法，执行取消注册，并触发 Channel Inactive 事件到 pipeline 中。详细解析，见

     

    「2.5 AbstractUnsafe#fireChannelInactiveAndDeregister」

     

    中。

    - 第 90 行：若 `inFlush0` 为 `false` ，**不在** flush 中，**直接**调用 `#fireChannelInactiveAndDeregister(boolean wasActive)` 方法，执行取消注册，并触发 Channel Inactive 事件到 pipeline 中。

## 2.2 NioSocketChannelUnsafe#prepareToClose

`NioSocketChannelUnsafe#prepareToClose()` 方法，执行准备关闭。代码如下：

```
 1: @Override
 2: protected Executor prepareToClose() {
 3:     try {
 4:         if (javaChannel().isOpen() && config().getSoLinger() > 0) {
 5:             // We need to cancel this key of the channel so we may not end up in a eventloop spin
 6:             // because we try to read or write until the actual close happens which may be later due
 7:             // SO_LINGER handling.
 8:             // See https://github.com/netty/netty/issues/4449
 9:             doDeregister();
10:             // 返回 GlobalEventExecutor 对象
11:             return GlobalEventExecutor.INSTANCE;
12:         }
13:     } catch (Throwable ignore) {
14:         // Ignore the error as the underlying channel may be closed in the meantime and so
15:         // getSoLinger() may produce an exception. In this case we just return null.
16:         // See https://github.com/netty/netty/issues/4449
17:     }
18:     return null;
19: }
```

- 第 4 行：如果配置 `StandardSocketOptions.SO_LINGER` 大于 0 。让我们先来看下它的定义：

  ```
  Socket 参数，关闭 Socket 的延迟时间，Netty 默认值为 -1 ，表示禁用该功能。
  
  * -1 表示 socket.close() 方法立即返回，但 OS 底层会将发送缓冲区全部发送到对端。
  * 0 表示 socket.close() 方法立即返回，OS 放弃发送缓冲区的数据直接向对端发送RST包，对端收到复位错误。
  * 非 0 整数值表示调用 socket.close() 方法的线程被阻塞直到延迟时间到或发送缓冲区中的数据发送完毕，若超时，则对端会收到复位错误。
  ```

  - 按照这个定义，如果**大于 0**，如果在**真正关闭** Channel ，需要**阻塞**直到延迟时间到或发送缓冲区中的数据发送完毕。
  - 如果在 EventLoop 中执行**真正关闭** Channel 的操作，那么势必会阻塞 EventLoop 的线程。所以，在【第 11 行】的代码，返回 `GlobalEventExecutor.INSTANCE` 对象，作为执行**真正关闭** Channel 的操作的**执行器**( 它也有一个自己的线程哟 )。

- 第 9 行：调用 `#doDeregister()` 方法，执行取消注册。详细解析，胖友先跳到 [「2.2 AbstractUnsafe#doDeregister」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 中。

- 【来自我表弟普架的牛逼解答，我表示点赞支持】第 9 行的：为什么要调用

   

  ```
  #doDeregister()
  ```

   

  方法呢？因为

   

  ```
  SO_LINGER
  
  ```

   

  大于 0 时，

  真正关闭

   

  Channel ，需要

  阻塞

  直到延迟时间到或发送缓冲区中的数据发送完毕。如果不取消该 Channel 的

   

  ```
  SelectionKey.OP_READ
  
  ```

   

  事件的感兴趣，就会不断触发读事件，导致 CPU 空轮询。为什么呢?在 Channel 关闭时，会

  自动

  触发

   

  ```
  SelectionKey.OP_READ
  
  ```

   

  事件。而且，会不断不断不断的触发，如果不进行取消

   

  ```
  SelectionKey.OP_READ
  
  ```

   

  事件的感兴趣。

  - 😈 感叹一句，细思极恐啊，厉害了，Netty 。

- 第 11 行：如果开启 `SO_LINGER` 功能，返回 `GlobalEventExecutor.INSTANCE` 对象。

- 第 18 行：若果关闭 `SO_LINGER` 功能，返回 `null` 对象。

- 😈 胖友，调回 [「2.1 AbstractUnsafe#close」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 继续把。

## 2.3 AbstractUnsafe#doDeregister

`AbstractUnsafe#doDeregister()` 方法，执行取消注册。代码如下：

```
@Override
protected void doDeregister() throws Exception {
    eventLoop().cancel(selectionKey());
}

```

- 调用 `EventLoop#cancel(SelectionKey key)` 方法，取消 SelectionKey ，即相当于调用 `SelectionKey#cancel()` 方法。如此，对通道的读写等等 IO 就绪事件不再感兴趣，也不会做出相应的处理。

## 2.4 AbstractUnsafe#doClose0

`AbstractUnsafe#doClose0(ChannelPromise promise)` 方法，执行**真正的**关闭。代码如下：

```
 1: private void doClose0(ChannelPromise promise) {
 2:     try {
 3:         // 执行关闭
 4:         doClose();
 5:         // 通知 closeFuture 关闭完成
 6:         closeFuture.setClosed();
 7:         // 通知 Promise 关闭成功
 8:         safeSetSuccess(promise);
 9:     } catch (Throwable t) {
10:         // 通知 closeFuture 关闭完成
11:         closeFuture.setClosed();
12:         // 通知 Promise 关闭异常
13:         safeSetFailure(promise, t);
14:     }
15: }

```

- 第 4 行：调用 `#doClose()` 方法，执行关闭。这是一个**抽象**方法，NioSocketChannel 对它的实现，胖友先跳到 [「2.4.1 NioSocketChannel#doClose」 ](http://svip.iocoder.cn/Netty/Channel-7-close/#)中。

- 第 6 行：调用 `CloseFuture#setClosed()` 方法，通知 `closeFuture` 关闭完成。此处就会结束我们在 EchoClient 的阻塞监听客户端关闭。例如：

  ```
  // Wait until the connection is closed.
  // 监听客户端关闭，并阻塞等待
  f.channel().closeFuture().sync();
  
  ```

  - 哟哟哟，就要结束阻塞等待了。

- 第 8 行：调用 `#safeSetSuccess(promise)` 方法，通知 通知 Promise 关闭**成功**。此处就会回调我们对 `Channel#close()`方法的返回的 ChannelFuture 的监听。示例如下：

  ```
  ctx.channel().close().addListener(new ChannelFutureListener() { // 我是一个萌萌哒监听器
      @Override
      public void operationComplete(ChannelFuture future) throws Exception {
          System.out.println(Thread.currentThread() + "我会被唤醒");
      }
  });
  
  ```

  - 哟哟哟，要被回调了。

- 若发生异常：

  - 第 11 行：调用 `CloseFuture#setClosed()` 方法，通知 `closeFuture` 关闭完成。
  - 第 13 行: 调用 `#safeSetFailure(promise, t)` 方法，通知 通知 Promise 关闭**异常**。

### 2.4.1 NioSocketChannel#doClose

`NioSocketChannel#doClose()` 方法，执行 Java 原生 NIO SocketChannel 关闭。代码如下：

```
1: @Override
2: protected void doClose() throws Exception {
3:     // 执行父类关闭方法
4:     super.doClose();
5:     // 执行 Java 原生 NIO SocketChannel 关闭
6:     javaChannel().close();
7: }

```

- 第 4 行：调用 `AbstractNioChannel#doClose()` 方法，执行**父类**关闭方法。代码如下：

  ```
  @Override
  protected void doClose() throws Exception {
      // 通知 connectPromise 异常失败
      ChannelPromise promise = connectPromise;
      if (promise != null) {
          // Use tryFailure() instead of setFailure() to avoid the race against cancel().
          promise.tryFailure(DO_CLOSE_CLOSED_CHANNEL_EXCEPTION);
          connectPromise = null;
      }
  
      // 取消 connectTimeoutFuture 等待
      ScheduledFuture<?> future = connectTimeoutFuture;
      if (future != null) {
          future.cancel(false);
          connectTimeoutFuture = null;
      }
  }
  
  ```

  - 适用于客户端**正在**发起对服务端的连接的阶段。

- 【重要】第 6 行：调用 `SocketChannel#close()` 方法，执行 Java 原生 NIO SocketChannel 关闭。

## 2.5 AbstractUnsafe#fireChannelInactiveAndDeregister

`AbstractUnsafe#fireChannelInactiveAndDeregister(boolean wasActive)` 方法，执行取消注册，并触发 Channel Inactive 事件到 pipeline 中。代码如下：

```
private void fireChannelInactiveAndDeregister(final boolean wasActive) {
    deregister(voidPromise() /** <1> **/, wasActive && !isActive() /** <2> **/); 
}

  1: private void deregister(final ChannelPromise promise, final boolean fireChannelInactive) {
  2:     // 设置 Promise 不可取消
  3:     if (!promise.setUncancellable()) {
  4:         return;
  5:     }
  6: 
  7:     // 不处于已经注册状态，直接通知 Promise 取消注册成功。
  8:     if (!registered) {
  9:         safeSetSuccess(promise);
 10:         return;
 11:     }
 12: 
 13:     // As a user may call deregister() from within any method while doing processing in the ChannelPipeline,
 14:     // we need to ensure we do the actual deregister operation later. This is needed as for example,
 15:     // we may be in the ByteToMessageDecoder.callDecode(...) method and so still try to do processing in
 16:     // the old EventLoop while the user already registered the Channel to a new EventLoop. Without delay,
 17:     // the deregister operation this could lead to have a handler invoked by different EventLoop and so
 18:     // threads.
 19:     //
 20:     // See:
 21:     // https://github.com/netty/netty/issues/4435
 22:     invokeLater(new Runnable() {
 23:         @Override
 24:         public void run() {
 25:             try {
 26:                 // 执行取消注册
 27:                 doDeregister();
 28:             } catch (Throwable t) {
 29:                 logger.warn("Unexpected exception occurred while deregistering a channel.", t);
 30:             } finally {
 31:                 // 触发 Channel Inactive 事件到 pipeline 中
 32:                 if (fireChannelInactive) {
 33:                     pipeline.fireChannelInactive();
 34:                 }
 35: 
 36:                 // Some transports like local and AIO does not allow the deregistration of
 37:                 // an open channel.  Their doDeregister() calls close(). Consequently,
 38:                 // close() calls deregister() again - no need to fire channelUnregistered, so check
 39:                 // if it was registered.
 40:                 if (registered) {
 41:                     // 标记为未注册
 42:                     registered = false;
 43:                     // 触发 Channel Unregistered 事件到 pipeline 中
 44:                     pipeline.fireChannelUnregistered();
 45:                 }
 46: 
 47:                 // 通知 Promise 取消注册成功。
 48:                 safeSetSuccess(promise);
 49:             }
 50:         }
 51:     });
 52: }

```

- `<1>` 处，传入 `#deregister(...)` 方法的第一个参数为 `unsafeVoidPromise` ，类型为 VoidChannelPromise **类**，表示需要通知 Promise 。为什么这么说呢？在 `#safeSetSuccess(promise)` 方法中，可以看到：

  ```
  protected final void safeSetSuccess(ChannelPromise promise) {
      if (!(promise instanceof VoidChannelPromise) && !promise.trySuccess()) {
          logger.warn("Failed to mark a promise as success because it is done already: {}", promise);
      }
  }
  
  ```

  - `!(promise instanceof VoidChannelPromise)` 代码块，表示排除 VoidChannelPromise 类型的 `promise` 。

- `<2>` 处，通过对比新老的 `active` 的值，判断是否 Channel 的状态是否从 Active 变成 Inactive 。

- 第 2 至 5 行：调用 `ChannelPromise#setUncancellable()` 方法，设置 Promise 不可取消。

- 第 7 至 11 行：不处于已经注册状态，直接通知 Promise 取消注册成功，并

   

  ```
  return
  
  ```

   

  返回。

  - 😈 在当前情况下，`registered = true` ，所以不符合条件。

- 第 22 行：调用

   

  ```
  #invokeLater(Runnable)
  
  ```

   

  方法，提交任务到 EventLoop 的线程中执行，以避免

  一个

   

  Channel 的 ChannelHandler 在

  不同

  的 EventLoop 或者线程中执行。详细的说明，可以看下【第 13 至 21 行】的英文说明。

  - 😈 实际从目前该方法的调用看下来，有可能不是从 EventLoop 的线程中调用。

- 第 27 行：调用 `AbstractUnsafe#doDeregister()` 方法，执行取消注册。在 [「2.3 AbstractUnsafe#doDeregister」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 中，已经详细解析。

- 第 31 至 34 行：如果 `fireChannelInactive = true` ，调用 `ChannelPipeline#fireChannelInactive()` 方法，触发 Channel Inactive 事件到 pipeline 中。而 Channel Inactive 事件属于 Inbound 事件，所以会从 `head` 节点开始，最终传播到 `tail` 节点，目前并未执行什么逻辑，感兴趣的胖友，可以自己去看看。如果胖友业务上有需要，可以自己添加 ChannelHandler 进行处理。

- 第 40 至 42 行：标记为未注册。

- 第 44 行：调用

   

  ```
  ChannelPipeline#fireChannelUnregistered()
  
  ```

   

  方法，触发 Channel Unregistered 事件到 pipeline 中。而 Channel Unregistered 事件属于 Inbound 事件，所以会从

   

  ```
  head
  
  ```

   

  节点开始，最终传播到

   

  ```
  tail
  
  ```

   

  节点，目前并未执行什么逻辑，感兴趣的胖友，可以自己去看看。如果胖友业务上有需要，可以自己添加 ChannelHandler 进行处理。

  - 😈 又啰嗦了一遍，【第 31 至 34 行】的代码的逻辑。

- 第 48 行：调用 `#safeSetSuccess(promise)` 方法，通知 Promise 取消注册成功。

# 3. NioServerSocketChannel

通过 `NioServerSocketChannel#close()` 方法，应用程序里可以主动关闭 NioServerSocketChannel 通道。在具体的代码实现上，唯一的差别就是对 `AbstractNioChannel#doClose()` 方法的实现不同( 对应 [「2.4.1 NioSocketChannel#doClose」](http://svip.iocoder.cn/Netty/Channel-7-close/#) )。代码如下：

`NioSocketChannel#doClose()` 方法，执行 Java 原生 NIO SocketServerChannel 关闭。代码如下：

```
@Override
protected void doClose() throws Exception {
    javaChannel().close();
}

```

- 调用 `SocketServerChannel#close()` 方法，执行 Java 原生 NIO SocketServerChannel 关闭。

------

那么可能会有胖友有疑惑了，`#close()` 方法的实现，99.99% 都相似，那么 NioSocketChannel 和 NioServerSocketChannel 差异的关闭逻辑怎么实现呢？答案其实很简单，通过给它们配置不同的 ChannelHandler 实现类即可。

# 4. Unsafe#closeForcibly

实际上，在 Unsafe 接口上定义了 `#closeForcibly()` 方法，英文注释如下：

```
/**
 * Closes the {@link Channel} immediately without firing any events.  Probably only useful
 * when registration attempt failed.
 */
void closeForcibly();

```

- 立即关闭 Channel ，并且不触发 pipeline 上的任何事件。
- 仅仅用于 Channel 注册到 EventLoop 上失败的情况下。😈 这也就是为什么 `without firing any events` 的原因啦。

AbstractUnsafe 对该接口方法，实现代码如下：

```
@Override
public final void closeForcibly() {
    assertEventLoop();

    try {
        doClose();
    } catch (Exception e) {
        logger.warn("Failed to close a channel.", e);
    }
}

```

- 在方法内部，调用 `AbstractNioChannel#doClose()` 方法，执行 Java 原生 NIO SocketServerChannel 或 SocketChannel 关闭。
- 并且，从代码实现上，我们可以看到，确实并未触发任何 pipeline 上的事件。

# 5. 服务端处理客户端主动关闭连接

在客户端主动关闭时，服务端会收到一个 `SelectionKey.OP_READ` 事件的就绪，在调用客户端对应在服务端的 SocketChannel 的 `#read()` 方法会返回 **-1** ，从而实现在服务端关闭客户端的逻辑。在 Netty 的实现，在 `NioByteUnsafe#read()` 方法中，简化代码如下：

```
// <1>
// 读取数据
// 设置最后读取字节数
allocHandle.lastBytesRead(doReadBytes(byteBuf));
// 如果最后读取的字节为小于 0 ，说明对端已经关闭
close = allocHandle.lastBytesRead() < 0;

// 关闭客户端的连接
if (close) {
    closeOnRead(pipeline);
}

```

- `<1>` 处，读取客户端的 SocketChannel 返回 **-1** ，说明客户端已经关闭。

- `<2>` 处，调用 `#closeOnRead(ChannelPipeline pipeline)` 方法，关闭客户端的连接。代码如下：

  ```
   1: private void closeOnRead(ChannelPipeline pipeline) {
   2:     if (!isInputShutdown0()) {
   3:         // 开启连接半关闭
   4:         if (isAllowHalfClosure(config())) {
   5:             // 关闭 Channel 数据的读取
   6:             shutdownInput();
   7:             // 触发 ChannelInputShutdownEvent.INSTANCE 事件到 pipeline 中
   8:             pipeline.fireUserEventTriggered(ChannelInputShutdownEvent.INSTANCE);
   9:         } else {
  10:             close(voidPromise());
  11:         }
  12:     } else {
  13:         // 标记 inputClosedSeenErrorOnRead 为 true
  14:         inputClosedSeenErrorOnRead = true;
  15:         // 触发 ChannelInputShutdownEvent.INSTANCE 事件到 pipeline 中
  16:         pipeline.fireUserEventTriggered(ChannelInputShutdownReadComplete.INSTANCE);
  17:     }
  18: }
  
  ```

  - 第 2 行：调用 `NioSocketChannel#isInputShutdown0()` 方法，判断是否关闭 Channel 数据的读取。代码如下：

    ```
    // NioSocketChannel.java
    @Override
    protected boolean isInputShutdown0() {
        return isInputShutdown();
    }
    
    @Override
    public boolean isInputShutdown() {
        return javaChannel().socket().isInputShutdown() || !isActive();
    }
    
    // java.net.Socket.java
    private boolean shutIn = false;
    /**
     * Returns whether the read-half of the socket connection is closed.
     *
     * @return true if the input of the socket has been shutdown
     * @since 1.4
     * @see #shutdownInput
     */
    public boolean isInputShutdown() {
        return shutIn;
    }
    
    ```

    - 😈 注意看下英文注释。

  - `<1>` 第 4 行：调用 `AbstractNioByteChannel#isAllowHalfClosure()` 方法，判断是否开启连接**半关闭**的功能。代码如下：

    ```
    // AbstractNioByteChannel.java
    private static boolean isAllowHalfClosure(ChannelConfig config) {
        return config instanceof SocketChannelConfig &&
                ((SocketChannelConfig) config).isAllowHalfClosure();
    }
    
    ```

    - 可通过

       

      ```
      ALLOW_HALF_CLOSURE
      
      ```

       

      配置项开启。

      - Netty 参数，一个连接的远端关闭时本地端是否关闭，默认值为 `false` 。
      - 值为 `false`时，连接自动关闭。
      - 值为 `true` 时，触发 ChannelInboundHandler 的`#userEventTriggered()` 方法，事件 ChannelInputShutdownEvent 。

    - `<1.1>` 第 6 行：调用 `NioSocketChannel#shutdownInput()` 方法，关闭 Channel 数据的读取。代码如下：

      ```
      @Override
      public ChannelFuture shutdownInput() {
          return shutdownInput(newPromise());
      }
      
      @Override
      public ChannelFuture shutdownInput(final ChannelPromise promise) {
          EventLoop loop = eventLoop();
          if (loop.inEventLoop()) {
              shutdownInput0(promise);
          } else {
              loop.execute(new Runnable() {
                  @Override
                  public void run() {
                      shutdownInput0(promise);
                  }
              });
          }
          return promise;
      }
      
      private void shutdownInput0(final ChannelPromise promise) {
          try {
              // 关闭 Channel 数据的读取
              shutdownInput0();
              // 通知 Promise 成功
              promise.setSuccess();
          } catch (Throwable t) {
              // 通知 Promise 失败
              promise.setFailure(t);
          }
      }
      
      private void shutdownInput0() throws Exception {
          // 调用 Java NIO Channel 的 shutdownInput 方法
          if (PlatformDependent.javaVersion() >= 7) {
              javaChannel().shutdownInput();
          } else {
              javaChannel().socket().shutdownInput();
          }
      }
      
      ```

      - 核心是，调用 Java NIO Channel 的 shutdownInput 方法。

    - `<1.1>` 第 8 行：调用 `ChannelPipeline#fireUserEventTriggered(Object event)` 方法，触发 `ChannelInputShutdownEvent.INSTANCE` 事件到 pipeline 中。关于这个事件，胖友可以看看 [《netty 处理远程主机强制关闭一个连接》](https://my.oschina.net/chenleijava/blog/484667) 。

    - `<1.2>` 第 9 至 11 行：调用 `#close(Promise)` 方法，关闭客户端的 Channel 。后续的，就是 [「2. NioSocketChannel」](http://svip.iocoder.cn/Netty/Channel-7-close/#) 中。

- 第 12 至 17 行：

  - 第 14 行：标记 `inputClosedSeenErrorOnRead` 为 `true` 。原因如下：

    ```
    /**
     * 通道关闭读取，又错误读取的错误的标识
     *
     * 详细见 https://github.com/netty/netty/commit/ed0668384b393c3502c2136e3cc412a5c8c9056e 提交
     */
    private boolean inputClosedSeenErrorOnRead;
    
    ```

    - 如下是提交的说明：

      ```
      AbstractNioByteChannel will detect that the remote end of the socket has
      been closed and propagate a user event through the pipeline. However if
      the user has auto read on, or calls read again, we may propagate the
      same user events again. If the underlying transport continuously
      notifies us that there is read activity this will happen in a spin loop
      which consumes unnecessary CPU.
      
      ```

      - 胖友认真看下英文注释。结合 [《NIO read spin event loop spin when half closed #7801》](https://github.com/netty/netty/pull/7801) 提供的示例。

      - 在标记 `inputClosedSeenErrorOnRead = true` 后，在 `NioByteUnsafe#read()` 方法中，会主动对 `SelectionKey.OP_READ` 的感兴趣，避免空轮询。代码如下：

        ```
        // AbstractNioByteUnsafe.java
        public final void read() {
            final ChannelConfig config = config();
            // 若 inputClosedSeenErrorOnRead = true ，移除对 SelectionKey.OP_READ 事件的感兴趣。
            if (shouldBreakReadReady(config)) {
                clearReadPending(); // 移除对 SelectionKey.OP_READ 事件的感兴趣
                return;
            }
            
            // ... 省略其他代码。
        }
        
        // AbstractNioByteChannel.java
        final boolean shouldBreakReadReady(ChannelConfig config) {
            return isInputShutdown0() && (inputClosedSeenErrorOnRead || !isAllowHalfClosure(config));
        }
        
        ```

        - x

  - 第 16 行：调用 `ChannelPipeline#fireUserEventTriggered(Object event)` 方法，触发 `ChannelInputShutdownEvent.INSTANCE` 事件到 pipeline 中。

# 666. 彩蛋

比想象中简单的文章。但是，卡了比较久的时间。主要是针对 [《High CPU usage with SO_LINGER and sudden connection close (4.0.26.Final+) #4449》](https://github.com/netty/netty/issues/4449) 的讨论，中间请教了基友闪电侠和表弟普架。

痛并快乐的过程。如果英文好一点，相信解决的过程，可能更加愉快一些把。

# Channel（八）之 disconnect 操作



# 1. 概述

本文分享 Netty NIO Channel **客户端**断开连接( **disconnect** )操作的过程。

在看 Netty NIO Channel 对 `#disconnect(ChannelPromise promise)` 方法的实现代码之前，我们先来看看 Java **原生** NIO SocketChannel 的 `#disconnect()` 方法。

- 结果，结果，结果，翻了半天，只看到 NIO SocketChannel 的父类 AbstractInterruptibleChannel 中，有 `#close()` 方法，而找不到 `#disconnect()` 方法。这个是啥情况？
- 我们又去翻了 Java **原生** UDP DatagramSocket 类，结果找到了 `#connect()` 方法。这个又是啥情况？

不卖关子了，直接说结论啦：

- Java **原生** NIO SocketChannel **不存在**，当调用 Netty `NioSocketChannel#disconnect(ChannelPromise promise)` 时，会自动转换成 **close** 操作，即 [《精尽 Netty 源码解析 —— Channel（七）之 close 操作》](http://svip.iocoder.cn/Netty/Channel-7-close/) 。
- 实际上， `Channel#disconnect(ChannelPromise promise)` 方法，是 Netty 为 UDP 设计的。

# 2. NioSocketChannel

通过 `NioSocketChannel#disconnect()` 方法，应用程序里可以主动关闭 NioSocketChannel 通道。代码如下：

```java
@Override
public ChannelFuture disconnect() {
    return pipeline.disconnect();
}
```

- NioSocketChannel 继承 AbstractChannel 抽象类，所以 `#disconnect()` 方法实际是 AbstractChannel 实现的。
- 在方法内部，会调用对应的 `ChannelPipeline#disconnect()` 方法，将 disconnect 事件在 pipeline 上传播。

# 3. DefaultChannelPipeline

`DefaultChannelPipeline#disconnect()` 方法，代码如下：

```java
@Override
public final ChannelPipeline disconnect() {
    tail.disconnect();
    return this;
}
```

- 在方法内部，会调用 `TailContext#disconnect()` 方法，将 flush 事件在 pipeline 中，从尾节点向头节点传播。详细解析，见 [「4. TailContext」](http://svip.iocoder.cn/Netty/Channel-8-disconnect/#) 。

# 4. TailContext

TailContext 对 `#flush()` 方法的实现，是从 AbstractChannelHandlerContext 抽象类继承，代码如下：

```java
@Override
public ChannelFuture disconnect() {
    return disconnect(newPromise());
}

@Override
public ChannelFuture disconnect(final ChannelPromise promise) {
    // 判断是否为合法的 Promise 对象
    if (isNotValidPromise(promise, false)) {
        // cancelled
        return promise;
    }

    final AbstractChannelHandlerContext next = findContextOutbound();
    EventExecutor executor = next.executor();
    if (executor.inEventLoop()) {
        // <1> 如果没有 disconnect 操作，则执行 close 事件在 pipeline 上
        // Translate disconnect to close if the channel has no notion of disconnect-reconnect.
        // So far, UDP/IP is the only transport that has such behavior.
        if (!channel().metadata().hasDisconnect()) {
            next.invokeClose(promise);
        // 如果有 disconnect 操作，则执行 disconnect 事件在 pipeline 上
        } else {
            next.invokeDisconnect(promise);
        }
    } else {
        safeExecute(executor, new Runnable() {
            @Override
            public void run() {
                // <1> 如果没有 disconnect 操作，则执行 close 事件在 pipeline 上
                if (!channel().metadata().hasDisconnect()) {
                    next.invokeClose(promise);
                    // 如果有 disconnect 操作，则执行 disconnect 事件在 pipeline 上
                } else {
                    next.invokeDisconnect(promise);
                }
            }
        }, promise, null);
    }
    return promise;
}
```

- 在`<1>`处，调用`ChannelMetadata#hasDisconnect()`方法，判断 Channel是否支持`disconnect` 操作。

  - 如果支持，则**转换**执行 close 事件在 pipeline 上。后续的逻辑，就是 [《精尽 Netty 源码解析 —— Channel（七）之 close 操作》](http://svip.iocoder.cn/Netty/Channel-7-close/) 。
  - 如果不支持，则**保持**执行 disconnect 事件在 pipeline 上。

- 支持 disconnect 操作的 Netty Channel 实现类有：

  ![æ¯æ](http://static2.iocoder.cn/images/Netty/2018_07_22/01.png)

  - 和文头，我们提到的，只有 Java **原生** UDP DatagramSocket 支持是一致的。从 `So far, UDP/IP is the only transport that has such behavior.` 的英文注释，也能证实这一点。

- 不支持 disconnect 操作的 Netty Channel 实现类有：

  ![ä¸æ¯æ](http://static2.iocoder.cn/images/Netty/2018_07_22/02.png)

  - 和文头，我们提到的，只有 Java **原生** NIO SocketChannel 不支持是一致的。

因为本系列，暂时不分享 UDP 相关的内容，所以对“执行 disconnect 事件在 pipeline 上”就不解析了。

# 666. 彩蛋

水更一篇，本来以为 Netty NIO Channel 的 disconnect 操作是个**骚**操作。

# 精尽 Netty 源码解析 —— Buffer 之 ByteBuf（一）简介



# 1. 概述

从本文开始，我们来分享 Netty ByteBuf 相关的内容。它在 `buffer` 模块中实现，在功能定位上，它和 NIO ByteBuffer 是一致的，但是强大非常多。如下是 [《Netty 实战》](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 对它的**优点总**结：

> - A01. 它可以被用户自定义的**缓冲区类型**扩展
> - A02. 通过内置的符合缓冲区类型实现了透明的**零拷贝**
> - A03. 容量可以**按需增长**
> - A04. 在读和写这两种模式之间切换不需要调用 `#flip()` 方法
> - A05. 读和写使用了**不同的索引**
> - A06. 支持方法的**链式**调用
> - A07. 支持引用计数
> - A08. 支持**池化**

- 特别是第 A04 这点，相信很多胖友都被 NIO ByteBuffer 反人类的读模式和写模式给坑哭了。在 [《精尽 Netty 源码分析 —— NIO 基础（三）之 Buffer》](http://svip.iocoder.cn/Netty/nio-3-buffer/) 中，我们也吐槽过了。😈
- 当然，可能胖友看着这些优点，会一脸懵逼，不要紧，边读源码边理解落。

------

> 老艿艿，从下文开始，Netty ByteBuf ，我们只打 ByteBuf 。相比 NIO ByteBuffer ，它少 `"fer"` 三个字母。

ByteBuf 的代码实现挺有趣的，但是会略有一点点深度，所以笔者会分成三大块来分享：

- ByteBuf 相关，主要是它的核心 API 和核心子类实现。
- ByteBufAllocator 相关，用于创建 ByteBuf 对象。
- Jemalloc 相关，内存管理算法，Netty 基于该算法，实现对内存高效和有效的管理。😈 这块是最最最有趣的。

每一块，我们会分成几篇小的文章。而本文，我们就来对 ByteBuf 有个整体的认识，特别是核心 API 部分。

# 2. ByteBuf

`io.netty.buffer.ByteBuf` ，实现 ReferenceCounted 、Comparable 接口，ByteBuf **抽象类**。注意，ByteBuf 是一个抽象类，而不是一个接口。当然，实际上，它主要定义了**抽象**方法，**很少**实现对应的方法。

关于 `io.netty.util.ReferenceCounted` 接口，对象引用计数器接口。

- 对象的初始引用计数为 1 。
- 当引用计数器值为 0 时，表示该对象不能再被继续引用，只能被释放。
- 本文暂时不解析，我们会在 TODO 1011

## 2.1 抽象方法

因为 ByteBuf 的方法非常多，所以笔者对它的方法做了简单的归类。Let’s Go 。

### 2.1.1 基础信息

```java
public abstract int capacity(); // 容量
public abstract ByteBuf capacity(int newCapacity);
public abstract int maxCapacity(); // 最大容量

public abstract ByteBufAllocator alloc(); // 分配器，用于创建 ByteBuf 对象。

@Deprecated
public abstract ByteOrder order(); // 字节序，即大小端。推荐阅读 http://www.ruanyifeng.com/blog/2016/11/byte-order.html
@Deprecated
public abstract ByteBuf order(ByteOrder endianness);

public abstract ByteBuf unwrap(); // 获得被包装( wrap )的 ByteBuf 对象。

public abstract boolean isDirect(); // 是否 NIO Direct Buffer

public abstract boolean isReadOnly(); // 是否为只读 Buffer
public abstract ByteBuf asReadOnly();

public abstract int readerIndex(); // 读取位置
public abstract ByteBuf readerIndex(int readerIndex);
public abstract int writerIndex(); // 写入位置
public abstract ByteBuf writerIndex(int writerIndex);
public abstract ByteBuf setIndex(int readerIndex, int writerIndex); // 设置读取和写入位置
public abstract int readableBytes(); // 剩余可读字节数
public abstract int writableBytes(); // 剩余可写字节数
public abstract int maxWritableBytes();
public abstract boolean isReadable();
public abstract boolean isReadable(int size);
public abstract boolean isWritable();
public abstract boolean isWritable(int size);
public abstract ByteBuf ensureWritable(int minWritableBytes);
public abstract int ensureWritable(int minWritableBytes, boolean force);
public abstract ByteBuf markReaderIndex(); // 标记读取位置
public abstract ByteBuf resetReaderIndex();
public abstract ByteBuf markWriterIndex(); // 标记写入位置
public abstract ByteBuf resetWriterIndex();
```

主要是如下四个属性：

- `readerIndex` ，读索引。
- `writerIndex` ，写索引。
- `capacity` ，当前容量。
- `maxCapacity` ，最大容量。当 `writerIndex` 写入超过 `capacity` 时，可自动扩容。**每次**扩容的大小，为 `capacity`的 2 倍。当然，前提是不能超过 `maxCapacity` 大小。

所以，ByteBuf 通过 `readerIndex` 和 `writerIndex` 两个索引，解决 ByteBuffer 的读写模式的问题。

四个大小关系很简单：`readerIndex` <= `writerIndex` <= `capacity` <= `maxCapacity` 。如下图所示：![分段](http://static2.iocoder.cn/images/Netty/2018_08_01/01.png)

- 图中一共有三段，实际是四段，省略了 `capacity` 到 `maxCapacity` 之间的一段。
- discardable bytes ，废弃段。一般情况下，可以理解成已读的部分。
- readable bytes ，可读段。可通过 `#readXXX()` 方法，顺序向下读取。
- writable bytes ，可写段。可通过 `#writeXXX()` 方法，顺序向下写入。

另外，ByteBuf 还有 `markReaderIndex` 和 `markWriterIndex` 两个属性：

- 通过对应的 `#markReaderIndex()` 和 `#markWriterIndex()` 方法，分别标记读取和写入位置。
- 通过对应的 `#resetReaderIndex()` 和 `#resetWriterIndex()` 方法，分别读取和写入位置到标记处。

### 3.1.2 读取 / 写入操作

```java
// Boolean 1 字节
public abstract boolean getBoolean(int index);
public abstract ByteBuf setBoolean(int index, boolean value);
public abstract boolean readBoolean();
public abstract ByteBuf writeBoolean(boolean value);

// Byte 1 字节
public abstract byte  getByte(int index);
public abstract short getUnsignedByte(int index);
public abstract ByteBuf setByte(int index, int value);
public abstract byte  readByte();
public abstract short readUnsignedByte();
public abstract ByteBuf writeByte(int value);

// Short 2 字节
public abstract short getShort(int index);
public abstract short getShortLE(int index);
public abstract int getUnsignedShort(int index);
public abstract int getUnsignedShortLE(int index);
public abstract ByteBuf setShort(int index, int value);
public abstract ByteBuf setShortLE(int index, int value);
public abstract short readShort();
public abstract short readShortLE();
public abstract int   readUnsignedShort();
public abstract int   readUnsignedShortLE();
public abstract ByteBuf writeShort(int value);
public abstract ByteBuf writeShortLE(int value);

// 【特殊】Medium 3 字节
public abstract int   getMedium(int index);
public abstract int getMediumLE(int index);
public abstract int   getUnsignedMedium(int index);
public abstract int   getUnsignedMediumLE(int index);
public abstract ByteBuf setMedium(int index, int value);
public abstract ByteBuf setMediumLE(int index, int value);
public abstract int   readMedium();
public abstract int   readMediumLE();
public abstract int   readUnsignedMedium();
public abstract int   readUnsignedMediumLE();
public abstract ByteBuf writeMedium(int value);
public abstract ByteBuf writeMediumLE(int value);

// Int 4 字节
public abstract int   getInt(int index);
public abstract int   getIntLE(int index);
public abstract long  getUnsignedInt(int index);
public abstract long  getUnsignedIntLE(int index);
public abstract ByteBuf setInt(int index, int value);
public abstract ByteBuf setIntLE(int index, int value);
public abstract int   readInt();
public abstract int   readIntLE();
public abstract long  readUnsignedInt();
public abstract long  readUnsignedIntLE();
public abstract ByteBuf writeInt(int value);
public abstract ByteBuf writeIntLE(int value);

// Long 8 字节
public abstract long  getLong(int index);
public abstract long  getLongLE(int index);
public abstract ByteBuf setLong(int index, long value);
public abstract ByteBuf setLongLE(int index, long value);
public abstract long  readLong();
public abstract long  readLongLE();
public abstract ByteBuf writeLong(long value);
public abstract ByteBuf writeLongLE(long value);

// Char 2 字节
public abstract char  getChar(int index);
public abstract ByteBuf setChar(int index, int value);
public abstract char  readChar();
public abstract ByteBuf writeChar(int value);

// Float 4 字节
public abstract float getFloat(int index);
public float getFloatLE(int index) {
    return Float.intBitsToFloat(getIntLE(index));
}
public abstract ByteBuf setFloat(int index, float value);
public ByteBuf setFloatLE(int index, float value) {
    return setIntLE(index, Float.floatToRawIntBits(value));
}
public abstract float readFloat();
public float readFloatLE() {
    return Float.intBitsToFloat(readIntLE());
}
public abstract ByteBuf writeFloat(float value);
public ByteBuf writeFloatLE(float value) {
    return writeIntLE(Float.floatToRawIntBits(value));
}

// Double 8 字节
public abstract double getDouble(int index);
public double getDoubleLE(int index) {
    return Double.longBitsToDouble(getLongLE(index));
}
public abstract ByteBuf setDouble(int index, double value);
public ByteBuf setDoubleLE(int index, double value) {
    return setLongLE(index, Double.doubleToRawLongBits(value));
}
public abstract double readDouble();
public double readDoubleLE() {
    return Double.longBitsToDouble(readLongLE());
}
public abstract ByteBuf writeDouble(double value);
public ByteBuf writeDoubleLE(double value) {
    return writeLongLE(Double.doubleToRawLongBits(value));
}

// Byte 数组
public abstract ByteBuf getBytes(int index, ByteBuf dst);
public abstract ByteBuf getBytes(int index, ByteBuf dst, int length);
public abstract ByteBuf getBytes(int index, ByteBuf dst, int dstIndex, int length);
public abstract ByteBuf getBytes(int index, byte[] dst);
public abstract ByteBuf getBytes(int index, byte[] dst, int dstIndex, int length);
public abstract ByteBuf getBytes(int index, ByteBuffer dst);
public abstract ByteBuf getBytes(int index, OutputStream out, int length) throws IOException;
public abstract int getBytes(int index, GatheringByteChannel out, int length) throws IOException;
public abstract int getBytes(int index, FileChannel out, long position, int length) throws IOException;
public abstract ByteBuf setBytes(int index, ByteBuf src);
public abstract ByteBuf setBytes(int index, ByteBuf src, int length);
public abstract ByteBuf setBytes(int index, ByteBuf src, int srcIndex, int length);
public abstract ByteBuf setBytes(int index, byte[] src);
public abstract ByteBuf setBytes(int index, byte[] src, int srcIndex, int length);
public abstract ByteBuf setBytes(int index, ByteBuffer src);
public abstract int setBytes(int index, InputStream in, int length) throws IOException;
public abstract int setBytes(int index, ScatteringByteChannel in, int length) throws IOException;
public abstract int setBytes(int index, FileChannel in, long position, int length) throws IOException;
public abstract ByteBuf setZero(int index, int length);
public abstract ByteBuf readBytes(int length);
public abstract ByteBuf readSlice(int length);
public abstract ByteBuf readRetainedSlice(int length);
public abstract ByteBuf readBytes(ByteBuf dst);
public abstract ByteBuf readBytes(ByteBuf dst, int length);
public abstract ByteBuf readBytes(ByteBuf dst, int dstIndex, int length);
public abstract ByteBuf readBytes(byte[] dst);
public abstract ByteBuf readBytes(byte[] dst, int dstIndex, int length);
public abstract ByteBuf readBytes(ByteBuffer dst);
public abstract ByteBuf readBytes(OutputStream out, int length) throws IOException;
public abstract int readBytes(GatheringByteChannel out, int length) throws IOException;
public abstract int readBytes(FileChannel out, long position, int length) throws IOException;
public abstract ByteBuf skipBytes(int length); // 忽略指定长度的字节数
public abstract ByteBuf writeBytes(ByteBuf src);
public abstract ByteBuf writeBytes(ByteBuf src, int length);
public abstract ByteBuf writeBytes(ByteBuf src, int srcIndex, int length);
public abstract ByteBuf writeBytes(byte[] src);
public abstract ByteBuf writeBytes(byte[] src, int srcIndex, int length);
public abstract ByteBuf writeBytes(ByteBuffer src);
public abstract int  writeBytes(InputStream in, int length) throws IOException;
public abstract int writeBytes(ScatteringByteChannel in, int length) throws IOException;
public abstract int writeBytes(FileChannel in, long position, int length) throws IOException;
public abstract ByteBuf writeZero(int length); // 填充指定长度的 0

// String
public abstract CharSequence getCharSequence(int index, int length, Charset charset);
public abstract int setCharSequence(int index, CharSequence sequence, Charset charset);
public abstract CharSequence readCharSequence(int length, Charset charset);
public abstract int writeCharSequence(CharSequence sequence, Charset charset);
```

虽然方法比较多，总结下来是不同数据类型的**四种**读写方法：

- `#getXXX(index)` 方法，读取**指定**位置的数据，不改变 `readerIndex` 索引。
- `#readXXX()` 方法，读取 `readerIndex` 位置的数据，会改成 `readerIndex` 索引。
- `#setXXX(index, value)` 方法，写入数据到**指定**位置，不改变 `writeIndex` 索引。
- `#writeXXX(value)` 方法，写入数据到**指定**位置，会改变 `writeIndex` 索引。

### 2.1.3 查找 / 遍历操作

```java
public abstract int indexOf(int fromIndex, int toIndex, byte value); // 指定值( value ) 在 ByteBuf 中的位置
public abstract int bytesBefore(byte value);
public abstract int bytesBefore(int length, byte value);
public abstract int bytesBefore(int index, int length, byte value);

public abstract int forEachByte(ByteProcessor processor); // 遍历 ByteBuf ，进行自定义处理
public abstract int forEachByte(int index, int length, ByteProcessor processor);
public abstract int forEachByteDesc(ByteProcessor processor);
public abstract int forEachByteDesc(int index, int length, ByteProcessor processor);
```

### 3.1.4 释放操作

```java
public abstract ByteBuf discardReadBytes(); // 释放已读的字节空间
public abstract ByteBuf discardSomeReadBytes(); // 释放部分已读的字节空间

public abstract ByteBuf clear(); // 清空字节空间。实际是修改 readerIndex=writerIndex=0，标记清空。
```

**discardReadBytes**

`#discardReadBytes()` 方法，释放【所有的】**废弃段**的空间内存。

- 优点：达到重用废弃段的空间内存。
- 缺点：释放的方式，是通过复制**可读段**到 ByteBuf 的头部。所以，频繁释放会导致性能下降。
- 总结：这是典型的问题：选择空间还是时间。具体的选择，需要看对应的场景。😈 后续的文章，我们会看到对该方法的调用。

整个过程如下图：![discardReadBytes](http://static2.iocoder.cn/images/Netty/2018_08_01/02.png)

**discardSomeReadBytes**

`#discardSomeReadBytes()` 方法，释放【部分的】**废弃段**的空间内存。

这是对 `#discardSomeReadBytes()` 方法的这种方案，具体的实现，见 [「4. AbstractByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 中。

**clear**

`#clear()` 方法，清空字节空间。实际是修改 `readerIndex = writerIndex = 0` ，标记清空。

- 优点：通过标记来实现清空，避免置空 ByteBuf ，提升性能。
- 缺点：数据实际还存在，如果错误修改 `writerIndex` 时，会导致读到“脏”数据。

整个过程如下图：![discardReadBytes](http://static2.iocoder.cn/images/Netty/2018_08_01/03.png)

### 3.1.5 拷贝操作

```java
public abstract ByteBuf copy(); // 拷贝可读部分的字节数组。独立，互相不影响。
public abstract ByteBuf copy(int index, int length);

public abstract ByteBuf slice(); // 拷贝可读部分的字节数组。共享，相互影响。
public abstract ByteBuf slice(int index, int length);
public abstract ByteBuf retainedSlice();

public abstract ByteBuf duplicate(); // 拷贝整个的字节数组。共享，相互影响。
public abstract ByteBuf retainedDuplicate();
```

### 3.1.6 转换 NIO ByteBuffer 操作

```java
// ByteBuf 包含 ByteBuffer 数量。
// 如果返回 = 1 ，则调用 `#nioBuffer()` 方法，获得 ByteBuf 包含的 ByteBuffer 对象。
// 如果返回 > 1 ，则调用 `#nioBuffers()` 方法，获得 ByteBuf 包含的 ByteBuffer 数组。
public abstract int nioBufferCount();

public abstract ByteBuffer nioBuffer();
public abstract ByteBuffer nioBuffer(int index, int length);
public abstract ByteBuffer internalNioBuffer(int index, int length);

public abstract ByteBuffer[] nioBuffers();
public abstract ByteBuffer[] nioBuffers(int index, int length);
```

### 3.1.7 Heap 相关方法

```java
// 适用于 Heap 类型的 ByteBuf 对象的 byte[] 字节数组
public abstract boolean hasArray(); // 是否有 byte[] 字节数组
public abstract byte[] array();
public abstract int arrayOffset();
```

- 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl)

### 3.1.8 Unsafe 相关方法

```java
// 适用于 Unsafe 类型的 ByteBuf 对象
public abstract boolean hasMemoryAddress(); // 是否有内存地址
public abstract long memoryAddress();
```

- 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl)

### 3.1.9 Object 相关

```java
@Override
public abstract String toString();
public abstract String toString(Charset charset);
public abstract String toString(int index, int length, Charset charset);

@Override
public abstract int hashCode();

@Override
public abstract boolean equals(Object obj);

@Override
public abstract int compareTo(ByteBuf buffer);
```

### 3.1.10 引用计数相关

本文暂时不解析，我们会在 TODO 1011 。

来自 ReferenceCounted

<https://skyao.gitbooks.io/learning-netty/content/buffer/interface_ReferenceCounted.html> 可参考

```java
@Override
public abstract ByteBuf retain(int increment);
@Override
public abstract ByteBuf retain();

@Override
public abstract ByteBuf touch();
@Override
public abstract ByteBuf touch(Object hint);
```

## 3.2 子类类图

ByteBuf 的子类灰常灰常灰常多，胖友点击 [传送门](http://static2.iocoder.cn/images/Netty/2018_08_01/04.png) 可以进行查看。

本文仅分享 ByteBuf 的**五个**直接子类实现，如下图所示：![传送门](http://static2.iocoder.cn/images/Netty/2018_08_01/05.png)

- 【重点】AbstractByteBuf ，ByteBuf 抽象实现类，提供 ByteBuf 的默认实现类。可以说，是 ByteBuf 最最最重要的子类。详细解析，见 [「4. AbstractByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 。
- EmptyByteBuf ，用于构建空 ByteBuf 对象，`capacity` 和 `maxCapacity` 均为 0 。详细解析，见 [「5. EmptyByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 。
- WrappedByteBuf ，用于装饰 ByteBuf 对象。详细解析，见 [「6. WrappedByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 。
- SwappedByteBuf ，用于构建具有切换**字节序**功能的 ByteBuf 对象。详细解析，见 [「7. SwappedByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 。
- ReplayingDecoderByteBuf ，用于构建在 IO 阻塞条件下实现无阻塞解码的特殊 ByteBuf 对象，当要读取的数据还未接收完全时，抛出异常，交由 ReplayingDecoder处理。详细解析，见 [「8. ReplayingDecoderByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 。

# 4. AbstractByteBuf

`io.netty.buffer.AbstractByteBuf` ，实现 ByteBuf 抽象类，ByteBuf 抽象实现类。官方注释如下：

```java
/**
 * A skeletal implementation of a buffer.
 */
```

因为 AbstractByteBuf 实现类 ByteBuf 超级多的方法，所以我们还是按照 ByteBuf 的归类，逐个分析过去。

## 4.1 基础信息

### 4.1.1 构造方法

```java
/**
 * 读取位置
 */
int readerIndex;
/**
 * 写入位置
 */
int writerIndex;
/**
 * {@link #readerIndex} 的标记
 */
private int markedReaderIndex;
/**
 * {@link #writerIndex} 的标记
 */
private int markedWriterIndex;
/**
 * 最大容量
 */
private int maxCapacity;

protected AbstractByteBuf(int maxCapacity) {
    if (maxCapacity < 0) {
        throw new IllegalArgumentException("maxCapacity: " + maxCapacity + " (expected: >= 0)");
    }
    this.maxCapacity = maxCapacity;
}
```

- `capacity` 属性，在 AbstractByteBuf 未定义，而是由子类来实现。为什么呢？在后面的文章，我们会看到，ByteBuf 根据**内存类型**分成 Heap 和 Direct ，它们获取 `capacity` 的值的方式不同。

- `maxCapacity` 属性，相关的方法：

  ```java
  @Override
  public int maxCapacity() {
      return maxCapacity;
  }
  
  protected final void maxCapacity(int maxCapacity) {
      this.maxCapacity = maxCapacity;
  }
  ```

### 4.1.2 读索引相关的方法

**获取和设置读位置**

```java
@Override
public int readerIndex() {
    return readerIndex;
}
    
@Override
public ByteBuf readerIndex(int readerIndex) {
    if (readerIndex < 0 || readerIndex > writerIndex) {
        throw new IndexOutOfBoundsException(String.format(
                "readerIndex: %d (expected: 0 <= readerIndex <= writerIndex(%d))", readerIndex, writerIndex));
    }
    this.readerIndex = readerIndex;
    return this;
}
```

------

**是否可读**

```java
@Override
public boolean isReadable() {
    return writerIndex > readerIndex;
}
@Override
public boolean isReadable(int numBytes) {
    return writerIndex - readerIndex >= numBytes;
}

@Override
public int readableBytes() {
    return writerIndex - readerIndex;
}
```

------

**标记和重置读位置**

```java
@Override
public ByteBuf markReaderIndex() {
    markedReaderIndex = readerIndex;
    return this;
}

@Override
public ByteBuf resetReaderIndex() {
    readerIndex(markedReaderIndex);
    return this;
}
```

### 4.1.3 写索引相关的方法

**获取和设置写位置**

```java
@Override
public int writerIndex() {
    return writerIndex;
}
    
@Override
public ByteBuf writerIndex(int writerIndex) {
    if (writerIndex < readerIndex || writerIndex > capacity()) {
        throw new IndexOutOfBoundsException(String.format(
                "writerIndex: %d (expected: readerIndex(%d) <= writerIndex <= capacity(%d))",
                writerIndex, readerIndex, capacity()));
    }
    this.writerIndex = writerIndex;
    return this;
}

```

------

**是否可写**

```java
@Override
public boolean isWritable() {
    return capacity() > writerIndex;
}
@Override
public boolean isWritable(int numBytes) {
    return capacity() - writerIndex >= numBytes;
}

@Override
public int writableBytes() {
    return capacity() - writerIndex;
}
@Override
public int maxWritableBytes() {
    return maxCapacity() - writerIndex;
}

```

------

**标记和重置写位置**

```java
@Override
public ByteBuf markWriterIndex() {
    markedWriterIndex = writerIndex;
    return this;
}

@Override
public ByteBuf resetWriterIndex() {
    writerIndex(markedWriterIndex);
    return this;
}

```

------

**保证可写**

`#ensureWritable(int minWritableBytes)` 方法，保证有足够的可写空间。若不够，则进行扩容。代码如下：

```
 1: @Override
 2: public ByteBuf ensureWritable(int minWritableBytes) {
 3:     if (minWritableBytes < 0) {
 4:         throw new IllegalArgumentException(String.format(
 5:                 "minWritableBytes: %d (expected: >= 0)", minWritableBytes));
 6:     }
 7:     ensureWritable0(minWritableBytes);
 8:     return this;
 9: }
10: 
11: final void ensureWritable0(int minWritableBytes) {
12:     // 检查是否可访问
13:     ensureAccessible();
14:     // 目前容量可写，直接返回
15:     if (minWritableBytes <= writableBytes()) {
16:         return;
17:     }
18: 
19:     // 超过最大上限，抛出 IndexOutOfBoundsException 异常
20:     if (minWritableBytes > maxCapacity - writerIndex) {
21:         throw new IndexOutOfBoundsException(String.format(
22:                 "writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s",
23:                 writerIndex, minWritableBytes, maxCapacity, this));
24:     }
25: 
26:     // 计算新的容量。默认情况下，2 倍扩容，并且不超过最大容量上限。
27:     // Normalize the current capacity to the power of 2.
28:     int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity);
29: 
30:     // 设置新的容量大小
31:     // Adjust to the new capacity.
32:     capacity(newCapacity);
33: }

```

- 第 13 行：调用 `#ensureAccessible()` 方法，检查是否可访问。代码如下：

  ```
  /**
   * Should be called by every method that tries to access the buffers content to check
   * if the buffer was released before.
   */
  protected final void ensureAccessible() {
      if (checkAccessible && refCnt() == 0) { // 若指向为 0 ，说明已经释放，不可继续写入。
          throw new IllegalReferenceCountException(0);
      }
  }
  
  private static final String PROP_MODE = "io.netty.buffer.bytebuf.checkAccessible";
  /**
   * 是否检查可访问
   *
   * @see #ensureAccessible() 
   */
  private static final boolean checkAccessible;
  
  static {
      checkAccessible = SystemPropertyUtil.getBoolean(PROP_MODE, true);
      if (logger.isDebugEnabled()) {
          logger.debug("-D{}: {}", PROP_MODE, checkAccessible);
      }
  }
  
  ```

- 第 14 至 17 行：目前容量可写，直接返回。

- 第 19 至 24 行：超过最大上限，抛出 IndexOutOfBoundsException 异常。

- 第 28 行：调用

   

  ```
  ByteBufAllocator#calculateNewCapacity(int minNewCapacity, int maxCapacity)
  
  ```

   

  方法，计算新的容量。默认情况下，2 倍扩容，并且不超过最大容量上限。

  注意

  ，此处仅仅是计算，并没有扩容内存复制等等操作。

  - 第 32 行：调用 `#capacity(newCapacity)` 方法，设置新的容量大小。

`#ensureWritable(int minWritableBytes, boolean force)` 方法，保证有足够的可写空间。若不够，则进行扩容。代码如下：

```
@Override
public int ensureWritable(int minWritableBytes, boolean force) {
    // 检查是否可访问
    ensureAccessible();
    if (minWritableBytes < 0) {
        throw new IllegalArgumentException(String.format(
                "minWritableBytes: %d (expected: >= 0)", minWritableBytes));
    }

    // 目前容量可写，直接返回 0
    if (minWritableBytes <= writableBytes()) {
        return 0;
    }

    final int maxCapacity = maxCapacity();
    final int writerIndex = writerIndex();
    // 超过最大上限
    if (minWritableBytes > maxCapacity - writerIndex) {
        // 不强制设置，或者已经到达最大容量
        if (!force || capacity() == maxCapacity) {
            // 返回 1
            return 1;
        }

        // 设置为最大容量
        capacity(maxCapacity);
        // 返回 3
        return 3;
    }

    // 计算新的容量。默认情况下，2 倍扩容，并且不超过最大容量上限。
    // Normalize the current capacity to the power of 2.
    int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity);

    // 设置新的容量大小
    // Adjust to the new capacity.
    capacity(newCapacity);

    // 返回 2
    return 2;
}

```

和 `#ensureWritable(int minWritableBytes)` 方法，有两点不同：

- 超过最大容量的上限时，不会抛出 IndexOutOfBoundsException 异常。
- 根据执行的过程不同，返回不同的返回值。

比较简单，胖友自己看下代码。

### 4.1.4 setIndex

```
@Override
public ByteBuf setIndex(int readerIndex, int writerIndex) {
    if (readerIndex < 0 || readerIndex > writerIndex || writerIndex > capacity()) {
        throw new IndexOutOfBoundsException(String.format(
                "readerIndex: %d, writerIndex: %d (expected: 0 <= readerIndex <= writerIndex <= capacity(%d))",
                readerIndex, writerIndex, capacity()));
    }
    setIndex0(readerIndex, writerIndex);
    return this;
}

final void setIndex0(int readerIndex, int writerIndex) {
    this.readerIndex = readerIndex;
    this.writerIndex = writerIndex;
}

```

### 4.1.5 读索引标记位相关的方法

```
@Override
public ByteBuf markReaderIndex() {
    markedReaderIndex = readerIndex;
    return this;
}

@Override
public ByteBuf resetReaderIndex() {
    readerIndex(markedReaderIndex);
    return this;
}

```

### 4.1.6 写索引标记位相关的方法

```
@Override
public ByteBuf markWriterIndex() {
    markedWriterIndex = writerIndex;
    return this;
}

@Override
public ByteBuf resetWriterIndex() {
    writerIndex(markedWriterIndex);
    return this;
}

```

### 4.1.7 是否只读相关

`#isReadOnly()` 方法，返回是否只读。代码如下：

```
@Override
public boolean isReadOnly() {
    return false;
}

```

- 默认返回 `false` 。子类可覆写该方法，根据情况返回结果。

------

`#asReadOnly()` 方法，转换成只读 ByteBuf 对象。代码如下：

```
@SuppressWarnings("deprecation")
@Override
public ByteBuf asReadOnly() {
    // 如果是只读，直接返回
    if (isReadOnly()) {
        return this;
    }
    // 转化成只读 Buffer 对象
    return Unpooled.unmodifiableBuffer(this);
}

```

- 如果已是只读，直接返回该 ByteBuf 对象。

- 如果不是只读，调用 `Unpooled#unmodifiableBuffer(Bytebuf)` 方法，转化成只读 Buffer 对象。代码如下：

  ```
  /**
   * Creates a read-only buffer which disallows any modification operations
   * on the specified {@code buffer}.  The new buffer has the same
   * {@code readerIndex} and {@code writerIndex} with the specified
   * {@code buffer}.
   *
   * @deprecated Use {@link ByteBuf#asReadOnly()}.
   */
  @Deprecated
  public static ByteBuf unmodifiableBuffer(ByteBuf buffer) {
      ByteOrder endianness = buffer.order();
      // 大端
      if (endianness == BIG_ENDIAN) {
          return new ReadOnlyByteBuf(buffer);
      }
      // 小端
      return new ReadOnlyByteBuf(buffer.order(BIG_ENDIAN)).order(LITTLE_ENDIAN);
  }
  
  ```

  - 注意，返回的是**新的** `io.netty.buffer.ReadOnlyByteBuf` 对象。并且，和原 ByteBuf 对象，共享 `readerIndex`和 `writerIndex` 索引，以及相关的数据。仅仅是说，只读，不能写入。

### 4.1.8 ByteOrder 相关的方法

`#order()` 方法，获得字节序。由子类实现，因为 AbstractByteBuf 的内存类型，不确定是 Heap 还是 Direct 。

------

`#order(ByteOrder endianness)` 方法，设置字节序。代码如下：

```
@Override
public ByteBuf order(ByteOrder endianness) {
    if (endianness == null) {
        throw new NullPointerException("endianness");
    }
    // 未改变，直接返回
    if (endianness == order()) {
        return this;
    }
    // 创建 SwappedByteBuf 对象
    return newSwappedByteBuf();
}

/**
 * Creates a new {@link SwappedByteBuf} for this {@link ByteBuf} instance.
 */
protected SwappedByteBuf newSwappedByteBuf() {
    return new SwappedByteBuf(this);
}

```

- 如果字节序未修改，直接返回该 ByteBuf 对象。
- 如果字节序有修改，调用 `#newSwappedByteBuf()` 方法，TODO SwappedByteBuf

### 4.1.9 未实现方法

和 [「2.1.1 基础信息」](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/#) 相关的方法，有三个未实现，如下：

```
public abstract ByteBufAllocator alloc(); // 分配器，用于创建 ByteBuf 对象。

public abstract ByteBuf unwrap(); // 获得被包装( wrap )的 ByteBuf 对象。

public abstract boolean isDirect(); // 是否 NIO Direct Buffer

```

## 4.2 读取 / 写入操作

我们以 Int 类型为例子，来看看它的读取和写入操作的实现代码。

### 4.2.1 getInt

```
@Override
public int getInt(int index) {
    // 校验读取是否会超过容量
    checkIndex(index, 4);
    // 读取 Int 数据
    return _getInt(index);
}

```

- 调用 `#checkIndex(index, fieldLength)` 方法，校验读取是否会超过**容量**。注意，不是超过 `writerIndex` 位置。因为，只是读取指定位置开始的 Int 数据，不会改变 `readerIndex` 。代码如下：

  ```
  protected final void checkIndex(int index, int fieldLength) {
      // 校验是否可访问
      ensureAccessible();
      // 校验是否会超过容量
      checkIndex0(index, fieldLength);
  }
  final void checkIndex0(int index, int fieldLength) {
      if (isOutOfBounds(index, fieldLength, capacity())) {
          throw new IndexOutOfBoundsException(String.format(
                  "index: %d, length: %d (expected: range(0, %d))", index, fieldLength, capacity()));
      }
  }
  
  // MathUtil.java
  /**
   * Determine if the requested {@code index} and {@code length} will fit within {@code capacity}.
   * @param index The starting index.
   * @param length The length which will be utilized (starting from {@code index}).
   * @param capacity The capacity that {@code index + length} is allowed to be within.
   * @return {@code true} if the requested {@code index} and {@code length} will fit within {@code capacity}.
   * {@code false} if this would result in an index out of bounds exception.
   */
  public static boolean isOutOfBounds(int index, int length, int capacity) {
      // 只有有负数，或运算，就会有负数。
      // 另外，此处的越界，不仅仅有 capacity - (index + length < 0 ，例如 index < 0 ，也是越界
      return (index | length | (index + length) | (capacity - (index + length))) < 0;
  }
  
  ```

- 调用 `#_getInt(index)` 方法，读取 Int 数据。这是一个**抽象**方法，由子类实现。代码如下：

  ```
  protected abstract int _getInt(int index);
  
  ```

关于 `#getIntLE(int index)` / `getUnsignedInt(int index)` / `getUnsignedIntLE(int index)` 方法的实现，胖友自己去看。

### 4.2.2 readInt

```
@Override
public int readInt() {
    // 校验读取是否会超过可读段
    checkReadableBytes0(4);
    // 读取 Int 数据
    int v = _getInt(readerIndex);
    // 修改 readerIndex ，加上已读取字节数
    readerIndex += 4;
    return v;
}

```

- 调用 `#checkReadableBytes0(fieldLength)` 方法，校验读取是否会超过**可读段**。代码如下：

  ```
  private void checkReadableBytes0(int minimumReadableBytes) {
      // 是否可访问
      ensureAccessible();
      // 是否超过写索引，即超过可读段
      if (readerIndex > writerIndex - minimumReadableBytes) {
          throw new IndexOutOfBoundsException(String.format(
                  "readerIndex(%d) + length(%d) exceeds writerIndex(%d): %s",
                  readerIndex, minimumReadableBytes, writerIndex, this));
      }
  }
  
  ```

- 调用 `#_getInt(index)` 方法，读取 Int 数据。

- 读取完成，修改 `readerIndex` 【**重要** 😈】，加上已读取字节数 4 。

关于 `#readIntLE()` / `readUnsignedInt()` / `readUnsignedIntLE()` 方法的实现，胖友自己去看。

### 4.2.3 setInt

```
@Override
public ByteBuf setInt(int index, int value) {
    // 校验写入是否会超过容量
    checkIndex(index, 4);
    // 设置 Int 数据
    _setInt(index, value);
    return this;
}

```

- 调用 `#checkIndex(index, fieldLength)` 方法，校验写入是否会超过**容量**。

- 调用 `#_setInt(index,value )` 方法，写入 Int 数据。这是一个**抽象**方法，由子类实现。代码如下：

  ```
  protected abstract int _setInt(int index, int value);
  
  ```

关于 `#setIntLE(int index, int value)` 方法的实现，胖友自己去看。

public abstract ByteBuf writeInt(int value);
public abstract ByteBuf writeIntLE(int value);

### 4.2.4 writeInt

```
@Override
public ByteBuf writeInt(int value) {
    // 保证可写入
    ensureWritable0(4);
    // 写入 Int 数据
    _setInt(writerIndex, value);
    // 修改 writerIndex ，加上已写入字节数
    writerIndex += 4;
    return this;
}

```

- 调用 `#ensureWritable0(int minWritableBytes)` 方法，保证可写入。
- 调用 `#_setInt(index, int value)` 方法，写入Int 数据。
- 写入完成，修改 `writerIndex` 【**重要** 😈】，加上已写入字节数 4 。

### 4.2.5 其它方法

其它类型的读取和写入操作的实现代码，胖友自己研究落。还是有一些有意思的方法，例如：

- `#writeZero(int length)` 方法。原本以为是循环 `length` 次写入 0 字节，结果发现会基于 `long` => `int` => `byte` 的顺序，尽可能合并写入。
- `#skipBytes((int length)` 方法

## 4.3 查找 / 遍历操作

查找 / 遍历操作相关的方法，实现比较简单。所以，感兴趣的胖友，可以自己去看。

## 4.4 释放操作

### 4.4.1 discardReadBytes

`#discardReadBytes()` 方法，代码如下：

```
 1: @Override
 2: public ByteBuf discardReadBytes() {
 3:     // 校验可访问
 4:     ensureAccessible();
 5:     // 无废弃段，直接返回
 6:     if (readerIndex == 0) {
 7:         return this;
 8:     }
 9: 
10:     // 未读取完
11:     if (readerIndex != writerIndex) {
12:         // 将可读段复制到 ByteBuf 头
13:         setBytes(0, this, readerIndex, writerIndex - readerIndex);
14:         // 写索引减小
15:         writerIndex -= readerIndex;
16:         // 调整标记位
17:         adjustMarkers(readerIndex);
18:         // 读索引重置为 0
19:         readerIndex = 0;
20:     // 全部读取完
21:     } else {
22:         // 调整标记位
23:         adjustMarkers(readerIndex);
24:         // 读写索引都重置为 0
25:         writerIndex = readerIndex = 0;
26:     }
27:     return this;
28: }

```

- 第 4 行：调用 `#ensureAccessible()` 方法，检查是否可访问。

- 第 5 至 8 行：无**废弃段**，直接返回。

- 第 10 至 19 行：未读取完，即还有**可读段**。

  - 第 13 行：调用 `#setBytes(int index, ByteBuf src, int srcIndex, int length)` 方法，将可读段复制到 ByteBuf 头开始。如下图所示：![discardReadBytes](http://static2.iocoder.cn/images/Netty/2018_08_01/02.png)

  - 第 15 行：写索引 `writerIndex` 减小。

  - 第 19 行：调用 `#adjustMarkers(int decrement)` 方法，调整标记位。代码如下：

    ```
    protected final void adjustMarkers(int decrement) {
        int markedReaderIndex = this.markedReaderIndex;
        // 读标记位小于减少值(decrement)
        if (markedReaderIndex <= decrement) {
            // 重置读标记位为 0
            this.markedReaderIndex = 0;
            // 写标记位小于减少值(decrement)
            int markedWriterIndex = this.markedWriterIndex;
            if (markedWriterIndex <= decrement) {
                // 重置写标记位为 0
                this.markedWriterIndex = 0;
            // 减小写标记位
            } else {
                this.markedWriterIndex = markedWriterIndex - decrement;
            }
        // 减小读写标记位
        } else {
            this.markedReaderIndex = markedReaderIndex - decrement;
            this.markedWriterIndex -= decrement;
        }
    }
    
    ```

    - 代码虽然比较多，但是目的很明确，**减小**读写标记位。并且，通过判断，**最多减小至 0** 。

  - 第 19 行：**仅**读索引重置为 0 。

- 第 20 至 26 行：全部读取完，即无

  可读段

  。

  - 第 23 行：调用 `#adjustMarkers(int decrement)` 方法，调整标记位。
  - 第 25 行：读写索引**都**重置为 0 。

### 4.4.2 discardSomeReadBytes

`#discardSomeReadBytes()` 方法，代码如下：

```
@Override
public ByteBuf discardSomeReadBytes() {
    // 校验可访问
    ensureAccessible();
    // 无废弃段，直接返回
    if (readerIndex == 0) {
        return this;
    }

    // 全部读取完
    if (readerIndex == writerIndex) {
        // 调整标记位
        adjustMarkers(readerIndex);
        // 读写索引都重置为 0
        writerIndex = readerIndex = 0;
        return this;
    }

    // 读取超过容量的一半，进行释放
    if (readerIndex >= capacity() >>> 1) {
        // 将可读段复制到 ByteBuf 头
        setBytes(0, this, readerIndex, writerIndex - readerIndex);
        // 写索引减小
        writerIndex -= readerIndex;
        // 调整标记位
        adjustMarkers(readerIndex);
        // 读索引重置为 0
        readerIndex = 0;
    }
    return this;
}

```

整体代码和 `#discardReadBytes()` 方法是**一致的**。差别在于，`readerIndex >= capacity() >>> 1` ，读取超过容量的**一半**时，进行释放。也就是说，在空间和时间之间，做了一个平衡。

😈 后续，我们来看看，Netty 具体在什么时候，调用 `#discardSomeReadBytes()` 和 `#discardReadBytes()` 方法。

### 4.4.3 clear

`#clear()` 方法，代码如下：

```
@Override
public ByteBuf clear() {
    readerIndex = writerIndex = 0;
    return this;
}

```

- 读写索引**都**重置为 0 。
- 读写标记位**不会**重置。

## 4.5 拷贝操作

### 4.5.1 copy

`#copy()` 方法，拷贝可读部分的字节数组。代码如下：

```
@Override
public ByteBuf copy() {
    return copy(readerIndex, readableBytes());
}

```

- 调用 `#readableBytes()` 方法，获得可读的字节数。
- 调用 `#copy(int index, int length)` 方法，拷贝**指定部分**的字节数组。独立，互相不影响。具体的实现，需要子类中实现，原因是做**深**拷贝，需要根据内存类型是 Heap 和 Direct 会有不同。

### 4.5.2 slice

`#slice()` 方法，拷贝可读部分的字节数组。代码如下：

```
@Override
public ByteBuf slice() {
    return slice(readerIndex, readableBytes());
}

```

- 调用 `#readableBytes()` 方法，获得可读的字节数。

- 调用 `#slice(int index, int length)` 方法，拷贝**指定部分**的字节数组。共享，互相影响。代码如下：

  ```
  @Override
  public ByteBuf slice(int index, int length) {
      // 校验可访问
      ensureAccessible();
      // 创建 UnpooledSlicedByteBuf 对象
      return new UnpooledSlicedByteBuf(this, index, length);
  }
  
  ```

  - 返回的是创建的 UnpooledSlicedByteBuf 对象。在它内部，会调用当前 ByteBuf 对象，所以这也是为什么说是**共享**的。或者说，我们可以认为这是一个**浅**拷贝。

------

`#retainedSlice()` 方法，在 `#slice()` 方法的基础上，引用计数加 1 。代码如下：

```
@Override
public ByteBuf retainedSlice(int index, int length) {
    return slice(index, length).retain();
}

```

- 调用 `#slice(int index, int length)` 方法，拷贝**指定部分**的字节数组。也就说，返回 UnpooledSlicedByteBuf 对象。
- 调用 `UnpooledSlicedByteBuf#retain()` 方法，，引用计数加 1 。本文暂时不解析，我们会在 TODO 1011 。

### 4.5.3 duplicate

`#duplicate()` 方法，拷贝**整个**的字节数组。代码如下：

```
@Override
public ByteBuf duplicate() {
    // 校验是否可访问
    ensureAccessible();
    return new UnpooledDuplicatedByteBuf(this);
}

```

- 创建的 UnpooledDuplicatedByteBuf 对象。在它内部，会调用当前 ByteBuf 对象，所以这也是为什么说是**共享**的。或者说，我们可以认为这是一个**浅**拷贝。
- 它和 `#slice()` 方法的差别在于，前者是**整个**，后者是**可写段**。

------

`#retainedDuplicate()` 方法，在 `#duplicate()` 方法的基础上，引用计数加 1 。代码如下：

```
@Override
public ByteBuf retainedDuplicate() {
    return duplicate().retain();
}

```

- 调用 `#duplicate()` 方法，拷贝**整个**的字节数组。也就说，返回 UnpooledDuplicatedByteBuf 对象。
- 调用 `UnpooledDuplicatedByteBuf#retain()` 方法，，引用计数加 1 。本文暂时不解析，我们会在 TODO 1011 。

## 4.6 转换 NIO ByteBuffer 操作

### 4.6.1 nioBuffer

`#nioBuffer()` 方法，代码如下：

```
@Override
public ByteBuffer nioBuffer() {
    return nioBuffer(readerIndex, readableBytes());
}

```

- 在方法内部，会调用 `#nioBuffer(int index, int length)` 方法。而该方法，由具体的子类实现。

  > FROM [《深入研究Netty框架之ByteBuf功能原理及源码分析》](https://my.oschina.net/7001/blog/742236)
  >
  > 将当前 ByteBuf 的可读缓冲区( `readerIndex` 到 `writerIndex` 之间的内容) 转换为 ByteBuffer 对象，两者共享共享缓冲区的内容。对 ByteBuffer 的读写操作不会影响 ByteBuf 的读写索引。
  >
  > 注意：ByteBuffer 无法感知 ByteBuf 的动态扩展操作。ByteBuffer 的长度为`readableBytes()` 。

### 4.6.2 nioBuffers

`#nioBuffers()` 方法，代码如下：

```
@Override
public ByteBuffer[] nioBuffers() {
    return nioBuffers(readerIndex, readableBytes());
}

```

- 在方法内部，会调用 `#nioBuffers(int index, int length)` 方法。而该方法，由具体的子类实现。
- 😈 为什么会产生数组的情况呢？例如 CompositeByteBuf 。当然，后续文章，我们也会具体分享。

## 4.7 Heap 相关方法

Heap 相关方法，在子类中实现。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl)

## 4.8 Unsafe 相关方法

Unsafe，在子类中实现。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl)

## 4.9 Object 相关

Object 相关的方法，主要调用 `io.netty.buffer.ByteBufUtil` 进行实现。而 ByteUtil 是一个非常有用的工具类，它提供了一系列静态方法，用于操作 ByteBuf 对象：![ByteUtil](http://static2.iocoder.cn/images/Netty/2018_08_01/06.png)

😈 因为 Object 相关的方法，实现比较简单。所以，感兴趣的胖友，可以自己去看。

## 4.10 引用计数相关

本文暂时不解析，我们会在 TODO 1011 。

# 5. EmptyByteBuf

`io.netty.buffer.EmptyByteBuf` ，继承 ByteBuf 抽象类，用于构建空 ByteBuf 对象，`capacity` 和 `maxCapacity` 均为 0 。

😈 代码实现超级简单，感兴趣的胖友，可以自己去看。

# 6. WrappedByteBuf

`io.netty.buffer.WrappedByteBuf` ，继承 ByteBuf 抽象类，用于装饰 ByteBuf 对象。构造方法如下：

```
/**
 * 被装饰的 ByteBuf 对象
 */
protected final ByteBuf buf;

protected WrappedByteBuf(ByteBuf buf) {
    if (buf == null) {
        throw new NullPointerException("buf");
    }
    this.buf = buf;
}

```

- `buf` 属性，被装饰的 ByteBuf 对象。

- 每个实现方法，是对 `buf` 的对应方法的调用。例如：

  ```
  @Override
  public final int capacity() {
      return buf.capacity();
  }
  
  @Override
  public ByteBuf capacity(int newCapacity) {
      buf.capacity(newCapacity);
      return this;
  }
  
  ```

# 7. SwappedByteBuf

`io.netty.buffer.SwappedByteBuf` ，继承 ByteBuf 抽象类，用于构建具有切换**字节序**功能的 ByteBuf 对象。构造方法如下：

```
/**
 * 原 ByteBuf 对象
 */
private final ByteBuf buf;
/**
 * 字节序
 */
private final ByteOrder order;

public SwappedByteBuf(ByteBuf buf) {
    if (buf == null) {
        throw new NullPointerException("buf");
    }
    this.buf = buf;
    // 初始化 order 属性
    if (buf.order() == ByteOrder.BIG_ENDIAN) {
        order = ByteOrder.LITTLE_ENDIAN;
    } else {
        order = ByteOrder.BIG_ENDIAN;
    }
}

```

- `buf` 属性，原 ByteBuf 对象。

- `order` 属性，字节数。

- 实际上，SwappedByteBuf 可以看成一个特殊的 WrappedByteBuf 实现，所以它除了读写操作外的方法，都是对 `buf` 的对应方法的调用。

  - `#capacity()` 方法，代码如下：

    ```
    @Override
    public int capacity() {
        return buf.capacity();
    }
    
    ```

    - 直接调用 `buf` 的对应方法。

  - `#setInt(int index, int value)` 方法，代码如下：

    ```
    @Override
    public ByteBuf setInt(int index, int value) {
        buf.setInt(index, ByteBufUtil.swapInt(value));
        return this;
    }
    
    // ByteBufUtil.java
    /**
     * Toggles the endianness of the specified 32-bit integer.
     */
    public static int swapInt(int value) {
        return Integer.reverseBytes(value);
    }
    
    ```

    - 先调用 `ByteBufUtil#swapInt(int value)` 方法，将 `value` 的值，转换成相反字节序的 Int 值。
    - 后调用 `buf` 的对应方法。

通过 SwappedByteBuf 类，我们可以很方便的修改原 ByteBuf 对象的字节序，并且无需进行内存复制。但是反过来，一定要注意，这两者是**共享**的。

# 8. ReplayingDecoderByteBuf

`io.netty.handler.codec.ReplayingDecoderByteBuf` ，继承 ByteBuf 抽象类，用于构建在 IO 阻塞条件下实现无阻塞解码的特殊 ByteBuf对 象。当要读取的数据还未接收完全时，抛出异常，交由 ReplayingDecoder 处理。

细心的胖友，会看到 ReplayingDecoderByteBuf 是在 `codec` 模块，配合 ReplayingDecoder 使用。所以，本文暂时不会分享它，而是在 [《TODO 2000 ReplayingDecoderByteBuf》](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/) 中，详细解析。

# 666. 彩蛋

每逢开篇，内容就特别啰嗦，哈哈哈哈。

推荐阅读如下文章：

- AbeJeffrey [《深入研究Netty框架之ByteBuf功能原理及源码分析》](https://my.oschina.net/7001/blog/742236)
- [《Netty 学习笔记 —— ByteBuf 继承结构》](https://skyao.gitbooks.io/learning-netty/content/buffer/inheritance.html)

# 精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类



# 1. 概述

在 [《精尽 Netty 源码解析 —— ByteBuf（一）之简介》](http://svip.iocoder.cn/Netty/ByteBuf-1-1-ByteBuf-intro/) 中，我们对 ByteBuf 有了整体的认识，特别是核心 API 部分。同时，我们也看到，ByteBuf 有非常非常非常多的子类，那么怎么办呢？实际上，**ByteBuf 有 8 个最最最核心的子类实现**。如下图所示：![核心子类](http://static2.iocoder.cn/images/Netty/2018_08_04/01.png)

一共可以按照三个维度来看这 8 个核心子类，刚好是 2 x 2 x 2 = 8 ：

- 按照**内存类型**分类：
  - ① 堆内存字节缓冲区( **Heap**ByteBuf )：底层为 JVM 堆内的字节数组，其特点是申请和释放效率较高。但是如果要进行 Socket 的 I/O 读写，需要额外多做一次内存复制，需要将堆内存对应的缓冲区复制到内核 Channel 中，性能可能会有一定程度的损耗。
- ② 直接内存字节缓冲区( **Direct**ByteBuf )：堆外内存，为操作系统内核空间的字节数组，它由操作系统直接管理和操作，其申请和释放的效率会慢于堆缓冲区。但是将它写入或者从 SocketChannel 中读取时，会少一次内存复制，这样可以大大提高 I/O 效率，实现零拷贝。
  - 关于这两者的对比，感兴趣的胖友，可以再看看 [《Java NIO direct buffer 的优势在哪儿？》](https://www.zhihu.com/question/60892134) 和 [《JAVA NIO 之 Direct Buffer 与 Heap Buffer的区别？》](http://eyesmore.iteye.com/blog/1133335)
- 按照**对象池**分类：
  - ① 基于对象池( **Pooled**ByteBuf )：基于对象池的 ByteBuf 可以重用 ByteBuf ，也就是说它自己内部维护着一个对象池，当对象释放后会归还给对象池，这样就可以循环地利用创建的 ByteBuf，提升内存的使用率，降低由于高负载导致的频繁 GC。当需要大量且频繁创建缓冲区时，推荐使用该类缓冲区。
- ② 不使用对象池( **Unpooled**ByteBuf )：对象池的管理和维护会比较困难，所以在不需要创建大量缓冲区对象时，推荐使用此类缓冲区。
- 按照**Unsafe**分类：
  - ① 使用 Unsafe ：基于 Java `sun.misc.Unsafe.Unsafe` 的 API ，直接访问内存中的数据。
- ② 不使用 Unsafe ： 基于 **Heap**ByteBuf 和 **Direct**ByteBuf 的标准 API ，进行访问对应的数据。
  - 关于 Unsafe ，JVM 大佬 R 大在知乎上有个回答：[《为什么 JUC 中大量使用了 sun.misc.Unsafe 这个类，但官方却不建议开发者使用？》](https://www.zhihu.com/question/29266773) 。关于为什么 Unsafe 的性能会更好：”其中一种是嫌 Java 性能不够好，例如说数组访问的边界检查语义，嫌这个开销太大，觉得用 Unsafe 会更快；”。

默认情况下，使用 PooledUnsafeDirectByteBuf 类型。所以，重点重点重点，看 [「2.4 PooledUnsafeDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 。

# 2. PooledByteBuf

`io.netty.buffer.PooledByteBuf` ，继承 AbstractReferenceCountedByteBuf 抽象类，**对象池化**的 ByteBuf 抽象基类，为基于**对象池**的 ByteBuf 实现类，提供公用的方法。

关于 `io.netty.util.AbstractReferenceCountedByteBuf` 抽象类，对象引用计数器抽象类。本文暂时不解析，我们会在 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（三）内存泄露检测》](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/) 详细解析。

## 2.1 内部方法

### 2.1.1 构造方法

```java
/**
 * Recycler 处理器，用于回收对象
 */
private final Recycler.Handle<PooledByteBuf<T>> recyclerHandle;

/**
 * Chunk 对象
 */
protected PoolChunk<T> chunk;
/**
 * 从 Chunk 对象中分配的内存块所处的位置
 */
protected long handle;
/**
 * 内存空间。具体什么样的数据，通过子类设置泛型。
 */
protected T memory;
/**
 * {@link #memory} 开始位置
 *
 * @see #idx(int)
 */
protected int offset;
/**
 * 容量
 *
 * @see #capacity()
 */
protected int length;
/**
 * 占用 {@link #memory} 的大小
 */
int maxLength;
/**
 * TODO 1013 Chunk
 */
PoolThreadCache cache;
/**
 * 临时 ByteBuff 对象
 *
 * @see #internalNioBuffer()
 */
private ByteBuffer tmpNioBuf;
/**
 * ByteBuf 分配器对象
 */
private ByteBufAllocator allocator;

@SuppressWarnings("unchecked")
protected PooledByteBuf(Recycler.Handle<? extends PooledByteBuf<T>> recyclerHandle, int maxCapacity) {
    super(maxCapacity);
    this.recyclerHandle = (Handle<PooledByteBuf<T>>) recyclerHandle;
}
```

- `recyclerHandle` 属性，Recycler 处理器，用于回收**当前**对象。

- `chunk`属性，PoolChunk 对象。在 Netty 中，使用 Jemalloc 算法管理内存，而 Chunk 是里面的一种

  内存块。在这里，我们可以理解`memory`所属的 PoolChunk 对象。

  - `handle` 属性，从 Chunk 对象中分配的内存块所处的位置。具体的，胖友后面仔细看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/) 和 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（三）PoolSubpage》](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/) 。
  - `memory`属性，内存空间。具体什么样的数据，通过子类设置泛型(`T`)。例如：1) PooledDirectByteBuf 和 PooledUnsafeDirectByteBuf 为**ByteBuffer**；2) PooledHeapByteBuf 和 PooledUnsafeHeapByteBuf 为`byte[]`。
  - `offset` 属性，使用 `memory` 的开始位置。
    - `maxLength` 属性，**最大**使用 `memory` 的长度( 大小 )。

- `length` 属性，**目前**使用 `memory` 的长度( 大小 )。

- 😈 因为 `memory` 属性，可以被**多个** ByteBuf 使用。**每个** ByteBuf 使用范围为 `[offset, maxLength)` 。

- `cache` 属性，TODO 1013 Chunk

- `tmpNioBuf` 属性，临时 ByteBuff 对象，通过 `#tmpNioBuf()` 方法生成。详细解析，见 [「2.1.9 internalNioBuffer」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 。

- `allocator` 属性，ByteBuf 分配器。

### 2.1.2 init0

`#init0(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache)` 方法，初始化 PooledByteBuf 对象。代码如下：

```java
private void init0(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) {
    assert handle >= 0;
    assert chunk != null;

    // From PoolChunk 对象
    this.chunk = chunk;
    memory = chunk.memory;
    allocator = chunk.arena.parent;
    // 其他
    this.cache = cache;
    this.handle = handle;
    this.offset = offset;
    this.length = length;
    this.maxLength = maxLength;
    tmpNioBuf = null;
}
```

仔细的胖友，可能会发现，这是一个 `private` 私有方法。目前它被两个方法调用：

- ① `#init(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache)` 方法，一般是基于 **pooled** 的 PoolChunk 对象，初始化 PooledByteBuf 对象。代码如下：

  ```java
  void init(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) {
      init0(chunk, handle, offset, length, maxLength, cache);
  }
  ```

- ② `#initUnpooled(PoolChunk<T> chunk, int length)` 方法，基于 **unPoolooled** 的 PoolChunk 对象，初始化 PooledByteBuf 对象。代码如下：

  ```java
  void initUnpooled(PoolChunk<T> chunk, int length) {
      init0(chunk, 0, chunk.offset, length, length, null);
  }
  ```

  - 例如说 **Huge** 大小的 PoolChunk 对象。
  - 注意，传入的给 `#init0(...)` 方法的 `length` 和 `maxLength` 方法参数，**都是** `length` 。

可能胖友读到此处会一脸懵逼。其实，这是很正常的。可以在看完 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/) 后，在回过头来，理解理解。

### 2.1.3 reuse

`#reuse(int maxCapacity)` 方法，每次在重用 PooledByteBuf 对象时，需要调用该方法，重置属性。代码如下：

```java
/**
 * Method must be called before reuse this {@link PooledByteBufAllocator}
 */
final void reuse(int maxCapacity) {
    // 设置最大容量
    maxCapacity(maxCapacity);
    // 设置引用数量为 0
    setRefCnt(1);
    // 重置读写索引为 0
    setIndex0(0, 0);
    // 重置读写标记位为 0
    discardMarks();
}
```

也就是说，该方法在 [「2.1.2 init9」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) **之前**就调用了。在下文中，我们会看到，该方法的调用。

### 2.1.4 capacity

`#capacity()` 方法，获得容量。代码如下：

```java
@Override
public final int capacity() {
    return length;
}
```

**当前**容量的值为 `length` 属性。
但是，要注意的是，`maxLength` 属性，**不是表示最大容量**。`maxCapacity` 属性，才是真正表示最大容量。
那么，`maxLength` 属性有什么用？表示**占用** `memory` 的最大容量( 而不是 PooledByteBuf 对象的最大容量 )。在写入数据超过 `maxLength` 容量时，会进行扩容，但是容量的上限，为 `maxCapacity` 。

------

`#capacity(int newCapacity)` 方法，调整容量大小。在这个过程中，根据情况，可能对 `memory` 扩容或缩容。代码如下：

```java
 1: @Override
 2: public final ByteBuf capacity(int newCapacity) {
 3:     // 校验新的容量，不能超过最大容量
 4:     checkNewCapacity(newCapacity);
 5: 
 6:     // Chunk 内存，非池化
 7:     // If the request capacity does not require reallocation, just update the length of the memory.
 8:     if (chunk.unpooled) {
 9:         if (newCapacity == length) { // 相等，无需扩容 / 缩容
10:             return this;
11:         }
12:     // Chunk 内存，是池化
13:     } else {
14:         // 扩容
15:         if (newCapacity > length) {
16:             if (newCapacity <= maxLength) {
17:                 length = newCapacity;
18:                 return this;
19:             }
20:         // 缩容
21:         } else if (newCapacity < length) {
22:             // 大于 maxLength 的一半
23:             if (newCapacity > maxLength >>> 1) {
24:                 if (maxLength <= 512) {
25:                     // 因为 Netty SubPage 最小是 16 ，如果小于等 16 ，无法缩容。
26:                     if (newCapacity > maxLength - 16) {
27:                         length = newCapacity;
28:                         // 设置读写索引，避免超过最大容量
29:                         setIndex(Math.min(readerIndex(), newCapacity), Math.min(writerIndex(), newCapacity));
30:                         return this;
31:                     }
32:                 } else { // > 512 (i.e. >= 1024)
33:                     length = newCapacity;
34:                     // 设置读写索引，避免超过最大容量
35:                     setIndex(Math.min(readerIndex(), newCapacity), Math.min(writerIndex(), newCapacity));
36:                     return this;
37:                 }
38:             }
39:         // 相等，无需扩容 / 缩容
40:         } else {
41:             return this;
42:         }
43:     }
44: 
45:     // 重新分配新的内存空间，并将数据复制到其中。并且，释放老的内存空间。
46:     // Reallocation required.
47:     chunk.arena.reallocate(this, newCapacity, true);
48:     return this;
49: }
```

- 第 4 行：调用 `AbstractByteBuf#checkNewCapacity(int newCapacity)` 方法，校验新的容量，不能超过最大容量。代码如下：

  ```java
  protected final void checkNewCapacity(int newCapacity) {
      ensureAccessible();
      if (newCapacity < 0 || newCapacity > maxCapacity()) {
          throw new IllegalArgumentException("newCapacity: " + newCapacity + " (expected: 0-" + maxCapacity() + ')');
      }
  }
  ```

- 第 6 至 11 行：对于基于 **unPoolooled** 的 PoolChunk 对象，除非容量不变，否则会扩容或缩容，即【第 47 行】的代码。为什么呢？在 `#initUnpooled(PoolChunk<T> chunk, int length)` 方法中，我们可以看到，`maxLength` 和 `length` 是相等的，所以大于或小于时，需要进行扩容或缩容。

- 第 13 行：对于基于**poolooled**的 PoolChunk 对象，需要根据情况：

  - 第 39 至 42 行：容量未变，不进行扩容。类似【第 9 至 11 行】的代码。

  - 第 14 至 19 行：新容量**大于**当前容量，但是小于 `memory` 最大容量，仅仅修改当前容量，无需进行扩容。否则，第【第 47 行】的代码，进行**扩容**。

  - 第 20 至 38 行：新容量**小于**当前容量，但是不到`memory`最大容量的**一半**，因为缩容**相对**

    释放不多，无需进行缩容。否则，第【第 47 行】的代码，进行**缩容**。

    - 比较神奇的是【第 26 行】的 `newCapacity > maxLength - 16` 代码块。 笔者的理解是，Netty SubPage **最小**是 16 B ，如果小于等 16 ，无法缩容。

- 第 47 行：调用 `PoolArena#reallocate(PooledByteBuf<T> buf, int newCapacity, boolean freeOldMemory)`方法，**重新分配**新的内存空间，并将数据**复制**到其中。并且，**释放**老的内存空间。详细解析，见 [《TODO 1013 Chunk》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 中。

### 2.1.5 order

`#order()` 方法，返回字节序为 `ByteOrder.BIG_ENDIAN` 大端。代码如下：

```java
@Override
public final ByteOrder order() {
    return ByteOrder.BIG_ENDIAN;
}
```

统一**大端**模式。

> FROM [《深入浅出： 大小端模式》](https://www.bysocket.com/?p=615)
>
> 在网络上传输数据时，由于数据传输的两端对应不同的硬件平台，采用的存储字节顺序可能不一致。所以在 TCP/IP 协议规定了在网络上必须采用网络字节顺序，也就是大端模式。

### 2.1.6 unwrap

`#unwrap()` 方法，返回空，因为没有被装饰的 ByteBuffer 对象。代码如下：

```java
@Override
public final ByteBuf unwrap() {
    return null;
}
```

### 2.1.7 retainedSlice

`#retainedSlice()` 方法，代码如下：

```java
@Override
public final ByteBuf retainedSlice() {
    final int index = readerIndex();
    return retainedSlice(index, writerIndex() - index);
}

@Override
public final ByteBuf retainedSlice(int index, int length) {
    return PooledSlicedByteBuf.newInstance(this, this, index, length);
}
```

- 调用 `PooledSlicedByteBuf#newInstance(AbstractByteBuf unwrapped, ByteBuf wrapped, int index, int length)` 方法，创建**池化的** PooledSlicedByteBuf 对象。
- TODO 1016 派生类

### 2.1.8 retainedDuplicate

`#retainedDuplicate()` 方法，代码如下：

```java
@Override
public final ByteBuf retainedDuplicate() {
    return PooledDuplicatedByteBuf.newInstance(this, this, readerIndex(), writerIndex());
}
```

- 调用 `PooledSlicedByteBuf#newInstance(AbstractByteBuf unwrapped, ByteBuf wrapped, int readerIndex, int writerIndex)` 方法，创建**池化的** PooledDuplicatedByteBuf.newInstance 对象。
- TODO 1016 派生类

### 2.1.9 internalNioBuffer

`#internalNioBuffer()` 方法，获得临时 ByteBuf 对象( `tmpNioBuf` ) 。代码如下：

```java
protected final ByteBuffer internalNioBuffer() {
    ByteBuffer tmpNioBuf = this.tmpNioBuf;
    // 为空，创建临时 ByteBuf 对象
    if (tmpNioBuf == null) {
        this.tmpNioBuf = tmpNioBuf = newInternalNioBuffer(memory);
    }
    return tmpNioBuf;
}
```

- 当 `tmpNioBuf` 属性为空时，调用 `#newInternalNioBuffer(T memory)` 方法，创建 ByteBuffer 对象。因为 `memory`的类型不确定，所以该方法定义成**抽象方法**，由子类实现。代码如下：

  ```java
  protected abstract ByteBuffer newInternalNioBuffer(T memory);
  ```

------

为什么要有 `tmpNioBuf` 这个属性呢？以 PooledDirectByteBuf 举例子，代码如下：

```java
@Override
public int setBytes(int index, FileChannel in, long position, int length) throws IOException {
    checkIndex(index, length);
    // 获得临时 ByteBuf 对象
    ByteBuffer tmpBuf = internalNioBuffer();
    index = idx(index);
    tmpBuf.clear().position(index).limit(index + length);
    try {
        // 写入临时 ByteBuf 对象
        return in.read(tmpBuf, position);
    } catch (ClosedChannelException ignored) {
        return -1;
    }
}

private int getBytes(int index, FileChannel out, long position, int length, boolean internal) throws IOException {
    checkIndex(index, length);
    if (length == 0) {
        return 0;
    }

    // 获得临时 ByteBuf 对象
    ByteBuffer tmpBuf = internal ? internalNioBuffer() : memory.duplicate();
    index = idx(index);
    tmpBuf.clear().position(index).limit(index + length);
    // 写入到 FileChannel 中
    return out.write(tmpBuf, position);
}
```

### 2.1.10 deallocate

`#deallocate()` 方法，当引用计数为 0 时，调用该方法，进行内存回收。代码如下：

```java
@Override
protected final void deallocate() {
    if (handle >= 0) {
        // 重置属性
        final long handle = this.handle;
        this.handle = -1;
        memory = null;
        tmpNioBuf = null;
        // 释放内存回 Arena 中
        chunk.arena.free(chunk, handle, maxLength, cache);
        chunk = null;
        // 回收对象
        recycle();
    }
}

private void recycle() {
    recyclerHandle.recycle(this); // 回收对象
}
```

### 2.1.11 idx

`#idx(int index)` 方法，获得指定位置在 `memory` 变量中的位置。代码如下：

```
protected final int idx(int index) {
    return offset + index;
}

```

## 2.2 PooledDirectByteBuf

`io.netty.buffer.PooledDirectByteBuf` ，实现 PooledByteBuf 抽象类，基于 **ByteBuffer** 的**可重用** ByteBuf 实现类。所以，泛型 `T` 为 ByteBuffer ，即：

```
final class PooledDirectByteBuf extends PooledByteBuf<ByteBuffer>

```

### 2.2.1 构造方法

```
private PooledDirectByteBuf(Recycler.Handle<PooledDirectByteBuf> recyclerHandle, int maxCapacity) {
    super(recyclerHandle, maxCapacity);
}

```

### 2.2.2 newInstance

`#newInstance(int maxCapacity)` **静态**方法，“创建” PooledDirectByteBuf 对象。代码如下：

```
/**
 * Recycler 对象
 */
private static final Recycler<PooledDirectByteBuf> RECYCLER = new Recycler<PooledDirectByteBuf>() {

    @Override
    protected PooledDirectByteBuf newObject(Handle<PooledDirectByteBuf> handle) {
        return new PooledDirectByteBuf(handle, 0); // 真正创建 PooledDirectByteBuf 对象
    }

};

static PooledDirectByteBuf newInstance(int maxCapacity) {
    // 从 Recycler 的对象池中获得 PooledDirectByteBuf 对象
    PooledDirectByteBuf buf = RECYCLER.get();
    // 重置 PooledDirectByteBuf 的属性
    buf.reuse(maxCapacity);
    return buf;
}

```

### 2.2.3 newInternalNioBuffer

`#newInternalNioBuffer(ByteBuffer memory)` 方法，获得临时 ByteBuf 对象( `tmpNioBuf` ) 。代码如下：

```
@Override
protected ByteBuffer newInternalNioBuffer(ByteBuffer memory) {
    return memory.duplicate();
}

```

- 调用 `ByteBuffer#duplicate()` 方法，复制一个 ByteBuffer 对象，**共享**里面的数据。

### 2.2.4 isDirect

`#isDirect()` 方法，获得内部类型是否为 Direct ，返回 `true` 。代码如下：

```
@Override
public boolean isDirect() {
    return true;
}

```

### 2.2.5 读取 / 写入操作

老样子，我们以 Int 类型为例子，来看看它的读取和写入操作的实现代码。代码如下：

```
@Override
protected int _getInt(int index) {
    return memory.getInt(idx(index));
}

@Override
protected void _setInt(int index, int value) {
    memory.putInt(idx(index), value);
}

```

### 2.2.6 copy

`#copy(int index, int length)` 方法，复制指定范围的数据到新创建的 Direct ByteBuf 对象。代码如下：

```
@Override
public ByteBuf copy(int index, int length) {
    // 校验索引
    checkIndex(index, length);
    // 创建一个 Direct ByteBuf 对象
    ByteBuf copy = alloc().directBuffer(length, maxCapacity());
    // 写入数据
    copy.writeBytes(this, index, length);
    return copy;
}

```

### 2.2.7 转换 NIO ByteBuffer 操作

#### 2.2.7.1 nioBufferCount

`#nioBufferCount()` 方法，返回 ByteBuf 包含 ByteBuffer 数量为 **1** 。代码如下：

```
@Override
public int nioBufferCount() {
    return 1;
}

```

#### 2.2.7.2 nioBuffer

`#nioBuffer(int index, int length)` 方法，返回 ByteBuf **指定范围**包含的 ByteBuffer 对象( **共享** )。代码如下：

```
@Override
public ByteBuffer nioBuffer(int index, int length) {
    checkIndex(index, length);
    // memory 中的开始位置
    index = idx(index);
    // duplicate 复制一个 ByteBuffer 对象，共享数据
    // position + limit 设置位置和大小限制
    // slice 创建 [position, limit] 子缓冲区，共享数据
    return ((ByteBuffer) memory.duplicate().position(index).limit(index + length)).slice();
}

```

- 代码比较简单，看具体注释。

#### 2.2.7.3 nioBuffers

`#nioBuffers(int index, int length)` 方法，返回 ByteBuf **指定范围**内包含的 ByteBuffer 数组( **共享** )。代码如下：

```
@Override
public ByteBuffer[] nioBuffers(int index, int length) {
    return new ByteBuffer[] { nioBuffer(index, length) };
}

```

- 在 `#nioBuffer(int index, int length)` 方法的基础上，创建大小为 1 的 ByteBuffer 数组。

#### 2.2.7.4 internalNioBuffer

`#internalNioBuffer(int index, int length)` 方法，返回 ByteBuf **指定范围**内的 ByteBuffer 对象( **共享** )。代码如下：

```
@Override
public ByteBuffer internalNioBuffer(int index, int length) {
    checkIndex(index, length);
    // memory 中的开始位置
    index = idx(index);
    // clear 标记清空（不会清理数据）
    // position + limit 设置位置和大小限制
    return (ByteBuffer) internalNioBuffer().clear().position(index).limit(index + length);
}

```

- 代码比较简单，看具体注释。
- 因为是基于 `tmpNioBuf` 属性实现，所以方法在命名上，以 `"internal"` 打头。

### 2.2.8 Heap 相关方法

不支持 Heap 相关方法。代码如下：

```
@Override
public boolean hasArray() {
    return false;
}

@Override
public byte[] array() {
    throw new UnsupportedOperationException("direct buffer");
}

@Override
public int arrayOffset() {
    throw new UnsupportedOperationException("direct buffer");
}

```

### 2.2.9 Unsafe 相关方法

不支持 Unsafe 相关方法。代码如下：

```
@Override
public boolean hasMemoryAddress() {
    return false;
}

@Override
public long memoryAddress() {
    throw new UnsupportedOperationException();
}

```

## 2.3 PooledHeapByteBuf

`io.netty.buffer.PooledHeapByteBuf` ，实现 PooledByteBuf 抽象类，基于 **ByteBuffer** 的**可重用** ByteBuf 实现类。所以，泛型 `T` 为 `byte[]` ，即：

```
class PooledHeapByteBuf extends PooledByteBuf<byte[]> {

```

### 2.3.1 构造方法

和 [「2.2.1 构造方法」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.3.2 newInstance

和 [「2.2.2 newInstance」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.3.3 newInternalNioBuffer

`#newInternalNioBuffer(byte[] memory)` 方法，获得临时 ByteBuf 对象( `tmpNioBuf` ) 。代码如下：

```
@Override
protected final ByteBuffer newInternalNioBuffer(byte[] memory) {
    return ByteBuffer.wrap(memory);
}

```

- 调用 `ByteBuffer#wrap(byte[] array)` 方法，创建 ByteBuffer 对象。注意，返回的是 HeapByteBuffer 对象。

### 2.3.4 isDirect

`#isDirect()` 方法，获得内部类型是否为 Direct ，返回 `false` 。代码如下：

```
@Override
public boolean isDirect() {
    return false;
}

```

### 2.3.5 读取 / 写入操作

老样子，我们以 Int 类型为例子，来看看它的读取和写入操作的实现代码。

① **读取**操作：

```
@Override
protected int _getInt(int index) {
    return HeapByteBufUtil.getInt(memory, idx(index));
}

// HeapByteBufUtil.java
static int getInt(byte[] memory, int index) {
    return  (memory[index]     & 0xff) << 24 |
            (memory[index + 1] & 0xff) << 16 |
            (memory[index + 2] & 0xff) <<  8 |
            memory[index + 3] & 0xff;
}

```

② **写入**操作：

```
@Override
protected void _setInt(int index, int   value) {
    HeapByteBufUtil.setInt(memory, idx(index), value);
}

// HeapByteBufUtil.java
static void setInt(byte[] memory, int index, int value) {
    memory[index]     = (byte) (value >>> 24);
    memory[index + 1] = (byte) (value >>> 16);
    memory[index + 2] = (byte) (value >>> 8);
    memory[index + 3] = (byte) value;
}

```

### 2.3.6 copy

`#copy(int index, int length)` 方法，复制指定范围的数据到新创建的 Heap ByteBuf 对象。代码如下：

```
@Override
public ByteBuf copy(int index, int length) {
    // 校验索引
    checkIndex(index, length);
    // 创建一个 Heap ByteBuf 对象
    ByteBuf copy = alloc().heapBuffer(length, maxCapacity());
    // 写入数据
    copy.writeBytes(this, index, length);
    return copy;
}

```

和 PooledDirectByteBuf [「2.2.6 copy」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 的差异在于，创建的是 **Heap** ByteBuf 对象。

### 2.3.7 转换 NIO ByteBuffer 操作

#### 2.3.7.1 nioBufferCount

和 [「2.2.7.1 nioBufferCount」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

#### 2.3.7.2 nioBuffer

`#nioBuffer(int index, int length)` 方法，返回 ByteBuf **指定范围**包含的 ByteBuffer 对象( **共享** )。代码如下：

```
@Override
public final ByteBuffer nioBuffer(int index, int length) {
    checkIndex(index, length);
    // memory 中的开始位置
    index = idx(index);
    // 创建 ByteBuffer 对象
    ByteBuffer buf =  ByteBuffer.wrap(memory, index, length);
    // slice 创建 [position, limit] 子缓冲区
    return buf.slice();
}

```

- 代码比较简单，看具体注释。

#### 2.3.7.3 nioBuffers

和 [「2.2.7.3 nioBuffers」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

#### 2.3.7.4 internalNioBuffer

和 [「2.2.7.4 nioBuffers」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

### 2.3.8 Heap 相关方法

```
@Override
public final boolean hasArray() {
    return true;
}

@Override
public final byte[] array() {
    ensureAccessible();
    return memory;
}

@Override
public final int arrayOffset() {
    return offset;
}

```

### 2.3.8 Unsafe 相关方法

和 [「2.2.9 Unsafe 相关方法」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

## 2.4 PooledUnsafeDirectByteBuf

> 老艿艿：它是 [「2.2 PooledDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 对应的基于 Unsafe 版本的实现类。

`io.netty.buffer.PooledUnsafeDirectByteBuf` ，实现 PooledByteBuf 抽象类，基于 **ByteBuffer** + **Unsafe** 的**可重用** ByteBuf 实现类。所以，泛型 `T` 为 `ByteBuffer` ，即：

```
final class PooledUnsafeDirectByteBuf extends PooledByteBuf<ByteBuffer>

```

### 2.4.1 构造方法

和 [「2.2.1 构造方法」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.4.2 newInstance

和 [「2.2.2 newInstance」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.4.3 初始化

PooledUnsafeDirectByteBuf 重写了初始化相关的方法，代码如下：

```
@Override
void init(PoolChunk<ByteBuffer> chunk, long handle, int offset, int length, int maxLength,
          PoolThreadCache cache) {
    // 调用父初始化方法
    super.init(chunk, handle, offset, length, maxLength, cache);
    // 初始化内存地址
    initMemoryAddress(); // <1>
}

@Override
void initUnpooled(PoolChunk<ByteBuffer> chunk, int length) {
    // 调用父初始化方法
    super.initUnpooled(chunk, length);
    // 初始化内存地址
    initMemoryAddress(); // <2>
}

```

- 在 `<1>` 处，增加调用 `#initMemoryAddress()` 方法，初始化内存地址。代码如下：

  ```
  /**
   * 内存地址
   */
  private long memoryAddress;
  
  private void initMemoryAddress() {
      memoryAddress = PlatformDependent.directBufferAddress(memory) + offset; // <2>
  }
  
  ```

  - 调用 `PlatformDependent#directBufferAddress(ByteBuffer buffer)` 方法，获得 ByteBuffer 对象的起始内存地址。代码如下：

    ```
    // PlatformDependent.java
    public static long directBufferAddress(ByteBuffer buffer) {
        return PlatformDependent0.directBufferAddress(buffer);
    }
    
    // PlatformDependent0.java
    static final Unsafe UNSAFE;
    
    static long directBufferAddress(ByteBuffer buffer) {
        return getLong(buffer, ADDRESS_FIELD_OFFSET);
    }
    
    private static long getLong(Object object, long fieldOffset) {
        return UNSAFE.getLong(object, fieldOffset);
    }
    
    ```

    - 对于 Unsafe 类不熟悉的胖友，可以看看 [《Java Unsafe 类》](https://blog.csdn.net/zhxdick/article/details/52003123)

  - 注意，`<2>` 处的代码，已经将 `offset` 添加到 `memoryAddress` 中。所以在 `#addr(int index)` 方法中，求指定位置( `index` ) 在内存地址的顺序，不用再添加。代码如下：

    ```
    private long addr(int index) {
        return memoryAddress + index;
    }
    
    ```

    - x

### 2.4.4 newInternalNioBuffer

和 [「2.2.3 newInternalNioBuffer」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.4.5 isDirect

和 [「2.2.4 isDirect」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.4.6 读取 / 写入操作

老样子，我们以 Int 类型为例子，来看看它的读取和写入操作的实现代码。

① **读取**操作：

```
@Override
protected int _getInt(int index) {
    return UnsafeByteBufUtil.getInt(addr(index));
}

// UnsafeByteBufUtil.java
static int getInt(long address) {
    if (UNALIGNED) {
        int v = PlatformDependent.getInt(address);
        return BIG_ENDIAN_NATIVE_ORDER ? v : Integer.reverseBytes(v);
    }
    return PlatformDependent.getByte(address) << 24 |
           (PlatformDependent.getByte(address + 1) & 0xff) << 16 |
           (PlatformDependent.getByte(address + 2) & 0xff) <<  8 |
           PlatformDependent.getByte(address + 3)  & 0xff;
}

// PlatformDependent.java
public static int getInt(long address) {
    return PlatformDependent0.getInt(address);
}

// PlatformDependent0.java
static int getInt(long address) {
    return UNSAFE.getInt(address);
}

```

② **写入**操作：

```
@Override
protected void _setInt(int index, int value) {
    UnsafeByteBufUtil.setInt(addr(index), value);
}

// UnsafeByteBufUtil.java
static void setInt(long address, int value) {
    if (UNALIGNED) {
        PlatformDependent.putInt(address, BIG_ENDIAN_NATIVE_ORDER ? value : Integer.reverseBytes(value));
    } else {
        PlatformDependent.putByte(address, (byte) (value >>> 24));
        PlatformDependent.putByte(address + 1, (byte) (value >>> 16));
        PlatformDependent.putByte(address + 2, (byte) (value >>> 8));
        PlatformDependent.putByte(address + 3, (byte) value);
    }
}

// PlatformDependent.java
public static void putInt(long address, int value) {
    PlatformDependent0.putInt(address, value);
}

// PlatformDependent0.java
static void putInt(long address, int value) {
    UNSAFE.putInt(address, value);
}

```

### 2.4.7 copy

`#copy(int index, int length)` 方法，复制指定范围的数据到新创建的 Direct ByteBuf 对象。代码如下：

```
@Override
public ByteBuf copy(int index, int length) {
    return UnsafeByteBufUtil.copy(this, addr(index), index, length);
}

// UnsafeByteBufUtil.java
static ByteBuf copy(AbstractByteBuf buf, long addr, int index, int length) {
    buf.checkIndex(index, length);
    // 创建 Direct ByteBuffer 对象
    ByteBuf copy = buf.alloc().directBuffer(length, buf.maxCapacity());
    if (length != 0) {
        if (copy.hasMemoryAddress()) {
            // 使用 Unsafe 操作来复制
            PlatformDependent.copyMemory(addr, copy.memoryAddress(), length);
            copy.setIndex(0, length);
        } else {
            copy.writeBytes(buf, index, length);
        }
    }
    return copy;
}

// PlatformDependent.java
public static void copyMemory(long srcAddr, long dstAddr, long length) {
    PlatformDependent0.copyMemory(srcAddr, dstAddr, length);
}

// PlatformDependent0.java
static void copyMemory(long srcAddr, long dstAddr, long length) {
    //UNSAFE.copyMemory(srcAddr, dstAddr, length);
    while (length > 0) {
        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);
        UNSAFE.copyMemory(srcAddr, dstAddr, size);
        length -= size;
        srcAddr += size;
        dstAddr += size;
    }
}

```

### 2.4.8 转换 NIO ByteBuffer 操作

#### 2.4.8.1 nioBufferCount

和 [「2.2.7.1 nioBufferCount」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

#### 2.4.8.2 nioBuffer

和 [「2.2.7.2 nioBuffer」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

#### 2.4.8.3 nioBuffers

和 [「2.2.7.3 nioBuffers」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

#### 2.4.8.4 internalNioBuffer

和 [「2.2.7.4 internalNioBuffer」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 一致。

### 2.4.9 Heap 相关方法

不支持 Heap 相关方法。

### 2.4.10 Unsafe 相关方法。

```
@Override
public boolean hasMemoryAddress() {
    return true;
}

@Override
public long memoryAddress() {
    ensureAccessible();
    return memoryAddress;
}

```

### 2.4.11 newSwappedByteBuf

> `#newSwappedByteBuf()` 方法的**重写**，是 Unsafe 类型独有的。

`#newSwappedByteBuf()` 方法，创建 SwappedByteBuf 对象。代码如下：

```
@Override
protected SwappedByteBuf newSwappedByteBuf() {
    if (PlatformDependent.isUnaligned()) { // 支持
        // Only use if unaligned access is supported otherwise there is no gain.
        return new UnsafeDirectSwappedByteBuf(this);
    }
    return super.newSwappedByteBuf();
}

```

- 对于 Linux 环境下，一般是支持 unaligned access( 对齐访问 )，所以返回的是 UnsafeDirectSwappedByteBuf 对象。详细解析，见 [《TODO 1016 派生类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 。
- 为什么要对齐访问呢？可看 [《什么是字节对齐，为什么要对齐?》](https://www.zhihu.com/question/23791224) 。有趣。

## 2.5 PooledUnsafeHeapByteBuf

`io.netty.buffer.PooledUnsafeHeapByteBuf` ，实现 PooledHeapByteBuf 类，在 [「2.3 PooledHeapByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#)的基础上，基于 **Unsafe** 的**可重用** ByteBuf 实现类。所以，泛型 `T` 为 `byte[]` ，即：

```
final class PooledUnsafeHeapByteBuf extends PooledHeapByteBuf

```

也因此，PooledUnsafeHeapByteBuf 需要实现的方法，灰常少。

### 2.5.1 构造方法

和 [「2.2.1 构造方法」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.5.2 newInstance

和 [「2.2.2 newInstance」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 相同。

### 2.5.3 读取 / 写入操作

老样子，我们以 Int 类型为例子，来看看它的读取和写入操作的实现代码。

① **读取**操作：

```
@Override
protected int _getInt(int index) {
    return UnsafeByteBufUtil.getInt(memory, idx(index));
}

// UnsafeByteBufUtil.java
static int getInt(byte[] array, int index) {
    if (UNALIGNED) {
        int v = PlatformDependent.getInt(array, index);
        return BIG_ENDIAN_NATIVE_ORDER ? v : Integer.reverseBytes(v);
    }
    return PlatformDependent.getByte(array, index) << 24 |
           (PlatformDependent.getByte(array, index + 1) & 0xff) << 16 |
           (PlatformDependent.getByte(array, index + 2) & 0xff) <<  8 |
           PlatformDependent.getByte(array, index + 3) & 0xff;
}

// PlatformDependent.java
public static int getInt(byte[] data, int index) {
    return PlatformDependent0.getInt(data, index);
}

// PlatformDependent0.java
static int getInt(byte[] data, int index) {
    return UNSAFE.getInt(data, BYTE_ARRAY_BASE_OFFSET + index);
}

```

- 基于 Unsafe 操作 `byte[]` 数组。

② **写入**操作：

```
@Override
protected void _setInt(int index, int value) {
    UnsafeByteBufUtil.setInt(memory, idx(index), value);
}

// UnsafeByteBufUtil.java
static void setInt(byte[] array, int index, int value) {
    if (UNALIGNED) {
        PlatformDependent.putInt(array, index, BIG_ENDIAN_NATIVE_ORDER ? value : Integer.reverseBytes(value));
    } else {
        PlatformDependent.putByte(array, index, (byte) (value >>> 24));
        PlatformDependent.putByte(array, index + 1, (byte) (value >>> 16));
        PlatformDependent.putByte(array, index + 2, (byte) (value >>> 8));
        PlatformDependent.putByte(array, index + 3, (byte) value);
    }
}

// PlatformDependent.java
public static void putInt(byte[] data, int index, int value) {
    PlatformDependent0.putInt(data, index, value);
}

// PlatformDependent0.java
static void putInt(byte[] data, int index, int value) {
    UNSAFE.putInt(data, BYTE_ARRAY_BASE_OFFSET + index, value);
}

```

### 2.5.4 newSwappedByteBuf

> `#newSwappedByteBuf()` 方法的**重写**，是 Unsafe 类型独有的。

`#newSwappedByteBuf()` 方法，创建 SwappedByteBuf 对象。代码如下：

```
@Override
@Deprecated
protected SwappedByteBuf newSwappedByteBuf() {
    if (PlatformDependent.isUnaligned()) {
        // Only use if unaligned access is supported otherwise there is no gain.
        return new UnsafeHeapSwappedByteBuf(this);
    }
    return super.newSwappedByteBuf();
}

```

- 对于 Linux 环境下，一般是支持 unaligned access( 对齐访问 )，所以返回的是 UnsafeHeapSwappedByteBuf 对象。详细解析，见 [《TODO 1016 派生类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 。

# 3. UnpooledByteBuf

😈 不存在 UnpooledByteBuf 这样一个类，主要是为了**聚合**所有 Unpooled 类型的 ByteBuf 实现类。

## 3.1 UnpooledDirectByteBuf

`io.netty.buffer.UnpooledDirectByteBuf` ，实现 AbstractReferenceCountedByteBuf 抽象类，对应 [「2.2 PooledDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 的**非池化** ByteBuf 实现类。

### 3.1.1 构造方法

```
/**
 * ByteBuf 分配器对象
 */
private final ByteBufAllocator alloc;

/**
 * 数据 ByteBuffer 对象
 */
private ByteBuffer buffer;
/**
 * 临时 ByteBuffer 对象
 */
private ByteBuffer tmpNioBuf;
/**
 * 容量
 */
private int capacity;
/**
 * 是否需要释放 <1>
 *
 * 如果 {@link #buffer} 从外部传入，则需要进行释放，即 {@link #UnpooledDirectByteBuf(ByteBufAllocator, ByteBuffer, int)} 构造方法。
 */
private boolean doNotFree;

public UnpooledDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
    // 设置最大容量
    super(maxCapacity);
    if (alloc == null) {
        throw new NullPointerException("alloc");
    }
    if (initialCapacity < 0) {
        throw new IllegalArgumentException("initialCapacity: " + initialCapacity);
    }
    if (maxCapacity < 0) {
        throw new IllegalArgumentException("maxCapacity: " + maxCapacity);
    }
    if (initialCapacity > maxCapacity) {
        throw new IllegalArgumentException(String.format("initialCapacity(%d) > maxCapacity(%d)", initialCapacity, maxCapacity));
    }

    this.alloc = alloc;

    // 创建 Direct ByteBuffer 对象
    // 设置数据 ByteBuffer 对象
    setByteBuffer(ByteBuffer.allocateDirect(initialCapacity));
}

protected UnpooledDirectByteBuf(ByteBufAllocator alloc, ByteBuffer initialBuffer, int maxCapacity) {
    // 设置最大容量
    super(maxCapacity);
    if (alloc == null) {
        throw new NullPointerException("alloc");
    }
    if (initialBuffer == null) {
        throw new NullPointerException("initialBuffer");
    }
    if (!initialBuffer.isDirect()) { // 必须是 Direct
        throw new IllegalArgumentException("initialBuffer is not a direct buffer.");
    }
    if (initialBuffer.isReadOnly()) { // 必须可写
        throw new IllegalArgumentException("initialBuffer is a read-only buffer.");
    }

    // 获得剩余可读字节数，作为初始容量大小 <2>
    int initialCapacity = initialBuffer.remaining();
    if (initialCapacity > maxCapacity) {
        throw new IllegalArgumentException(String.format(
                "initialCapacity(%d) > maxCapacity(%d)", initialCapacity, maxCapacity));
    }

    this.alloc = alloc;

    // 标记为 true 。因为 initialBuffer 是从外部传递进来，释放的工作，不交给当前 UnpooledDirectByteBuf 对象。
    doNotFree = true; <1>

    // slice 切片
    // 设置数据 ByteBuffer 对象
    setByteBuffer(initialBuffer.slice().order(ByteOrder.BIG_ENDIAN));
    // 设置写索引 <2>
    writerIndex(initialCapacity);
}

```

- 代码比较简单，主要要理解下 `<1>` 和 `<2>` 两处。

- 调用 `#allocateDirect(int initialCapacity)` 方法，创建 Direct ByteBuffer 对象。代码如下：

  ```
  protected ByteBuffer allocateDirect(int initialCapacity) {
      return ByteBuffer.allocateDirect(initialCapacity);
  }
  
  ```

- 调用 `#setByteBuffer(ByteBuffer buffer)` 方法，设置数据 ByteBuffer 对象。如果有老的**自己的**( 指的是自己创建的 ) `buffer` 对象，需要进行释放。代码如下：

  ```
  private void setByteBuffer(ByteBuffer buffer) {
      ByteBuffer oldBuffer = this.buffer;
      if (oldBuffer != null) {
          // 标记为 false 。因为设置的 ByteBuffer 对象，是 UnpooledDirectByteBuf 自己创建的
          if (doNotFree) {
              doNotFree = false;
          } else {
              // 释放老的 buffer 对象
              freeDirect(oldBuffer); // <3>
          }
      }
  
      // 设置 buffer
      this.buffer = buffer;
      // 重置 tmpNioBuf 为 null
      tmpNioBuf = null;
      // 设置容量
      capacity = buffer.remaining();
  }
  
  ```

  - `<3>` 处，调用 `#freeDirect(ByteBuffer buffer)` 方法，释放**老的** `buffer` 对象。详细解析，见 [「3.1.3 deallocate」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 。

### 3.1.2 capacity

`#capacity()` 方法，获得容量。代码如下：

```
@Override
public int capacity() {
    return capacity;
}

```

------

`#capacity(int newCapacity)` 方法，调整容量大小。在这个过程中，根据情况，可能对 `buffer` 扩容或缩容。代码如下：

```
@SuppressWarnings("Duplicates")
@Override
public ByteBuf capacity(int newCapacity) {
    // 校验新的容量，不能超过最大容量
    checkNewCapacity(newCapacity);

    int readerIndex = readerIndex();
    int writerIndex = writerIndex();

    int oldCapacity = capacity;
    // 扩容
    if (newCapacity > oldCapacity) {
        ByteBuffer oldBuffer = buffer;
        // 创建新的 Direct ByteBuffer 对象
        ByteBuffer newBuffer = allocateDirect(newCapacity);
        // 复制数据到新的 buffer 对象
        oldBuffer.position(0).limit(oldBuffer.capacity());
        newBuffer.position(0).limit(oldBuffer.capacity());
        newBuffer.put(oldBuffer);
        newBuffer.clear(); // 因为读取和写入，使用 readerIndex 和 writerIndex ，所以没关系。
        // 设置新的 buffer 对象，并根据条件释放老的 buffer 对象
        setByteBuffer(newBuffer);
    // 缩容
    } else if (newCapacity < oldCapacity) {
        ByteBuffer oldBuffer = buffer;
        // 创建新的 Direct ByteBuffer 对象
        ByteBuffer newBuffer = allocateDirect(newCapacity);
        if (readerIndex < newCapacity) {
            // 如果写索引超过新容量，需要重置下，设置为最大容量。否则就越界了。
            if (writerIndex > newCapacity) {
                writerIndex(writerIndex = newCapacity);
            }
            // 复制数据到新的 buffer 对象
            oldBuffer.position(readerIndex).limit(writerIndex);
            newBuffer.position(readerIndex).limit(writerIndex);
            newBuffer.put(oldBuffer);
            newBuffer.clear(); // 因为读取和写入，使用 readerIndex 和 writerIndex ，所以没关系。
        } else {
            // 因为读索引超过新容量，所以写索引超过新容量
            // 如果读写索引都超过新容量，需要重置下，都设置为最大容量。否则就越界了。
            setIndex(newCapacity, newCapacity);
            // 这里要注意下，老的数据，相当于不进行复制，因为已经读取完了。
        }
        // 设置新的 buffer 对象，并根据条件释放老的 buffer 对象
        setByteBuffer(newBuffer);
    }
    return this;
}

```

- 虽然代码比较长，实际很简单。胖友自己耐心看下注释进行理解下噢。

### 3.1.3 deallocate

`#deallocate()` 方法，当引用计数为 0 时，调用该方法，进行内存回收。代码如下：

```
@Override
protected void deallocate() {
    ByteBuffer buffer = this.buffer;
    if (buffer == null) {
        return;
    }
    // 置空 buffer 属性
    this.buffer = null;

    // 释放 buffer 对象
    if (!doNotFree) {
        freeDirect(buffer);
    }
}

```

- `#freeDirect(ByteBuffer buffer)` 方法，释放 `buffer` 对象。代码如下：

  ```
  protected void freeArray(byte[] array) {
      PlatformDependent.freeDirectBuffer(buffer);
  }
  
  // PlatformDependent.java
  private static final Cleaner NOOP = new Cleaner() { ... }
  
  public static void freeDirectBuffer(ByteBuffer buffer) {
      CLEANER.freeDirectBuffer(buffer);
  }
  
  ```

  - 通过调用 `io.netty.util.internal.Cleaner#freeDirectBuffer(ByteBuffer buffer)` 方法，释放 Direct ByteBuffer 对象。因为 Java 的版本不同，调用的方法，所以 Cleaner 有两个 实现类：
  - `io.netty.util.internal.CleanerJava9` ，适用于 Java9+ 的版本，通过反射调用 DirectByteBuffer 对象的 `#invokeCleaner()` 方法，进行释放。
  - `io.netty.util.internal.CleanerJava6` ，适用于 Java6+ 的版本，通过反射获得 DirectByteBuffer 对象的 `#cleaner()` 方法，从而调用 `sun.misc.Cleaner#clean()` 方法，进行释放。
  - 虽然实现略有不同，但是原理是一致的。感兴趣的胖友，自己看下 CleanerJava9 和 CleanerJava6 的实现代码。

### 3.1.4 其它方法

其他方法，和 [「2.2 PooledDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。

## 3.2 UnpooledHeapByteBuf

`io.netty.buffer.UnpooledHeapByteBuf` ，实现 AbstractReferenceCountedByteBuf 抽象类，对应 [「2.3 PooledHeapByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 的**非池化** ByteBuf 实现类。

### 3.2.1 构造方法

```
/**
 * ByteBuf 分配器对象
 */
private final ByteBufAllocator alloc;
/**
 * 字节数组
 */
byte[] array;
/**
 * 临时 ByteBuff 对象
 */
private ByteBuffer tmpNioBuf;

public UnpooledHeapByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
    // 设置最大容量
    super(maxCapacity);

    checkNotNull(alloc, "alloc");

    if (initialCapacity > maxCapacity) {
        throw new IllegalArgumentException(String.format(
                "initialCapacity(%d) > maxCapacity(%d)", initialCapacity, maxCapacity));
    }

    this.alloc = alloc;

    // 创建并设置字节数组
    setArray(allocateArray(initialCapacity));

    // 设置读写索引
    setIndex(0, 0);
}

protected UnpooledHeapByteBuf(ByteBufAllocator alloc, byte[] initialArray, int maxCapacity) {
    // 设置最大容量
    super(maxCapacity);

    checkNotNull(alloc, "alloc");
    checkNotNull(initialArray, "initialArray");

    if (initialArray.length > maxCapacity) {
        throw new IllegalArgumentException(String.format(
                "initialCapacity(%d) > maxCapacity(%d)", initialArray.length, maxCapacity));
    }

    this.alloc = alloc;

    // 设置字节数组
    setArray(initialArray);

    // 设置读写索引
    setIndex(0, initialArray.length);
}

```

- 第一、二个构造方法的区别，后者字节数组是否从方法参数( `initialArray` )传递进来。

- 调用 `#allocateArray(int initialCapacity)` 方法，创建字节数组。

  ```
  protected byte[] allocateArray(int initialCapacity) {
      return new byte[initialCapacity];
  }
  
  ```

- 调用 `#setArray(byte[] initialArray)` 方法，设置 `array` 属性。代码如下：

  ```
      private void setArray(byte[] initialArray) {
          array = initialArray;
          tmpNioBuf = null;
      }
  
  ```

  ### 3.2.2 capacity

  `#capacity()` 方法，获得容量。代码如下：

  ```Java
  @Override
  public int capacity() {
      return array.length;
  }
  
  
  ```

  ```
  
  ```

- 使用字节数组的大小，作为当前容量上限。

------

`#capacity(int newCapacity)` 方法，调整容量大小。在这个过程中，根据情况，可能对 `array` 扩容或缩容。代码如下：

```
@Override
public ByteBuf capacity(int newCapacity) {
    // // 校验新的容量，不能超过最大容量
    checkNewCapacity(newCapacity);

    int oldCapacity = array.length;
    byte[] oldArray = array;

    // 扩容
    if (newCapacity > oldCapacity) {
        // 创建新数组
        byte[] newArray = allocateArray(newCapacity);
        // 复制【全部】数据到新数组
        System.arraycopy(oldArray, 0, newArray, 0, oldArray.length);
        // 设置数组
        setArray(newArray);
        // 释放老数组
        freeArray(oldArray);
    // 缩容
    } else if (newCapacity < oldCapacity) {
        // 创建新数组
        byte[] newArray = allocateArray(newCapacity);
        int readerIndex = readerIndex();
        if (readerIndex < newCapacity) {
            // 如果写索引超过新容量，需要重置下，设置为最大容量。否则就越界了。
            int writerIndex = writerIndex();
            if (writerIndex > newCapacity) {
                writerIndex(writerIndex = newCapacity);
            }
            // 只复制【读取段】数据到新数组
            System.arraycopy(oldArray, readerIndex, newArray, readerIndex, writerIndex - readerIndex);
        } else {
            // 因为读索引超过新容量，所以写索引超过新容量
            // 如果读写索引都超过新容量，需要重置下，都设置为最大容量。否则就越界了。
            setIndex(newCapacity, newCapacity);
            // 这里要注意下，老的数据，相当于不进行复制，因为已经读取完了。
        }
        // 设置数组
        setArray(newArray);
        // 释放老数组
        freeArray(oldArray);
    }
    return this;
}

```

- 虽然代码比较长，实际很简单。胖友自己耐心看下注释进行理解下噢。😈 和 [「3.1.2 capacity」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一直的。

### 3.2.3 deallocate

`#deallocate()` 方法，当引用计数为 0 时，调用该方法，进行内存回收。代码如下：

```
@Override
protected void deallocate() {
    // 释放老数组
    freeArray(array);
    // 设置为空字节数组
    array = EmptyArrays.EMPTY_BYTES;
}

```

- `#freeArray(byte[] array)` 方法，释放数组。代码如下：

  ```
  protected void freeArray(byte[] array) {
      // NOOP
  }
  
  ```

  - 字节数组，无引用后，自然就会被 GC 回收。

### 3.2.4 其它方法

其它方法，和 [「2.3 PooledHeapByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。

## 3.3 UnpooledUnsafeDirectByteBuf

`io.netty.buffer.UnpooledUnsafeDirectByteBuf` ，实现 AbstractReferenceCountedByteBuf 抽象类，对应 `「2.4 PooledUnsafeDirectByteBuf」` 的**非池化** ByteBuf 实现类。

- 构造方法、`#capacity(...)` 方法、`#deallocate()` 方法，和 [「3.1 PooledDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。
- 其它方法，和 [「2.4 PooledUnsafeDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。

另外，UnpooledUnsafeDirectByteBuf 有一个子类 UnpooledUnsafeNoCleanerDirectByteBuf ，用于 `netty-microbench` 模块，进行基准测试。感兴趣的胖友，可以自己看看。

## 3.4 UnpooledUnsafeHeapByteBuf

`io.netty.buffer.UnpooledUnsafeHeapByteBuf` ，实现 AbstractReferenceCountedByteBuf 抽象类，对应 `「2.5 PooledUnsafeHeapByteBuf」` 的**非池化** ByteBuf 实现类。

- 构造方法、`#capacity(...)` 方法、`#deallocate()` 方法，和 [「3.2 PooledHeapByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。
- 其它方法，和 [「2.5 PooledUnsafeHeapByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/#) 基本一致。

## 3.5 ThreadLocal ByteBuf

> 老艿艿：这是本文的拓展内容。

虽然 UnpooledByteBuf 不基于**对象池**实现，但是考虑到 NIO Direct ByteBuffer 申请的成本是比较高的，所以基于 ThreadLocal + Recycler 实现重用。

`ByteBufUtil#threadLocalDirectBuffer()` 方法，创建 ThreadLocal ByteBuf 对象。代码如下：

```
private static final int THREAD_LOCAL_BUFFER_SIZE;
static {
    THREAD_LOCAL_BUFFER_SIZE = SystemPropertyUtil.getInt("io.netty.threadLocalDirectBufferSize", 0);
}

/**
 * Returns a cached thread-local direct buffer, if available.
 *
 * @return a cached thread-local direct buffer, if available.  {@code null} otherwise.
 */
public static ByteBuf threadLocalDirectBuffer() {
    if (THREAD_LOCAL_BUFFER_SIZE <= 0) {
        return null;
    }

    if (PlatformDependent.hasUnsafe()) {
        return ThreadLocalUnsafeDirectByteBuf.newInstance();
    } else {
        return ThreadLocalDirectByteBuf.newInstance();
    }
}

```

- `THREAD_LOCAL_BUFFER_SIZE` **静态**属性，通过 `"io.netty.threadLocalDirectBufferSize"` 配置，默认为 0 。也就是说，实际 `#threadLocalDirectBuffer()` 方法，返回 `null` ，不开启 ThreadLocal ByteBuf 的功能。
- 根据是否支持 Unsafe 操作，创建 ThreadLocalUnsafeDirectByteBuf 或 ThreadLocalDirectByteBuf 对象。

### 3.5.1 ThreadLocalUnsafeDirectByteBuf

ThreadLocalUnsafeDirectByteBuf ，在 ByteBufUtil 的**内部静态类**，继承 UnpooledUnsafeDirectByteBuf 类。代码如下：

```
static final class ThreadLocalUnsafeDirectByteBuf extends UnpooledUnsafeDirectByteBuf {

    /**
     * Recycler 对象
     */
    private static final Recycler<ThreadLocalUnsafeDirectByteBuf> RECYCLER =
            new Recycler<ThreadLocalUnsafeDirectByteBuf>() {
                @Override
                protected ThreadLocalUnsafeDirectByteBuf newObject(Handle<ThreadLocalUnsafeDirectByteBuf> handle) {
                    return new ThreadLocalUnsafeDirectByteBuf(handle);
                }
            };

    static ThreadLocalUnsafeDirectByteBuf newInstance() {
        // 从 RECYCLER 中，获得 ThreadLocalUnsafeDirectByteBuf 对象
        ThreadLocalUnsafeDirectByteBuf buf = RECYCLER.get();
        // 初始化 ref 为 1
        buf.setRefCnt(1);
        return buf;
    }

    /**
     * Recycler 处理器
     */
    private final Handle<ThreadLocalUnsafeDirectByteBuf> handle;

    private ThreadLocalUnsafeDirectByteBuf(Handle<ThreadLocalUnsafeDirectByteBuf> handle) {
        super(UnpooledByteBufAllocator.DEFAULT, 256, Integer.MAX_VALUE);
        this.handle = handle;
    }

    @Override
    protected void deallocate() {
        if (capacity() > THREAD_LOCAL_BUFFER_SIZE) { // <1>
            // 释放
            super.deallocate();
        } else {
            // 清空
            clear();
            // 回收对象
            handle.recycle(this);
        }
    }
}

```

- 在 `<1>` 处，我们可以看到，只有 ByteBuffer 容量小于 `THREAD_LOCAL_BUFFER_SIZE` 时，才会重用 ByteBuffer 对象。

### 3.5.2 ThreadLocalDirectByteBuf

ThreadLocalUnsafeDirectByteBuf ，在 ByteBufUtil 的**内部静态类**，继承 UnpooledDirectByteBuf 类。代码如下：

```
static final class ThreadLocalDirectByteBuf extends UnpooledDirectByteBuf {

    /**
     * Recycler 对象
     */
    private static final Recycler<ThreadLocalDirectByteBuf> RECYCLER = new Recycler<ThreadLocalDirectByteBuf>() {
        @Override
        protected ThreadLocalDirectByteBuf newObject(Handle<ThreadLocalDirectByteBuf> handle) {
            return new ThreadLocalDirectByteBuf(handle);
        }
    };

    static ThreadLocalDirectByteBuf newInstance() {
        // 从 RECYCLER 中，获得 ThreadLocalUnsafeDirectByteBuf 对象
        ThreadLocalDirectByteBuf buf = RECYCLER.get();
        // 初始化 ref 为 1
        buf.setRefCnt(1);
        return buf;
    }

    /**
     * Recycler 处理器
     */
    private final Handle<ThreadLocalDirectByteBuf> handle;

    private ThreadLocalDirectByteBuf(Handle<ThreadLocalDirectByteBuf> handle) {
        super(UnpooledByteBufAllocator.DEFAULT, 256, Integer.MAX_VALUE);
        this.handle = handle;
    }

    @Override
    protected void deallocate() {
        if (capacity() > THREAD_LOCAL_BUFFER_SIZE) {
            // 释放
            super.deallocate();
        } else {
            // 清理
            clear();
            // 回收
            handle.recycle(this);
        }
    }
}

```

## 3.6 WrappedUnpooledUnsafeDirectByteBuf

> 老艿艿：这是本文的拓展内容。

`io.netty.buffer.WrappedUnpooledUnsafeDirectByteBuf` ，继承 UnpooledUnsafeDirectByteBuf 类，基于 `memoryAddress` 内存地址，创建 Direct ByteBuf 对象。代码如下：

```
final class WrappedUnpooledUnsafeDirectByteBuf extends UnpooledUnsafeDirectByteBuf {

    // 基于 memoryAddress 内存地址，创建 Direct ByteBuf 对象
    WrappedUnpooledUnsafeDirectByteBuf(ByteBufAllocator alloc, long memoryAddress, int size, boolean doFree) {
        super(alloc, PlatformDependent.directBuffer(memoryAddress, size) /** 创建 Direct ByteBuf 对象 **/, size, doFree);
    }

    @Override
    protected void freeDirect(ByteBuffer buffer) {
        PlatformDependent.freeMemory(memoryAddress);
    }

}

```

> FROM [《Netty源码分析（一） ByteBuf》](https://www.jianshu.com/p/b833254908f7)
>
> 创建一个指定内存地址的UnpooledUnsafeDirectByteBuf，该内存块可能已被写入数据以减少一步拷贝操作。

# 666. 彩蛋

每次这种 N 多实现类的源码解析，写到 60% 的时候，就特别头疼。不是因为难写，是因为基本是组合排列，不断在啰嗦啰嗦啰嗦的感觉。

嗯嗯，如果有地方写的错乱，烦请指出。默默再 review 几遍。

------

推荐阅读文章：

- HryReal [《PooledByteBuf源码分析》](https://blog.csdn.net/qq_33394088/article/details/72763305)
- 江南白衣 [《Netty之Java堆外内存扫盲贴》](http://calvin1978.blogcn.com/articles/directbytebuffer.html)

# Buffer 之 ByteBuf（三）内存泄露检测



# 1. 概述

在本文，我们来分享 Netty 的**内存泄露检测**的实现机制。考虑到胖友更好的理解本文，请先阅读江南白衣大大的 [《Netty 之有效规避内存泄漏》](http://calvin1978.blogcn.com/articles/netty-leak.html) 。

因为江南白衣大大在文章中，已经很清晰的讲解了概念与原理，笔者就不班门弄斧，直接上手，撸源码。

# 2. ReferenceCounted

> FROM [《【Netty官方文档翻译】引用计数对象（reference counted objects）》](http://damacheng009.iteye.com/blog/2013657)
>
> 自从 Netty 4 开始，对象的生命周期由它们的引用计数( reference counts )管理，而不是由垃圾收集器( garbage collector )管理了。**ByteBuf 是最值得注意的，它使用了引用计数来改进分配内存和释放内存的性能**。

在 Netty 中，通过 `io.netty.util.ReferenceCounted` **接口**，定义了引用计数相关的一系列操作。代码如下：

```java
public interface ReferenceCounted {

    /**
     * 获得引用计数
     *
     * Returns the reference count of this object.  If {@code 0}, it means this object has been deallocated.
     */
    int refCnt();

    /**
     * 增加引用计数 1
     *
     * Increases the reference count by {@code 1}.
     */
    ReferenceCounted retain();
    /**
     * 增加引用计数 n
     *
     * Increases the reference count by the specified {@code increment}.
     */
    ReferenceCounted retain(int increment);

    /**
     * 等价于调用 `#touch(null)` 方法，即 hint 方法参数传递为 null 。
     *
     * Records the current access location of this object for debugging purposes.
     * If this object is determined to be leaked, the information recorded by this operation will be provided to you
     * via {@link ResourceLeakDetector}.  This method is a shortcut to {@link #touch(Object) touch(null)}.
     */
    ReferenceCounted touch();
    /**
     * 出于调试目的,用一个额外的任意的(arbitrary)信息记录这个对象的当前访问地址. 如果这个对象被检测到泄露了, 这个操作记录的信息将通过ResourceLeakDetector 提供.
     *
     * Records the current access location of this object with an additional arbitrary information for debugging
     * purposes.  If this object is determined to be leaked, the information recorded by this operation will be
     * provided to you via {@link ResourceLeakDetector}.
     */
    ReferenceCounted touch(Object hint);

    /**
     * 减少引用计数 1 。
     * 当引用计数为 0 时，释放
     *
     * Decreases the reference count by {@code 1} and deallocates this object if the reference count reaches at
     * {@code 0}.
     *
     * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated
     */
    boolean release();
    /**
     * 减少引用计数 n 。
     *  当引用计数为 0 时，释放
     *
     * Decreases the reference count by the specified {@code decrement} and deallocates this object if the reference
     * count reaches at {@code 0}.
     *
     * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated
     */
    boolean release(int decrement);
}
```

- `#refCnt()`、`#retain(...)`、`#release(...)` 三种方法比较好理解，对引用指数的获取与增减。
- `#touch(...)` 方法，主动记录一个 `hint` 给 ResourceLeakDetector ，方便我们在发现内存泄露有更多的信息进行排查。详细的，在下文 ResourceLeakDetector 相关的内容，具体来看。

------

ReferenceCounted 的直接子类 / 子接口有两个 ：

- `io.netty.buffer.ByteBuf` 。所以，所有 ByteBuf 实现类，都支持引用计数的操作。
- `io.netty.util.AbstractReferenceCounted`，ReferenceCounted 的抽象实现类。它的子类实现类，主要是除了 ByteBuf 之外，需要引用计数的操作的类。例如：AbstractHttpData、DefaultFileRegion 等等。
  - AbstractReferenceCounted 不是本文的重点，就不多做介绍。
  - AbstractReferenceCounted 的具体代码实现，在下文中，我们会看到和 `io.netty.buffer.AbstractReferenceCountedByteBuf` 基本差不多。

# 3. ByteBuf

ByteBuf 虽然继承了 ReferenceCounted 接口，但是并未实现相应的方法。那么真正实现与相关的类，如下图所示：![类图](http://static2.iocoder.cn/images/Netty/2018_08_07/01.png)

- 黄框
  - AbstractReferenceCountedByteBuf ，实现引用计数的获取与增减的操作。
- 红框
  - WrappedByteBuf ，实现对 ByteBuf 的装饰器实现类。
  - WrappedCompositeByteBuf ，实现对 CompositeByteBuf 的装饰器实现类。
- 绿框
  - SimpleLeakAwareByteBuf、SimpleLeakAwareCompositeByteBuf ，实现了 `SIMPLE` 级别的内存泄露检测。
  - AdvancedLeakAwareByteBuf、AdvancedLeakAwareCompositeByteBuf ，实现了 `ADVANCED` 和 `PARANOID` 级别的内存泄露检测。
- 蓝筐
  - UnreleasableByteBuf ，用于阻止他人对装饰的 ByteBuf 的销毁，避免被错误销毁掉。

因为带 `"Composite"` 类的代码实现，和不带的类( 例如 WrappedCompositeByteBuf 和 WrappedByteBuf )，实现代码基本一致，**所以本文只分享不带 "Composite" 的类**。

## 3.1 创建 LeakAware ByteBuf 对象

在前面的文章中，我们已经提到，ByteBufAllocator 可用于创建 ByteBuf 对象。创建的过程中，它会调用 `#toLeakAwareBuffer(...)` 方法，将 ByteBuf **装饰**成 LeakAware ( 可检测内存泄露 )的 ByteBuf 对象，代码如下：

```java
// AbstractByteBufAllocator.java
protected static ByteBuf toLeakAwareBuffer(ByteBuf buf) {
    ResourceLeakTracker<ByteBuf> leak;
    switch (ResourceLeakDetector.getLevel()) {
        case SIMPLE:
            leak = AbstractByteBuf.leakDetector.track(buf);
            if (leak != null) {
                buf = new SimpleLeakAwareByteBuf(buf, leak);
            }
            break;
        case ADVANCED:
        case PARANOID:
            leak = AbstractByteBuf.leakDetector.track(buf);
            if (leak != null) {
                buf = new AdvancedLeakAwareByteBuf(buf, leak);
            }
            break;
        default:
            break;
    }
    return buf;
}

protected static CompositeByteBuf toLeakAwareBuffer(CompositeByteBuf buf) {
    ResourceLeakTracker<ByteBuf> leak;
    switch (ResourceLeakDetector.getLevel()) {
        case SIMPLE:
            leak = AbstractByteBuf.leakDetector.track(buf);
            if (leak != null) {
                buf = new SimpleLeakAwareCompositeByteBuf(buf, leak);
            }
            break;
        case ADVANCED:
        case PARANOID:
            leak = AbstractByteBuf.leakDetector.track(buf);
            if (leak != null) {
                buf = new AdvancedLeakAwareCompositeByteBuf(buf, leak);
            }
            break;
        default:
            break;
    }
    return buf;
}
```

- 有两个 `#toLeakAwareBuffer(...)` 方法，分别对应带 `"Composite"` 的 组合 ByteBuf 类，和不带 `Composite` 普通 ByteBuf 类。因为这个不同，所以前者创建的是 SimpleLeakAwareCompositeByteBuf / AdvancedLeakAwareCompositeByteBuf 对象，后者创建的是 SimpleLeakAwareByteBuf / AdvancedLeakAwareByteBuf 对象。

- 当然，从总的逻辑来看，是

  一致

  的：

  - `SIMPLE` 级别，创建 SimpleLeakAwareByteBuf 或 SimpleLeakAwareCompositeByteBuf 对象。
  - `ADVANCED` 和 `PARANOID` 级别，创建 AdvancedLeakAwareByteBuf 或者 AdvancedLeakAwareCompositeByteBuf 对象。

- 是否需要创建 LeakAware ByteBuf 对象，有一个前提，调用`ResourceLeakDetector#track(ByteBuf)`方法，返回了 ResourceLeakTracker 对象。

  - 虽然说， `ADVANCED` 和 `PARANOID` 级别，都使用了 AdvancedLeakAwareByteBuf 或 AdvancedLeakAwareCompositeByteBuf 对象，但是它们的差异是：1) `PARANOID` 级别，一定返回 ResourceLeakTracker 对象；2) `ADVANCED` 级别，随机概率( 默认为 `1%` 左右 )返回 ResourceLeakTracker 对象。
  - 关于 `ResourceLeakDetector#track(ByteBuf)` 方法的实现，下文也会详细解析。

## 3.2 AbstractReferenceCountedByteBuf

`io.netty.buffer.AbstractReferenceCountedByteBuf` ，实现引用计数的获取与增减的操作。

### 3.2.1 构造方法

```java
/**
 * {@link #refCnt} 的更新器
 */
private static final AtomicIntegerFieldUpdater<AbstractReferenceCountedByteBuf> refCntUpdater = AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, "refCnt");

/**
 * 引用计数
 */
private volatile int refCnt;

protected AbstractReferenceCountedByteBuf(int maxCapacity) {
    // 设置最大容量
    super(maxCapacity);
    // 初始 refCnt 为 1
    refCntUpdater.set(this, 1);
}
```

- 为什么 `refCnt` 不使用 AtomicInteger 呢？

> 计数器基于 AtomicIntegerFieldUpdater ，为什么不直接用 AtomicInteger ？因为 ByteBuf 对象很多，如果都把 `int` 包一层 AtomicInteger 花销较大，而AtomicIntegerFieldUpdater 只需要一个全局的静态变量。

### 3.2.2 refCnt

```java
@Override
public int refCnt() {
    return refCnt;
}
```

### 3.2.3 setRefCnt

`#setRefCnt(int refCnt)` 方法，直接修改 `refCnt` 。代码如下：

```
/**
 * An unsafe operation intended for use by a subclass that sets the reference count of the buffer directly
 */
protected final void setRefCnt(int refCnt) {
    refCntUpdater.set(this, refCnt);
}
```

### 3.2.4 retain

```
@Override
public ByteBuf retain(int increment) {
    return retain0(checkPositive(increment, "increment"));
}

private ByteBuf retain0(final int increment) {
    // 增加
    int oldRef = refCntUpdater.getAndAdd(this, increment);
    // 原有 refCnt 就是 <= 0 ；或者，increment 为负数
    if (oldRef <= 0 || oldRef + increment < oldRef) {
        // Ensure we don't resurrect (which means the refCnt was 0) and also that we encountered an overflow.
        // 加回去，负负得正。
        refCntUpdater.getAndAdd(this, -increment);
        // 抛出 IllegalReferenceCountException 异常
        throw new IllegalReferenceCountException(oldRef, increment);
    }
    return this;
}
```

### 3.2.5 release

```
@Override
public boolean release() {
    return release0(1);
}

@Override
public boolean release(int decrement) {
    return release0(checkPositive(decrement, "decrement"));
}

@SuppressWarnings("Duplicates")
private boolean release0(int decrement) {
    // 减少
    int oldRef = refCntUpdater.getAndAdd(this, -decrement);
    // 原有 oldRef 等于减少的值
    if (oldRef == decrement) {
        // 释放
        deallocate();
        return true;
        // 减少的值得大于 原有 oldRef ，说明“越界”；或者，increment 为负数
    } else if (oldRef < decrement || oldRef - decrement > oldRef) {
        // Ensure we don't over-release, and avoid underflow.
        // 加回去，负负得正。
        refCntUpdater.getAndAdd(this, decrement);
        // 抛出 IllegalReferenceCountException 异常
        throw new IllegalReferenceCountException(oldRef, -decrement);
    }
    return false;
}
```

- 当释放完成，即 `refCnt` 等于 0 时，调用 `#deallocate()` 方法，进行**真正的释放**。这是个**抽象方法**，需要子类去实现。代码如下：

  ```
  /**
   * Called once {@link #refCnt()} is equals 0.
   */
  protected abstract void deallocate();
  ```

  - 在 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（二）核心子类》](http://svip.iocoder.cn/Netty/ByteBuf-1-2-ByteBuf-core-impl/) 中，可以看到各种 ByteBuf 对 `#deallocate()` 方法的实现。

### 3.2.6 touch

```
@Override
public ByteBuf touch() {
    return this;
}

@Override
public ByteBuf touch(Object hint) {
    return this;
}
```

一脸懵逼？！实际 AbstractReferenceCountedByteBuf **并未**实现 `#touch(...)` 方法。而是在 AdvancedLeakAwareByteBuf 中才实现。

## 3.3 SimpleLeakAwareByteBuf

`io.netty.buffer.SimpleLeakAwareByteBuf` ，继承 WrappedByteBuf 类，`Simple` 级别的 LeakAware ByteBuf 实现类。

### 3.3.1 构造方法

```
/**
 * 关联的 ByteBuf 对象
 *
 * This object's is associated with the {@link ResourceLeakTracker}. When {@link ResourceLeakTracker#close(Object)}
 * is called this object will be used as the argument. It is also assumed that this object is used when
 * {@link ResourceLeakDetector#track(Object)} is called to create {@link #leak}.
 */
private final ByteBuf trackedByteBuf;
/**
 * ResourceLeakTracker 对象
 */
final ResourceLeakTracker<ByteBuf> leak;

SimpleLeakAwareByteBuf(ByteBuf wrapped, ByteBuf trackedByteBuf, ResourceLeakTracker<ByteBuf> leak) { // <2>
    super(wrapped);
    this.trackedByteBuf = ObjectUtil.checkNotNull(trackedByteBuf, "trackedByteBuf");
    this.leak = ObjectUtil.checkNotNull(leak, "leak");
}

SimpleLeakAwareByteBuf(ByteBuf wrapped, ResourceLeakTracker<ByteBuf> leak) { // <1>
    this(wrapped, wrapped, leak);
}
```

- `leak` 属性，ResourceLeakTracker 对象。

- ```
  trackedByteBuf
  ```

   

  属性，

  真正

  关联

   

  ```
  leak
  ```

   

  的 ByteBuf 对象。

  - 对于构造方法 `<1>` ，`wrapped` 和 `trackedByteBuf` **相同**。
  - 对于构造方法 `<2>` ，`wrapped` 和 `trackedByteBuf` **一般不同**。
  - 有点难理解？继续往下看。

### 3.3.2 slice

```
@Override
public ByteBuf slice() {
    return newSharedLeakAwareByteBuf(super.slice());
}

@Override
public ByteBuf slice(int index, int length) {
    return newSharedLeakAwareByteBuf(super.slice(index, length));
}
```

- 首先，调用**父** `#slice(...)` 方法，获得 **slice** ByteBuf 对象。

- 之后，因为 **slice** ByteBuf 对象，并不是一个 LeakAware 的 ByteBuf 对象。所以调用 `#newSharedLeakAwareByteBuf(ByteBuf wrapped)` 方法，装饰成 LeakAware 的 ByteBuf 对象。代码如下：

  ```
  private SimpleLeakAwareByteBuf newSharedLeakAwareByteBuf(ByteBuf wrapped) {
      return newLeakAwareByteBuf(wrapped, trackedByteBuf /** <1> **/, leak);
  }
  
  protected SimpleLeakAwareByteBuf newLeakAwareByteBuf(ByteBuf buf, ByteBuf trackedByteBuf, ResourceLeakTracker<ByteBuf> leakTracker) {
      return new SimpleLeakAwareByteBuf(buf, trackedByteBuf /** <1> **/, leakTracker);
  }
  ```

  - 从 `<1>` 处，我们可以看到，`trackedByteBuf` 代表的是**原始的** ByteBuf 对象，它是跟 `leak` 真正进行关联的。而 `wrapped` 则不是。

------

在 SimpleLeakAwareByteBuf 中，还有如下方法，和 `#slice(...)` 方法是**类似**的，在调用完**父**对应的方法后，再调用 `#newSharedLeakAwareByteBuf(ByteBuf wrapped)` 方法，装饰成 LeakAware 的 ByteBuf 对象。整理如下：

```
@Override
public ByteBuf duplicate() {
    return newSharedLeakAwareByteBuf(super.duplicate());
}

@Override
public ByteBuf readSlice(int length) {
    return newSharedLeakAwareByteBuf(super.readSlice(length));
}

@Override
public ByteBuf asReadOnly() {
    return newSharedLeakAwareByteBuf(super.asReadOnly());
}

@Override
public ByteBuf order(ByteOrder endianness) {
    if (order() == endianness) {
        return this;
    } else {
        return newSharedLeakAwareByteBuf(super.order(endianness));
    }
}
```

### 3.3.3 retainedSlice

```
@Override
public ByteBuf retainedSlice() {
    return unwrappedDerived(super.retainedSlice());
}

@Override
public ByteBuf retainedSlice(int index, int length) {
    return unwrappedDerived(super.retainedSlice(index, length));
}
```

- 首先，调用**父** `#retainedSlice(...)` 方法，获得 **slice** ByteBuf 对象，引用计数加 1。

- 之后，因为 **slice** ByteBuf 对象，并不是一个 LeakAware 的 ByteBuf 对象。所以调用 `#unwrappedDerived(ByteBuf wrapped)` 方法，装饰成 LeakAware 的 ByteBuf 对象。代码如下：

  ```
  // TODO 芋艿，看不懂 1017
  private ByteBuf unwrappedDerived(ByteBuf derived) {
      // We only need to unwrap SwappedByteBuf implementations as these will be the only ones that may end up in
      // the AbstractLeakAwareByteBuf implementations beside slices / duplicates and "real" buffers.
      ByteBuf unwrappedDerived = unwrapSwapped(derived);
  
      if (unwrappedDerived instanceof AbstractPooledDerivedByteBuf) {
          // Update the parent to point to this buffer so we correctly close the ResourceLeakTracker.
          ((AbstractPooledDerivedByteBuf) unwrappedDerived).parent(this);
  
          ResourceLeakTracker<ByteBuf> newLeak = AbstractByteBuf.leakDetector.track(derived);
          if (newLeak == null) {
              // No leak detection, just return the derived buffer.
              return derived;
          }
          return newLeakAwareByteBuf(derived, newLeak);
      }
      return newSharedLeakAwareByteBuf(derived);
  }
  
  @SuppressWarnings("deprecation")
  private static ByteBuf unwrapSwapped(ByteBuf buf) {
      if (buf instanceof SwappedByteBuf) {
          do {
              buf = buf.unwrap();
          } while (buf instanceof SwappedByteBuf);
  
          return buf;
      }
      return buf;
  }
  
  private SimpleLeakAwareByteBuf newLeakAwareByteBuf(ByteBuf wrapped, ResourceLeakTracker<ByteBuf> leakTracker) {
      return newLeakAwareByteBuf(wrapped, wrapped, leakTracker);
  }
  
  ```

  - TODO 1017

------

在 SimpleLeakAwareByteBuf 中，还有如下方法，和 `#retainedSlice(...)` 方法是**类似**的，在调用完**父**对应的方法后，再调用 `#unwrappedDerived(ByteBuf derived)` 方法，装饰成 LeakAware 的 ByteBuf 对象。整理如下：

```
@Override
public ByteBuf retainedDuplicate() {
    return unwrappedDerived(super.retainedDuplicate());
}

@Override
public ByteBuf readRetainedSlice(int length) {
    return unwrappedDerived(super.readRetainedSlice(length));
}

```

### 3.3.4 release

```
@Override
public boolean release() {
    if (super.release()) { // 释放完成
        closeLeak();
        return true;
    }
    return false;
}

@Override
public boolean release(int decrement) {
    if (super.release(decrement)) { // 释放完成
        closeLeak();
        return true;
    }
    return false;
}

```

- 在调用**父** `#release(...)` 方法，释放完成后，会调用 `#closeLeak()` 方法，关闭 ResourceLeakTracker 。代码如下：

  ```
  private void closeLeak() {
      // Close the ResourceLeakTracker with the tracked ByteBuf as argument. This must be the same that was used when
      // calling DefaultResourceLeak.track(...).
      boolean closed = leak.close(trackedByteBuf);
      assert closed;
  }
  
  ```

```
* 进一步的详细解析，可以看看 [「5.1.5 close」](#) 。

```

### 3.3.5 touch

```
@Override
public ByteBuf touch() {
    return this;
}

@Override
public ByteBuf touch(Object hint) {
    return this;
}

```

又一脸懵逼？！实际 SimpleLeakAwareByteBuf **也并未**实现 `#touch(...)` 方法。而是在 AdvancedLeakAwareByteBuf 中才实现。

## 3.4 AdvancedLeakAwareByteBuf

`io.netty.buffer.AdvancedLeakAwareByteBuf` ，继承 SimpleLeakAwareByteBuf 类，`ADVANCED` 和 `PARANOID` 级别的 LeakAware ByteBuf 实现类。

### 3.4.1 构造方法

```
AdvancedLeakAwareByteBuf(ByteBuf buf, ResourceLeakTracker<ByteBuf> leak) {
    super(buf, leak);
}

AdvancedLeakAwareByteBuf(ByteBuf wrapped, ByteBuf trackedByteBuf, ResourceLeakTracker<ByteBuf> leak) {
    super(wrapped, trackedByteBuf, leak);
}

```

就是调用父构造方法，没啥特点。

### 3.4.2 retain

```
@Override
public ByteBuf retain() {
    leak.record();
    return super.retain();
}

@Override
public ByteBuf retain(int increment) {
    leak.record();
    return super.retain(increment);
}

```

- 会调用 `ResourceLeakTracer#record()` 方法，记录信息。

### 3.4.3 release

```
@Override
public boolean release() {
    leak.record();
    return super.release();
}

@Override
public boolean release(int decrement) {
    leak.record();
    return super.release(decrement);
}

```

- 会调用 `ResourceLeakTracer#record()` 方法，记录信息。

### 3.4.4 touch

```
@Override
public ByteBuf touch() {
    leak.record();
    return this;
}

@Override
public ByteBuf touch(Object hint) {
    leak.record(hint);
    return this;
}

```

- 会调用 `ResourceLeakTracer#record(...)` 方法，记录信息。
- 😈 `#touch(...)` 方法，终于实现了，哈哈哈。

### 3.4.5 recordLeakNonRefCountingOperation

`#recordLeakNonRefCountingOperation(ResourceLeakTracker<ByteBuf> leak)` **静态**方法，除了引用计数操作相关( 即 `#retain(...)`/`#release(...)`/`#touch(...)` 方法 )方法外，是否要调用记录信息。代码如下：

```
private static final String PROP_ACQUIRE_AND_RELEASE_ONLY = "io.netty.leakDetection.acquireAndReleaseOnly";
/**
 * 默认为
 */
private static final boolean ACQUIRE_AND_RELEASE_ONLY;

static {
    ACQUIRE_AND_RELEASE_ONLY = SystemPropertyUtil.getBoolean(PROP_ACQUIRE_AND_RELEASE_ONLY, false);
}

static void recordLeakNonRefCountingOperation(ResourceLeakTracker<ByteBuf> leak) {
    if (!ACQUIRE_AND_RELEASE_ONLY) {
        leak.record();
    }
}

```

- 负负得正，所以会调用 `ResourceLeakTracer#record(...)` 方法，记录信息。

- 也就是说，ByteBuf 的所有方法，都会记录信息。例如：

  ```
  @Override
  public ByteBuf order(ByteOrder endianness) {
      recordLeakNonRefCountingOperation(leak);
      return super.order(endianness);
  }
  
  @Override
  public int readIntLE() {
      recordLeakNonRefCountingOperation(leak);
      return super.readIntLE();
  }
  
  ```

  - 方法比较多，就不一一列举了。

### 3.4.6 newLeakAwareByteBuf

`#newLeakAwareByteBuf(ByteBuf buf, ByteBuf trackedByteBuf, ResourceLeakTracker<ByteBuf> leakTracker)` 方法，覆写父类方法，将原先装饰成 SimpleLeakAwareByteBuf 改成 AdvancedLeakAwareByteBuf 对象。代码如下:

```
@Override
protected AdvancedLeakAwareByteBuf newLeakAwareByteBuf(
        ByteBuf buf, ByteBuf trackedByteBuf, ResourceLeakTracker<ByteBuf> leakTracker) {
    return new AdvancedLeakAwareByteBuf(buf, trackedByteBuf, leakTracker);
}

```

## 3.5 UnreleasableByteBuf

`io.netty.buffer.UnreleasableByteBuf` ，继承 WrappedByteBuf 类，用于阻止他人对装饰的 ByteBuf 的销毁，避免被错误销毁掉。

它的实现方法比较简单，主要是两大点：

- 引用计数操作相关( 即 `#retain(...)`/`#release(...)`/`#touch(...)` 方法 )方法，不进行调用。代码如下：

  ```
  @Override
  public ByteBuf retain(int increment) {
      return this;
  }
  @Override
  public ByteBuf retain() {
      return this;
  }
  
  @Override
  public ByteBuf touch() {
      return this;
  }
  @Override
  public ByteBuf touch(Object hint) {
      return this;
  }
  
  @Override
  public boolean release() {
      return false;
  }
  @Override
  public boolean release(int decrement) {
      return false;
  }
  
  ```

- 拷贝操作相关方法，都会在包一层 UnreleasableByteBuf 对象。例如：

  ```
  @Override
  public ByteBuf slice() {
      return new UnreleasableByteBuf(buf.slice());
  }
  
  ```

# 4. ResourceLeakDetector

`io.netty.util.ResourceLeakDetector` ，内存泄露检测器。

> 老艿艿：Resource 翻译成“资源”更合理。考虑到标题叫做《内存泄露检测》，包括互联网其他作者在关于这块内容的命名，也是叫做“内存泄露检测”。所以，在下文，Resource 笔者还是继续翻译成“资源”。

ResourceLeakDetector 为了检测内存是否泄漏，使用了 WeakReference( 弱引用 )和 ReferenceQueue( 引用队列 )，过程如下：

1. 根据检测级别和采样率的设置，在需要时为需要检测的 ByteBuf 创建WeakReference 引用。
2. 当 JVM 回收掉 ByteBuf 对象时，JVM 会将 WeakReference 放入ReferenceQueue 队列中。
3. 通过对 ReferenceQueue 中 WeakReference 的检查，判断在 GC 前是否有释放ByteBuf 的资源，就可以知道是否有资源释放。

😈 看不太懂？继续往下看代码，在回过头来理解理解。

## 4.1 静态属性

```
private static final String PROP_LEVEL_OLD = "io.netty.leakDetectionLevel";
private static final String PROP_LEVEL = "io.netty.leakDetection.level";
/**
 * 默认内存检测级别
 */
private static final Level DEFAULT_LEVEL = Level.SIMPLE;

private static final String PROP_TARGET_RECORDS = "io.netty.leakDetection.targetRecords";
private static final int DEFAULT_TARGET_RECORDS = 4;

/**
 * 每个 DefaultResourceLeak 记录的 Record 数量
 */
private static final int TARGET_RECORDS;

/**
 * 内存检测级别枚举
 * 
 * Represents the level of resource leak detection.
 */
public enum Level {
    /**
     * Disables resource leak detection.
     */
    DISABLED,
    /**
     * Enables simplistic sampling resource leak detection which reports there is a leak or not,
     * at the cost of small overhead (default).
     */
    SIMPLE,
    /**
     * Enables advanced sampling resource leak detection which reports where the leaked object was accessed
     * recently at the cost of high overhead.
     */
    ADVANCED,
    /**
     * Enables paranoid resource leak detection which reports where the leaked object was accessed recently,
     * at the cost of the highest possible overhead (for testing purposes only).
     */
    PARANOID;

    /**
     * Returns level based on string value. Accepts also string that represents ordinal number of enum.
     *
     * @param levelStr - level string : DISABLED, SIMPLE, ADVANCED, PARANOID. Ignores case.
     * @return corresponding level or SIMPLE level in case of no match.
     */
    static Level parseLevel(String levelStr) {
        String trimmedLevelStr = levelStr.trim();
        for (Level l : values()) {
            if (trimmedLevelStr.equalsIgnoreCase(l.name()) || trimmedLevelStr.equals(String.valueOf(l.ordinal()))) {
                return l;
            }
        }
        return DEFAULT_LEVEL;
    }
}

/**
 * 内存泄露检测等级
 */
private static Level level;

/**
 * 默认采集频率
 */
// There is a minor performance benefit in TLR if this is a power of 2.
static final int DEFAULT_SAMPLING_INTERVAL = 128;
 
  1: static {
  2:     // 获得是否禁用泄露检测
  3:     final boolean disabled;
  4:     if (SystemPropertyUtil.get("io.netty.noResourceLeakDetection") != null) {
  5:         disabled = SystemPropertyUtil.getBoolean("io.netty.noResourceLeakDetection", false);
  6:         logger.debug("-Dio.netty.noResourceLeakDetection: {}", disabled);
  7:         logger.warn("-Dio.netty.noResourceLeakDetection is deprecated. Use '-D{}={}' instead.", PROP_LEVEL, DEFAULT_LEVEL.name().toLowerCase());
  8:     } else {
  9:         disabled = false;
 10:     }
 11: 
 12:     // 获得默认级别
 13:     Level defaultLevel = disabled? Level.DISABLED : DEFAULT_LEVEL;
 14:     // 获得配置的级别字符串，从老版本的配置
 15:     // First read old property name (兼容老版本）
 16:     String levelStr = SystemPropertyUtil.get(PROP_LEVEL_OLD, defaultLevel.name());
 17:     // 获得配置的级别字符串，从新版本的配置
 18:     // If new property name is present, use it
 19:     levelStr = SystemPropertyUtil.get(PROP_LEVEL, levelStr);
 20:     // 获得最终的级别
 21:     Level level = Level.parseLevel(levelStr);
 22:     // 设置最终的级别
 23:     ResourceLeakDetector.level = level;
 24: 
 25:     // 初始化 TARGET_RECORDS
 26:     TARGET_RECORDS = SystemPropertyUtil.getInt(PROP_TARGET_RECORDS, DEFAULT_TARGET_RECORDS);
 27: 
 28:     if (logger.isDebugEnabled()) {
 29:         logger.debug("-D{}: {}", PROP_LEVEL, level.name().toLowerCase());
 30:         logger.debug("-D{}: {}", PROP_TARGET_RECORDS, TARGET_RECORDS);
 31:     }
 32: }

```

- `level` **静态**属性，内存泄露等级。😈 不是说好了，静态变量要统一大写么。

  - 默认级别为 `DEFAULT_LEVEL = Level.SIMPLE` 。

  - 在 Level 中，枚举了四个级别。

    > - 禁用（DISABLED） - 完全禁止泄露检测，省点消耗。
    > - 简单（SIMPLE） - 默认等级，告诉我们取样的1%的ByteBuf是否发生了泄露，但总共一次只打印一次，看不到就没有了。
    > - 高级（ADVANCED） - 告诉我们取样的1%的ByteBuf发生泄露的地方。每种类型的泄漏（创建的地方与访问路径一致）只打印一次。对性能有影响。
    > - 偏执（PARANOID） - 跟高级选项类似，但此选项检测所有ByteBuf，而不仅仅是取样的那1%。对性能有绝大的影响。
    >   - 看着有点懵逼？下面继续看代码。

  - 在【第 2 至 23 行】的代码进行初始化。

- ```
  TARGET_RECORDS
  
  ```

   

  静态属性，每个 DefaultResourceLeak 记录的 Record 数量。

  - 默认大小为 `DEFAULT_TARGET_RECORDS = 4` 。
  - 在【第 26 行】的代码进行初始化。

- `DEFAULT_SAMPLING_INTERVAL` 静态属性，默认采集频率，128 。

## 4.2 构造方法

```
/**
 * DefaultResourceLeak 集合
 *
 * the collection of active resources
 */
private final ConcurrentMap<DefaultResourceLeak<?>, LeakEntry> allLeaks = PlatformDependent.newConcurrentHashMap();

/**
 * 引用队列
 */
private final ReferenceQueue<Object> refQueue = new ReferenceQueue<Object>();
/**
 * 已汇报的内存泄露的资源类型的集合
 */
private final ConcurrentMap<String, Boolean> reportedLeaks = PlatformDependent.newConcurrentHashMap();

/**
 * 资源类型
 */
private final String resourceType;
/**
 * 采集评率
 */
private final int samplingInterval;

public ResourceLeakDetector(Class<?> resourceType, int samplingInterval) {
    this(simpleClassName(resourceType) /** <1> **/, samplingInterval, Long.MAX_VALUE);
}

```

- ```
  allLeaks
  
  ```

   

  属性，DefaultResourceLeak 集合。因为 Java 没有自带的 ConcurrentSet ，所以只好使用使用 ConcurrentMap 。也就是说，value 属性实际没有任何用途。

  - 关于 LeakEntry ，可以看下 [「6. LeakEntry」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

- `refQueue` 属性，就是我们提到的**引用队列**( ReferenceQueue 队列 )。

- `reportedLeaks` 属性，已汇报的内存泄露的资源类型的集合。

- `resourceType` 属性，资源类型，使用资源类的类名简写，见 `<1>` 处。

- `samplingInterval` 属性，采集频率。

------

在 AbstractByteBuf 类中，我们可以看到创建了所有 ByteBuf 对象统一使用的 ResourceLeakDetector 对象。代码如下：

```
static final ResourceLeakDetector<ByteBuf> leakDetector = ResourceLeakDetectorFactory.instance().newResourceLeakDetector(ByteBuf.class);

```

- ResourceLeakDetector 的创建，通过

   

  ```
  io.netty.util.ResourceLeakDetectorFactory
  
  ```

   

  ，基于工厂模式的方式来创建。

  - 关于 ResourceLeakDetectorFactory 的代码比较简单，笔者就不赘述了。
  - 有一点要注意的是，可以通过 `"io.netty.customResourceLeakDetector"` 来**自定义** ResourceLeakDetector 的实现类。当然，绝大多数场景是完全不需要的。

## 4.3 track

`#track(...)` 方法，给指定资源( 例如 ByteBuf 对象 )创建一个检测它是否泄漏的 ResourceLeakTracker 对象。代码如下：

```
 1: public final ResourceLeakTracker<T> track(T obj) {
 2:     return track0(obj);
 3: }
 4: 
 5: @SuppressWarnings("unchecked")
 6: private DefaultResourceLeak track0(T obj) {
 7:     Level level = ResourceLeakDetector.level;
 8:     // DISABLED 级别，不创建
 9:     if (level == Level.DISABLED) {
10:         return null;
11:     }
12: 
13:     // SIMPLE 和 ADVANCED
14:     if (level.ordinal() < Level.PARANOID.ordinal()) {
15:         // 随机
16:         if ((PlatformDependent.threadLocalRandom().nextInt(samplingInterval)) == 0) {
17:             // 汇报内存是否泄漏
18:             reportLeak();
19:             // 创建 DefaultResourceLeak 对象
20:             return new DefaultResourceLeak(obj, refQueue, allLeaks);
21:         }
22:         return null;
23:     }
24: 
25:     // PARANOID 级别
26:     // 汇报内存是否泄漏
27:     reportLeak();
28:     // 创建 DefaultResourceLeak 对象
29:     return new DefaultResourceLeak(obj, refQueue, allLeaks);
30: }

```

- 第 8 至 11 行：`DISABLED` 级别时，不创建，直接返回 `null` 。
- 第 13 至 23 行：`SIMPLE` 和 `ADVANCED` 级别时，随机，概率为 `1 / samplingInterval` ，创建 DefaultResourceLeak 对象。默认情况下 `samplingInterval = 128` ，约等于 `1%` ，这也是就为什么说“告诉我们取样的 1% 的ByteBuf发生泄露的地方”。
- 第 27 至 29 行：`PARANOID` 级别时，一定创建 DefaultResourceLeak 对象。这也是为什么说“对性能有绝大的影响”。
- 第 18 至 27 行：笔者原本以为，ResourceLeakDetector 会有一个定时任务，不断检测是否有内存泄露。从这里的代码来看，它是在每次一次创建 DefaultResourceLeak 对象时，调用 `#reportLeak()` 方法，汇报内存是否泄漏。详细解析，见 [「4.4 reportLeak」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

## 4.4 reportLeak

`#reportLeak()` 方法，检测是否有内存泄露。若有，则进行汇报。代码如下：

```
 1: private void reportLeak() {
 2:     // 如果不允许打印错误日志，则无法汇报，清理队列，并直接结束。
 3:     if (!logger.isErrorEnabled()) {
 4:         // 清理队列
 5:         clearRefQueue();
 6:         return;
 7:     }
 8: 
 9:     // 循环引用队列，直到为空
10:     // Detect and report previous leaks.
11:     for (;;) {
12:         @SuppressWarnings("unchecked")
13:         DefaultResourceLeak ref = (DefaultResourceLeak) refQueue.poll();
14:         if (ref == null) {
15:             break;
16:         }
17: 
18:         // 清理，并返回是否内存泄露
19:         if (!ref.dispose()) {
20:             continue;
21:         }
22: 
23:         // 获得 Record 日志
24:         String records = ref.toString();
25:         // 相同 Record 日志，只汇报一次
26:         if (reportedLeaks.putIfAbsent(records, Boolean.TRUE) == null) {
27:             if (records.isEmpty()) {
28:                 reportUntracedLeak(resourceType);
29:             } else {
30:                 reportTracedLeak(resourceType, records);
31:             }
32:         }
33:     }
34: }

```

- 第 2 至 7 行：如果不允许打印错误日志，则无法汇报，因此调用 `#clearRefQueue()` 方法，清理队列，并直接结束。详细解析，见 [「4.5 clearRefQueue」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

- 第 9 至 16 行：循环引用队列 `refQueue` ，直到为空。

- 第 18 至 21 行：调用 `DefaultResourceLeak#dispose()` 方法，清理，并返回是否内存泄露。如果未泄露，就直接 `continue` 。详细解析，见 [「5.1.3 dispose」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

- 第 24 行：调用 `DefaultResourceLeak#toString()` 方法，获得 Record 日志。详细解析，见 [「5.1 DefaultResourceLeak」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

- 第 25 至 32 行：相同 Record 日志内容( 即“创建的地方与访问路径一致” )，**只汇报一次**。 代码如下：

  ```
  /**
   * This method is called when a traced leak is detected. It can be overridden for tracking how many times leaks
   * have been detected.
   */
  protected void reportTracedLeak(String resourceType, String records) {
      logger.error(
              "LEAK: {}.release() was not called before it's garbage-collected. " +
              "See http://netty.io/wiki/reference-counted-objects.html for more information.{}",
              resourceType, records);
  }
  
  /**
   * This method is called when an untraced leak is detected. It can be overridden for tracking how many times leaks
   * have been detected.
   */
  protected void reportUntracedLeak(String resourceType) {
      logger.error("LEAK: {}.release() was not called before it's garbage-collected. " +
              "Enable advanced leak reporting to find out where the leak occurred. " +
              "To enable advanced leak reporting, " +
              "specify the JVM option '-D{}={}' or call {}.setLevel() " +
              "See http://netty.io/wiki/reference-counted-objects.html for more information.",
              resourceType, PROP_LEVEL, Level.ADVANCED.name().toLowerCase(), simpleClassName(this));
  }
  
  ```

😈 这块逻辑的信息量，可能有点大，胖友可以看完 [「5. ResourceLeakTracker」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) ，再回过头理解下。

## 4.5 clearRefQueue

`#clearRefQueue()` 方法，清理队列。代码如下：

```
private void clearRefQueue() {
    for (;;) {
        @SuppressWarnings("unchecked")
        DefaultResourceLeak ref = (DefaultResourceLeak) refQueue.poll();
        if (ref == null) {
            break;
        }
        // 清理，并返回是否内存泄露
        ref.dispose();
    }
}

```

- 实际上，就是 `#reportLeak()` 方法的**不汇报内存泄露**的版本。

# 5. ResourceLeakTracker

`io.netty.util.ResourceLeakTracker` ，内存泄露追踪器接口。从 [「4.3 track」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 中，我们已经看到，每个资源( 例如：ByteBuf 对象 )，会创建一个追踪它是否内存泄露的 ResourceLeakTracker 对象。

接口方法定义如下：

```
public interface ResourceLeakTracker<T>  {

    /**
     * 记录
     *
     * Records the caller's current stack trace so that the {@link ResourceLeakDetector} can tell where the leaked
     * resource was accessed lastly. This method is a shortcut to {@link #record(Object) record(null)}.
     */
    void record();
    /**
     * 记录
     *
     * Records the caller's current stack trace and the specified additional arbitrary information
     * so that the {@link ResourceLeakDetector} can tell where the leaked resource was accessed lastly.
     */
    void record(Object hint);

    /**
     * 关闭
     *
     * Close the leak so that {@link ResourceLeakTracker} does not warn about leaked resources.
     * After this method is called a leak associated with this ResourceLeakTracker should not be reported.
     *
     * @return {@code true} if called first time, {@code false} if called already
     */
    boolean close(T trackedObject);

}

```

- `#record(...)` 方法，出于调试目的，用一个额外的任意的( arbitrary )信息记录这个对象的当前访问地址。如果这个对象被检测到泄露了, 这个操作记录的信息将通过ResourceLeakDetector 提供。实际上，就是 `ReferenceCounted#touch(...)` 方法，会调用 `#record(...)` 方法。
- `#close(T trackedObject)` 方法，关闭 ResourceLeakTracker 。如果资源( 例如：ByteBuf 对象 )被正确释放，则会调用 `#close(T trackedObject)` 方法，关闭 ResourceLeakTracker ，从而结束追踪。这样，在 `ResourceLeakDetector#reportLeak()` 方法，就不会提示该资源泄露。

## 4.6 addExclusions

`#addExclusions(Class clz, String ... methodNames)` 方法，添加忽略方法的集合。代码如下：

```
/**
 * 忽略的方法集合
 */
private static final AtomicReference<String[]> excludedMethods = new AtomicReference<String[]>(EmptyArrays.EMPTY_STRINGS);

public static void addExclusions(Class clz, String ... methodNames) {
    Set<String> nameSet = new HashSet<String>(Arrays.asList(methodNames));
    // Use loop rather than lookup. This avoids knowing the parameters, and doesn't have to handle
    // NoSuchMethodException.
    for (Method method : clz.getDeclaredMethods()) {
        if (nameSet.remove(method.getName()) && nameSet.isEmpty()) {
            break;
        }
    }
    if (!nameSet.isEmpty()) {
        throw new IllegalArgumentException("Can't find '" + nameSet + "' in " + clz.getName());
    }
    String[] oldMethods;
    String[] newMethods;
    do {
        oldMethods = excludedMethods.get();
        newMethods = Arrays.copyOf(oldMethods, oldMethods.length + 2 * methodNames.length);
        for (int i = 0; i < methodNames.length; i++) {
            newMethods[oldMethods.length + i * 2] = clz.getName();
            newMethods[oldMethods.length + i * 2 + 1] = methodNames[i];
        }
    } while (!excludedMethods.compareAndSet(oldMethods, newMethods));
}

```

- 代码比较简单，胖友自己理解。

- 具体的用途，可参见 [「7. Record」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 的 `#toString()` 方法。

- 目前调用该静态方法的有如下几处：

  ```
  // AbstractByteBufAllocator.java
  static {
      ResourceLeakDetector.addExclusions(AbstractByteBufAllocator.class, "toLeakAwareBuffer");
  }
  
  // AdvancedLeakAwareByteBuf.java
  static {
      ResourceLeakDetector.addExclusions(AdvancedLeakAwareByteBuf.class, "touch", "recordLeakNonRefCountingOperation");
  }
  
  // ReferenceCountUtil.java
  static {
      ResourceLeakDetector.addExclusions(ReferenceCountUtil.class, "touch");
  }
  
  ```

## 5.1 DefaultResourceLeak

DefaultResourceLeak ，继承 `java.lang.ref.WeakReference` 类，实现 ResourceLeakTracker 接口，默认 ResourceLeakTracker 实现类。同时，它是 ResourceLeakDetector 内部静态类。即：

```
// ... 简化无关代码
public class ResourceLeakDetector<T> {

    private static final class DefaultResourceLeak<T> extends WeakReference<Object> implements ResourceLeakTracker<T>, ResourceLeak {
    }

}

```

那么为什么要继承 `java.lang.ref.WeakReference` 类呢？在 [「5.1.1 构造方法」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 见分晓。

### 5.1.1 构造方法

```
/**
 * {@link #head} 的更新器
 */
@SuppressWarnings("unchecked") // generics and updaters do not mix.
private static final AtomicReferenceFieldUpdater<DefaultResourceLeak<?>, Record> headUpdater =
        (AtomicReferenceFieldUpdater)
                AtomicReferenceFieldUpdater.newUpdater(DefaultResourceLeak.class, Record.class, "head");

/**
 * {@link #droppedRecords} 的更新器
 */
@SuppressWarnings("unchecked") // generics and updaters do not mix.
private static final AtomicIntegerFieldUpdater<DefaultResourceLeak<?>> droppedRecordsUpdater =
        (AtomicIntegerFieldUpdater)
                AtomicIntegerFieldUpdater.newUpdater(DefaultResourceLeak.class, "droppedRecords");

/**
 * Record 链的头节点
 *
 * 看完 {@link #record()} 方法后，实际上，head 是尾节点，即最后( 新 )的一条 Record 。
 */
@SuppressWarnings("unused")
private volatile Record head;
/**
 * 丢弃的 Record 计数
 */
@SuppressWarnings("unused")
private volatile int droppedRecords;

/**
 * DefaultResourceLeak 集合。来自 {@link ResourceLeakDetector#allLeaks}
 */
private final ConcurrentMap<DefaultResourceLeak<?>, LeakEntry> allLeaks;
/**
 * hash 值
 *
 * 保证 {@link #close(Object)} 传入的对象，就是 {@link #referent} 对象
 */
private final int trackedHash;

  1: DefaultResourceLeak(
  2:         Object referent,
  3:         ReferenceQueue<Object> refQueue,
  4:         ConcurrentMap<DefaultResourceLeak<?>, LeakEntry> allLeaks) {
  5:     // 父构造方法 <1>
  6:     super(referent, refQueue);
  7: 
  8:     assert referent != null;
  9: 
 10:     // Store the hash of the tracked object to later assert it in the close(...) method.
 11:     // It's important that we not store a reference to the referent as this would disallow it from
 12:     // be collected via the WeakReference.
 13:     trackedHash = System.identityHashCode(referent);
 14:     allLeaks.put(this, LeakEntry.INSTANCE);
 15:     // Create a new Record so we always have the creation stacktrace included.
 16:     headUpdater.set(this, new Record(Record.BOTTOM));
 17:     this.allLeaks = allLeaks;
 18: }

```

- ```
  head
  
  ```

   

  属性，Record 链的头节点。

  - 为什么说它是链呢？详细解析，胖友可以先跳到 [「7. Record」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。
  - 实际上，`head` 是尾节点，即最后( 新 )的一条 Record 记录。详细解析，见 [「5.1.2 record」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。
  - 在【第 16 行】代码，会默认创建尾节点 `Record.BOTTOM` 。

- `droppedRecords` 属性，丢弃的 Record 计数。详细解析，见 [「5.1.2 record」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。

- ```
  allLeaks
  
  ```

   

  属性，DefaultResourceLeak 集合。来自

   

  ```
  ResourceLeakDetector.allLeaks
  
  ```

   

  属性。

  - 在【第 14 行】代码，会将自己添加到 `allLeaks` 中。

- ```
  trackedHash
  
  ```

   

  属性，hash 值。保证在

   

  ```
  #close(T trackedObject)
  
  ```

   

  方法，传入的对象，就是

   

  ```
  referent
  
  ```

   

  属性，即就是 DefaultResourceLeak 指向的资源( 例如：ByteBuf 对象 )。详细解析，见

   

  「5.1.4 close」

   

  。

  - 在【第 10 至 13 行】代码，计算并初始化 `trackedHash` 属性。

- 【重要】在 `<1>` 处，会将 `referent`( 资源，例如：ByteBuf 对象 )和 `refQueue`( 引用队列 )传入父 WeakReference 构造方法。

  > FROM [《译文：理解Java中的弱引用》](https://droidyue.com/blog/2014/10/12/understanding-weakreference-in-java/index.html)
  >
  > **引用队列(Reference Queue)**
  >
  > 一旦弱引用对象开始返回null，该弱引用指向的对象就被标记成了垃圾。而这个弱引用对象（非其指向的对象）就没有什么用了。通常这时候需要进行一些清理工作。比如WeakHashMap会在这时候移除没用的条目来避免保存无限制增长的没有意义的弱引用。
  >
  > 引用队列可以很容易地实现跟踪不需要的引用。当你在构造WeakReference时传入一个ReferenceQueue对象，当该引用指向的对象被标记为垃圾的时候，这个引用对象会自动地加入到引用队列里面。接下来，你就可以在固定的周期，处理传入的引用队列，比如做一些清理工作来处理这些没有用的引用对象。

  - 也就是说，`referent` 被标记为垃圾的时候，它对应的 WeakReference 对象会被添加到 `refQueue` 队列中。**在此处，即将 DefaultResourceLeak 添加到 referent 队列中**。
  - 那又咋样呢？假设 `referent` 为 ByteBuf 对象。如果它被正确的释放，即调用了 [「3.3.4 release」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 方法，从而调用了 `AbstractReferenceCountedByteBuf#closeLeak()` 方法，最终调用到 `ResourceLeakTracker#close(trackedByteBuf)` 方法，那么该 ByteBuf 对象对应的 ResourceLeakTracker 对象，将从 `ResourceLeakDetector.allLeaks` 中移除。
  - 那这又意味着什么呢？ 在 `ResourceLeakDetector#reportLeak()` 方法中，即使从 `refQueue` 队列中，获取到该 ByteBuf 对象对应 ResourceLeakTracker 对象，因为在 `ResourceLeakDetector.allLeaks` 中移除了，所以在 `ResourceLeakDetector#reportLeak()`方法的【第 19 行】代码 `!ref.dispose() = true` ，直接 `continue` 。
  - 😈 比较绕，胖友再好好理解下。胖友可以在思考下，如果 ByteBuf 对象，没有被正确的释放，是怎么样一个流程。

### 5.1.2 record

`#record(...)` 方法，创建 Record 对象，添加到 `head` 链中。代码如下：

```
@Override
public void record() {
    record0(null);
}
@Override
public void record(Object hint) {
    record0(hint);
}

/**
 * This method works by exponentially backing off as more records are present in the stack. Each record has a
 * 1 / 2^n chance of dropping the top most record and replacing it with itself. This has a number of convenient
 * properties:
 *
 * <ol>
 * <li>  The current record is always recorded. This is due to the compare and swap dropping the top most
 *       record, rather than the to-be-pushed record.
 * <li>  The very last access will always be recorded. This comes as a property of 1.
 * <li>  It is possible to retain more records than the target, based upon the probability distribution.
 * <li>  It is easy to keep a precise record of the number of elements in the stack, since each element has to
 *     know how tall the stack is.
 * </ol>
 *
 * In this particular implementation, there are also some advantages. A thread local random is used to decide
 * if something should be recorded. This means that if there is a deterministic access pattern, it is now
 * possible to see what other accesses occur, rather than always dropping them. Second, after
 * {@link #TARGET_RECORDS} accesses, backoff occurs. This matches typical access patterns,
 * where there are either a high number of accesses (i.e. a cached buffer), or low (an ephemeral buffer), but
 * not many in between.
 *
 * The use of atomics avoids serializing a high number of accesses, when most of the records will be thrown
 * away. High contention only happens when there are very few existing records, which is only likely when the
 * object isn't shared! If this is a problem, the loop can be aborted and the record dropped, because another
 * thread won the race.
 */
  1: private void record0(Object hint) {
  2:     // Check TARGET_RECORDS > 0 here to avoid similar check before remove from and add to lastRecords
  3:     if (TARGET_RECORDS > 0) {
  4:         Record oldHead;
  5:         Record prevHead;
  6:         Record newHead;
  7:         boolean dropped;
  8:         do {
  9:             // 已经关闭，则返回
 10:             if ((prevHead = oldHead = headUpdater.get(this)) == null) {
 11:                 // already closed.
 12:                 return;
 13:             }
 14:             // 当超过 TARGET_RECORDS 数量时，随机丢到头节点。
 15:             final int numElements = oldHead.pos + 1;
 16:             if (numElements >= TARGET_RECORDS) {
 17:                 final int backOffFactor = Math.min(numElements - TARGET_RECORDS, 30);
 18:                 if (dropped = PlatformDependent.threadLocalRandom().nextInt(1 << backOffFactor) != 0) {
 19:                     prevHead = oldHead.next;
 20:                 }
 21:             } else {
 22:                 dropped = false;
 23:             }
 24:             // 创建新的头节点
 25:             newHead = hint != null ? new Record(prevHead, hint) : new Record(prevHead);
 26:         } while (!headUpdater.compareAndSet(this, oldHead, newHead)); // cas 修改头节点
 27:         // 若丢弃，增加 droppedRecordsUpdater 计数
 28:         if (dropped) {
 29:             droppedRecordsUpdater.incrementAndGet(this);
 30:         }
 31:     }
 32: }

```

- 第 9 至 13 行：通过 `headUpdater` 获得 `head` 属性，若为 `null` 时，说明 DefaultResourceLeak 已经关闭。为什么呢？详细可见 [「5.1.4 close」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 和 [5.1.5 toString](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 。
- 第 14 至 23 行：当当前 DefaultResourceLeak 对象所拥有的 Record 数量超过 `TARGET_RECORDS` 时，随机丢弃当前 `head` 节点的数据。也就是说，尽量保留**老**的 Record 节点。这是为什么呢?越是**老**( 开始 )的 Record 节点，越有利于排查问题。另外，随机丢弃的的概率，按照 `1 - (1 / 2^n）` 几率，越来越**大**。
- 第 25 行：创建新 Record 对象，作为头节点，指向**原头节点**。这也是为什么说，“实际上，head 是尾节点，即最后( 新 )的一条 Record”。
- 第 26 行：通过 CAS 的方式，修改新创建的 Record 对象为头节点。
- 第 27 至 30 行：若丢弃，增加 `droppedRecordsUpdater` 计数。

### 5.1.3 dispose

`#dispose()` 方法， 清理，并返回是否内存泄露。代码如下：

```
// 清理，并返回是否内存泄露
boolean dispose() {
    // 清理 referent 的引用
    clear();
    // 移除出 allLeaks 。移除成功，意味着内存泄露。
    return allLeaks.remove(this, LeakEntry.INSTANCE);
}

```

### 5.1.4 close

`#close(T trackedObject)` 方法，关闭 DefaultResourceLeak 对象。代码如下：

```
 1: @Override
 2: public boolean close(T trackedObject) {
 3:     // 校验一致
 4:     // Ensure that the object that was tracked is the same as the one that was passed to close(...).
 5:     assert trackedHash == System.identityHashCode(trackedObject);
 6: 
 7:     // 关闭
 8:     // We need to actually do the null check of the trackedObject after we close the leak because otherwise
 9:     // we may get false-positives reported by the ResourceLeakDetector. This can happen as the JIT / GC may
10:     // be able to figure out that we do not need the trackedObject anymore and so already enqueue it for
11:     // collection before we actually get a chance to close the enclosing ResourceLeak.
12:     return close() && trackedObject != null;
13: }

```

- 第 5 行：校验一致性。

- 第 12 行：调用 `#close()` 方法，关闭 DefaultResourceLeak 对象。代码如下：

  ```
  @Override
  public boolean close() {
      // 移除出 allLeaks
      // Use the ConcurrentMap remove method, which avoids allocating an iterator.
      if (allLeaks.remove(this, LeakEntry.INSTANCE)) {
          // 清理 referent 的引用
          // Call clear so the reference is not even enqueued.
          clear();
          // 置空 head
          headUpdater.set(this, null);
          return true; // 返回成功
      }
      return false; // 返回失败
  }
  
  ```

  - 关闭时，会将 DefaultResourceLeak 对象，从 `allLeaks` 中移除。

### 5.1.5 toString

当 DefaultResourceLeak 追踪到内存泄露，会在 `ResourceLeakDetector#reportLeak()` 方法中，调用 `DefaultResourceLeak#toString()` 方法，拼接提示信息。代码如下：

```
@Override
public String toString() {
    // 获得 head 属性，并置空 <1>
    Record oldHead = headUpdater.getAndSet(this, null);
    // 若为空，说明已经关闭。
    if (oldHead == null) {
        // Already closed
        return EMPTY_STRING;
    }

    final int dropped = droppedRecordsUpdater.get(this);
    int duped = 0;

    int present = oldHead.pos + 1;
    // Guess about 2 kilobytes per stack trace
    StringBuilder buf = new StringBuilder(present * 2048).append(NEWLINE);
    buf.append("Recent access records: ").append(NEWLINE);

    // 拼接 Record 练
    int i = 1;
    Set<String> seen = new HashSet<String>(present);
    for (; oldHead != Record.BOTTOM; oldHead = oldHead.next) {
        String s = oldHead.toString();
        if (seen.add(s)) { // 是否重复
            if (oldHead.next == Record.BOTTOM) {
                buf.append("Created at:").append(NEWLINE).append(s);
            } else {
                buf.append('#').append(i++).append(':').append(NEWLINE).append(s);
            }
        } else {
            duped++;
        }
    }

    // 拼接 duped ( 重复 ) 次数
    if (duped > 0) {
        buf.append(": ")
                .append(dropped)
                .append(" leak records were discarded because they were duplicates")
                .append(NEWLINE);
    }

    // 拼接 dropped (丢弃) 次数
    if (dropped > 0) {
        buf.append(": ")
           .append(dropped)
           .append(" leak records were discarded because the leak record count is targeted to ")
           .append(TARGET_RECORDS)
           .append(". Use system property ")
           .append(PROP_TARGET_RECORDS)
           .append(" to increase the limit.")
           .append(NEWLINE);
    }

    buf.setLength(buf.length() - NEWLINE.length());
    return buf.toString();
}

```

- 代码比较简单，胖友自己看注释。
- `<1>` 处，真的是个神坑。如果胖友在 IDEA 调试时，因为默认会调用对应的 `#toString()` 方法，会导致 `head` 属性被错误的重置为 `null`值。wtf！！！笔者在这里卡了好久好久。

# 6. LeakEntry

LeakEntry ，用于 `ResourceLeakDetector.allLeaks` 属性的 value 值。代码如下：

```
private static final class LeakEntry {

    /**
     * 单例
     */
    static final LeakEntry INSTANCE = new LeakEntry();

    /**
     * hash 值，避免重复计算
     */
    private static final int HASH = System.identityHashCode(INSTANCE);

    private LeakEntry() { // 禁止创建，仅使用 INSTANCE 单例
    }

    @Override
    public int hashCode() {
        return HASH;
    }

    @Override
    public boolean equals(Object obj) {
        return obj == this;
    }

}

```

😈 没有什么功能逻辑。

# 7. Record

Record ，记录。每次调用 `ResourceLeakTracker#touch(...)` 方法后，会产生响应的 Record 对象。代码如下：

```
private static final class Record extends Throwable {

    private static final long serialVersionUID = 6065153674892850720L;

    /**
     * 尾节点的单例
     */
    private static final Record BOTTOM = new Record();

    /**
     * hint 字符串
     */
    private final String hintString;
    /**
     * 下一个节点
     */
    private final Record next;
    /**
     * 位置
     */
    private final int pos;

    // =========== 构造方法 ===========

    Record(Record next, Object hint) {
        // This needs to be generated even if toString() is never called as it may change later on.
        hintString = hint instanceof ResourceLeakHint ? ((ResourceLeakHint) hint).toHintString() : hint.toString(); // <1>
        this.next = next;
        this.pos = next.pos + 1;
    }

    Record(Record next) {
       hintString = null;
       this.next = next;
       this.pos = next.pos + 1;
    }

    // Used to terminate the stack
    private Record() {
        hintString = null;
        next = null;
        pos = -1;
    }

    // =========== toString ===========

    @Override
    public String toString() {
        StringBuilder buf = new StringBuilder(2048);
        if (hintString != null) {
            buf.append("\tHint: ").append(hintString).append(NEWLINE);
        }

        // Append the stack trace.
        StackTraceElement[] array = getStackTrace();
        // Skip the first three elements.
        out: for (int i = 3; i < array.length; i++) {
            StackTraceElement element = array[i];
            // 跳过忽略的方法 <2>
            // Strip the noisy stack trace elements.
            String[] exclusions = excludedMethods.get();
            for (int k = 0; k < exclusions.length; k += 2) {
                if (exclusions[k].equals(element.getClassName())
                        && exclusions[k + 1].equals(element.getMethodName())) {
                    continue out;
                }
            }

            buf.append('\t');
            buf.append(element.toString());
            buf.append(NEWLINE);
        }
        return buf.toString();
    }

}

```

- 通过 `next` 属性，我们可以得知，Record 是链式结构。
- `<1>` 处，如果传入的 `hint` 类型为 ResourceLeakHint 类型，会调用对应的 `#toHintString()` 方法，拼接更友好的字符串提示信息。
- `<2>` 处，如果调用栈的方法在 `ResourceLeakDetector.exclusions` 属性中，进行忽略。

# 8. ResourceLeakHint

`io.netty.util.ResourceLeakHint` ，接口，提供人类可读( 易懂 )的提示信息，使用在 ResourceLeakDetector 中。代码如下：

```
/**
 * A hint object that provides human-readable message for easier resource leak tracking.
 */
public interface ResourceLeakHint {

    /**
     * Returns a human-readable message that potentially enables easier resource leak tracking.
     */
    String toHintString();

}

```

目前它的实现类是 AbstractChannelHandlerContext 。对应的实现方法如下：

```
/**
 * 名字
 */
private final String name;

@Override
public String toHintString() {
    return '\'' + name + "' will handle the message from this point.";
}

```

# 666. 彩蛋

比想象中长很多的文章，也比想象中花费了更多时间的文章。主要是 xxx 的 [「5.1.5 toString」](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector/#) 中卡了好久啊！！！！

推荐阅读文章：

- [《Netty 学习笔记 —— Reference Count》](https://skyao.gitbooks.io/learning-netty/content/buffer/reference_count.html)
- 唯有坚持不懈 [《Netty学习之旅—-源码分析Netty内存泄漏检测》](https://blog.csdn.net/prestigeding/article/details/54233327)

上述两篇文章，因为分析的 Netty 不是最新版本，所以代码会有一些差异，例如 `maxActive` 已经被去除。

# 精尽 Netty 源码解析 —— Buffer 之 ByteBufAllocator（一）简介



# 1. 概述

本文，我们来分享 ByteBufAllocator 。它是 ByteBuf 的分配器，负责创建 ByteBuf 对象。它的子类类图如下：![类图](http://static2.iocoder.cn/images/Netty/2018_08_20/01.png)

主要有三个子类：

- PreferHeapByteBufAllocator ，倾向创建 **Heap** ByteBuf 的分配器。
- PooledByteBufAllocator ，基于**内存池**的 ByteBuf 的分配器。
- UnpooledByteBufAllocator ，**普通**的 ByteBuf 的分配器。

本文分享上面类图红框部分，后面两篇文章再分别分享 UnpooledByteBufAllocator 和 PooledByteBufAllocator 。

# 2. ByteBufAllocator

`io.netty.buffer.ByteBufAllocator` ，ByteBuf 分配器**接口**。

还是老样子，我们逐个来看看每个方法。

## 2.1 DEFAULT

```
ByteBufAllocator DEFAULT = ByteBufUtil.DEFAULT_ALLOCATOR;
```

- 默认 ByteBufAllocator 对象，通过 `ByteBufUtil.DEFAULT_ALLOCATOR` 中获得。代码如下：

  ```
  static final ByteBufAllocator DEFAULT_ALLOCATOR;
  
  static {
      // 读取 ByteBufAllocator 配置
      String allocType = SystemPropertyUtil.get("io.netty.allocator.type", PlatformDependent.isAndroid() ? "unpooled" : "pooled");
      allocType = allocType.toLowerCase(Locale.US).trim();
  
      // 读取 ByteBufAllocator 对象
      ByteBufAllocator alloc;
      if ("unpooled".equals(allocType)) {
          alloc = UnpooledByteBufAllocator.DEFAULT;
          logger.debug("-Dio.netty.allocator.type: {}", allocType);
      } else if ("pooled".equals(allocType)) {
          alloc = PooledByteBufAllocator.DEFAULT;
          logger.debug("-Dio.netty.allocator.type: {}", allocType);
      } else {
          alloc = PooledByteBufAllocator.DEFAULT;
          logger.debug("-Dio.netty.allocator.type: pooled (unknown: {})", allocType);
      }
  
      DEFAULT_ALLOCATOR = alloc;
  
      // ... 省略无关代码
  }
  ```

  - 在非 Android 环境下，使用 PooledByteBufAllocator 作为默认 ByteBufAllocator 对象。
  - 在 Android 环境下，使用 UnpooledByteBufAllocator 作为默认 ByteBufAllocator 对象。因为 Android 客户端的内存相对有限。

## 2.2 buffer

`#buffer(...)` 方法，创建一个 ByteBuf 对象。具体创建的是 Heap ByteBuf 还是 Direct ByteBuf ，由实现类决定。

```
/**
 * Allocate a {@link ByteBuf}. If it is a direct or heap buffer
 * depends on the actual implementation.
 */
ByteBuf buffer();
ByteBuf buffer(int initialCapacity);
ByteBuf buffer(int initialCapacity, int maxCapacity);
```

### 2.2.1 ioBuffer

`#ioBuffer(...)` 方法，创建一个用于 IO 操作的 ByteBuf 对象。倾向于 Direct ByteBuf ，因为对于 IO 操作来说，性能更优。

```
/**
 * Allocate a {@link ByteBuf}, preferably a direct buffer which is suitable for I/O.
 */
ByteBuf ioBuffer();
ByteBuf ioBuffer(int initialCapacity);
ByteBuf ioBuffer(int initialCapacity, int maxCapacity);
```

### 2.2.2 heapBuffer

`#heapBuffer(...)` 方法，创建一个 Heap Buffer 对象。代码如下：

```
/**
 * Allocate a heap {@link ByteBuf}.
 */
ByteBuf heapBuffer();
ByteBuf heapBuffer(int initialCapacity);
ByteBuf heapBuffer(int initialCapacity, int maxCapacity);
```

### 2.2.3 directBuffer

`#directBuffer(...)` 方法，创建一个 Direct Buffer 对象。代码如下：

```
/**
 * Allocate a direct {@link ByteBuf} with the given initial capacity.
 */
ByteBuf directBuffer(int initialCapacity);
ByteBuf directBuffer(int initialCapacity, int maxCapacity);
CompositeByteBuf compositeBuffer();
```

## 2.3 compositeBuffer

`#compositeBuffer(...)` 方法，创建一个 Composite ByteBuf 对象。具体创建的是 Heap ByteBuf 还是 Direct ByteBuf ，由实现类决定。

```
/**
 * Allocate a {@link CompositeByteBuf}.
 * If it is a direct or heap buffer depends on the actual implementation.
 */
CompositeByteBuf compositeBuffer();
CompositeByteBuf compositeBuffer(int maxNumComponents);
```

### 2.3.1 compositeHeapBuffer

`#compositeHeapBuffer(...)` 方法，创建一个 Composite Heap ByteBuf 对象。代码如下：

```
/**
 * Allocate a heap {@link CompositeByteBuf}.
 */
CompositeByteBuf compositeHeapBuffer();
CompositeByteBuf compositeHeapBuffer(int maxNumComponents);
```

### 2.3.2 compositeDirectBuffer

`#compositeDirectBuffer(...)` 方法，创建一个 Composite Direct ByteBuf 对象。代码如下：

```
/**
 * Allocate a direct {@link CompositeByteBuf}.
 */
CompositeByteBuf compositeDirectBuffer();
CompositeByteBuf compositeDirectBuffer(int maxNumComponents);
```

## 2.4 isDirectBufferPooled

`#isDirectBufferPooled()` 方法，是否基于 Direct ByteBuf 对象池。代码如下：

```
/**
 * Returns {@code true} if direct {@link ByteBuf}'s are pooled
 */
boolean isDirectBufferPooled();
```

## 2.5 calculateNewCapacity

`#calculateNewCapacity(int minNewCapacity, int maxCapacity)` 方法，在 ByteBuf 扩容时，计算新的容量，该容量的值在 `[minNewCapacity, maxCapacity]` 范围内。代码如下：

```
/**
 * Calculate the new capacity of a {@link ByteBuf} that is used when a {@link ByteBuf} needs to expand by the
 * {@code minNewCapacity} with {@code maxCapacity} as upper-bound.
 */
int calculateNewCapacity(int minNewCapacity, int maxCapacity);
```

# 3. AbstractByteBufAllocator

`io.netty.buffer.AbstractByteBufAllocator` ，实现 ByteBufAllocator 接口，ByteBufAllocator 抽象实现类，为 PooledByteBufAllocator 和 UnpooledByteBufAllocator 提供公共的方法。

## 3.1 构造方法

```
/**
 * 是否倾向创建 Direct ByteBuf
 */
private final boolean directByDefault;
/**
 * 空 ByteBuf 缓存
 */
private final ByteBuf emptyBuf;

/**
 * Instance use heap buffers by default
 */
protected AbstractByteBufAllocator() {
    this(false);
}

/**
 * Create new instance
 *
 * @param preferDirect {@code true} if {@link #buffer(int)} should try to allocate a direct buffer rather than
 *                     a heap buffer
 */
protected AbstractByteBufAllocator(boolean preferDirect) {
    directByDefault = preferDirect && PlatformDependent.hasUnsafe(); // 支持 Unsafe
    emptyBuf = new EmptyByteBuf(this);
}
```

- `directByDefault` 属性，是否倾向创建 Direct ByteBuf 。有一个前提是需要支持 Unsafe 操作。
- `emptyBuf` 属性，空 ByteBuf 缓存对象。用于 `#buffer()` 等方法，创建**空** ByteBuf 对象时。

## 3.2 buffer

```
@Override
public ByteBuf buffer() {
    if (directByDefault) {
        return directBuffer();
    }
    return heapBuffer();
}
@Override
public ByteBuf buffer(int initialCapacity) {
    if (directByDefault) {
        return directBuffer(initialCapacity);
    }
    return heapBuffer(initialCapacity);
}
@Override
public ByteBuf buffer(int initialCapacity, int maxCapacity) {
    if (directByDefault) {
        return directBuffer(initialCapacity, maxCapacity);
    }
    return heapBuffer(initialCapacity, maxCapacity);
}
```

- 根据 `directByDefault` 的值，调用 `#directBuffer(...)` 方法，还是调用 `#heapBuffer(...)` 方法。

### 3.2.1 ioBuffer

```
/**
 * 默认容量大小
 */
static final int DEFAULT_INITIAL_CAPACITY = 256;

@Override
public ByteBuf ioBuffer() {
    if (PlatformDependent.hasUnsafe()) {
        return directBuffer(DEFAULT_INITIAL_CAPACITY);
    }
    return heapBuffer(DEFAULT_INITIAL_CAPACITY);
}

@Override
public ByteBuf ioBuffer(int initialCapacity) {
    if (PlatformDependent.hasUnsafe()) {
        return directBuffer(initialCapacity);
    }
    return heapBuffer(initialCapacity);
}

@Override
public ByteBuf ioBuffer(int initialCapacity, int maxCapacity) {
    if (PlatformDependent.hasUnsafe()) {
        return directBuffer(initialCapacity, maxCapacity);
    }
    return heapBuffer(initialCapacity, maxCapacity);
}
```

- 根据是否支持 Unsafe 操作的情况，调用 `#directBuffer(...)` 方法，还是调用 `#heapBuffer(...)` 方法。

### 3.2.2 heapBuffer

```
/**
 * 默认最大容量大小，无限。
 */
static final int DEFAULT_MAX_CAPACITY = Integer.MAX_VALUE;

@Override
public ByteBuf heapBuffer() {
    return heapBuffer(DEFAULT_INITIAL_CAPACITY, DEFAULT_MAX_CAPACITY);
}

@Override
public ByteBuf heapBuffer(int initialCapacity) {
    return heapBuffer(initialCapacity, DEFAULT_MAX_CAPACITY);
}

@Override
public ByteBuf heapBuffer(int initialCapacity, int maxCapacity) {
    // 空 ByteBuf 对象
    if (initialCapacity == 0 && maxCapacity == 0) {
        return emptyBuf;
    }
    validate(initialCapacity, maxCapacity); // 校验容量的参数
    // 创建 Heap ByteBuf 对象
    return newHeapBuffer(initialCapacity, maxCapacity);
}
```

- 最终调用 `#newHeapBuffer(int initialCapacity, int maxCapacity)` **抽象**方法，创建 Heap ByteBuf 对象。代码如下：

  ```
  /**
   * Create a heap {@link ByteBuf} with the given initialCapacity and maxCapacity.
   */
  protected abstract ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity);
  ```

  - 因为是否基于对象池的方式，创建 Heap ByteBuf 对象的实现会不同，所以需要抽象。

### 3.2.3 directBuffer

```
@Override
public ByteBuf directBuffer() {
    return directBuffer(DEFAULT_INITIAL_CAPACITY, DEFAULT_MAX_CAPACITY);
}

@Override
public ByteBuf directBuffer(int initialCapacity) {
    return directBuffer(initialCapacity, DEFAULT_MAX_CAPACITY);
}

@Override
public ByteBuf directBuffer(int initialCapacity, int maxCapacity) {
    // 空 ByteBuf 对象
    if (initialCapacity == 0 && maxCapacity == 0) {
        return emptyBuf;
    }
    validate(initialCapacity, maxCapacity); // 校验容量的参数
    // 创建 Direct ByteBuf 对象
    return newDirectBuffer(initialCapacity, maxCapacity);
}

```

- 最终调用 `#newDirectBuffer(int initialCapacity, int maxCapacity)` **抽象**方法，创建 Direct ByteBuf 对象。代码如下：

  ```
  /**
   * Create a direct {@link ByteBuf} with the given initialCapacity and maxCapacity.
   */
  protected abstract ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity);
  
  ```

  - 因为是否基于对象池的方式，创建 Direct ByteBuf 对象的实现会不同，所以需要抽象。

## 3.3 compositeBuffer

```
@Override
public CompositeByteBuf compositeBuffer() {
    if (directByDefault) {
        return compositeDirectBuffer();
    }
    return compositeHeapBuffer();
}

@Override
public CompositeByteBuf compositeBuffer(int maxNumComponents) {
    if (directByDefault) {
        return compositeDirectBuffer(maxNumComponents);
    }
    return compositeHeapBuffer(maxNumComponents);
}

```

- 根据 `directByDefault` 的值，调用 `#compositeDirectBuffer(...)` 方法，还是调用 `#compositeHeapBuffer(...)` 方法。

### 3.3.1 compositeHeapBuffer

```
/**
 * Composite ByteBuf 可包含的 ByteBuf 的最大数量
 */
static final int DEFAULT_MAX_COMPONENTS = 16;

@Override
public CompositeByteBuf compositeHeapBuffer() {
    return compositeHeapBuffer(DEFAULT_MAX_COMPONENTS);
}

@Override
public CompositeByteBuf compositeHeapBuffer(int maxNumComponents) {
    return toLeakAwareBuffer(new CompositeByteBuf(this, false, maxNumComponents));
}

```

- 创建 CompositeByteBuf 对象，并且方法参数 `direct` 为 `false` ，表示 Heap 类型。
- 调用 `#toLeakAwareBuffer(CompositeByteBuf)` 方法，装饰成 LeakAware 的 ByteBuf 对象。

### 3.3.2 compositeDirectBuffer

```
@Override
public CompositeByteBuf compositeDirectBuffer() {
    return compositeDirectBuffer(DEFAULT_MAX_COMPONENTS);
}

@Override
public CompositeByteBuf compositeDirectBuffer(int maxNumComponents) {
    return toLeakAwareBuffer(new CompositeByteBuf(this, true, maxNumComponents));
}

```

- 创建 CompositeByteBuf 对象，并且方法参数 `direct` 为 `true` ，表示 Direct 类型。
- 调用 `#toLeakAwareBuffer(CompositeByteBuf)` 方法，装饰成 LeakAware 的 ByteBuf 对象。

## 3.4 toLeakAwareBuffer

在 [《精尽 Netty 源码解析 —— Buffer 之 ByteBuf（三）内存泄露检测》](http://svip.iocoder.cn/Netty/ByteBuf-1-3-ByteBuf-resource-leak-detector) 中的 [「3.1 创建 LeakAware ByteBuf 对象」](http://svip.iocoder.cn/Netty/ByteBuf-2-1-ByteBufAllocator-intro/#) 小节，已经详细解析。

## 3.5 calculateNewCapacity

```
/**
 * 扩容分界线，4M
 */
static final int CALCULATE_THRESHOLD = 1048576 * 4; // 4 MiB page

  1: @Override
  2: public int calculateNewCapacity(int minNewCapacity, int maxCapacity) {
  3:     if (minNewCapacity < 0) {
  4:         throw new IllegalArgumentException("minNewCapacity: " + minNewCapacity + " (expected: 0+)");
  5:     }
  6:     if (minNewCapacity > maxCapacity) {
  7:         throw new IllegalArgumentException(String.format(
  8:                 "minNewCapacity: %d (expected: not greater than maxCapacity(%d)",
  9:                 minNewCapacity, maxCapacity));
 10:     }
 11:     final int threshold = CALCULATE_THRESHOLD; // 4 MiB page
 12: 
 13:     // <1> 等于 threshold ，直接返回 threshold 。
 14:     if (minNewCapacity == threshold) {
 15:         return threshold;
 16:     }
 17: 
 18:     // <2> 超过 threshold ，增加 threshold ，不超过 maxCapacity 大小。
 19:     // If over threshold, do not double but just increase by threshold.
 20:     if (minNewCapacity > threshold) {
 21:         int newCapacity = minNewCapacity / threshold * threshold;
 22:         if (newCapacity > maxCapacity - threshold) { // 不超过 maxCapacity
 23:             newCapacity = maxCapacity;
 24:         } else {
 25:             newCapacity += threshold;
 26:         }
 27:         return newCapacity;
 28:     }
 29: 
 30:     // <3> 未超过 threshold ，从 64 开始两倍计算，不超过 4M 大小。
 31:     // Not over threshold. Double up to 4 MiB, starting from 64.
 32:     int newCapacity = 64;
 33:     while (newCapacity < minNewCapacity) {
 34:         newCapacity <<= 1;
 35:     }
 36:     return Math.min(newCapacity, maxCapacity);
 37: }

```

- 按照 `CALCULATE_THRESHOLD` 作为分界线，分成 3 种情况：`<1>`/`<2>`/`<3>` 。代码比较简单，胖友自己看注释。

# 4. PreferHeapByteBufAllocator

`io.netty.channel.PreferHeapByteBufAllocator` ，实现 ByteBufAllocator 接口，**倾向创建 Heap ByteBuf** 的分配器。也就是说，`#buffer(...)` 和 `#ioBuffer(...)` 和 `#compositeBuffer(...)` 方法，创建的都是 Heap ByteBuf 对象。代码如下：

```
/**
 * 真正的分配器对象
 */
private final ByteBufAllocator allocator;

public PreferHeapByteBufAllocator(ByteBufAllocator allocator) {
    this.allocator = ObjectUtil.checkNotNull(allocator, "allocator");
}

@Override
public ByteBuf buffer() {
    return allocator.heapBuffer();
}

@Override
public ByteBuf ioBuffer() {
    return allocator.heapBuffer();
}

@Override
public CompositeByteBuf compositeBuffer() {
    return allocator.compositeHeapBuffer();
}

```

其它方法，就是调用 `allocator` 的对应的方法。

# 666. 彩蛋

😈 小水文一篇。铺垫铺垫，你懂的。

# 精尽 Netty 源码解析 —— Buffer 之 ByteBufAllocator（二）UnpooledByteBufAllocator



# 1. 概述

本文，我们来分享 UnpooledByteBufAllocator ，**普通**的 ByteBuf 的分配器，**不基于内存池**。

# 2. ByteBufAllocatorMetricProvider

`io.netty.buffer.ByteBufAllocatorMetricProvider` ，ByteBufAllocator Metric 提供者接口，**用于监控 ByteBuf 的 Heap 和 Direct 占用内存的情况**。代码如下：

```
public interface ByteBufAllocatorMetricProvider {

    /**
     * Returns a {@link ByteBufAllocatorMetric} for a {@link ByteBufAllocator}.
     */
    ByteBufAllocatorMetric metric();

}
```

ByteBufAllocatorMetricProvider 有两个子类：UnpooledByteBufAllocator 和 PooledByteBufAllocator 。

# 3. ByteBufAllocatorMetric

`io.netty.buffer.ByteBufAllocatorMetric` ，ByteBufAllocator Metric 接口。代码如下：

```
public interface ByteBufAllocatorMetric {

    /**
     * Returns the number of bytes of heap memory used by a {@link ByteBufAllocator} or {@code -1} if unknown.
     *
     * 已使用 Heap 占用内存大小
     */
    long usedHeapMemory();

    /**
     * Returns the number of bytes of direct memory used by a {@link ByteBufAllocator} or {@code -1} if unknown.
     *
     * 已使用 Direct 占用内存大小
     */
    long usedDirectMemory();

}
```

ByteBufAllocatorMetric 有两个子类：UnpooledByteBufAllocatorMetric 和 PooledByteBufAllocatorMetric 。

## 3.1 UnpooledByteBufAllocatorMetric

UnpooledByteBufAllocatorMetric ，在 UnpooledByteBufAllocator 的**内部静态类**，实现 ByteBufAllocatorMetric 接口，UnpooledByteBufAllocator Metric 实现类。代码如下：

```
/**
 * Direct ByteBuf 占用内存大小
 */
final LongCounter directCounter = PlatformDependent.newLongCounter();
/**
 * Heap ByteBuf 占用内存大小
 */
final LongCounter heapCounter = PlatformDependent.newLongCounter();

@Override
public long usedHeapMemory() {
    return heapCounter.value();
}

@Override
public long usedDirectMemory() {
    return directCounter.value();
}
```

- 比较简单，两个计数器。

- `PlatformDependent#newLongCounter()` 方法，获得 LongCounter 对象。代码如下：

  ```
  /**
   * Creates a new fastest {@link LongCounter} implementation for the current platform.
   */
  public static LongCounter newLongCounter() {
      if (javaVersion() >= 8) {
          return new LongAdderCounter();
      } else {
          return new AtomicLongCounter();
      }
  }
  ```

  - 也就是说，JDK `>=8` 使用 `java.util.concurrent.atomic.LongAdder` ，JDK `<7` 使用 `java.util.concurrent.atomic.AtomicLong` 。相比来说，Metric 写多读少，所以 LongAdder 比 AtomicLong 更合适。对比的解析，可以看看 [《Java并发计数器探秘》](https://www.cnkirito.moe/java-concurrent-counter/) 。

# 4. UnpooledByteBufAllocator

`io.netty.buffer.UnpooledByteBufAllocator` ，实现 ByteBufAllocatorMetricProvider 接口，继承 AbstractByteBufAllocator 抽象类，**普通**的 ByteBuf 的分配器，**不基于内存池**。

## 4.1 构造方法

```
/**
 * Metric
 */
private final UnpooledByteBufAllocatorMetric metric = new UnpooledByteBufAllocatorMetric();
/**
 * 是否禁用内存泄露检测功能
 */
private final boolean disableLeakDetector;
/**
 * 不使用 `io.netty.util.internal.Cleaner` 释放 Direct ByteBuf
 *
 * @see UnpooledUnsafeNoCleanerDirectByteBuf
 * @see InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf
 */
private final boolean noCleaner;

public UnpooledByteBufAllocator(boolean preferDirect) {
    this(preferDirect, false);
}

public UnpooledByteBufAllocator(boolean preferDirect, boolean disableLeakDetector) {
    this(preferDirect, disableLeakDetector, PlatformDependent.useDirectBufferNoCleaner() /** 返回 true **/ );
}

/**
 * Create a new instance
 *
 * @param preferDirect {@code true} if {@link #buffer(int)} should try to allocate a direct buffer rather than
 *                     a heap buffer
 * @param disableLeakDetector {@code true} if the leak-detection should be disabled completely for this
 *                            allocator. This can be useful if the user just want to depend on the GC to handle
 *                            direct buffers when not explicit released.
 * @param tryNoCleaner {@code true} if we should try to use {@link PlatformDependent#allocateDirectNoCleaner(int)}
 *                            to allocate direct memory.
 */
public UnpooledByteBufAllocator(boolean preferDirect, boolean disableLeakDetector, boolean tryNoCleaner) {
    super(preferDirect);
    this.disableLeakDetector = disableLeakDetector;
    noCleaner = tryNoCleaner && PlatformDependent.hasUnsafe() /** 返回 true **/
            && PlatformDependent.hasDirectBufferNoCleanerConstructor() /** 返回 true **/ ;
}
```

- `metric` 属性，UnpooledByteBufAllocatorMetric 对象。

- ```
  disableLeakDetector
  ```

   

  属性，是否禁用内存泄露检测功能。

  - 默认为 `false` 。

- ```
  noCleaner
  ```

   

  属性，是否不使用

   

  ```
  io.netty.util.internal.Cleaner
  ```

   

  来释放 Direct ByteBuf 。

  - 默认为 `true` 。
  - 详细解析，见 [「5.5 InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-2-2-ByteBufAllocator-unpooled/#) 。

## 4.2 newHeapBuffer

```
@Override
protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) {
    return PlatformDependent.hasUnsafe() ?
            new InstrumentedUnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) :
            new InstrumentedUnpooledHeapByteBuf(this, initialCapacity, maxCapacity);
}
```

- 创建的是以 `"Instrumented"` 的 Heap ByteBuf 对象，因为要结合 Metric 。详细解析，见 [「5. Instrumented ByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-2-2-ByteBufAllocator-unpooled/#) 。

## 4.3 newDirectBuffer

```
@Override
protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {
    final ByteBuf buf;
    if (PlatformDependent.hasUnsafe()) {
        buf = noCleaner ? new InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(this, initialCapacity, maxCapacity) :
                new InstrumentedUnpooledUnsafeDirectByteBuf(this, initialCapacity, maxCapacity);
    } else {
        buf = new InstrumentedUnpooledDirectByteBuf(this, initialCapacity, maxCapacity);
    }
    return disableLeakDetector ? buf : toLeakAwareBuffer(buf);
}
```

- 创建的是以 `"Instrumented"` 的 Heap ByteBuf 对象，因为要结合 Metric 。详细解析，见 [「5. Instrumented ByteBuf」](http://svip.iocoder.cn/Netty/ByteBuf-2-2-ByteBufAllocator-unpooled/#) 。
- 结合了 `disableLeakDetector` 属性。

## 4.4 compositeHeapBuffer

```
@Override
public CompositeByteBuf compositeHeapBuffer(int maxNumComponents) {
    CompositeByteBuf buf = new CompositeByteBuf(this, false, maxNumComponents);
    return disableLeakDetector ? buf : toLeakAwareBuffer(buf);
}
```

- 结合了 `disableLeakDetector` 属性。

## 4.5 compositeDirectBuffer

```
@Override
public CompositeByteBuf compositeDirectBuffer(int maxNumComponents) {
    CompositeByteBuf buf = new CompositeByteBuf(this, true, maxNumComponents);
    return disableLeakDetector ? buf : toLeakAwareBuffer(buf);
}
```

- 结合了 `disableLeakDetector` 属性。

## 4.6 isDirectBufferPooled

```
@Override
public boolean isDirectBufferPooled() {
    return false;
}
```

## 4.7 Metric 相关操作方法

```
@Override
public ByteBufAllocatorMetric metric() {
    return metric;
}

void incrementDirect(int amount) { // 增加 Direct
    metric.directCounter.add(amount);
}
void decrementDirect(int amount) { // 减少 Direct
    metric.directCounter.add(-amount);
}

void incrementHeap(int amount) { // 增加 Heap
    metric.heapCounter.add(amount);
}
void decrementHeap(int amount) { // 减少 Heap
    metric.heapCounter.add(-amount);
}
```

# 5. Instrumented ByteBuf

因为要和 Metric 结合，所以通过**继承**的方式，进行增强。

## 5.1 InstrumentedUnpooledUnsafeHeapByteBuf

**Instrumented**UnpooledUnsafeHeapByteBuf ，在 UnpooledByteBufAllocator 的**内部静态类**，继承 UnpooledUnsafeHeapByteBuf 类。代码如下：

```
private static final class InstrumentedUnpooledUnsafeHeapByteBuf extends UnpooledUnsafeHeapByteBuf {

    InstrumentedUnpooledUnsafeHeapByteBuf(UnpooledByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected byte[] allocateArray(int initialCapacity) {
        byte[] bytes = super.allocateArray(initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementHeap(bytes.length);
        return bytes;
    }

    @Override
    protected void freeArray(byte[] array) {
        int length = array.length;
        super.freeArray(array);
        // Metric --
        ((UnpooledByteBufAllocator) alloc()).decrementHeap(length);
    }

}
```

- 在原先的基础上，调用 Metric 相应的增减操作方法，得以记录 Heap 占用内存的大小。

## 5.2 InstrumentedUnpooledHeapByteBuf

**Instrumented**UnpooledHeapByteBuf ，在 UnpooledByteBufAllocator 的**内部静态类**，继承 UnpooledHeapByteBuf 类。代码如下：

```
private static final class InstrumentedUnpooledHeapByteBuf extends UnpooledHeapByteBuf {

    InstrumentedUnpooledHeapByteBuf(UnpooledByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected byte[] allocateArray(int initialCapacity) {
        byte[] bytes = super.allocateArray(initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementHeap(bytes.length);
        return bytes;
    }

    @Override
    protected void freeArray(byte[] array) {
        int length = array.length;
        super.freeArray(array);
        // Metric --
        ((UnpooledByteBufAllocator) alloc()).decrementHeap(length);
    }

}
```

- 在原先的基础上，调用 Metric 相应的增减操作方法，得以记录 Heap 占用内存的大小。

## 5.3 InstrumentedUnpooledUnsafeDirectByteBuf

**Instrumented**UnpooledUnsafeDirectByteBuf ，在 UnpooledByteBufAllocator 的**内部静态类**，继承 UnpooledUnsafeDirectByteBuf 类。代码如下：

```
private static final class InstrumentedUnpooledUnsafeDirectByteBuf extends UnpooledUnsafeDirectByteBuf {
    InstrumentedUnpooledUnsafeDirectByteBuf(
            UnpooledByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected ByteBuffer allocateDirect(int initialCapacity) {
        ByteBuffer buffer = super.allocateDirect(initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementDirect(buffer.capacity());
        return buffer;
    }

    @Override
    protected void freeDirect(ByteBuffer buffer) {
        int capacity = buffer.capacity();
        super.freeDirect(buffer);
        // Metric --
        ((UnpooledByteBufAllocator) alloc()).decrementDirect(capacity);
    }
}

```

- 在原先的基础上，调用 Metric 相应的增减操作方法，得以记录 Direct 占用内存的大小。

## 5.4 InstrumentedUnpooledDirectByteBuf

**Instrumented**UnpooledDirectByteBuf 的**内部静态类**，继承 UnpooledDirectByteBuf 类。代码如下：

```
private static final class InstrumentedUnpooledDirectByteBuf extends UnpooledDirectByteBuf {

    InstrumentedUnpooledDirectByteBuf(
            UnpooledByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected ByteBuffer allocateDirect(int initialCapacity) {
        ByteBuffer buffer = super.allocateDirect(initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementDirect(buffer.capacity());
        return buffer;
    }

    @Override
    protected void freeDirect(ByteBuffer buffer) {
        int capacity = buffer.capacity();
        super.freeDirect(buffer);
        // Metric --
        ((UnpooledByteBufAllocator) alloc()).decrementDirect(capacity);
    }

}

```

- 在原先的基础上，调用 Metric 相应的增减操作方法，得以记录 Direct 占用内存的大小。

## 5.5 InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf

**Instrumented**UnpooledDirectByteBuf 的**内部静态类**，继承 UnpooledUnsafeNoCleanerDirectByteBuf 类。代码如下：

```
private static final class InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf
        extends UnpooledUnsafeNoCleanerDirectByteBuf {

    InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(
            UnpooledByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected ByteBuffer allocateDirect(int initialCapacity) {
        ByteBuffer buffer = super.allocateDirect(initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementDirect(buffer.capacity());
        return buffer;
    }

    @Override
    ByteBuffer reallocateDirect(ByteBuffer oldBuffer, int initialCapacity) {
        int capacity = oldBuffer.capacity();
        ByteBuffer buffer = super.reallocateDirect(oldBuffer, initialCapacity);
        // Metric ++
        ((UnpooledByteBufAllocator) alloc()).incrementDirect(buffer.capacity() - capacity);
        return buffer;
    }

    @Override
    protected void freeDirect(ByteBuffer buffer) {
        int capacity = buffer.capacity();
        super.freeDirect(buffer);
        // Metric --
        ((UnpooledByteBufAllocator) alloc()).decrementDirect(capacity);
    }

}

```

- 在原先的基础上，调用 Metric 相应的增减操作方法，得以记录 Heap 占用内存的大小。

### 5.5.1 UnpooledUnsafeNoCleanerDirectByteBuf

`io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf` ，继承 UnpooledUnsafeDirectByteBuf 类。代码如下：

```
class UnpooledUnsafeNoCleanerDirectByteBuf extends UnpooledUnsafeDirectByteBuf {

    UnpooledUnsafeNoCleanerDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) {
        super(alloc, initialCapacity, maxCapacity);
    }

    @Override
    protected ByteBuffer allocateDirect(int initialCapacity) {
        // 反射，直接创建 ByteBuffer 对象。并且该对象不带 Cleaner 对象
        return PlatformDependent.allocateDirectNoCleaner(initialCapacity);
    }

    ByteBuffer reallocateDirect(ByteBuffer oldBuffer, int initialCapacity) {
        return PlatformDependent.reallocateDirectNoCleaner(oldBuffer, initialCapacity);
    }

    @Override
    protected void freeDirect(ByteBuffer buffer) {
        // 直接释放 ByteBuffer 对象
        PlatformDependent.freeDirectNoCleaner(buffer);
    }

    @Override
    public ByteBuf capacity(int newCapacity) {
        checkNewCapacity(newCapacity);

        int oldCapacity = capacity();
        if (newCapacity == oldCapacity) {
            return this;
        }

        // 重新分配 ByteBuf 对象
        ByteBuffer newBuffer = reallocateDirect(buffer, newCapacity);

        if (newCapacity < oldCapacity) {
            if (readerIndex() < newCapacity) {
                // 重置 writerIndex 为 newCapacity ，避免越界
                if (writerIndex() > newCapacity) {
                    writerIndex(newCapacity);
                }
            } else {
                // 重置 writerIndex 和 readerIndex 为 newCapacity ，避免越界
                setIndex(newCapacity, newCapacity);
            }
        }

        // 设置 ByteBuf 对象
        setByteBuffer(newBuffer, false);
        return this;
    }

}

```

> FROM [《Netty源码分析（一） ByteBuf》](https://www.jianshu.com/p/b833254908f7)
>
> 和 UnpooledUnsafeDirectByteBuf 最大区别在于 UnpooledUnsafeNoCleanerDirectByteBuf 在 allocate的时候通过反射构造函数的方式创建DirectByteBuffer，这样在DirectByteBuffer中没有对应的Cleaner函数(通过ByteBuffer.allocateDirect的方式会自动生成Cleaner函数，Cleaner用于内存回收，具体可以看源码)，内存回收时，UnpooledUnsafeDirectByteBuf通过调用DirectByteBuffer中的Cleaner函数回收，而UnpooledUnsafeNoCleanerDirectByteBuf直接使用UNSAFE.freeMemory(address)释放内存地址。

# 666. 彩蛋

😈 小水文一篇。铺垫铺垫，你懂的。

# 精尽 Netty 源码解析 —— Buffer 之 ByteBufAllocator（三）PooledByteBufAllocator



# 1. 概述

本文，我们来分享 PooledByteBufAllocator ，基于**内存池**的 ByteBuf 的分配器。而 PooledByteBufAllocator 的内存池，是基于 **Jemalloc** 算法进行分配管理，所以在看本文之前，胖友先跳到 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）简介》](http://svip.iocoder.cn/Netty/ByteBuf-3-1-Jemalloc-intro) ，将 Jemalloc 相关的**几篇**文章看完，在回到此处。

# 2. PooledByteBufAllocatorMetric

`io.netty.buffer.PooledByteBufAllocatorMetric` ，实现 ByteBufAllocatorMetric 接口，PooledByteBufAllocator Metric 实现类。代码如下：

```
public final class PooledByteBufAllocatorMetric implements ByteBufAllocatorMetric {

    /**
     * PooledByteBufAllocator 对象
     */
    private final PooledByteBufAllocator allocator;

    PooledByteBufAllocatorMetric(PooledByteBufAllocator allocator) {
        this.allocator = allocator;
    }

    /**
     * Return the number of heap arenas.
     */
    public int numHeapArenas() {
        return allocator.numHeapArenas();
    }
    /**
     * Return the number of direct arenas.
     */
    public int numDirectArenas() {
        return allocator.numDirectArenas();
    }

    /**
     * Return a {@link List} of all heap {@link PoolArenaMetric}s that are provided by this pool.
     */
    public List<PoolArenaMetric> heapArenas() {
        return allocator.heapArenas();
    }
    /**
     * Return a {@link List} of all direct {@link PoolArenaMetric}s that are provided by this pool.
     */
    public List<PoolArenaMetric> directArenas() {
        return allocator.directArenas();
    }

    /**
     * Return the number of thread local caches used by this {@link PooledByteBufAllocator}.
     */
    public int numThreadLocalCaches() {
        return allocator.numThreadLocalCaches();
    }

    /**
     * Return the size of the tiny cache.
     */
    public int tinyCacheSize() {
        return allocator.tinyCacheSize();
    }
    /**
     * Return the size of the small cache.
     */
    public int smallCacheSize() {
        return allocator.smallCacheSize();
    }
    /**
     * Return the size of the normal cache.
     */
    public int normalCacheSize() {
        return allocator.normalCacheSize();
    }

    /**
     * Return the chunk size for an arena.
     */
    public int chunkSize() {
        return allocator.chunkSize();
    }

    @Override
    public long usedHeapMemory() {
        return allocator.usedHeapMemory();
    }
    @Override
    public long usedDirectMemory() {
        return allocator.usedDirectMemory();
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder(256);
        sb.append(StringUtil.simpleClassName(this))
                .append("(usedHeapMemory: ").append(usedHeapMemory())
                .append("; usedDirectMemory: ").append(usedDirectMemory())
                .append("; numHeapArenas: ").append(numHeapArenas())
                .append("; numDirectArenas: ").append(numDirectArenas())
                .append("; tinyCacheSize: ").append(tinyCacheSize())
                .append("; smallCacheSize: ").append(smallCacheSize())
                .append("; normalCacheSize: ").append(normalCacheSize())
                .append("; numThreadLocalCaches: ").append(numThreadLocalCaches())
                .append("; chunkSize: ").append(chunkSize()).append(')');
        return sb.toString();
    }

}
```

- 每个实现方法，都是调用 `allocator` 对应的方法。通过 PooledByteBufAllocatorMetric 的封装，可以统一获得 PooledByteBufAllocator Metric 相关的信息。

# 3. PooledByteBufAllocator

`io.netty.buffer.PooledByteBufAllocator` ，实现 ByteBufAllocatorMetricProvider 接口，实现 AbstractByteBufAllocator 抽象类，基于**内存池**的 ByteBuf 的分配器。

## 3.1 静态属性

```
/**
 * 默认 Heap 类型的 Arena 数量
 */
private static final int DEFAULT_NUM_HEAP_ARENA;
/**
 * 默认 Direct 类型的 Arena 数量
 */
private static final int DEFAULT_NUM_DIRECT_ARENA;

/**
 * 默认 Page 的内存大小，单位：B 。
 *
 * 默认配置，8192 B = 8 KB
 */
private static final int DEFAULT_PAGE_SIZE;
/**
 * {@link PoolChunk} 满二叉树的高度，默认为 11 。
 */
private static final int DEFAULT_MAX_ORDER; // 8192 << 11 = 16 MiB per chunk
/**
 * 默认 {@link PoolThreadCache} 的 tiny 类型的内存块的缓存数量。默认为 512 。
 *
 * @see #tinyCacheSize
 */
private static final int DEFAULT_TINY_CACHE_SIZE;
/**
 * 默认 {@link PoolThreadCache} 的 small 类型的内存块的缓存数量。默认为 256 。
 *
 * @see #smallCacheSize
 */
private static final int DEFAULT_SMALL_CACHE_SIZE;
/**
 * 默认 {@link PoolThreadCache} 的 normal 类型的内存块的缓存数量。默认为 64 。
 *
 * @see #normalCacheSize
 */
private static final int DEFAULT_NORMAL_CACHE_SIZE;
/**
 * 默认 {@link PoolThreadCache} 缓存的内存块的最大字节数
 */
private static final int DEFAULT_MAX_CACHED_BUFFER_CAPACITY;
/**
 * 默认 {@link PoolThreadCache}
 */
private static final int DEFAULT_CACHE_TRIM_INTERVAL;
/**
 * 默认是否使用 {@link PoolThreadCache}
 */
private static final boolean DEFAULT_USE_CACHE_FOR_ALL_THREADS;

/**
 * 默认 Direct 内存对齐基准
 */
private static final int DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT;

/**
 * Page 的内存最小值。默认为 4KB = 4096B
 */
private static final int MIN_PAGE_SIZE = 4096;
/**
 * Chunk 的内存最大值。默认为 1GB
 */
private static final int MAX_CHUNK_SIZE = (int) (((long) Integer.MAX_VALUE + 1) / 2);

static {
    // 初始化 DEFAULT_PAGE_SIZE
    int defaultPageSize = SystemPropertyUtil.getInt("io.netty.allocator.pageSize", 8192);
    Throwable pageSizeFallbackCause = null;
    try {
        validateAndCalculatePageShifts(defaultPageSize);
    } catch (Throwable t) {
        pageSizeFallbackCause = t;
        defaultPageSize = 8192;
    }
    DEFAULT_PAGE_SIZE = defaultPageSize;

    // 初始化 DEFAULT_MAX_ORDER
    int defaultMaxOrder = SystemPropertyUtil.getInt("io.netty.allocator.maxOrder", 11);
    Throwable maxOrderFallbackCause = null;
    try {
        validateAndCalculateChunkSize(DEFAULT_PAGE_SIZE, defaultMaxOrder);
    } catch (Throwable t) {
        maxOrderFallbackCause = t;
        defaultMaxOrder = 11;
    }
    DEFAULT_MAX_ORDER = defaultMaxOrder;

    // Determine reasonable default for nHeapArena and nDirectArena.
    // Assuming each arena has 3 chunks, the pool should not consume more than 50% of max memory.
    final Runtime runtime = Runtime.getRuntime();

    /*
     * We use 2 * available processors by default to reduce contention as we use 2 * available processors for the
     * number of EventLoops in NIO and EPOLL as well. If we choose a smaller number we will run into hot spots as
     * allocation and de-allocation needs to be synchronized on the PoolArena.
     *
     * See https://github.com/netty/netty/issues/3888.
     */
    // 默认最小 Arena 个数。为什么这样计算，见上面的英文注释，大体的思路是，一个 EventLoop 一个 Arena ，避免多线程竞争。
    final int defaultMinNumArena = NettyRuntime.availableProcessors() * 2;
    // 初始化默认 Chunk 的内存大小。默认值为 8192 << 11 = 16 MiB per chunk
    final int defaultChunkSize = DEFAULT_PAGE_SIZE << DEFAULT_MAX_ORDER;
    // 初始化 DEFAULT_NUM_HEAP_ARENA
    DEFAULT_NUM_HEAP_ARENA = Math.max(0,
            SystemPropertyUtil.getInt(
                    "io.netty.allocator.numHeapArenas",
                    (int) Math.min(
                            defaultMinNumArena,
                            runtime.maxMemory() / defaultChunkSize / 2 / 3))); // `/ 2` 是为了不超过内存的一半，`/ 3` 是为了每个 Arena 有三个 Chunk
    // 初始化 DEFAULT_NUM_DIRECT_ARENA
    DEFAULT_NUM_DIRECT_ARENA = Math.max(0,
            SystemPropertyUtil.getInt(
                    "io.netty.allocator.numDirectArenas",
                    (int) Math.min(
                            defaultMinNumArena,
                            PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3)));

    // cache sizes
    // <1> 初始化 DEFAULT_TINY_CACHE_SIZE
    DEFAULT_TINY_CACHE_SIZE = SystemPropertyUtil.getInt("io.netty.allocator.tinyCacheSize", 512);
    // 初始化 DEFAULT_SMALL_CACHE_SIZE
    DEFAULT_SMALL_CACHE_SIZE = SystemPropertyUtil.getInt("io.netty.allocator.smallCacheSize", 256);
    // 初始化 DEFAULT_NORMAL_CACHE_SIZE
    DEFAULT_NORMAL_CACHE_SIZE = SystemPropertyUtil.getInt("io.netty.allocator.normalCacheSize", 64);

    // 初始化 DEFAULT_MAX_CACHED_BUFFER_CAPACITY
    // 32 kb is the default maximum capacity of the cached buffer. Similar to what is explained in
    // 'Scalable memory allocation using jemalloc'
    DEFAULT_MAX_CACHED_BUFFER_CAPACITY = SystemPropertyUtil.getInt("io.netty.allocator.maxCachedBufferCapacity", 32 * 1024);

    // 初始化 DEFAULT_CACHE_TRIM_INTERVAL
    // the number of threshold of allocations when cached entries will be freed up if not frequently used
    DEFAULT_CACHE_TRIM_INTERVAL = SystemPropertyUtil.getInt("io.netty.allocator.cacheTrimInterval", 8192);

    // 初始化 DEFAULT_USE_CACHE_FOR_ALL_THREADS
    DEFAULT_USE_CACHE_FOR_ALL_THREADS = SystemPropertyUtil.getBoolean("io.netty.allocator.useCacheForAllThreads", true);

    // 初始化 DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT
    DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT = SystemPropertyUtil.getInt("io.netty.allocator.directMemoryCacheAlignment", 0);

    // 打印调试日志( 省略... )
}
```

- 静态变量有点多，主要是为 PoolThreadCache 做的**默认**配置项。读过 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache》](http://svip.iocoder.cn/Netty/ByteBuf-2-3-ByteBufAllocator-pooled/精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache) 的胖友，是不是灰常熟悉。

- 比较有意思的是，

  ```
  DEFAULT_NUM_HEAP_ARENA
  ```

   

  和

   

  ```
  DEFAULT_NUM_DIRECT_ARENA
  ```

   

  变量的初始化，在

   

  ```
  <1>
  ```

   

  处。

  - 默认情况下，最小值是 `NettyRuntime.availableProcessors() * 2` ，也就是 CPU 线程数。这样的好处是， 一个 EventLoop 一个 Arena ，**避免多线程竞争**。更多的讨论，胖友可以看看 <https://github.com/netty/netty/issues/3888> 。
  - 比较有趣的一段是 `runtime.maxMemory() / defaultChunkSize / 2 / 3` 代码块。其中，`/ 2` 是为了保证 Arena 不超过内存的一半，而 `/ 3` 是为了每个 Arena 有三个 Chunk 。
  - 当然最终取值是上述两值的最小值。所以在推荐上，尽可能配置的内存，能够保证 `defaultMinNumArena` 。因为**要避免多线程竞争**。

## 3.2 validateAndCalculatePageShifts

`#validateAndCalculatePageShifts(int pageSize)` 方法，校验 `pageSize` 参数，并计算 `pageShift` 值。代码如下：

```
private static int validateAndCalculatePageShifts(int pageSize) {
    // 校验
    if (pageSize < MIN_PAGE_SIZE) {
        throw new IllegalArgumentException("pageSize: " + pageSize + " (expected: " + MIN_PAGE_SIZE + ")");
    }
    // 校验 Page 的内存大小，必须是 2 的指数级
    if ((pageSize & pageSize - 1) != 0) {
        throw new IllegalArgumentException("pageSize: " + pageSize + " (expected: power of 2)");
    }

    // 计算 pageShift
    // Logarithm base 2. At this point we know that pageSize is a power of two.
    return Integer.SIZE - 1 - Integer.numberOfLeadingZeros(pageSize);
}
```

- 默认情况下，`pageSize = 8KB = 8 * 1024= 8096` ，`pageShift = 8192` 。

## 3.3 validateAndCalculateChunkSize

`#validateAndCalculateChunkSize(int pageSize, int maxOrder)` 方法，校验 `maxOrder` 参数，并计算 `chunkSize`值。代码如下：

```
private static int validateAndCalculateChunkSize(int pageSize, int maxOrder) {
    if (maxOrder > 14) {
        throw new IllegalArgumentException("maxOrder: " + maxOrder + " (expected: 0-14)");
    }

    // 计算 chunkSize
    // Ensure the resulting chunkSize does not overflow.
    int chunkSize = pageSize;
    for (int i = maxOrder; i > 0; i --) {
        if (chunkSize > MAX_CHUNK_SIZE / 2) {
            throw new IllegalArgumentException(String.format(
                    "pageSize (%d) << maxOrder (%d) must not exceed %d", pageSize, maxOrder, MAX_CHUNK_SIZE));
        }
        chunkSize <<= 1;
    }
    return chunkSize;
}
```

## 3.4 构造方法

```
/**
 * 单例
 */
public static final PooledByteBufAllocator DEFAULT = new PooledByteBufAllocator(PlatformDependent.directBufferPreferred());

/**
 * Heap PoolArena 数组
 */
private final PoolArena<byte[]>[] heapArenas;
/**
 * Direct PoolArena 数组
 */
private final PoolArena<ByteBuffer>[] directArenas;
/**
 * {@link PoolThreadCache} 的 tiny 内存块缓存数组的大小
 */
private final int tinyCacheSize;
/**
 * {@link PoolThreadCache} 的 small 内存块缓存数组的大小
 */
private final int smallCacheSize;
/**
 * {@link PoolThreadCache} 的 normal 内存块缓存数组的大小
 */
private final int normalCacheSize;
/**
 * PoolArenaMetric 数组
 */
private final List<PoolArenaMetric> heapArenaMetrics;
/**
 * PoolArenaMetric 数组
 */
private final List<PoolArenaMetric> directArenaMetrics;
/**
 * 线程变量，用于获得 PoolThreadCache 对象。
 */
private final PoolThreadLocalCache threadCache;
/**
 * Chunk 大小
 */
private final int chunkSize;
/**
 * PooledByteBufAllocatorMetric 对象
 */
private final PooledByteBufAllocatorMetric metric;

public PooledByteBufAllocator() {
    this(false);
}

@SuppressWarnings("deprecation")
public PooledByteBufAllocator(boolean preferDirect) {
    this(preferDirect, DEFAULT_NUM_HEAP_ARENA, DEFAULT_NUM_DIRECT_ARENA, DEFAULT_PAGE_SIZE, DEFAULT_MAX_ORDER);
}

@SuppressWarnings("deprecation")
public PooledByteBufAllocator(int nHeapArena, int nDirectArena, int pageSize, int maxOrder) {
    this(false, nHeapArena, nDirectArena, pageSize, maxOrder);
}

/**
 * @deprecated use
 * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}
 */
@Deprecated
public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder) {
    this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder,
            DEFAULT_TINY_CACHE_SIZE, DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE);
}

/**
 * @deprecated use
 * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}
 */
@Deprecated
public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder,
                              int tinyCacheSize, int smallCacheSize, int normalCacheSize) {
    this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder, tinyCacheSize, smallCacheSize,
            normalCacheSize, DEFAULT_USE_CACHE_FOR_ALL_THREADS, DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT);
}

public PooledByteBufAllocator(boolean preferDirect, int nHeapArena,
                              int nDirectArena, int pageSize, int maxOrder, int tinyCacheSize,
                              int smallCacheSize, int normalCacheSize,
                              boolean useCacheForAllThreads) {
    this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder,
            tinyCacheSize, smallCacheSize, normalCacheSize,
            useCacheForAllThreads, DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT);
}

public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder,
                              int tinyCacheSize, int smallCacheSize, int normalCacheSize,
                              boolean useCacheForAllThreads, int directMemoryCacheAlignment) {
    super(preferDirect);
    // 创建 PoolThreadLocalCache 对象
    threadCache = new PoolThreadLocalCache(useCacheForAllThreads);
    this.tinyCacheSize = tinyCacheSize;
    this.smallCacheSize = smallCacheSize;
    this.normalCacheSize = normalCacheSize;
    // 计算 chunkSize
    chunkSize = validateAndCalculateChunkSize(pageSize, maxOrder);

    if (nHeapArena < 0) {
        throw new IllegalArgumentException("nHeapArena: " + nHeapArena + " (expected: >= 0)");
    }
    if (nDirectArena < 0) {
        throw new IllegalArgumentException("nDirectArea: " + nDirectArena + " (expected: >= 0)");
    }

    if (directMemoryCacheAlignment < 0) {
        throw new IllegalArgumentException("directMemoryCacheAlignment: "
                + directMemoryCacheAlignment + " (expected: >= 0)");
    }
    if (directMemoryCacheAlignment > 0 && !isDirectMemoryCacheAlignmentSupported()) {
        throw new IllegalArgumentException("directMemoryCacheAlignment is not supported");
    }

    if ((directMemoryCacheAlignment & -directMemoryCacheAlignment) != directMemoryCacheAlignment) {
        throw new IllegalArgumentException("directMemoryCacheAlignment: "
                + directMemoryCacheAlignment + " (expected: power of two)");
    }

    int pageShifts = validateAndCalculatePageShifts(pageSize);

    if (nHeapArena > 0) {
        // 创建 heapArenas 数组
        heapArenas = newArenaArray(nHeapArena);
        // 创建 metrics 数组
        List<PoolArenaMetric> metrics = new ArrayList<PoolArenaMetric>(heapArenas.length);
        // 初始化 heapArenas 和  metrics 数组
        for (int i = 0; i < heapArenas.length; i ++) {
            // 创建 HeapArena 对象
            PoolArena.HeapArena arena = new PoolArena.HeapArena(this,
                    pageSize, maxOrder, pageShifts, chunkSize,
                    directMemoryCacheAlignment);
            heapArenas[i] = arena;
            metrics.add(arena);
        }
        heapArenaMetrics = Collections.unmodifiableList(metrics);
    } else {
        heapArenas = null;
        heapArenaMetrics = Collections.emptyList();
    }

    if (nDirectArena > 0) {
        directArenas = newArenaArray(nDirectArena);
        List<PoolArenaMetric> metrics = new ArrayList<PoolArenaMetric>(directArenas.length);
        for (int i = 0; i < directArenas.length; i ++) {
            PoolArena.DirectArena arena = new PoolArena.DirectArena(
                    this, pageSize, maxOrder, pageShifts, chunkSize, directMemoryCacheAlignment);
            directArenas[i] = arena;
            metrics.add(arena);
        }
        directArenaMetrics = Collections.unmodifiableList(metrics);
    } else {
        directArenas = null;
        directArenaMetrics = Collections.emptyList();
    }
    // 创建 PooledByteBufAllocatorMetric
    metric = new PooledByteBufAllocatorMetric(this);
}
```

- orz 代码比较长，主要是构造方法和校验代码比较长。胖友自己耐心看下。笔者下面只重点讲几个属性。

- `DEFAULT` **静态**属性，PooledByteBufAllocator 单例。绝绝绝大多数情况下，我们不需要自己创建 PooledByteBufAllocator 对象，而只要使用该单例即可。

- `threadCache` 属性，**线程变量**，用于获得 PoolThreadCache 对象。通过该属性，不同线程虽然使用**相同**的 `DEFAULT` 单例，但是可以获得**不同**的 PoolThreadCache 对象。关于 PoolThreadLocalCache 的详细解析，见 [「4. PoolThreadLocalCache」](http://svip.iocoder.cn/Netty/ByteBuf-2-3-ByteBufAllocator-pooled/#) 中。

- `#newArenaArray(int size)` 方法，创建 PoolArena 数组。代码如下：

  ```
  private static <T> PoolArena<T>[] newArenaArray(int size) {
      return new PoolArena[size];
  }
  ```

## 3.5 newHeapBuffer

`#newHeapBuffer(int initialCapacity, int maxCapacity)` 方法，创建 Heap ByteBuf 对象。代码如下：

```
@Override
protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) {
    // <1> 获得线程的 PoolThreadCache 对象
    PoolThreadCache cache = threadCache.get();
    PoolArena<byte[]> heapArena = cache.heapArena;

    // <2.1> 从 heapArena 中，分配 Heap PooledByteBuf 对象，基于池化
    final ByteBuf buf;
    if (heapArena != null) {
        buf = heapArena.allocate(cache, initialCapacity, maxCapacity);
    // <2.2> 直接创建 Heap ByteBuf 对象，基于非池化
    } else {
        buf = PlatformDependent.hasUnsafe() ?
                new UnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) :
                new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity);
    }

    // <3> 将 ByteBuf 装饰成 LeakAware ( 可检测内存泄露 )的 ByteBuf 对象
    return toLeakAwareBuffer(buf);
}
```

- 代码比较易懂，胖友自己看代码注释。

## 3.6 newDirectBuffer

`#newDirectBuffer(int initialCapacity, int maxCapacity)` 方法，创建 Direct ByteBuf 对象。代码如下：

```
@Override
protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {
    // <1> 获得线程的 PoolThreadCache 对象
    PoolThreadCache cache = threadCache.get();
    PoolArena<ByteBuffer> directArena = cache.directArena;

    final ByteBuf buf;
    // <2.1> 从 directArena 中，分配 Direct PooledByteBuf 对象，基于池化
    if (directArena != null) {
        buf = directArena.allocate(cache, initialCapacity, maxCapacity);
    // <2.2> 直接创建 Direct ByteBuf 对象，基于非池化
    } else {
        buf = PlatformDependent.hasUnsafe() ?
                UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) :
                new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity);
    }

    // <3> 将 ByteBuf 装饰成 LeakAware ( 可检测内存泄露 )的 ByteBuf 对象
    return toLeakAwareBuffer(buf);
}
```

- 代码比较易懂，胖友自己看代码注释。

## 3.6 其它方法

其它方法，主要是 Metric 相关操作为主。这里就不再多做哔哔啦，胖友自己感兴趣的话，可以翻翻噢。

# 4. PoolThreadLocalCache

PoolThreadLocalCache ，是 PooledByteBufAllocator 的内部类。继承 FastThreadLocal 抽象类，PoolThreadCache **ThreadLocal** 类。

## 4.1 构造方法

```
/**
 * 是否使用缓存
 */
private final boolean useCacheForAllThreads;

PoolThreadLocalCache(boolean useCacheForAllThreads) {
    this.useCacheForAllThreads = useCacheForAllThreads;
}
```

## 4.2 leastUsedArena

`#leastUsedArena(PoolArena<T>[] arenas)` 方法，从 PoolArena 数组中，获取线程使用最少的 PoolArena 对象，基于 `PoolArena.numThreadCaches` 属性。通过这样的方式，尽可能让 PoolArena 平均分布在不同线程，从而尽肯能避免线程的**同步和竞争**问题。代码如下：

```
private <T> PoolArena<T> leastUsedArena(PoolArena<T>[] arenas) {
    // 一个都没有，返回 null
    if (arenas == null || arenas.length == 0) {
        return null;
    }

    // 获得第零个 PoolArena 对象
    PoolArena<T> minArena = arenas[0];
    // 比较后面的 PoolArena 对象，选择线程使用最少的
    for (int i = 1; i < arenas.length; i++) {
        PoolArena<T> arena = arenas[i];
        if (arena.numThreadCaches.get() < minArena.numThreadCaches.get()) {
            minArena = arena;
        }
    }

    return minArena;
}
```

## 4.3 initialValue

`#initialValue()` 方法，初始化线程的 PoolThreadCache 对象。代码如下：

```
@Override
protected synchronized PoolThreadCache initialValue() {
    // 分别获取线程使用最少的 heapArena 和 directArena 对象，基于 `PoolArena.numThreadCaches` 属性。
    final PoolArena<byte[]> heapArena = leastUsedArena(heapArenas);
    final PoolArena<ByteBuffer> directArena = leastUsedArena(directArenas);

    // 创建开启缓存的 PoolThreadCache 对象
    Thread current = Thread.currentThread();
    if (useCacheForAllThreads || current instanceof FastThreadLocalThread) {
        return new PoolThreadCache(
                heapArena, directArena, tinyCacheSize, smallCacheSize, normalCacheSize,
                DEFAULT_MAX_CACHED_BUFFER_CAPACITY, DEFAULT_CACHE_TRIM_INTERVAL);
    }

    // 创建不进行缓存的 PoolThreadCache 对象
    // No caching so just use 0 as sizes.
    return new PoolThreadCache(heapArena, directArena, 0, 0, 0, 0, 0);
}
```

## 4.4 onRemoval

`#onRemoval(PoolThreadCache threadCache)` 方法，释放 PoolThreadCache 对象的缓存。代码如下：

```
@Override
protected void onRemoval(PoolThreadCache threadCache) {
    // 释放缓存
    threadCache.free();
}
```

# 666. 彩蛋

推荐阅读文章：

- 杨武兵 [《netty源码分析系列——PooledByteBuf&PooledByteBufAllocator》](https://my.oschina.net/ywbrj042/blog/909925)
- wojiushimogui [《Netty源码分析：PooledByteBufAllocator》](https://blog.csdn.net/u010412719/article/details/78298811)
- RobertoHuang [《死磕Netty源码之内存分配详解(一)(PooledByteBufAllocator)》](https://blog.csdn.net/RobertoHuang/article/details/81046419)

# 精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）简介



# 1. 概述

在看 Netty 对 Jemalloc 内存管理算法的具体代码实现之前，笔者想先通过这篇文章，**简单**阐述三个问题：

- Netty 为什么要实现内存管理？
- Netty 为什么选择 Jemalloc 算法？
- Jemalloc 的实现原理？

因为笔者对内存管理的了解程度，处于青铜级别，所以为了更好的让大家理解，本文会以引用牛 x 大佬的文章为主。

# 2. Netty 为什么要实现内存管理

**老艿艿的理解**

在 Netty 中，IO 读写必定是非常频繁的操作，而考虑到更高效的网络传输性能，Direct ByteBuffer 必然是最合适的选择。但是 Direct ByteBuffer 的申请和释放是高成本的操作，那么进行**池化**管理，多次重用是比较有效的方式。但是，不同于一般于我们常见的对象池、连接池等**池化**的案例，ByteBuffer 是有**大小**一说。又但是，申请多大的 Direct ByteBuffer 进行池化又会是一个大问题，太大会浪费内存，太小又会出现频繁的扩容和内存复制！！！所以呢，就需要有一个合适的内存管理算法，解决**高效分配内存**的同时又解决**内存碎片化**的问题。

**官方的说法**

> FROM [《Netty 学习笔记 —— Pooled buffer》](https://skyao.gitbooks.io/learning-netty/content/buffer/pooled_buffer.html)
>
> Netty 4.x 增加了 Pooled Buffer，实现了高性能的 buffer 池，分配策略则是结合了 buddy allocation 和 slab allocation 的 **jemalloc** 变种，代码在`io.netty.buffer.PoolArena` 中。
>
> 官方说提供了以下优势：
>
> - 频繁分配、释放 buffer 时减少了 GC 压力。
> - 在初始化新 buffer 时减少内存带宽消耗( 初始化时不可避免的要给buffer数组赋初始值 )。
> - 及时的释放 direct buffer 。

**hushi55 大佬的理解**

> > C/C++ 和 java 中有个围城，城里的想出来，城外的想进去！**
>
> 这个围城就是自动内存管理！
>
> **Netty 4 buffer 介绍**
>
> Netty4 带来一个与众不同的特点是其 ByteBuf 的实现，相比之下，通过维护两个独立的读写指针， 要比 `io.netty.buffer.ByteBuf` 简单不少，也会更高效一些。不过，Netty 的 ByteBuf 带给我们的最大不同，就是他不再基于传统 JVM 的 GC 模式，相反，它采用了类似于 C++ 中的 malloc/free 的机制，需要开发人员来手动管理回收与释放。从手动内存管理上升到GC，是一个历史的巨大进步， 不过，在20年后，居然有曲线的回归到了手动内存管理模式，正印证了马克思哲学观： **社会总是在螺旋式前进的，没有永远的最好。**
>
> **① GC 内存管理分析**
>
> 的确，就内存管理而言，GC带给我们的价值是不言而喻的，不仅大大的降低了程序员的心智包袱， 而且，也极大的减少了内存管理带来的 Crash 困扰，为函数式编程（大量的临时对象）、脚本语言编程带来了春天。 并且，高效的GC算法也让大部分情况下程序可以有更高的执行效率。 不过，也有很多的情况，可能是手工内存管理更为合适的。譬如：
>
> - 对于类似于业务逻辑相对简单，譬如网络路由转发型应用（很多erlang应用其实是这种类型）， 但是 QPS 非常高，比如1M级，在这种情况下，在每次处理中即便产生1K的垃圾，都会导致频繁的GC产生。 在这种模式下，erlang 的按进程回收模式，或者是 C/C++ 的手工回收机制，效率更高。
> - Cache 型应用，由于对象的存在周期太长，GC 基本上就变得没有价值。
>
> 所以，理论上，尴尬的GC实际上比较适合于处理介于这 2 者之间的情况： 对象分配的频繁程度相比数据处理的时间要少得多的，但又是相对短暂的， 典型的，对于OLTP型的服务，处理能力在 1K QPS 量级，每个请求的对象分配在 10K-50K 量级， 能够在 5-10s 的时间内进行一 次younger GC ，每次GC的时间可以控制在 10ms 水平上， 这类的应用，实在是太适合 GC 行的模式了，而且结合 Java 高效的分代 GC ，简直就是一个理想搭配。
>
> **② 影响**
>
> Netty 4 引入了手工内存的模式，我觉得这是一大创新，这种模式甚至于会延展， 应用到 Cache 应用中。实际上，结合 JVM 的诸多优秀特性，如果用 Java 来实现一个 Redis 型 Cache、 或者 In-memory SQL Engine，或者是一个 Mongo DB，我觉得相比 C/C++ 而言，都要更简单很多。 实际上，JVM 也已经提供了打通这种技术的机制，就是 Direct Memory 和 Unsafe 对象。 基于这个基础，我们可以像 C 语言一样直接操作内存。实际上，Netty4 的 ByteBuf 也是基于这个基础的。

# 3. Netty 为什么选择 Jemalloc 算法

推荐直接阅读

- bhpike65 [《内存优化总结:ptmalloc、tcmalloc 和 jemalloc》](http://www.cnhalo.net/2016/06/13/memory-optimize/)

# 4. Jemalloc 的实现原理

推荐直接阅读

- Hypercube [《自顶向下深入分析Netty（十）–JEMalloc分配算法》](https://www.jianshu.com/p/15304cd63175)
- 高兴的博客 [《jemalloc和内存管里》](http://www.cnblogs.com/gaoxing/p/4253833.html)
- 沧行 [《Netty内存池实现》](https://www.jianshu.com/p/8d894e42b6e6) 这篇，有几个图，非常非常非常不错。

# 666. 彩蛋

推荐的博客比较多，如果你和笔者一样对内存管理的理解处于**青铜**级别，可能看完这几篇博文，很大可能还是一脸懵逼+一脸懵逼+一脸懵逼。

这是个比较正常的情况。胖友可以跟着笔者继续看看 Netty 对 Jemalloc 算法的具体实现后，再回过头继续理解下这几篇文章。

另外，后续的文章，会有大量大量大量的**位运算**，所以当胖友看到不熟悉的**位运算**，可以看看 [《Java 位运算(移位、位与、或、异或、非）》](https://blog.csdn.net/xiaochunyong/article/details/7748713) 。https://www.jianshu.com/p/70181af2972a)

# 精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）简介



# 1. 概述

在看 Netty 对 Jemalloc 内存管理算法的具体代码实现之前，笔者想先通过这篇文章，**简单**阐述三个问题：

- Netty 为什么要实现内存管理？
- Netty 为什么选择 Jemalloc 算法？
- Jemalloc 的实现原理？

因为笔者对内存管理的了解程度，处于青铜级别，所以为了更好的让大家理解，本文会以引用牛 x 大佬的文章为主。

# 2. Netty 为什么要实现内存管理

**老艿艿的理解**

在 Netty 中，IO 读写必定是非常频繁的操作，而考虑到更高效的网络传输性能，Direct ByteBuffer 必然是最合适的选择。但是 Direct ByteBuffer 的申请和释放是高成本的操作，那么进行**池化**管理，多次重用是比较有效的方式。但是，不同于一般于我们常见的对象池、连接池等**池化**的案例，ByteBuffer 是有**大小**一说。又但是，申请多大的 Direct ByteBuffer 进行池化又会是一个大问题，太大会浪费内存，太小又会出现频繁的扩容和内存复制！！！所以呢，就需要有一个合适的内存管理算法，解决**高效分配内存**的同时又解决**内存碎片化**的问题。

**官方的说法**

> FROM [《Netty 学习笔记 —— Pooled buffer》](https://skyao.gitbooks.io/learning-netty/content/buffer/pooled_buffer.html)
>
> Netty 4.x 增加了 Pooled Buffer，实现了高性能的 buffer 池，分配策略则是结合了 buddy allocation 和 slab allocation 的 **jemalloc** 变种，代码在`io.netty.buffer.PoolArena` 中。
>
> 官方说提供了以下优势：
>
> - 频繁分配、释放 buffer 时减少了 GC 压力。
> - 在初始化新 buffer 时减少内存带宽消耗( 初始化时不可避免的要给buffer数组赋初始值 )。
> - 及时的释放 direct buffer 。

**hushi55 大佬的理解**

> > C/C++ 和 java 中有个围城，城里的想出来，城外的想进去！**
>
> 这个围城就是自动内存管理！
>
> **Netty 4 buffer 介绍**
>
> Netty4 带来一个与众不同的特点是其 ByteBuf 的实现，相比之下，通过维护两个独立的读写指针， 要比 `io.netty.buffer.ByteBuf` 简单不少，也会更高效一些。不过，Netty 的 ByteBuf 带给我们的最大不同，就是他不再基于传统 JVM 的 GC 模式，相反，它采用了类似于 C++ 中的 malloc/free 的机制，需要开发人员来手动管理回收与释放。从手动内存管理上升到GC，是一个历史的巨大进步， 不过，在20年后，居然有曲线的回归到了手动内存管理模式，正印证了马克思哲学观： **社会总是在螺旋式前进的，没有永远的最好。**
>
> **① GC 内存管理分析**
>
> 的确，就内存管理而言，GC带给我们的价值是不言而喻的，不仅大大的降低了程序员的心智包袱， 而且，也极大的减少了内存管理带来的 Crash 困扰，为函数式编程（大量的临时对象）、脚本语言编程带来了春天。 并且，高效的GC算法也让大部分情况下程序可以有更高的执行效率。 不过，也有很多的情况，可能是手工内存管理更为合适的。譬如：
>
> - 对于类似于业务逻辑相对简单，譬如网络路由转发型应用（很多erlang应用其实是这种类型）， 但是 QPS 非常高，比如1M级，在这种情况下，在每次处理中即便产生1K的垃圾，都会导致频繁的GC产生。 在这种模式下，erlang 的按进程回收模式，或者是 C/C++ 的手工回收机制，效率更高。
> - Cache 型应用，由于对象的存在周期太长，GC 基本上就变得没有价值。
>
> 所以，理论上，尴尬的GC实际上比较适合于处理介于这 2 者之间的情况： 对象分配的频繁程度相比数据处理的时间要少得多的，但又是相对短暂的， 典型的，对于OLTP型的服务，处理能力在 1K QPS 量级，每个请求的对象分配在 10K-50K 量级， 能够在 5-10s 的时间内进行一 次younger GC ，每次GC的时间可以控制在 10ms 水平上， 这类的应用，实在是太适合 GC 行的模式了，而且结合 Java 高效的分代 GC ，简直就是一个理想搭配。
>
> **② 影响**
>
> Netty 4 引入了手工内存的模式，我觉得这是一大创新，这种模式甚至于会延展， 应用到 Cache 应用中。实际上，结合 JVM 的诸多优秀特性，如果用 Java 来实现一个 Redis 型 Cache、 或者 In-memory SQL Engine，或者是一个 Mongo DB，我觉得相比 C/C++ 而言，都要更简单很多。 实际上，JVM 也已经提供了打通这种技术的机制，就是 Direct Memory 和 Unsafe 对象。 基于这个基础，我们可以像 C 语言一样直接操作内存。实际上，Netty4 的 ByteBuf 也是基于这个基础的。

# 3. Netty 为什么选择 Jemalloc 算法

推荐直接阅读

- bhpike65 [《内存优化总结:ptmalloc、tcmalloc 和 jemalloc》](http://www.cnhalo.net/2016/06/13/memory-optimize/)

# 4. Jemalloc 的实现原理

推荐直接阅读

- Hypercube [《自顶向下深入分析Netty（十）–JEMalloc分配算法》](https://www.jianshu.com/p/15304cd63175)
- 高兴的博客 [《jemalloc和内存管里》](http://www.cnblogs.com/gaoxing/p/4253833.html)
- 沧行 [《Netty内存池实现》](https://www.jianshu.com/p/8d894e42b6e6) 这篇，有几个图，非常非常非常不错。

# 666. 彩蛋

推荐的博客比较多，如果你和笔者一样对内存管理的理解处于**青铜**级别，可能看完这几篇博文，很大可能还是一脸懵逼+一脸懵逼+一脸懵逼。

这是个比较正常的情况。胖友可以跟着笔者继续看看 Netty 对 Jemalloc 算法的具体实现后，再回过头继续理解下这几篇文章。

另外，后续的文章，会有大量大量大量的**位运算**，所以当胖友看到不熟悉的**位运算**，可以看看 [《Java 位运算(移位、位与、或、异或、非）》](https://blog.csdn.net/xiaochunyong/article/details/7748713) 。

# Buffer 之 Jemalloc（二）PoolChunk



# 1. 概述

> 老艿艿：如下阐释的内容，参考 Hypercube [《自顶向下深入分析Netty（十）–JEMalloc分配算法》](https://www.jianshu.com/p/15304cd63175) 。

为了提高内存**分配效率**并减少**内存碎片**，Jemalloc 算法将每个 Arena 切分成多个**小块** Chunk 。但是实际上，每个 Chunk 依然是**相当大**的内存块。因为在 Jemalloc 建议为 4MB ，Netty 默认使用为 16MB 。

为了进一步提供提高内存**分配效率**并减少**内存碎片**，Jemalloc 算法将每个 Chunk 切分成多个**小块** Page 。一个典型的切分是将 Chunk 切分为 2048 块 Page ，Netty 也是如此，因此 Page 的大小为：`16MB / 2048 = 8KB` 。

一个好的内存分配算法，应使得已分配内存块尽可能保持连续，这将大大减少内部碎片，由此 Jemalloc 使用[伙伴分配算法](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#)尽可能提高连续性。**伙伴分配算法**的示意图如下：

> 可能很多胖友不了解【伙伴分配算法】，感兴趣的话，可以看看 [《伙伴分配器的一个极简实现》](https://coolshell.cn/articles/10427.html) 了解了解。
>
> 当然，Netty PoolChunk 也是基于【伙伴分配算法】实现。

![满二叉树](http://static2.iocoder.cn/images/Netty/2018_09_04/01.png)

图中**最底层**表示一个被切分为 2048 个 Page 的 Chunk 块。自底向上，每一层节点作为上一层的子节点构造出一棵[满二叉树](https://baike.baidu.com/item/满二叉树)，然后按层分配满足要求的内存块。以待分配序列 8KB、16KB、8KB 为例分析分配过程( 假设每个 Page 大小 8KB )：

1. 8KB —— 需要一个 Page ，第 11 层满足要求，故分配 *2048* 节点即 **Page0** 。
2. 16KB —— 需要两个Page ，故需要在第 10 层进行分配，而 *1024* 的子节点 *2048* 已分配，从左到右找到满足要求的 *1025* 节点，故分配节点 *1025* 即**Page2** 和 **Page3** 。
3. 8KB —— 需要一个 Page ，第 11 层满足要求，但是 *2048* 已分配，从左到右找到 *2049* 节点即 **Page1** 进行分配。

总结来说：

- 分配结束后，已分配连续的 **Page0 - Page3** 。这样的连续内存块，大大减少内部碎片并提高**内存使用率**。
- 通过使用**满二叉树**这样的树结构，提升检索到可用 Page 的速度，从而提高内存**分配效率**。

# 2. PoolChunk

`io.netty.buffer.PoolChunk` ，实现 PoolChunkMetric 接口，Netty 对 Jemalloc Chunk 的实现类。

## 2.1 构造方法

```java
/**
 * 所属 Arena 对象
 */
final PoolArena<T> arena;
/**
 * 内存空间。
 *
 * @see PooledByteBuf#memory
 */
final T memory;
/**
 * 是否非池化
 *
 * @see #PoolChunk(PoolArena, Object, int, int) 非池化。当申请的内存大小为 Huge 类型时，创建一整块 Chunk ，并且不拆分成若干 Page
 * @see #PoolChunk(PoolArena, Object, int, int, int, int, int) 池化
 */
final boolean unpooled;
/**
 * TODO 芋艿
 */
final int offset;

/**
 * 分配信息满二叉树
 *
 * index 为节点编号
 */
private final byte[] memoryMap;
/**
 * 高度信息满二叉树
 *
 * index 为节点编号
 */
private final byte[] depthMap;
/**
 * PoolSubpage 数组
 */
private final PoolSubpage<T>[] subpages;
/**
 * 判断分配请求内存是否为 Tiny/Small ，即分配 Subpage 内存块。
 *
 * Used to determine if the requested capacity is equal to or greater than pageSize.
 */
private final int subpageOverflowMask;
/**
 * Page 大小，默认 8KB = 8192B
 */
private final int pageSize;
/**
 * 从 1 开始左移到 {@link #pageSize} 的位数。默认 13 ，1 << 13 = 8192 。
 *
 * 具体用途，见 {@link #allocateRun(int)} 方法，计算指定容量所在满二叉树的层级。
 */
private final int pageShifts;
/**
 * 满二叉树的高度。默认为 11 。
 */
private final int maxOrder;
/**
 * Chunk 内存块占用大小。默认为 16M = 16 * 1024  。
 */
private final int chunkSize;
/**
 * log2 {@link #chunkSize} 的结果。默认为 log2( 16M ) = 24 。
 */
private final int log2ChunkSize;
/**
 * 可分配 {@link #subpages} 的数量，即数组大小。默认为 1 << maxOrder = 1 << 11 = 2048 。
 */
private final int maxSubpageAllocs;
/**
 * 标记节点不可用。默认为 maxOrder + 1 = 12 。
 *
 * Used to mark memory as unusable
 */
private final byte unusable;

/**
 * 剩余可用字节数
 */
private int freeBytes;

/**
 * 所属 PoolChunkList 对象
 */
PoolChunkList<T> parent;
/**
 * 上一个 Chunk 对象
 */
PoolChunk<T> prev;
/**
 * 下一个 Chunk 对象
 */
PoolChunk<T> next;

// 构造方法一：
  1: PoolChunk(PoolArena<T> arena, T memory, int pageSize, int maxOrder, int pageShifts, int chunkSize, int offset) {
  2:     // 池化
  3:     unpooled = false;
  4:     this.arena = arena;
  5:     this.memory = memory;
  6:     this.pageSize = pageSize;
  7:     this.pageShifts = pageShifts;
  8:     this.maxOrder = maxOrder;
  9:     this.chunkSize = chunkSize;
 10:     this.offset = offset;
 11:     unusable = (byte) (maxOrder + 1);
 12:     log2ChunkSize = log2(chunkSize);
 13:     subpageOverflowMask = ~(pageSize - 1);
 14:     freeBytes = chunkSize;
 15: 
 16:     assert maxOrder < 30 : "maxOrder should be < 30, but is: " + maxOrder;
 17:     maxSubpageAllocs = 1 << maxOrder;
 18: 
 19:     // 初始化 memoryMap 和 depthMap
 20:     // Generate the memory map.
 21:     memoryMap = new byte[maxSubpageAllocs << 1];
 22:     depthMap = new byte[memoryMap.length];
 23:     int memoryMapIndex = 1;
 24:     for (int d = 0; d <= maxOrder; ++ d) { // move down the tree one level at a time
 25:         int depth = 1 << d;
 26:         for (int p = 0; p < depth; ++ p) {
 27:             // in each level traverse left to right and set value to the depth of subtree
 28:             memoryMap[memoryMapIndex] = (byte) d;
 29:             depthMap[memoryMapIndex] = (byte) d;
 30:             memoryMapIndex ++;
 31:         }
 32:     }
 33: 
 34:     // 初始化 subpages
 35:     subpages = newSubpageArray(maxSubpageAllocs);
 36: }


// 构造方法二： 
 38: /** Creates a special chunk that is not pooled. */
 39: PoolChunk(PoolArena<T> arena, T memory, int size, int offset) {
 40:     // 非池化
 41:     unpooled = true;
 42:     this.arena = arena;
 43:     this.memory = memory;
 44:     this.offset = offset;
 45:     memoryMap = null;
 46:     depthMap = null;
 47:     subpages = null;
 48:     subpageOverflowMask = 0;
 49:     pageSize = 0;
 50:     pageShifts = 0;
 51:     maxOrder = 0;
 52:     unusable = (byte) (maxOrder + 1);
 53:     chunkSize = size;
 54:     log2ChunkSize = log2(chunkSize);
 55:     maxSubpageAllocs = 0;
 56: }
```

- `arena`属性，所属 Arena 对象。详细解析，见《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》。

  - `memory` 属性，内存空间。即**用于** `PooledByteBuf.memory` 属性，有 Direct ByteBuffer 和 `byte[]` 字节数组。
  - `unpooled`属性，是否非池化。
  - `unpooled = false` ，池化，对应构造方法**一**。默认情况下，对于 分配 16M **以内**的内存空间时，Netty 会分配一个 Normal 类型的 Chunk 块。并且，该 Chunk 块在使用完后，进行池化缓存，重复使用。
    - `unpooled = true` ，非池化，对应构造方法**二**。默认情况下，对于分配 16M **以上**的内存空间时，Netty 会分配一个 Huge 类型的**特殊**的 Chunk 块。并且，由于 Huge 类型的 Chunk 占用内存空间较大，比较特殊，所以该 Chunk 块在使用完后，立即释放，不进行重复使用。

- 笔者对 Netty 对 Jemalloc 不同类型的内存块的整理，如下图所示：![内存块分类](http://static2.iocoder.cn/images/Netty/2018_09_04/02.png)

- Jemalloc 基于【伙伴分配算法】分配 Chunk 中的 Page 节点。Netty 实现的伙伴分配算法中，构造了**两颗**满二叉树。因为满二叉树非常适合数组存储，Netty 使用两个字节数组 `memoryMap` 和 `depthMap` 来分别表示**分配信息**满二叉树、**高度信息**满二叉树。如下图所示：![满二叉树](http://static2.iocoder.cn/images/Netty/2018_09_04/03.png)

  - `maxOrder` 属性，满二叉树的高度。默认为 11 。注意，层高是从 0 开始。

  - `maxSubpageAllocs` 属性，可分配的 Page 的数量。默认为 2048 ，在【第 17 行】的代码进行初始化。在第 11 层，可以看到 Page0 - Page2047 这 2048 个节点，也也符合 `1 << maxOrder = 11 << 11 = 2048` 的计算。

  - 在【第 19 至 32 行】的代码，`memoryMap` 和 `depthMap` 进行满二叉树的初始化。

    - 数组大小为 `maxSubpageAllocs << 1 = 2048 << 1 = 4096` 。

    - 数组下标为**左图**对应的节点编号。在【第 23 行】的代码，从 `memoryMapIndex = 1` 代码可以看出，满二叉树的节点编号是**从 1 开始**。省略 0 是因为这样更容易计算父子关系：子节点加倍，父节点减半，例如：512 的子节点为 1024( `512 * 2` )和 1025( `512 * 2 + 1` )。

    - 初始时，`memoryMap` 和 `depthMap` 相等，值为**节点高度**。例如：

      ```
      memoryMap[1024] = depthMap[1024] = 10;
      ```

      - 对应**右图**。

    - 分配节点时，`depthMap`的值保持**不变**( 因为，节点的高度没发生变化 )，`memoryMap`的值发生**变化**

      ( 因为，节点的分配信息发生变化 )。当一个节点被分配后，该节点的值设为`unusable`

      ( 标记节点不可用。默认为`maxOrder + 1 = 12`) 。

      并且，会更新祖先节点的值为其子节点较小的值

      ( 因为，祖先节点共用该节点的 Page 内存；同时，一个父节点有两个子节点，一个节点不可用后，另一个子节点可能可用，所以更新为其子节点

      较小

      的值。 )。举个例子，下图表示随着节点 4 分配而更新祖先节点的过程，其中每个节点的第一个数字表示**节点编号**，第二个数字表示**节点高度**：

      ![ä¾å­](http://static2.iocoder.cn/images/Netty/2018_09_04/04.png)

      - 节点 4 被**完全**分配，将高度值设置为 12 表示不可用。

- 节点 4 的父节点 2，将高度值更新为两个子节点的较小值。其他祖先节点亦然，直到高度值更新至根节点。

- `memoryMap`数组的值，总结为 3 种情况：

  - 1、`memoryMap[id] = depthMap[id]` ，该节点没有被分配。
    - 2、`最大高度 >= memoryMap[id] > depthMap[id]` ，至少有一个子节点被分配，不能再分配该高度满足的内存，但可以根据实际分配较小一些的内存。比如，上图中父节点 2 分配了子节点 4，值从 1 更新为 2，表示该节点不能再分配 8MB 的只能最大分配 4MB 内存，即只剩下节点 5 可用。
    - 3、`memoryMap[id] = 最大高度 + 1` ，该节点及其子节点已被**完全**分配，没有剩余空间。

- Chunk 相关字段

  - `chunkSize` 属性，Chunk 内存块占用大小。默认为 `16M = 16 * 1024KB` 。

  - `log2ChunkSize` 属性，`log2(chunkSize)` 的结果。默认为 `log2( 16M ) = 24` 。 代码如下：

    ```java
    private static final int INTEGER_SIZE_MINUS_ONE = Integer.SIZE - 1; // 32 - 1 = 31
    
    private static int log2(int val) {
        // compute the (0-based, with lsb = 0) position of highest set bit i.e, log2
        return INTEGER_SIZE_MINUS_ONE - Integer.numberOfLeadingZeros(val);
    }
    ```

    - x

  - `freeBytes` 属性，剩余可用字节数。

- Page 相关字段

  - `pageSize` 属性，每个 Page 的大小。默认为 `8KB = 8192B` 。
  - `pageShifts` 属性，从 1 开始左移到 `pageSize` 的位数。默认 13 ，`1 << 13 = 8192` 。具体用于计算指定容量所在满二叉树的层级，详细解析，见 [「2.2.1 allocateRun」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#) 。

- SubPage 相关字段

  - 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（三）PoolSubpage》](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage) 。

  - `subpages` 属性，PoolSubpage 数组。每个节点对应一个 PoolSubpage 对象。因为实际上，每个 Page 还是**比较大**的内存块，可以进一步切分成小块 SubPage 。在【第 35 行】的代码，调用 `#newSubpageArray(int size)` 方法，进行初始化。代码如下：

    ```java
    private PoolSubpage<T>[] newSubpageArray(int size) {
        return new PoolSubpage[size];
    }
    ```

    - 默认情况下，数组大小为 `maxSubpageAllocs = 2048` 。

  - `subpageOverflowMask` 属性，判断分配请求内存是否为 **Tiny/Small** ，即分配 Subpage 内存块。默认，-8192 。在【13 行】的代码进行初始化。对于 -8192 的二进制，除了首 bits 为 1 ，其它都为 0 。这样，对于小于 8K 字节的申请，求 `subpageOverflowMask & length` 都等于 0 ；对于大于 8K 字节的申请，求 `subpageOverflowMask & length` 都**不**等于 0 。相当于说，做了 `if ( length < pageSize )` 的计算优化。

- ChunkList 相关字段

  - 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（四）PoolChunkList》](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList) 。
  - `parent` 属性，所属 PoolChunkList 对象。
  - `prev` 属性，上一个 Chunk 对象。
  - `next` 属性，下一个 Chunk 对象。

内容比较“厚实”( 😈 字比较多 )，建议胖友再读一遍，再看下面的代码具体实现。

## 2.2 allocate

`#allocate(int normCapacity)` 方法，分配内存空间。代码如下：

```java
1: long allocate(int normCapacity) {
2:     // 大于等于 Page 大小，分配 Page 内存块
3:     if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize
4:         return allocateRun(normCapacity);
5:     // 小于 Page 大小，分配 Subpage 内存块
6:     } else {
7:         return allocateSubpage(normCapacity);
8:     }
9: }
```

- 第 2 至 4 行：当申请的 `normCapacity` 大于等于 Page 大小时，调用 `#allocateRun(int normCapacity)` 方法，分配 Page 内存块。详细解析，见 [「2.2.1 allocateRun」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#) 中。
- 第 5 至 8 行：调用 `#allocateSubpage(int normCapacity)` 方法，分配 Subpage 内存块。详细解析，见 [「2.2.1 allocateSubpage」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#) 中。

### 2.2.1 allocateRun

`#allocateRun(int normCapacity)` 方法，分配 Page 内存块。代码如下：

```java
   /**
    * Allocate a run of pages (>=1)
    *
    * @param normCapacity normalized capacity
    * @return index in memoryMap
    */
 1: private long allocateRun(int normCapacity) {
 2:     // 获得层级
 3:     int d = maxOrder - (log2(normCapacity) - pageShifts);
 4:     // 获得节点
 5:     int id = allocateNode(d);
 6:     // 未获得到节点，直接返回
 7:     if (id < 0) {
 8:         return id;
 9:     }
10:     // 减少剩余可用字节数
11:     freeBytes -= runLength(id);
12:     return id;
13: }
```

- 第 3 行：获得层级。

- 第 5 行：调用`#allocateNode(int normCapacity)`方法，分配节点。详细解析，见「2.2.3 allocateNode」中。

  - 第 7 至 9 行：未获得到节点，直接返回。

- 第 11 行：调用 `#runLength(int id)` 方法，计算使用节点的字节数，并减少剩余可用字节数。代码如下：

  ```java
  private int runLength(int id) {
      // represents the size in #bytes supported by node 'id' in the tree
      return 1 << log2ChunkSize - depth(id);
  }
  
  private byte depth(int id) {
      return depthMap[id];
  }
  ```

### 2.2.2 allocateSubpage

> 老艿艿：本小节，胖友先看完 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（三）PoolSubpage》](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage) 。

`#allocateSubpage(int normCapacity)` 方法，分配 Subpage 内存块。代码如下：

```java
   /**
    * Create/ initialize a new PoolSubpage of normCapacity
    * Any PoolSubpage created/ initialized here is added to subpage pool in the PoolArena that owns this PoolChunk
    *
    * @param normCapacity normalized capacity
    * @return index in memoryMap
    */
 1: private long allocateSubpage(int normCapacity) {
 2:     // 获得对应内存规格的 Subpage 双向链表的 head 节点
 3:     // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.
 4:     // This is need as we may add it back and so alter the linked-list structure.
 5:     PoolSubpage<T> head = arena.findSubpagePoolHead(normCapacity);
 6:     // 加锁，分配过程会修改双向链表的结构，会存在多线程的情况。
 7:     synchronized (head) {
 8:         // 获得最底层的一个节点。Subpage 只能使用二叉树的最底层的节点。
 9:         int d = maxOrder; // subpages are only be allocated from pages i.e., leaves
10:         int id = allocateNode(d);
11:         // 获取失败，直接返回
12:         if (id < 0) {
13:             return id;
14:         }
15: 
16:         final PoolSubpage<T>[] subpages = this.subpages;
17:         final int pageSize = this.pageSize;
18: 
19:         // 减少剩余可用字节数
20:         freeBytes -= pageSize;
21: 
22:         // 获得节点对应的 subpages 数组的编号
23:         int subpageIdx = subpageIdx(id);
24:         // 获得节点对应的 subpages 数组的 PoolSubpage 对象
25:         PoolSubpage<T> subpage = subpages[subpageIdx];
26:         // 初始化 PoolSubpage 对象
27:         if (subpage == null) { // 不存在，则进行创建 PoolSubpage 对象
28:             subpage = new PoolSubpage<T>(head, this, id, runOffset(id), pageSize, normCapacity);
29:             subpages[subpageIdx] = subpage;
30:         } else { // 存在，则重新初始化 PoolSubpage 对象
31:             subpage.init(head, normCapacity);
32:         }
33:         // 分配 PoolSubpage 内存块
34:         return subpage.allocate();
35:     }
36: }
```

- 第 5 行：调用 `PoolArena#findSubpagePoolHead(int normCapacity)` 方法，获得对应内存规格的 Subpage 双向链表的 `head`节点。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena) 。

- 第 7 行：`synchronized` 加锁，分配过程会修改双向链表的结构，会存在**多线程**的情况。

- 第 8 至 10 行：调用`#allocateNode(int d)`方法，获得最底层的一个节点。**Subpage 只能使用二叉树的最底层的节点**。

  - 第 11 至 14 行：获取失败，直接返回。

- 第 20 行：减少剩余可用字节数。

- 第 23 至 34 行：分配 PoolSubpage 内存块。

  - 第 23 行：调用 `#subpageIdx(int id)` 方法，获得节点对应的 `subpages` 数组的编号。代码如下：

    ```java
    private int subpageIdx(int memoryMapIdx) {
        return memoryMapIdx ^ maxSubpageAllocs; // remove highest set bit, to get offset
    }
    ```

    - 去掉最高位( bit )。例如节点 2048 计算后的结果为 0 。

  - 第 25 行：获得节点对应的 `subpages` 数组的 PoolSubpage 对象。

  - 第 26 至 32 行：初始化 PoolSubpage 对象。

  - 第 34 行：调用 `PoolSubpage#allocate()` 方法，分配 PoolSubpage 内存块。

### 2.2.3 allocateNode

`#allocateNode(int normCapacity)` 方法，分配节点。代码如下：

```java
   /**
    * Algorithm to allocate an index in memoryMap when we query for a free node
    * at depth d
    *
    * @param d depth
    * @return index in memoryMap
    */
 1: private int allocateNode(int d) {
 2:     int id = 1;
 3:     int initial = - (1 << d); // has last d bits = 0 and rest all = 1
 4:     // 获得根节点的指值。
 5:     // 如果根节点的值，大于 d ，说明，第 d 层没有符合的节点，也就是说 [0, d-1] 层也没有符合的节点。即，当前 Chunk 没有符合的节点。
 6:     byte val = value(id);
 7:     if (val > d) { // unusable
 8:         return -1;
 9:     }
10:     // 获得第 d 层，匹配的节点。
11:     // id & initial 来保证，高度小于 d 会继续循环
12:     while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0
13:         // 进入下一层
14:         // 获得左节点的编号
15:         id <<= 1;
16:         // 获得左节点的值
17:         val = value(id);
18:         // 如果值大于 d ，说明，以左节点作为根节点形成虚拟的虚拟满二叉树，没有符合的节点。
19:         if (val > d) {
20:             // 获得右节点的编号
21:             id ^= 1;
22:             // 获得右节点的值
23:             val = value(id);
24:         }
25:     }
26: 
27:     // 校验获得的节点值合理
28:     byte value = value(id);
29:     assert value == d && (id & initial) == 1 << d : String.format("val = %d, id & initial = %d, d = %d",
30:             value, id & initial, d);
31: 
32:     // 更新获得的节点不可用
33:     setValue(id, unusable); // mark as unusable
34:     // 更新获得的节点的祖先都不可用
35:     updateParentsAlloc(id);
36: 
37:     // 返回节点编号
38:     return id;
39: }
```

- 第 3 行：通过 `- (1 << d)` 计算，获得 `initial` 。用于【第 12 行】的代码，`id & initial` ，来保证，高度小于 `d` 会继续**循环**。

- 第 6 行：获得根节点( `id = 1` )的指值。代码如下：

  ```java
  private byte value(int id) {
      return memoryMap[id];
  }
  ```

  - 第 7 至 9 行：如果根节点的值，大于 `d` ，说明，第 `d` 层没有符合的节点，也就是说 `[1, d-1]` 层也没有符合的节点。即，当前 Chunk 没有符合的节点。

- 第 10 至 25 行：获得第`d`层，匹配的节点。因为`val < d`难以保证是第`d`层，`[0, d-1]`层也可以满足`val < d`，所以才有`id & initial`来保证，高度小于`d`会继续循环。

  - ← 第 15 行：`<< 1` 操作，进入下一层。获得**左节点**的编号。

- ← 第 17 行：获得左节点的值。

  - → 第 19 行：如果值大于 `d` ，说明，以左节点作为根节点形成虚拟的虚拟满二叉树，没有符合的节点。此时，需要跳到**右节点**。
  - → 第 21 行：`^ 1` 操作，获得**右节点**的编号。
  - → 第 23 行：获得右节点的值。

- 【第 17 行】或者【第 23 行】的代码，会通过【第 12 行】的代码，结束循环。也就说，获得第 `d` 层，匹配的节点。

- 第 33 行：调用 `#setValue(int id, byte val)` 方法，设置获得的节点的值为 `unusable` ，表示不可用。代码如下：

  ```java
  private void setValue(int id, byte val) {
      memoryMap[id] = val;
  }
  ```

- 第 35 行：调用 `#updateParentsAlloc(int id)` 方法，更新获得的节点的祖先都不可用。详细解析，见 [「2.4.1 updateParentsAlloc」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#) 。

- 第 38 行：返回节点编号。

## 2.3 free

> 老艿艿：本小节，胖友先看完 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（三）PoolSubpage》](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage) 。

`#free(long handle)` 方法，释放指定位置的内存块。根据情况，内存块可能是 SubPage ，也可能是 Page ，也可能是释放 SubPage 并且释放对应的 Page 。代码如下：

```java
   /**
    * Free a subpage or a run of pages
    * When a subpage is freed from PoolSubpage, it might be added back to subpage pool of the owning PoolArena
    * If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we can
    * completely free the owning Page so it is available for subsequent allocations
    *
    * @param handle handle to free
    */
 1: void free(long handle) {
 2:     // 获得 memoryMap 数组的编号( 下标 )
 3:     int memoryMapIdx = memoryMapIdx(handle);
 4:     // 获得 bitmap 数组的编号( 下标 )。注意，此时获得的还不是真正的 bitmapIdx 值，需要经过 `bitmapIdx & 0x3FFFFFFF` 运算。
 5:     int bitmapIdx = bitmapIdx(handle);
 6: 
 7:     // 释放 Subpage begin ~
 8: 
 9:     if (bitmapIdx != 0) { // free a subpage bitmapIdx 非空，说明释放的是 Subpage
10:         // 获得 PoolSubpage 对象
11:         PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];
12:         assert subpage != null && subpage.doNotDestroy;
13: 
14:         // 获得对应内存规格的 Subpage 双向链表的 head 节点
15:         // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.
16:         // This is need as we may add it back and so alter the linked-list structure.
17:         PoolSubpage<T> head = arena.findSubpagePoolHead(subpage.elemSize);
18:         // 加锁，分配过程会修改双向链表的结构，会存在多线程的情况。
19:         synchronized (head) {
20:             // 释放 Subpage 。
21:             if (subpage.free(head, bitmapIdx & 0x3FFFFFFF)) {
22:                 return;
23:             }
24:             // ↑↑↑ 返回 false ，说明 Page 中无切分正在使用的 Subpage 内存块，所以可以继续向下执行，释放 Page
25:         }
26:     }
27: 
28:     // 释放 Page begin ~
29: 
30:     // 增加剩余可用字节数
31:     freeBytes += runLength(memoryMapIdx);
32:     // 设置 Page 对应的节点可用
33:     setValue(memoryMapIdx, depth(memoryMapIdx));
34:     // 更新 Page 对应的节点的祖先可用
35:     updateParentsFree(memoryMapIdx);
36: }
```

- 第 3 行：调用 `#memoryMapIdx(handle)` 方法，获得 `memoryMap` 数组的编号( 下标 )。代码如下：

  ```java
  private static int memoryMapIdx(long handle) {
      return (int) handle;
  }
  ```

- 第 5 行：调用 `#bitmapIdx(handle)` 方法，获得 `bitmap` 数组的编号( 下标 )。代码如下：

  ```java
  private static int bitmapIdx(long handle) {
      return (int) (handle >>> Integer.SIZE);
  }
  ```

  - 注意，此时获得的还不是真正的 bitmapIdx 值，需要经过 `bitmapIdx & 0x3FFFFFFF` 运算，即【第 21 行】的代码。

- 第 9 至 26 行：释放 Subpage 内存块。

  - 第 9 行：通过 `bitmapIdx !=0` 判断，说明释放的是 Subpage 内存块。
  - 第 11 行：获得 PoolSubpage 对象。
  - 第 17 行：调用 `PoolArena#findSubpagePoolHead(int normCapacity)` 方法，获得对应内存规格的 Subpage 双向链表的 `head` 节点。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena) 。
  - 第 19 行：`synchronized` 加锁，分配过程会修改双向链表的结构，会存在多线程的情况。
  - 第 21 行：调用`SubPage#free(PoolSubpage<T> head, int bitmapIdx)`方法，释放 Subpage 内存块。
    - 如果返回 `false` ，说明 Page 中**无切分正在使用**的 Subpage 内存块，所以可以继续向下执行，释放 Page 内存块。

- 第 30 至 35 行：释放 Page 内存块。

  - 第 31 行：增加剩余可用字节数。
  - 第 33 行：调用 `#setValue(int id, byte val)` 方法，设置 Page 对应的节点**可用**。
  - 第 35 行：调用 `#updateParentsAlloc(int id)` 方法，更新获得的节点的祖先**可用**。

## 2.4 updateParents

### 2.4.1 updateParentsAlloc

`#updateParentsAlloc(int id)` 方法，更新获得的节点的祖先都不可用。代码如下：

```java
   /**
    * Update method used by allocate
    * This is triggered only when a successor is allocated and all its predecessors
    * need to update their state
    * The minimal depth at which subtree rooted at id has some free space
    *
    * @param id id
    */
 1: private void updateParentsAlloc(int id) {
 2:     while (id > 1) {
 3:         // 获得父节点的编号
 4:         int parentId = id >>> 1;
 5:         // 获得子节点的值
 6:         byte val1 = value(id);
 7:         // 获得另外一个子节点的
 8:         byte val2 = value(id ^ 1);
 9:         // 获得子节点较小值，并设置到父节点
10:         byte val = val1 < val2 ? val1 : val2;
11:         setValue(parentId, val);
12:         // 跳到父节点
13:         id = parentId;
14:     }
15: }
```

- 😈 注意，调用此方法时，节点 `id` 已经更新为**不可用**。
- 第 2 行：循环，直到**根**节点。
- 第 4 行：`>>> 1` 操作，获得父节点的编号。
- 第 5 至 11 行：获得子节点较小值，并调用 `#setValue(int id, int value)` 方法，设置到父节点。
- 第 13 行：跳到父节点。

### 2.4.2 updateParentsFree

`#updateParentsAlloc(int id)` 方法，更新获得的节点的祖先可用。代码如下：

```java
   /**
    * Update method used by free
    * This needs to handle the special case when both children are completely free
    * in which case parent be directly allocated on request of size = child-size * 2
    *
    * @param id id
    */
 1: private void updateParentsFree(int id) {
 2:     // 获得当前节点的子节点的层级
 3:     int logChild = depth(id) + 1;
 4:     while (id > 1) {
 5:         // 获得父节点的编号
 6:         int parentId = id >>> 1;
 7:         // 获得子节点的值
 8:         byte val1 = value(id);
 9:         // 获得另外一个子节点的值
10:         byte val2 = value(id ^ 1);
11:         // 获得当前节点的层级
12:         logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up
13: 
14:         // 两个子节点都可用，则直接设置父节点的层级
15:         if (val1 == logChild && val2 == logChild) {
16:             setValue(parentId, (byte) (logChild - 1));
17:         // 两个子节点任一不可用，则取子节点较小值，并设置到父节点
18:         } else {
19:             byte val = val1 < val2 ? val1 : val2;
20:             setValue(parentId, val);
21:         }
22: 
23:         // 跳到父节点
24:         id = parentId;
25:     }
26: }

```

- 😈 注意，调用此方法时，节点 `id` 已经更新为可用。
- 第 3 行：获得当前节点的子节点的层级。
- 第 4 行：循环，直到**根**节点。
- 第 6 行：`>>> 1` 操作，获得**父**节点的编号。
- 第 7 至 10 行：获得两个**子**节点的值。
- 第 12 行：获得当前节点的层级。
- 第 14 至 16 行：两个子节点都可用，则调用 `#setValue(id, value)` 方法，直接设置父节点的层级( 注意，是 `logChild - 1` )。
- 第 17 至 21 行：两个子节点任一不可用，则`#setValue(id, value)` 方法，取子节点较小值，并设置到父节点。
- 第 24 行：跳到父节点。

## 2.5 initBuf

`#initBuf(PooledByteBuf<T> buf, long handle, int reqCapacity)` 方法，初始化分配的内存块到 PooledByteBuf 中。代码如下：

```java
 1: void initBuf(PooledByteBuf<T> buf, long handle, int reqCapacity) {
 2:     // 获得 memoryMap 数组的编号( 下标 )
 3:     int memoryMapIdx = memoryMapIdx(handle);
 4:     // 获得 bitmap 数组的编号( 下标 )。注意，此时获得的还不是真正的 bitmapIdx 值，需要经过 `bitmapIdx & 0x3FFFFFFF` 运算。
 5:     int bitmapIdx = bitmapIdx(handle);
 6:     // 内存块为 Page
 7:     if (bitmapIdx == 0) {
 8:         byte val = value(memoryMapIdx);
 9:         assert val == unusable : String.valueOf(val);
10:         // 初始化 Page 内存块到 PooledByteBuf 中
11:         buf.init(this, handle, runOffset(memoryMapIdx) + offset, reqCapacity, runLength(memoryMapIdx), arena.parent.threadCache());
12:     // 内存块为 SubPage
13:     } else {
14:         // 初始化 SubPage 内存块到 PooledByteBuf 中
15:         initBufWithSubpage(buf, handle, bitmapIdx, reqCapacity);
16:     }
17: }

```

- 第 3 行：调用 `#memoryMapIdx(handle)` 方法，获得 `memoryMap` 数组的编号( 下标 )。

- 第 5 行：调用 `#bitmapIdx(handle)` 方法，获得 `bitmap` 数组的编号( 下标 )。

- 第 6 至 11 行：通过 `bitmapIdx == 0` 判断出，内存块是 Page 。所以，调用 `PooledByteBuf#init(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache)` 方法，初始化 Page 内存块到 PooledByteBuf 中。其中，`runOffset(memoryMapIdx) + offset` 代码块，计算 Page 内存块在 `memory` 中的开始位置。`runOffset(int id)` 方法，代码如下：

  ```java
  private int runOffset(int id) {
      // represents the 0-based offset in #bytes from start of the byte-array chunk
      int shift = id ^ 1 << depth(id);
      return shift * runLength(id);
  }
      
  private int runLength(int id) {
      // represents the size in #bytes supported by node 'id' in the tree
      return 1 << log2ChunkSize - depth(id);
  }
  
  ```

- 第12 至 16 行：通过 `bitmapIdx != 0` 判断出，内存块是 SubPage 。所以，调用 `#initBufWithSubpage(PooledByteBuf<T> buf, long handle, int reqCapacity)` 方法，初始化 SubPage 内存块到 PooledByteBuf 中。详细解析，见 [「2.5.1 initBufWithSubpage」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk/#) 。

### 2.5.1 initBufWithSubpage

`#initBufWithSubpage(PooledByteBuf<T> buf, long handle, int reqCapacity)` 方法，初始化 SubPage 内存块到 PooledByteBuf 中。代码如下：

```java
   void initBufWithSubpage(PooledByteBuf<T> buf, long handle, int reqCapacity) {
       initBufWithSubpage(buf, handle, bitmapIdx(handle), reqCapacity);
   }

 1: private void initBufWithSubpage(PooledByteBuf<T> buf, long handle, int bitmapIdx, int reqCapacity) {
 2:     assert bitmapIdx != 0;
 3: 
 4:     // 获得 memoryMap 数组的编号( 下标 )
 5:     int memoryMapIdx = memoryMapIdx(handle);
 6:     // 获得 SubPage 对象
 7:     PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];
 8:     assert subpage.doNotDestroy;
 9:     assert reqCapacity <= subpage.elemSize;
10: 
11:     // 初始化 SubPage 内存块到 PooledByteBuf 中
12:     buf.init(
13:         this, handle,
14:         runOffset(memoryMapIdx) + (bitmapIdx & 0x3FFFFFFF) * subpage.elemSize + offset,
15:             reqCapacity, subpage.elemSize, arena.parent.threadCache());
16: }

```

- 第 3 至 7 行：获得 SubPage 对象。
- 第 11 至于 15 行：调用 `PooledByteBuf#init(PoolChunk<T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache)` 方法，初始化 SubPage 内存块到 PooledByteBuf 中。其中，`runOffset(memoryMapIdx) + (bitmapIdx & 0x3FFFFFFF) * subpage.elemSize + offset` 代码块，计算 SubPage 内存块在 `memory` 中的开始位置。

## 2.6 destroy

`#destroy()` 方法，从 Arena 中销毁当前 Chunk 。代码如下：

```java
void destroy() {
    arena.destroyChunk(this);
}

```

- 详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena) 。

## 2.7 PoolChunkMetric

`io.netty.buffer.PoolChunkMetric` ，PoolChunk Metric 接口。代码如下：

```java
public interface PoolChunkMetric {

    /**
     * Return the percentage of the current usage of the chunk.
     */
    int usage();

    /**
     * Return the size of the chunk in bytes, this is the maximum of bytes that can be served out of the chunk.
     */
    int chunkSize();

    /**
     * Return the number of free bytes in the chunk.
     */
    int freeBytes();

}

```

------

PoolChunk 对 PoolChunkMetric 接口的实现，代码如下：

```java
@Override
public int usage() {
    final int freeBytes;
    synchronized (arena) {
        freeBytes = this.freeBytes;
    }
    return usage(freeBytes);
}

private int usage(int freeBytes) {
    // 全部使用，100%
    if (freeBytes == 0) {
        return 100;
    }

    // 部分使用，最高 99%
    int freePercentage = (int) (freeBytes * 100L / chunkSize);
    if (freePercentage == 0) {
        return 99;
    }
    return 100 - freePercentage;
}

@Override
public int chunkSize() {
    return chunkSize;
}

@Override
public int freeBytes() {
    synchronized (arena) {
        return freeBytes;
    }
}

```

- `synchronized` 的原因是，保证 `freeBytes` 对其它线程的可见性。对应 Github 提交为 [a7fe6c01539d3ad92d7cd94a25daff9e10851088](https://github.com/netty/netty/commit/a7fe6c01539d3ad92d7cd94a25daff9e10851088) 。

  > **Motivation**:
  >
  > As we may access the metrics exposed of PooledByteBufAllocator from another thread then the allocations happen we need to ensure we synchronize on the PoolArena to ensure correct visibility.
  >
  > **Modifications**:
  >
  > Synchronize on the PoolArena to ensure correct visibility.
  >
  > **Result**:
  >
  > Fix multi-thread issues on the metrics

# 666. 彩蛋

老艿艿有点二，在 `#allocateNode(int normCapacity)` 方法卡了很久。因为没看到 `memoryMap` 和 `depthMap` 数组，下标是从 1 开始的！！！我恨那。

参考如下文章：

- 占小狼 [《深入浅出Netty内存管理 PoolChunk》](https://www.jianshu.com/p/c4bd37a3555b)
- Hypercube [《自顶向下深入分析Netty（十）–PoolChunk》](https://www.jianshu.com/p/70181af2972a)

# Buffer 之 Jemalloc（三）PoolSubpage



# 1. 概述

在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) 一文中，我们已经看到，为了进一步提供提高内存**分配效率**并减少**内存碎片**，Jemalloc 算法将每个 Chunk 切分成多个**小块** Page 。

但是实际应用中，Page 也是**比较大**的内存块，如果直接使用，明显是很浪费的。因此，Jemalloc 算法将每个 Page 更进一步的切分为**多个** Subpage 内存块。Page 切分成**多个** Subpage 内存块，并未采用相对复杂的算法和数据结构，而是直接基于**数组**，通过数组来**标记**每个 Subpage 内存块是否已经分配。如下图所示：![PoolSubpage](http://static2.iocoder.cn/images/Netty/2018_09_07/01.png)

- 一个 Page ，切分出的**多个** Subpage 内存块**大小均等**。

- 每个 Page 拆分的 Subpage 内存块

  可以不同

  ，以 Page 第一次拆分为 Subpage 内存块时请求分配的内存大小为准。例如：

  - 初始时，申请一个 16B 的内存块，那么 Page0 被拆成成 512( `8KB / 16B` )个 Subpage 块，使用第 0 块。
  - 然后，申请一个 32B 的内存块，那么 Page1 被拆分成 256( `8KB / 32B` )个 Subpage 块，使用第 0 块。
  - 最后，申请一个 16B 的内存块，那么重用 Page0 ，使用第 1 块。
  - 总结来说，申请 Subpage 内存块时，先去找**大小匹配**，且有可分配 Subpage 内存块的 Page ：1）如果有，则使用其中的一块 Subpage ；2）如果没有，则选择一个新的 Page 拆分成多个 Subpage 内存块，使用第 0 块 Subpage 。

- Subpage 的内存规格，分成 Tiny 和 Small 两类，并且每类有多种大小，如下图所示：![Subpage 内存规格](http://static2.iocoder.cn/images/Netty/2018_09_07/02.png)

- 为了方便描述，下文我们会继续将 `ele` 小块，描述成“Subpage 内存块”，简称“Subpage” 。

# 2. PoolSubpage

`io.netty.buffer.PoolSubpage` ，实现 PoolSubpageMetric 接口，Netty 对 Jemalloc Subpage 的实现类。

虽然，PoolSubpage 类的命名是“Subpage”，实际描述的是，Page 切分为**多个** Subpage 内存块的分配情况。那么为什么不直接叫 PoolPage 呢？在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（一）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) 一文中，我们可以看到，当申请分配的内存规格为 Normal 和 Huge 时，使用的是一块或多块 Page 内存块。如果 PoolSubpage 命名成 PoolPage 后，和这块的分配策略是有所冲突的。或者说，**Subpage ，只是 Page 分配内存的一种形式**。

## 2.1 构造方法

```java
/**
 * 所属 PoolChunk 对象
 */
final PoolChunk<T> chunk;
/**
 * 在 {@link PoolChunk#memoryMap} 的节点编号
 */
private final int memoryMapIdx;
/**
 * 在 Chunk 中，偏移字节量
 *
 * @see PoolChunk#runOffset(int) 
 */
private final int runOffset;
/**
 * Page 大小 {@link PoolChunk#pageSize}
 */
private final int pageSize;

/**
 * Subpage 分配信息数组
 *
 * 每个 long 的 bits 位代表一个 Subpage 是否分配。
 * 因为 PoolSubpage 可能会超过 64 个( long 的 bits 位数 )，所以使用数组。
 *   例如：Page 默认大小为 8KB ，Subpage 默认最小为 16 B ，所以一个 Page 最多可包含 8 * 1024 / 16 = 512 个 Subpage 。
 *        因此，bitmap 数组大小为 512 / 64 = 8 。
 * 另外，bitmap 的数组大小，使用 {@link #bitmapLength} 来标记。或者说，bitmap 数组，默认按照 Subpage 的大小为 16B 来初始化。
 *    为什么是这样的设定呢？因为 PoolSubpage 可重用，通过 {@link #init(PoolSubpage, int)} 进行重新初始化。
 */
private final long[] bitmap;

/**
 * 双向链表，前一个 PoolSubpage 对象
 */
PoolSubpage<T> prev;
/**
 * 双向链表，后一个 PoolSubpage 对象
 */
PoolSubpage<T> next;

/**
 * 是否未销毁
 */
boolean doNotDestroy;
/**
 * 每个 Subpage 的占用内存大小
 */
int elemSize;
/**
 * 总共 Subpage 的数量
 */
private int maxNumElems;
/**
 * {@link #bitmap} 长度
 */
private int bitmapLength;
/**
 * 下一个可分配 Subpage 的数组位置
 */
private int nextAvail;
/**
 * 剩余可用 Subpage 的数量
 */
private int numAvail;

  1: // 【构造方法 1】 双向链表，头节点
  2: /** Special constructor that creates a linked list head */
  3: PoolSubpage(int pageSize) {
  4:     chunk = null;
  5:     memoryMapIdx = -1;
  6:     runOffset = -1;
  7:     elemSize = -1;
  8:     this.pageSize = pageSize;
  9:     bitmap = null;
 10: }
 11: 
 12: // 【构造方法 2】 双向链表，Page 节点
 13: PoolSubpage(PoolSubpage<T> head, PoolChunk<T> chunk, int memoryMapIdx, int runOffset, int pageSize, int elemSize) {
 14:     this.chunk = chunk;
 15:     this.memoryMapIdx = memoryMapIdx;
 16:     this.runOffset = runOffset;
 17:     this.pageSize = pageSize;
 18:     // 创建 bitmap 数组
 19:     bitmap = new long[pageSize >>> 10]; // pageSize / 16 / 64
 20:     // 初始化
 21:     init(head, elemSize);
 22: }
```

- Chunk 相关
  - `chunk` 属性，所属 PoolChunk 对象。
  - `memoryMapIdx` 属性，在 `PoolChunk.memoryMap` 的节点编号，例如节点编号 2048 。
  - `runOffset` 属性，在 Chunk 中，偏移字节量，通过 `PoolChunk#runOffset(id)` 方法计算。在 PoolSubpage 中，无相关的逻辑，仅用于 `#toString()` 方法，打印信息。
  - `pageSize` 属性，Page 大小。
- Subpage 相关
  - `bitmap`属性，Subpage**分配信息**数组。
    - 1、每个 `long` 的 bits 位代表一个 Subpage 是否分配。因为 PoolSubpage 可能会超过 64 个( `long` 的 bits 位数 )，所以使用数组。例如：Page 默认大小为 `8KB` ，Subpage 默认最小为 `16B` ，所以一个 Page 最多可包含 `8 * 1024 / 16` = 512 个 Subpage 。
- 2、在【第 19 行】的代码，创建`bitmap`数组。我们可以看到，`bitmap`数组的大小为 8(`pageSize >>> 10 = pageSize / 16 / 64 = 512 / 64`) 个。
  - 为什么是**固定大小**呢？因为 PoolSubpage **可重用**，通过 `#init(PoolSubpage, int)` 进行重新初始化。
  - 那么数组大小怎么获得？通过 `bitmapLength` 属性来标记**真正**使用的数组大小。
- `bitmapLength` 属性，`bitmap` 数组的**真正**使用的数组大小。
- `elemSize` 属性，每个 Subpage 的占用内存大小，例如 `16B`、`32B` 等等。
- `maxNumElems` 属性，总共 Subpage 的数量。例如 `16B` 为 512 个，`32b` 为 256 个。
- `numAvail` 属性，剩余可用 Subpage 的数量。
- `nextAvail` 属性，下一个可分配 Subpage 的数组( `bitmap` )位置。可能会有胖友有疑问，`bitmap` 又是数组，又考虑 bits 位，怎么计算位置呢？在 [「2.6 getNextAvail」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 见分晓。
- `doNotDestroy` 属性，是否未销毁。详细解析，见 [「2.5 free」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 中。
- Arena 相关
  - `prev` 属性，双向链表，前一个 PoolSubpage 对象。
  - `next` 属性，双向链表，后一个 PoolSubpage 对象。
  - 详细解析，见 [「2.3 双向链表」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 。
- 构造方法 **1** ，用于创建双向链表的头( head )节点。
- 构造方法`2`，用于创建双向链表的 Page 节点。
  - 第 21 行：调用 `#init(PoolSubpage<T> head, int elemSize)` 方法，初始化。详细解析，见 [「2.2 init」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 。

## 2.2 init

`#init(PoolSubpage<T> head, int elemSize)` 方法，初始化。代码如下：

```
 1: void init(PoolSubpage<T> head, int elemSize) {
 2:     // 未销毁
 3:     doNotDestroy = true;
 4:     // 初始化 elemSize
 5:     this.elemSize = elemSize;
 6:     if (elemSize != 0) {
 7:         // 初始化 maxNumElems
 8:         maxNumElems = numAvail = pageSize / elemSize;
 9:         // 初始化 nextAvail
10:         nextAvail = 0;
11:         // 计算 bitmapLength 的大小
12:         bitmapLength = maxNumElems >>> 6;
13:         if ((maxNumElems & 63) != 0) { // 未整除，补 1.
14:             bitmapLength ++;
15:         }
16: 
17:         // 初始化 bitmap
18:         for (int i = 0; i < bitmapLength; i ++) {
19:             bitmap[i] = 0;
20:         }
21:     }
22:     // 添加到 Arena 的双向链表中。
23:     addToPool(head);
24: }
```

- 第 3 行：未销毁。
- 第 5 行：初始化`elemSize`。
  - 第 8 行：初始化 `maxNumElems` 。
- 第 10 行：初始化 `nextAvail` 。
- 第 11 至 15 行：初始化`bitmapLength`。
  - 第 17 至 20 行：初始化 `bitmap` 。
- 第 23 行：调用 `#addToPool(PoolSubpage<T> head)` 方法中，添加到 Arena 的双向链表中。详细解析，见 [「2.3.1 addToPool」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#)中。

## 2.3 双向链表

在每个 Arena 中，有 `tinySubpagePools` 和 `smallSubpagePools` 属性，分别表示 **tiny** 和 **small** 类型的 PoolSubpage 数组。代码如下：

```
// PoolArena.java

/**
 * tiny 类型的 PoolSubpage 数组
 *
 * 数组的每个元素，都是双向链表
 */
private final PoolSubpage<T>[] tinySubpagePools;
/**
 * small 类型的 SubpagePools 数组
 *
 * 数组的每个元素，都是双向链表
 */
private final PoolSubpage<T>[] smallSubpagePools;
```

- 数组的每个元素，通过 `prev` 和 `next` 属性，形成**双向**链表。并且，每个元素，表示对应的 Subpage 内存规格的**双向**链表，例如：`tinySubpagePools[0]` 表示 `16B` ，`tinySubpagePools[1]` 表示 `32B` 。

- 通过 `tinySubpagePools` 和 `smallSubpagePools` 属性，可以从中查找，是否已经有符合分配内存规格的 Subpage 节点可分配。

- 初始时，每个双向链表，会创建对应的 `head` 节点，代码如下：

  ```
  // PoolArena.java
  
  private PoolSubpage<T> newSubpagePoolHead(int pageSize) {
      PoolSubpage<T> head = new PoolSubpage<T>(pageSize);
      head.prev = head;
      head.next = head;
      return head;
  }
  ```

  - 比较神奇的是，`head` 的上下节点都是**自己**。也就说，这是个双向环形( 循环 )链表。

### 2.3.1 addToPool

`#addToPool(PoolSubpage<T> head)` 方法中，添加到 Arena 的双向链表中。代码如下：

```
private void addToPool(PoolSubpage<T> head) {
    assert prev == null && next == null;
    // 将当前节点，插入到 head 和 head.next 中间
    prev = head;
    next = head.next;
    next.prev = this;
    head.next = this;
}
```

- 将当前节点，插入到`head`和`head.next`中间。如下图所示：
- ![æå¥è¿ç¨](http://static2.iocoder.cn/images/Netty/2018_09_07/03.png)
- 注意，是在 `head` 和 `head.next` **中间**插入节点噢。

### 2.3.2 removeFromPool

`#removeFromPool()` 方法中，从双向链表中移除。代码如下：

```
private void removeFromPool() {
    assert prev != null && next != null;
    // 前后节点，互相指向
    prev.next = next;
    next.prev = prev;
    // 当前节点，置空
    next = null;
    prev = null;
}
```

## 2.4 allocate

`#allocate()` 方法，分配一个 Subpage 内存块，并返回该内存块的位置 `handle` 。代码如下：

> 关于 `handle` 怎么翻译和解释好呢？笔者暂时没想好，官方的定义是 `"Returns the bitmap index of the subpage allocation."` 。

```java
 1: long allocate() {
 2:     // 防御性编程，不存在这种情况。
 3:     if (elemSize == 0) {
 4:         return toHandle(0);
 5:     }
 6: 
 7:     // 可用数量为 0 ，或者已销毁，返回 -1 ，即不可分配。
 8:     if (numAvail == 0 || !doNotDestroy) {
 9:         return -1;
10:     }
11: 
12:     // 获得下一个可用的 Subpage 在 bitmap 中的总体位置
13:     final int bitmapIdx = getNextAvail();
14:     // 获得下一个可用的 Subpage 在 bitmap 中数组的位置
15:     int q = bitmapIdx >>> 6;
16:     // 获得下一个可用的 Subpage 在 bitmap 中数组的位置的第几 bits
17:     int r = bitmapIdx & 63;
18:     assert (bitmap[q] >>> r & 1) == 0;
19:     // 修改 Subpage 在 bitmap 中不可分配。
20:     bitmap[q] |= 1L << r;
21: 
22:     // 可用 Subpage 内存块的计数减一
23:     if (-- numAvail == 0) { // 无可用 Subpage 内存块
24:         // 从双向链表中移除
25:         removeFromPool();
26:     }
27: 
28:     // 计算 handle
29:     return toHandle(bitmapIdx);
30: }
```

- 第 2 至 5 行：防御性编程，不存在这种情况。

- 第 7 至 10 行：可用数量为 0 ，或者已销毁，返回 -1 ，即**不可分配**。

- 第 12 至 20 行：分配一个 Subpage 内存块。

  - 第 13 行：调用 `#getNextAvail()` 方法，获得下一个可用的 Subpage 在 bitmap 中的**总体**位置。详细解析，见 [「2.6 getNextAvail」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 。
  - 第 15 行：`bitmapIdx >>> 6 = bitmapIdx / 64` 操作，获得下一个可用的 Subpage 在 bitmap 中**数组的位置**。
  - 第 17 行：`bitmapIdx & 63 = bitmapIdx % 64` 操作， 获得下一个可用的 Subpage 在 bitmap 中数组的位置的**第几 bit** 。
  - 第 20 行：`| (1L << r)` 操作，修改 Subpage 在 bitmap 中不可分配。

- 第 23 行：可用 Subpage 内存块的计数减一。

  - 第 25 行：当 `numAvail == 0` 时，表示无可用 Subpage 内存块。所以，调用 `#removeFromPool()` 方法，从双向链表中移除。详细解析，见 [「2.3.2 removeFromPool」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 。

- 第 29 行：调用 `#toHandle(bitmapIdx)` 方法，计算 `handle` 值。代码如下：

  ```java
  private long toHandle(int bitmapIdx) {
      return 0x4000000000000000L | (long) bitmapIdx << 32 | memoryMapIdx;
  }
  ```

  - 低 32 bits ：`memoryMapIdx` ，可以判断所属 Chunk 的哪个 Page 节点，即 `memoryMap[memoryMapIdx]` 。

  - 高 32 bits ：`bitmapIdx`，可以判断 Page 节点中的哪个 Subpage 的内存块，即`bitmap[bitmapIdx]`。

    - 那么为什么会有`0x4000000000000000L`呢？因为在

       

      ```
      PoolChunk#allocate(int normCapacity)
      ```

       

      中：

      - 如果分配的是 Page 内存块，返回的是 `memoryMapIdx` 。

- 如果分配的是 Subpage 内存块，返回的是 `handle` 。**但但但是**，如果说 `bitmapIdx = 0` ，那么没有 `0x4000000000000000L` 情况下，就会和【分配 Page 内存块】冲突。因此，需要有 `0x4000000000000000L` 。

- 因为有了 `0x4000000000000000L`(最高两位为 `01` ，其它位为 `0` )，所以获取 `bitmapIdx` 时，通过 `handle >>> 32 & 0x3FFFFFFF` 操作。使用 `0x3FFFFFFF`( 最高两位为 `00` ，其它位为 `1` ) 进行消除 `0x4000000000000000L` 带来的影响。

## 2.5 free

`#free(PoolSubpage<T> head, int bitmapIdx)` 方法，释放指定位置的 Subpage 内存块，并返回当前 Page **是否正在使用中**( `true` )。代码如下：

```
 1: boolean free(PoolSubpage<T> head, int bitmapIdx) {
 2:     // 防御性编程，不存在这种情况。
 3:     if (elemSize == 0) {
 4:         return true;
 5:     }
 6:     // 获得 Subpage 在 bitmap 中数组的位置
 7:     int q = bitmapIdx >>> 6;
 8:     // 获得 Subpage 在 bitmap 中数组的位置的第几 bits
 9:     int r = bitmapIdx & 63;
10:     assert (bitmap[q] >>> r & 1) != 0;
11:     // 修改 Subpage 在 bitmap 中可分配。
12:     bitmap[q] ^= 1L << r;
13: 
14:     // 设置下一个可用为当前 Subpage
15:     setNextAvail(bitmapIdx);
16: 
17:     // 可用 Subpage 内存块的计数加一
18:     if (numAvail ++ == 0) {
19:         // 添加到 Arena 的双向链表中。
20:         addToPool(head);
21:         return true;
22:     }
23: 
24:     // 还有 Subpage 在使用
25:     if (numAvail != maxNumElems) {
26:         return true;
27:     // 没有 Subpage 在使用
28:     } else {
29:         // 双向链表中，只有该节点，不进行移除
30:         // Subpage not in use (numAvail == maxNumElems)
31:         if (prev == next) {
32:             // Do not remove if this subpage is the only one left in the pool.
33:             return true;
34:         }
35: 
36:         // 标记为已销毁
37:         // Remove this subpage from the pool if there are other subpages left in the pool.
38:         doNotDestroy = false;
39:         // 从双向链表中移除
40:         removeFromPool();
41:         return false;
42:     }
43: }
```

- 第 2 至 5 行：防御性编程，不存在这种情况。

- 第 6 至 12 行：释放指定位置的 Subpage 内存块。

  - 第 7 行：`bitmapIdx >>> 6 = bitmapIdx / 64` 操作，获得下一个可用的 Subpage 在 bitmap 中**数组的位置**。
  - 第 9 行：`bitmapIdx & 63 = bitmapIdx % 64` 操作， 获得下一个可用的 Subpage 在 bitmap 中数组的位置的**第几 bit** 。
  - 第 12 行：`^ (1L << r)` 操作，修改 Subpage 在 bitmap 中可分配。

- 第 15 行：调用 `#setNextAvail(int bitmapIdx)` 方法，设置下一个可用为当前 Subpage 的位置。这样，就能避免下次分配 Subpage 时，再去找位置。代码如下：

  ```
  private void setNextAvail(int bitmapIdx) {
      nextAvail = bitmapIdx;
  }
  ```

- 第 18 行：可用 Subpage 内存块的计数加一。

  - 第 20 行：当之前 `numAvail == 0` 时，表示**又有**可用 Subpage 内存块。所以，调用 `#addToPool(PoolSubpage<T> head)`方法，添加到 Arena 的双向链表中。详细解析，见 [「2.3.1 addToPool」](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage/#) 。
  - 第 21 行：返回 `true` ，正在使用中。

- 第 24 至 26 行：返回 `true` ，因为还有其它在使用的 Subpage 内存块。

- 第 27 至 42 行：没有 Subpage 在使用。

  - 第 29 至 34 行：返回 `true` ，因为通过 `prev == next` 可判断，当前节点为双向链表中的唯一节点，不进行移除。也就说，该节点后续，继续使用。

  - 第 36 至 41 行：返回

     

    ```
    false
    ```

     

    ，不在使用中。

    - 第 38 行：标记为已销毁。
    - 第 40 行：调用 `#removeFromPool()` 方法，从双向链表中移除。因为此时双向链表中，还有其它节点可使用，**没必要保持多个相同规格的节点**。

------

关于为什么 `#free(PoolSubpage<T> head, int bitmapIdx)` 方法，需要返回 `true` 或 `false` 呢？胖友再看看 `PoolChunk#free(long handle)` 方法，就能明白。答案是，如果不再使用，可以将该节点( Page )从 Chunk 中释放，标记为可用。😈😈😈

## 2.6 getNextAvail

`#getNextAvail()` 方法，获得下一个可用的 Subpage 在 bitmap 中的**总体**位置。代码如下：

```
private int getNextAvail() {
    int nextAvail = this.nextAvail;
    // <1> nextAvail 大于 0 ，意味着已经“缓存”好下一个可用的位置，直接返回即可。
    if (nextAvail >= 0) {
        this.nextAvail = -1;
        return nextAvail;
    }
    // <2> 寻找下一个 nextAvail
    return findNextAvail();
}
```

- ```
  <1>
  ```

   

  处，如果

   

  ```
  nextAvail
  ```

   

  大于 0 ，意味着已经“缓存”好下一个可用的位置，直接返回即可。

  - 获取好后，会将 `nextAvail` 置为 -1 。意味着，下次需要寻找下一个 `nextAvail` 。

- `<2>` 处，调用 `#findNextAvail()` 方法，寻找下一个 `nextAvail` 。代码如下：

  ```
  private int findNextAvail() {
      final long[] bitmap = this.bitmap;
      final int bitmapLength = this.bitmapLength;
      // 循环 bitmap
      for (int i = 0; i < bitmapLength; i ++) {
          long bits = bitmap[i];
          // ~ 操作，如果不等于 0 ，说明有可用的 Subpage
          if (~bits != 0) {
              // 在这 bits 寻找可用 nextAvail
              return findNextAvail0(i, bits);
          }
      }
      // 未找到
      return -1;
  }
  ```

  - 代码比较简单，胖友直接看注释。

  - 调用 `#findNextAvail0(int i, long bits)` 方法，在这 bits 寻找可用 `nextAvail` 。代码如下：

    ```
     1: private int findNextAvail0(int i, long bits) {
     2:     final int maxNumElems = this.maxNumElems;
     3:     // 计算基础值，表示在 bitmap 的数组下标
     4:     final int baseVal = i << 6; // 相当于 * 64
     5: 
     6:     // 遍历 64 bits
     7:     for (int j = 0; j < 64; j ++) {
     8:         // 计算当前 bit 是否未分配
     9:         if ((bits & 1) == 0) {
    10:             // 可能 bitmap 最后一个元素，并没有 64 位，通过 baseVal | j < maxNumElems 来保证不超过上限。
    11:             int val = baseVal | j;
    12:             if (val < maxNumElems) {
    13:                 return val;
    14:             } else {
    15:                 break;
    16:             }
    17:         }
    18:         // 去掉当前 bit
    19:         bits >>>= 1;
    20:     }
    21: 
    22:     // 未找到
    23:     return -1;
    24: }
    
    ```

    - 第 4 行：计算基础值，表示在 `bitmap` 的数组**下标**。通过 `i << 6 = i * 64` 的计算，我们可以通过 `i >>> 6 = i / 64` 的方式，知道是 `bitmap` 数组的第几个元素。

    - 第 7 行：循环 64 bits 。

      - 第 9 行：

        ```
        (bits & 1) == 0
        
        ```

         

        操作，计算当前 bit 是否

        未分配

        。

        - 第 11 行：`baseVal | j` 操作，使用**低 64 bits** ，表示分配 `bitmap` 数组的元素的**第几 bit** 。

        - 第 12 行：可能

           

          ```
          bitmap
          
          ```

           

          数组的最后一个元素，并没有 64 位，通过

           

          ```
          baseVal | j < maxNumElems
          
          ```

           

          来保证不超过上限。如果

          - 第 13 行：未超过，返回 `val` 。
          - 第 15 行：超过，结束循环，最终返回 `-1` 。

      - 第 19 行：去掉当前 bit 。这样，下次循环就可以判断下一个 bit 是否**未分配**。

    - 第 23 行：返回 `-1` ，表示未找到。

## 2.6 destroy

`#destroy()` 方法，销毁。代码如下：

```
void destroy() {
    if (chunk != null) {
        chunk.destroy();
    }
}

```

## 2.7 PoolSubpageMetric

`io.netty.buffer.PoolSubpageMetric` ，PoolSubpage Metric 接口。代码如下：

```
public interface PoolSubpageMetric {

    /**
     * Return the number of maximal elements that can be allocated out of the sub-page.
     */
    int maxNumElements();

    /**
     * Return the number of available elements to be allocated.
     */
    int numAvailable();

    /**
     * Return the size (in bytes) of the elements that will be allocated.
     */
    int elementSize();

    /**
     * Return the size (in bytes) of this page.
     */
    int pageSize();
}

```

------

PoolChunk 对 PoolChunkMetric 接口的实现，代码如下：

```
@Override
public int maxNumElements() {
    synchronized (chunk.arena) {
        return maxNumElems;
    }
}

@Override
public int numAvailable() {
    synchronized (chunk.arena) {
        return numAvail;
    }
}

@Override
public int elementSize() {
    synchronized (chunk.arena) {
        return elemSize;
    }
}

@Override
public int pageSize() {
    return pageSize;
}

```

# 666. 彩蛋

PoolSubpage 相比 PoolChunk 来说，简单好多。嘿嘿。

参考如下文章：

- 占小狼 [《深入浅出Netty内存管理 PoolSubpage》](https://www.jianshu.com/p/d91060311437)
- Hypercube [《自顶向下深入分析Netty（十）–PoolSubpage》](https://www.jianshu.com/p/7afd3a801b15)

# Buffer 之 Jemalloc（四）PoolChunkList



# 1. 概述

在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) ，我们看到 PoolChunk 有如下三个属性：

```
/**
 * 所属 PoolChunkList 对象
 */
PoolChunkList<T> parent;
/**
 * 上一个 Chunk 对象
 */
PoolChunk<T> prev;
/**
 * 下一个 Chunk 对象
 */
PoolChunk<T> next;
```

- 通过 `prev` 和 `next` 两个属性，形成一个**双向** Chunk 链表 `parent`( PoolChunkList )。

那么为什么需要有 PoolChunkList 这样一个链表呢？直接开始撸代码。

# 2. PoolChunkList

`io.netty.buffer.PoolChunkList` ，实现 PoolChunkListMetric 接口，负责管理多个 Chunk 的生命周期，**在此基础上对内存分配进行进一步的优化**。

## 2.1 构造方法

```
/**
 * 所属 PoolArena 对象
 */
private final PoolArena<T> arena;
/**
 * 下一个 PoolChunkList 对象
 */
private final PoolChunkList<T> nextList;
/**
 * Chunk 最小内存使用率
 */
private final int minUsage;
/**
 * Chunk 最大内存使用率
 */
private final int maxUsage;
/**
 * 每个 Chunk 最大可分配的容量
 *
 * @see #calculateMaxCapacity(int, int) 方法
 */
private final int maxCapacity;
/**
 * PoolChunk 头节点
 */
private PoolChunk<T> head;

/**
 * 前一个 PoolChunkList 对象
 */
// This is only update once when create the linked like list of PoolChunkList in PoolArena constructor.
private PoolChunkList<T> prevList;

// TODO: Test if adding padding helps under contention
//private long pad0, pad1, pad2, pad3, pad4, pad5, pad6, pad7;

PoolChunkList(PoolArena<T> arena, PoolChunkList<T> nextList, int minUsage, int maxUsage, int chunkSize) {
    assert minUsage <= maxUsage;
    this.arena = arena;
    this.nextList = nextList;
    this.minUsage = minUsage;
    this.maxUsage = maxUsage;
    // 计算 maxUsage 属性
    maxCapacity = calculateMaxCapacity(minUsage, chunkSize);
}
```

- `arena` 属性，所属 PoolArena 对象。

- `prevList` + `nextList` 属性，上一个和下一个 PoolChunkList 对象。也就是说，PoolChunkList 除了**自身**有一条双向链表外，PoolChunkList 和 PoolChunkList **之间**也形成了一条双向链表。如下图所示：

  > FROM [《深入浅出Netty内存管理 PoolChunkList》](https://www.jianshu.com/p/a1debfe4ff02)
  >
  > ![双向链表](http://static2.iocoder.cn/images/Netty/2018_09_10/01.png)

- `head` 属性，PoolChunkList **自身**的双向链表的**头节点**。

- ```
  minUsage
  ```

   

  +

   

  ```
  maxUsage
  ```

   

  属性，PoolChunkList 管理的 Chunk 们的内存使用率。

  - 当 Chunk 分配的内存率超过 `maxUsage` 时，从当前 PoolChunkList 节点移除，添加到下一个 PoolChunkList 节点( `nextList`)。TODO 详细解析。
  - 当 Chunk 分配的内存率小于 `minUsage` 时，从当前 PoolChunkList 节点移除，添加到上一个 PoolChunkList 节点( `prevList`)。TODO 详细解析。

- `maxCapacity` 属性，每个 Chunk 最大可分配的容量。通过 `#calculateMaxCapacity(int minUsage, int chunkSize)` 方法，来计算。代码如下：

  ```
  /**
   * Calculates the maximum capacity of a buffer that will ever be possible to allocate out of the {@link PoolChunk}s
   * that belong to the {@link PoolChunkList} with the given {@code minUsage} and {@code maxUsage} settings.
   */
  private static int calculateMaxCapacity(int minUsage, int chunkSize) {
      // 计算 minUsage 值
      minUsage = minUsage0(minUsage);
  
      if (minUsage == 100) {
          // If the minUsage is 100 we can not allocate anything out of this list.
          return 0;
      }
  
      // Calculate the maximum amount of bytes that can be allocated from a PoolChunk in this PoolChunkList.
      //
      // As an example:
      // - If a PoolChunkList has minUsage == 25 we are allowed to allocate at most 75% of the chunkSize because
      //   this is the maximum amount available in any PoolChunk in this PoolChunkList.
      return  (int) (chunkSize * (100L - minUsage) / 100L);
  }
  
  // 保证最小 >= 1
  private static int minUsage0(int value) {
      return max(1, value);
  }
  ```

  - 为什么使用 `(int) (chunkSize * (100L - minUsage) / 100L)` 来计算呢？因为 Chunk 进入当前 PoolChunkList 节点，意味着 Chunk 内存已经分配了 `minUsage` 比率，所以 Chunk 剩余的容量是 `chunkSize * (100L - minUsage) / 100L` 。😈 是不是豁然开朗噢？！

## 2.2 allocate

> 随着 Chunk 中 Page 的不断分配和释放，会导致很多碎片内存段，大大增加了之后分配一段连续内存的失败率。针对这种情况，可以把内存使用率较大的 Chunk 放到PoolChunkList 链表更后面。

`#allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity)` 方法，给 PooledByteBuf 对象分配内存块，并返回是否分配内存块成功。代码如下：

```
 1: boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity) {
 2:     // 双向链表中无 Chunk
 3:     // 申请分配的内存超过 ChunkList 的每个 Chunk 最大可分配的容量
 4:     if (head == null || normCapacity > maxCapacity) {
 5:         // Either this PoolChunkList is empty or the requested capacity is larger then the capacity which can
 6:         // be handled by the PoolChunks that are contained in this PoolChunkList.
 7:         return false;
 8:     }
 9: 
10:     // 遍历双向链表。注意，遍历的是 ChunkList 的内部双向链表。
11:     for (PoolChunk<T> cur = head;;) {
12:         // 分配内存块
13:         long handle = cur.allocate(normCapacity);
14:         // 分配失败
15:         if (handle < 0) {
16:             // 进入下一节点
17:             cur = cur.next;
18:             // 若下一个节点不存在，返回 false ，结束循环
19:             if (cur == null) {
20:                 return false; // 分配失败
21:             }
22:         // 分配成功
23:         } else {
24:             // 初始化内存块到 PooledByteBuf 对象中
25:             cur.initBuf(buf, handle, reqCapacity);
26:             // 超过当前 ChunkList 管理的 Chunk 的内存使用率上限
27:             if (cur.usage() >= maxUsage) {
28:                 // 从当前 ChunkList 节点移除
29:                 remove(cur);
30:                 // 添加到下一个 ChunkList 节点
31:                 nextList.add(cur); 
32:             }
33:             return true; // 分配成功
34:         }
35:     }
36: }
```

- 第 2 至 8 行：双向链表中无 Chunk，或者申请分配的内存超过 ChunkList 的每个 Chunk 最大可分配的容量，返回 `false` ，分配失败。

- 第 11 行：遍历双向链表。**注意，遍历的是 ChunkList 的内部双向链表**。

- 第 13 行：调用 `PoolChunk#allocate(normCapacity)` 方法，分配内存块。这块，可以结合 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》「2.2 allocate」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) 在复习下。

- 第 15 至 17 行：分配失败，进入下一个节点。

  - 第 18 至 21 行：若下一个节点不存在，返回 `false` ，分配失败。

- 第 22 至 25 行：分配成功，调用

   

  ```
  PooledByteBuf##initBuf(PooledByteBuf<T> buf, long handle, int reqCapacity)
  ```

   

  方法，初始化分配的内存块到 PooledByteBuf 中。这块，可以结合

   

  《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》「2.5 initBuf」

   

  在复习下。

  - 第 26 至 32 行：超过当前 ChunkList 管理的 Chunk 的内存使用率上限，从当前 ChunkList 节点移除，并添加到“

    下

    ”一个 ChunkList 节点。

    - 第 29 行：调用 `#remove(PoolChunk<T> cur)` 方法，解析见 [「2.4.2 remove」](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList/#) 。
    - 第 31 行：调用 `#remove(PoolChunk<T> cur)` 方法，解析见 [「2.4.1 add」](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList/#) 。

  - 第 33 行：返回 `true` ，分配成功。

## 2.3 free

`#free(PoolChunk<T> chunk, long handle)` 方法，释放 PoolChunk 的指定位置( `handle` )的内存块。代码如下：

```
 1: boolean free(PoolChunk<T> chunk, long handle) {
 2:     // 释放 PoolChunk 的指定位置( handle )的内存块
 3:     chunk.free(handle);
 4:     // 小于当前 ChunkList 管理的 Chunk 的内存使用率下限
 5:     if (chunk.usage() < minUsage) {
 6:         // 从当前 ChunkList 节点移除
 7:         remove(chunk);
 8:         // 添加到上一个 ChunkList 节点
 9:         // Move the PoolChunk down the PoolChunkList linked-list.
10:         return move0(chunk);
11:     }
12:     // 释放成功
13:     return true;
14: }
```

- 第 3 行：调用 `PoolChunk#free(long handle)` 方法，释放指定位置的内存块。这块，可以结合 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》「2.3 free」](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) 在复习下。
- 第 5 行：小于当前 ChunkList 管理的 Chunk 的内存使用率下限：
  - 第 7 行：调用 `#remove(PoolChunk<T> cur)` 方法，从当前 ChunkList 节点移除。
  - 第 10 行：调用 `#move(PoolChunk<T> chunk)` 方法， 添加到“上”一个 ChunkList 节点。详细解析，见 [「2.4.3 move」](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList/#) 。
- 第 13 行：返回 `true` ，释放成功。

## 2.4 双向链表操作

### 2.4.1 add

`#add(PoolChunk<T> chunk)` 方法，将 PoolChunk 添加到 ChunkList 节点中。代码如下：

```
1: void add(PoolChunk<T> chunk) {
2:     // 超过当前 ChunkList 管理的 Chunk 的内存使用率上限，继续递归到下一个 ChunkList 节点进行添加。
3:     if (chunk.usage() >= maxUsage) {
4:         nextList.add(chunk);
5:         return;
6:     }
7:     // 执行真正的添加
8:     add0(chunk);
9: }
```

- 第 2 至 6 行：超过当前 ChunkList 管理的 Chunk 的内存使用率上限，调用 `nextList` 的 `#add(PoolChunk<T> chunk)` 方法，继续递归到下一个 ChunkList 节点进行添加。

- 第 8 行：调用 `#add0(PoolChunk<T> chunk)` 方法，执行真正的添加。代码如下：

  ```
  /**
   * Adds the {@link PoolChunk} to this {@link PoolChunkList}.
   */
  void add0(PoolChunk<T> chunk) {
      chunk.parent = this;
      // <1> 无头节点，自己成为头节点
      if (head == null) {
          head = chunk;
          chunk.prev = null;
          chunk.next = null;
      // <2> 有头节点，自己成为头节点，原头节点成为自己的下一个节点
      } else {
          chunk.prev = null;
          chunk.next = head;
          head.prev = chunk;
          head = chunk;
      }
  }
  ```

  - `<1>` 处，比较好理解，胖友自己看。
  - `<2>` 处，因为 `chunk` **新**进入下一个 ChunkList 节点，一般来说，内存使用率相对较低，分配内存块成功率相对较高，所以变成新的首节点。

### 2.4.2 remove

`#remove(PoolChunk<T> chunk)` 方法，从当前 ChunkList 节点移除。代码如下：

```
private void remove(PoolChunk<T> cur) {
    // 当前节点为首节点，将下一个节点设置为头节点
    if (cur == head) {
        head = cur.next;
        if (head != null) {
            head.prev = null;
        }
    // 当前节点非首节点，将节点的上一个节点指向节点的下一个节点
    } else {
        PoolChunk<T> next = cur.next;
        cur.prev.next = next;
        if (next != null) {
            next.prev = cur.prev;
        }
    }
}
```

- 代码比较简单，胖友自己研究。

### 2.4.3 move

`#move(PoolChunk<T> chunk)` 方法， 添加到“上”一个 ChunkList 节点。代码如下：

```
   /**
    * Moves the {@link PoolChunk} down the {@link PoolChunkList} linked-list so it will end up in the right
    * {@link PoolChunkList} that has the correct minUsage / maxUsage in respect to {@link PoolChunk#usage()}.
    */
 1: private boolean move(PoolChunk<T> chunk) {
 2:     assert chunk.usage() < maxUsage;
 3: 
 4:     // 小于当前 ChunkList 管理的 Chunk 的内存使用率下限，继续递归到上一个 ChunkList 节点进行添加。
 5:     if (chunk.usage() < minUsage) {
 6:         // Move the PoolChunk down the PoolChunkList linked-list.
 7:         return move0(chunk);
 8:     }
 9: 
10:     // 执行真正的添加
11:     // PoolChunk fits into this PoolChunkList, adding it here.
12:     add0(chunk);
13:     return true;
14: }
```

- 第 4 至 8 行：小于当前 ChunkList 管理的 Chunk 的内存使用率下限，调用 `#move0(PoolChunk<T> chunk)` 方法，继续递归到上一个 ChunkList 节点进行添加。代码如下：

  ```
  private boolean move(PoolChunk<T> chunk) {
      assert chunk.usage() < maxUsage;
  
      // 小于当前 ChunkList 管理的 Chunk 的内存使用率下限，继续递归到上一个 ChunkList 节点进行添加。
      if (chunk.usage() < minUsage) {
          // Move the PoolChunk down the PoolChunkList linked-list.
          return move0(chunk);
      }
  
      // 执行真正的添加
      // PoolChunk fits into this PoolChunkList, adding it here.
      add0(chunk);
      return true;
  }
  ```

- 第 12 行：调用 `#add0(PoolChunk<T> chunk)` 方法，执行真正的添加。

- 第 13 行：返回 `true` ，移动成功。

## 2.5 iterator

`#iterator()` 方法，创建 Iterator 对象。代码如下：

```
private static final Iterator<PoolChunkMetric> EMPTY_METRICS = Collections.<PoolChunkMetric>emptyList().iterator();

@Override
public Iterator<PoolChunkMetric> iterator() {
    synchronized (arena) {
        // 空，返回 EMPTY_METRICS
        if (head == null) {
            return EMPTY_METRICS;
        }
        // 生成数组，后生成 Iterator
        List<PoolChunkMetric> metrics = new ArrayList<PoolChunkMetric>();
        for (PoolChunk<T> cur = head;;) {
            metrics.add(cur);
            cur = cur.next;
            if (cur == null) {
                break;
            }
        }
        return metrics.iterator();
    }
}
```

## 2.6 destroy

`#destroy()` 方法，销毁。代码如下：

```
void destroy(PoolArena<T> arena) {
    // 循环，销毁 ChunkList 管理的所有 Chunk
    PoolChunk<T> chunk = head;
    while (chunk != null) {
        arena.destroyChunk(chunk);
        chunk = chunk.next;
    }
    // 置空
    head = null;
}
```

## 2.7 PoolChunkListMetric

`io.netty.buffer.PoolChunkListMetric` ，继承 Iterable 接口，PoolChunkList Metric 接口。代码如下：

```
public interface PoolChunkListMetric extends Iterable<PoolChunkMetric> {

    /**
     * Return the minimum usage of the chunk list before which chunks are promoted to the previous list.
     */
    int minUsage();

    /**
     * Return the maximum usage of the chunk list after which chunks are promoted to the next list.
     */
    int maxUsage();
}
```

------

PoolChunkList 对 PoolChunkMetric 接口的实现，代码如下：

```
@Override
public int minUsage() {
    return minUsage0(minUsage);
}

@Override
public int maxUsage() {
    return min(maxUsage, 100);
}

```

# 3. PoolChunkList 初始化

在 PoolChunkArena 中，初始化 PoolChunkList 代码如下：

```
// PoolChunkList 之间的双向链表

private final PoolChunkList<T> q050;
private final PoolChunkList<T> q025;
private final PoolChunkList<T> q000;
private final PoolChunkList<T> qInit;
private final PoolChunkList<T> q075;
private final PoolChunkList<T> q100;

/**
 * PoolChunkListMetric 数组
 */
private final List<PoolChunkListMetric> chunkListMetrics;

  1: protected PoolArena(PooledByteBufAllocator parent, int pageSize,
  2:       int maxOrder, int pageShifts, int chunkSize, int cacheAlignment) {
  3:       
  4:     // ... 省略其它无关代码
  5:       
  6:     // PoolChunkList 之间的双向链表，初始化
  7: 
  8:     q100 = new PoolChunkList<T>(this, null, 100, Integer.MAX_VALUE, chunkSize);
  9:     q075 = new PoolChunkList<T>(this, q100, 75, 100, chunkSize);
 10:     q050 = new PoolChunkList<T>(this, q075, 50, 100, chunkSize);
 11:     q025 = new PoolChunkList<T>(this, q050, 25, 75, chunkSize);
 12:     q000 = new PoolChunkList<T>(this, q025, 1, 50, chunkSize);
 13:     qInit = new PoolChunkList<T>(this, q000, Integer.MIN_VALUE, 25, chunkSize);
 14:     
 15:     q100.prevList(q075);
 16:     q075.prevList(q050);
 17:     q050.prevList(q025);
 18:     q025.prevList(q000);
 19:     q000.prevList(null); // 无前置节点
 20:     qInit.prevList(qInit); // 前置节点为自己
 21:     
 22:     // 创建 PoolChunkListMetric 数组
 23:     List<PoolChunkListMetric> metrics = new ArrayList<PoolChunkListMetric>(6);
 24:     metrics.add(qInit);
 25:     metrics.add(q000);
 26:     metrics.add(q025);
 27:     metrics.add(q050);
 28:     metrics.add(q075);
 29:     metrics.add(q100);
 30:     chunkListMetrics = Collections.unmodifiableList(metrics);
 31: }

```

- PoolChunkList 之间的双向链表有 `qInit`、`q000`、`q025`、`q050`、`q075`、`q100` 有 6 个节点，在【第 6 至 20 行】的代码，进行**初始化**。链表如下：

  ```
  // 正向
  qInit -> q000 -> q025 -> q050 -> q075 -> q100 -> null
  
  // 逆向
  null <- q000 <- q025 <- q050 <- q075 <- q100
  qInit <- qInit
  
  ```

  - 比较神奇的是，

    ```
    qInit
    
    ```

     

    指向自己？！

    ```
    qInit
    
    ```

     

    用途是，新创建的 Chunk 内存块

     

    ```
    chunk_new
    
    ```

    ( 这只是个代号，方便描述 ) ，添加到

     

    ```
    qInit
    
    ```

     

    后，不会被释放掉。

    - 为什么不会被释放掉？`qInit.minUsage = Integer.MIN_VALUE` ，所以在 `PoolChunkList#move(PoolChunk chunk)` 方法中，`chunk_new` 的内存使用率最小值为 0 ，所以肯定不会被释放。
    - 那岂不是 `chunk_new` 无法被释放？随着 `chunk_new` 逐渐分配内存，内存使用率到达 25 ( `qInit.maxUsage` )后，会移动到 `q000` 。再随着 `chunk_new` 逐渐释放内存，内存使用率降到 0 (`q000.minUsage`) 后，就可以被释放。

  - 当然，如果新创建的 Chunk 内存块 `chunk_new` **第一次**分配的内存使用率超过 25 ( `qInit.maxUsage` )，不会进入 `qInit`中，而是进入后面的 PoolChunkList 节点。

- `chunkListMetrics` 属性，PoolChunkListMetric 数组。在【第 22 至 30 行】的代码，进行**初始化**。

# 666. 彩蛋

PoolChunList 相比 PoolSubpage 来说，又又又更加简单啦。

老艿艿整理了下 Arena、ChunkList、Chunk、Page、Subpage 的“操纵”关系如下图：

![PoolSubpage](http://static2.iocoder.cn/images/Netty/2018_09_10/02.png)

- 当然，这不是一幅严谨的图，仅仅表达“操纵”的关系。

参考如下文章：

- Hypercube [《自顶向下深入分析Netty（十）–PoolChunkList》](https://www.jianshu.com/p/2b8375df2d1a)
- 占小狼 [《深入浅出Netty内存管理 PoolChunkList》](https://www.jianshu.com/p/4856bd30dd56)

# Buffer 之 Jemalloc（五）PoolArena



# 1. 概述

在应用程序里，我们可以使用 PooledByteBufAllocator 来创建 ByteBuf 对象。代码如下：

```
PooledByteBufAllocator.DEFAULT.buffer(1024);
```

- 在方法的内部实现，通过 PoolArena 来进行内存分配。

下面，就让我们来看看 PoolArena 具体的代码实现。

> FROM [《自顶向下深入分析Netty（十）–JEMalloc分配算法》](https://www.jianshu.com/p/15304cd63175)
>
> 为了提高内存分配效率并减少内部碎片，Jemalloc 算法将 Arena 切分为小块 Chunk，根据每块的内存使用率又将小块组合为以下几种状态：QINIT、Q00、Q25、Q50、Q75、Q100 。Chunk 块可以在这几种状态间随着内存使用率的变化进行转移，从而提高分配效率。

# 2. PoolArena

`io.netty.buffer.PoolArena` ，实现 PoolArenaMetric 接口，Netty 对 Jemalloc Arena 的抽象实现类。

PoolArena 有两个子类实现：

- HeapArena ，对 Heap 类型的内存分配。
- DirectArena ，对 Direct 类型的内存分配。

## 2.1 构造方法

```
/**
 * 是否支持 Unsafe 操作
 */
static final boolean HAS_UNSAFE = PlatformDependent.hasUnsafe();

/**
 * 内存分类
 */
enum SizeClass {
    Tiny,
    Small,
    Normal

    // 还有一个隐藏的，Huge
}

/**
 * {@link #tinySubpagePools} 数组的大小
 *
 * 默认为 32
 */
static final int numTinySubpagePools = 512 >>> 4;

/**
 * 所属 PooledByteBufAllocator 对象
 */
final PooledByteBufAllocator parent;

/**
 * 满二叉树的高度。默认为 11 。
 */
private final int maxOrder;
/**
 * Page 大小，默认 8KB = 8192B
 */
final int pageSize;
/**
 * 从 1 开始左移到 {@link #pageSize} 的位数。默认 13 ，1 << 13 = 8192 。
 */
final int pageShifts;
/**
 * Chunk 内存块占用大小。默认为 16M = 16 * 1024  。
 */
final int chunkSize;
/**
 * 判断分配请求内存是否为 Tiny/Small ，即分配 Subpage 内存块。
 *
 * Used to determine if the requested capacity is equal to or greater than pageSize.
 */
final int subpageOverflowMask;

/**
 * {@link #smallSubpagePools} 数组的大小
 *
 * 默认为 23
 */
final int numSmallSubpagePools;

/**
 * 对齐基准
 */
final int directMemoryCacheAlignment;
/**
 * {@link #directMemoryCacheAlignment} 掩码
 */
final int directMemoryCacheAlignmentMask;

/**
 * tiny 类型的 PoolSubpage 数组
 *
 * 数组的每个元素，都是双向链表
 */
private final PoolSubpage<T>[] tinySubpagePools;
/**
 * small 类型的 SubpagePools 数组
 *
 * 数组的每个元素，都是双向链表
 */
private final PoolSubpage<T>[] smallSubpagePools;

// PoolChunkList 之间的双向链表

private final PoolChunkList<T> q050;
private final PoolChunkList<T> q025;
private final PoolChunkList<T> q000;
private final PoolChunkList<T> qInit;
private final PoolChunkList<T> q075;
private final PoolChunkList<T> q100;

/**
 * PoolChunkListMetric 数组
 */
private final List<PoolChunkListMetric> chunkListMetrics;

// Metrics for allocations and deallocations
/**
 * 分配 Normal 内存块的次数
 */
private long allocationsNormal;
// We need to use the LongCounter here as this is not guarded via synchronized block.
/**
 * 分配 Tiny 内存块的次数
 */
private final LongCounter allocationsTiny = PlatformDependent.newLongCounter();
/**
 * 分配 Small 内存块的次数
 */
private final LongCounter allocationsSmall = PlatformDependent.newLongCounter();
/**
 * 分配 Huge 内存块的次数
 */
private final LongCounter allocationsHuge = PlatformDependent.newLongCounter();
/**
 * 正在使用中的 Huge 内存块的总共占用字节数
 */
private final LongCounter activeBytesHuge = PlatformDependent.newLongCounter();

/**
 * 释放 Tiny 内存块的次数
 */
private long deallocationsTiny;
/**
 * 释放 Small 内存块的次数
 */
private long deallocationsSmall;
/**
 * 释放 Normal 内存块的次数
 */
private long deallocationsNormal;

/**
 * 释放 Huge 内存块的次数
 */
// We need to use the LongCounter here as this is not guarded via synchronized block.
private final LongCounter deallocationsHuge = PlatformDependent.newLongCounter();

/**
 * 该 PoolArena 被多少线程引用的计数器
 */
// Number of thread caches backed by this arena.
final AtomicInteger numThreadCaches = new AtomicInteger();

  1: protected PoolArena(PooledByteBufAllocator parent, int pageSize,
  2:       int maxOrder, int pageShifts, int chunkSize, int cacheAlignment) {
  3:     this.parent = parent;
  4:     this.pageSize = pageSize;
  5:     this.maxOrder = maxOrder;
  6:     this.pageShifts = pageShifts;
  7:     this.chunkSize = chunkSize;
  8:     directMemoryCacheAlignment = cacheAlignment;
  9:     directMemoryCacheAlignmentMask = cacheAlignment - 1;
 10:     subpageOverflowMask = ~(pageSize - 1);
 11: 
 12:     // 初始化 tinySubpagePools 数组
 13:     tinySubpagePools = newSubpagePoolArray(numTinySubpagePools);
 14:     for (int i = 0; i < tinySubpagePools.length; i ++) {
 15:         tinySubpagePools[i] = newSubpagePoolHead(pageSize);
 16:     }
 17: 
 18:     // 初始化 smallSubpagePools 数组
 19:     numSmallSubpagePools = pageShifts - 9;
 20:     smallSubpagePools = newSubpagePoolArray(numSmallSubpagePools);
 21:     for (int i = 0; i < smallSubpagePools.length; i ++) {
 22:         smallSubpagePools[i] = newSubpagePoolHead(pageSize);
 23:     }
 24: 
 25:     // PoolChunkList 之间的双向链表，初始化
 26: 
 27:     q100 = new PoolChunkList<T>(this, null, 100, Integer.MAX_VALUE, chunkSize);
 28:     q075 = new PoolChunkList<T>(this, q100, 75, 100, chunkSize);
 29:     q050 = new PoolChunkList<T>(this, q075, 50, 100, chunkSize);
 30:     q025 = new PoolChunkList<T>(this, q050, 25, 75, chunkSize);
 31:     q000 = new PoolChunkList<T>(this, q025, 1, 50, chunkSize);
 32:     qInit = new PoolChunkList<T>(this, q000, Integer.MIN_VALUE, 25, chunkSize);
 33: 
 34:     q100.prevList(q075);
 35:     q075.prevList(q050);
 36:     q050.prevList(q025);
 37:     q025.prevList(q000);
 38:     q000.prevList(null); // 无前置节点
 39:     qInit.prevList(qInit); // 前置节点为自己
 40: 
 41:     // 创建 PoolChunkListMetric 数组
 42:     List<PoolChunkListMetric> metrics = new ArrayList<PoolChunkListMetric>(6);
 43:     metrics.add(qInit);
 44:     metrics.add(q000);
 45:     metrics.add(q025);
 46:     metrics.add(q050);
 47:     metrics.add(q075);
 48:     metrics.add(q100);
 49:     chunkListMetrics = Collections.unmodifiableList(metrics);
 50: }
```

- 虽然属性比较多，但是内部主要还是以 PoolSubpage 和 PoolChunkList 对象为主。如下图所示：

  > FROM [《深入浅出Netty内存管理 PoolArena》](https://www.jianshu.com/p/4856bd30dd56)
  >
  > ![大体结构](http://static2.iocoder.cn/images/Netty/2018_09_13/01.png)

- SizeClass **枚举类**，内存分类，一共有四种：Tiny、Small、Normal、Huge 。如下图所示：![内存分配](http://static2.iocoder.cn/images/Netty/2018_09_13/02.png)

- `parent` 属性，所属 PooledByteBufAllocator 对象。

- 内存属性相关

  - `HAS_UNSAFE` **静态**属性，是否支持 Unsafe 操作。
  - `directMemoryCacheAlignment` 属性，对齐基准，默认为 0 。😈 实际可以忽略哈。
  - `directMemoryCacheAlignmentMask` 属性，`directMemoryCacheAlignment` 的掩码，默认为 -1( 【第 9 行】的代码 `directMemoryCacheAlignment - 1` )。😈 实际可以忽略哈。

- PoolChunk 属性相关，`maxOrder`、`pageSize`、`pageShifts`、`chunkSize`、`subpageOverflowMask` 。已经在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk) 。

- PoolSubpage 属性相关

  - ```
    tinySubpagePools
    ```

     

    属性，tiny 类型的 PoolSubpage 数组。数组的每个元素，都是

    双向链表

    。

    - 在【第 12 至 16 行】的代码，进行初始化。
    - `numTinySubpagePools` **静态**属性，数组大小。默认为 32 。

  - ```
    smallSubpagePools
    ```

     

    属性，small 类型的 SubpagePools 数组。数组的每个元素，都是

    双向链表

    。

    - 在【第 18 至 23 行】的代码，进行初始化。
    - `numSmallSubpagePools` 属性，数组大小。默认为 23( `numTinySubpagePools - 9` )。

- PoolChunkList 属性相关，`qInit`、`q025`、`q050`、`q075`、`q100`、`chunkListMetrics` 。已经在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（四）PoolChunkList》](http://svip.iocoder.cn/Netty/Netty/ByteBuf-3-4-Jemalloc-chunkList) 。

- PoolArenaMetric 属性相关

  - 分配 *XXX* 内存块的次数的属性：`allocationsNormal`、`allocationsTiny`、`allocationsSmall`、`allocationsHuge`。
  - 释放 *XXX* 内存块的次数的属性：`deallocationsTiny`、`deallocationsSmall`、`deallocationsNormal`、`deallocationsHuge` 。
  - ↑↑↑ 上述属性使用 LongCounter 还是 `long` 类型，主要是变量访问时，是否在 `synchronized {}` 代码块中访问，从而保证**内存的可见性**。
  - `activeBytesHuge` 属性，**正在使用中**的 Huge 内存块的总共占用字节数。
  - `numThreadCaches` 属性，该 PoolArena 被多少线程引用的计数器。

- 😈 构造方法，简单看看就好，基本上面都已经提到了。

## 2.2 容量相关方法

### 2.2.1 normalizeCapacity

`#normalizeCapacity(int reqCapacity)` 方法，标准化请求分配的内存大小。通过这样的方式，**保证分配的内存块统一**。代码如下：

```
 1: int normalizeCapacity(int reqCapacity) {
 2:     if (reqCapacity < 0) {
 3:         throw new IllegalArgumentException("capacity: " + reqCapacity + " (expected: 0+)");
 4:     }
 5: 
 6:     // Huge 内存类型，直接使用 reqCapacity ，无需进行标准化。
 7:     if (reqCapacity >= chunkSize) {
 8:         return directMemoryCacheAlignment == 0 ? reqCapacity : alignCapacity(reqCapacity);
 9:     }
10: 
11:     // 非 tiny 内存类型
12:     if (!isTiny(reqCapacity)) { // >= 512
13:         // Doubled
14:         // 转换成接近于两倍的容量
15:         int normalizedCapacity = reqCapacity;
16:         normalizedCapacity --;
17:         normalizedCapacity |= normalizedCapacity >>>  1;
18:         normalizedCapacity |= normalizedCapacity >>>  2;
19:         normalizedCapacity |= normalizedCapacity >>>  4;
20:         normalizedCapacity |= normalizedCapacity >>>  8;
21:         normalizedCapacity |= normalizedCapacity >>> 16;
22:         normalizedCapacity ++;
23:         if (normalizedCapacity < 0) {
24:             normalizedCapacity >>>= 1;
25:         }
26:         assert directMemoryCacheAlignment == 0 || (normalizedCapacity & directMemoryCacheAlignmentMask) == 0;
27: 
28:         return normalizedCapacity;
29:     }
30: 
31:     if (directMemoryCacheAlignment > 0) {
32:         return alignCapacity(reqCapacity);
33:     }
34: 
35:     // 补齐成 16 的倍数
36:     // Quantum-spaced
37:     if ((reqCapacity & 15) == 0) {
38:         return reqCapacity;
39:     }
40:     return (reqCapacity & ~15) + 16;
41: }
```

- 第 6 至 9 行：**Huge** 内存类型，直接使用 reqCapacity ，无需进行标准化。
- 第 11 至 29 行：**Small**、**Normal** 内存类型，转换成接近于**两倍**的容量。
- 第 35 至 40 行：**Tiny** 内存类型，补齐成 **16** 的倍数。

总结来说，还是下图：![内存容量](http://static2.iocoder.cn/images/Netty/2018_09_13/03.png)

### 2.2.2 alignCapacity

`#alignCapacity(int reqCapacity)` 方法，对齐请求分配的内存大小。代码如下：

```
int alignCapacity(int reqCapacity) {
    // 获得 delta
    int delta = reqCapacity & directMemoryCacheAlignmentMask;
    // 补齐 directMemoryCacheAlignment ，并减去 delta
    return delta == 0 ? reqCapacity : reqCapacity + directMemoryCacheAlignment - delta;
}
```

### 2.2.3 isTinyOrSmall

`#isTinyOrSmall(int normCapacity)` 方法，判断请求分配的内存类型是否为 tiny 或 small 类型。代码如下：

```
// capacity < pageSize
boolean isTinyOrSmall(int normCapacity) {
    return (normCapacity & subpageOverflowMask) == 0;
}
```

### 2.2.4 isTiny

`#isTiny(int normCapacity)` 方法，判断请求分配的内存类型是否为 tiny 类型。代码如下：

```
// normCapacity < 512
static boolean isTiny(int normCapacity) {
    return (normCapacity & 0xFFFFFE00) == 0;
}
```

### 2.2.5 tinyIdx

`#tinyIdx(int normCapacity)` **静态**方法，计算请求分配的内存大小在 `tinySubpagePools` 数组的下标。代码如下：

```
static int tinyIdx(int normCapacity) {
    return normCapacity >>> 4;
}
```

### 2.2.6 smallIdx

`#smallIdx(int normCapacity)` **静态**方法，计算请求分配的内存大小在 `smallSubpagePools` 数组的下标。代码如下：

```
static int smallIdx(int normCapacity) {
    int tableIdx = 0;
    int i = normCapacity >>> 10;
    while (i != 0) {
        i >>>= 1;
        tableIdx ++;
    }
    return tableIdx;
}
```

### 2.2.7 sizeClass

`#sizeClass(int normCapacity)` 方法，计算请求分配的内存的内存类型。代码如下：

```
private SizeClass sizeClass(int normCapacity) {
    if (!isTinyOrSmall(normCapacity)) {
        return SizeClass.Normal;
    }
    return isTiny(normCapacity) ? SizeClass.Tiny : SizeClass.Small;
}
```

## 2.3 findSubpagePoolHead

`#findSubpagePoolHead(int elemSize)` 方法，获得请求分配的 Subpage 类型的内存的链表的**头节点**。代码如下：

```
PoolSubpage<T> findSubpagePoolHead(int elemSize) {
    int tableIdx;
    PoolSubpage<T>[] table;
    if (isTiny(elemSize)) { // < 512
        // 实际上，就是 `#tinyIdx(int normCapacity)` 方法
        tableIdx = elemSize >>> 4;
        // 获得 table
        table = tinySubpagePools;
    } else {
        // 实际上，就是 `#smallIdx(int normCapacity)` 方法
        tableIdx = 0;
        elemSize >>>= 10;
        while (elemSize != 0) {
            elemSize >>>= 1;
            tableIdx ++;
        }
        // 获得 table
        table = smallSubpagePools;
    }

    // 获得 Subpage 链表的头节点
    return table[tableIdx];
}
```

## 2.4 allocate

PoolArena 根据申请分配的内存大小不同，提供了**两种**方式分配内存：

- 1、PoolSubpage ，用于分配

  小于

   

  ```
  8KB
  ```

   

  的内存块

  - 1.1 `tinySubpagePools` 属性，用于分配小于 `512B` 的 tiny **Subpage** 内存块。
  - 1.2 `smallSubpagePools` 属性，用于分配小于 `8KB` 的 small **Subpage** 内存块。

- 2、PoolChunkList ，用于分配

  大于等于

   

  ```
  8KB
  ```

   

  的内存块

  - 2.1 小于 `32MB` ，分配 normal 内存块，即一个 Chunk 中的 **Page** 内存块。
  - 2.2 大于等于 `32MB` ，分配 huge 内存块，即一整个 **Chunk** 内存块。

------

`#allocate(PoolThreadCache cache, int reqCapacity, int maxCapacity)` 方法，创建 PooledByteBuf 对象，并分配内存块给 PooledByteBuf 对象。代码如下：

```
 1: private void allocate(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity) {
 2:     // 标准化请求分配的容量
 3:     final int normCapacity = normalizeCapacity(reqCapacity);
 4:     // PoolSubpage 的情况
 5:     if (isTinyOrSmall(normCapacity)) { // capacity < pageSize
 6:         int tableIdx;
 7:         PoolSubpage<T>[] table;
 8:         // 判断是否为 tiny 类型的内存块申请
 9:         boolean tiny = isTiny(normCapacity);
10:         if (tiny) { // < 512 tiny 类型的内存块申请
11:             // 从 PoolThreadCache 缓存中，分配 tiny 内存块，并初始化到 PooledByteBuf 中。
12:             if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) {
13:                 // was able to allocate out of the cache so move on
14:                 return;
15:             }
16:             // 获得 tableIdx 和 table 属性
17:             tableIdx = tinyIdx(normCapacity);
18:             table = tinySubpagePools;
19:         } else {
20:             // 从 PoolThreadCache 缓存中，分配 small 内存块，并初始化到 PooledByteBuf 中。
21:             if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) {
22:                 // was able to allocate out of the cache so move on
23:                 return;
24:             }
25:             // 获得 tableIdx 和 table 属性
26:             tableIdx = smallIdx(normCapacity);
27:             table = smallSubpagePools;
28:         }
29: 
30:         // 获得 PoolSubpage 链表的头节点
31:         final PoolSubpage<T> head = table[tableIdx];
32: 
33:         // 从 PoolSubpage 链表中，分配 Subpage 内存块
34:         /**
35:          * Synchronize on the head. This is needed as {@link PoolChunk#allocateSubpage(int)} and
36:          * {@link PoolChunk#free(long)} may modify the doubly linked list as well.
37:          */
38:         synchronized (head) { // 同步 head ，避免并发问题
39:             final PoolSubpage<T> s = head.next;
40:             if (s != head) {
41:                 assert s.doNotDestroy && s.elemSize == normCapacity;
42:                 // 分配 Subpage 内存块
43:                 long handle = s.allocate();
44:                 assert handle >= 0;
45:                 // 初始化 Subpage 内存块到 PooledByteBuf 对象中
46:                 s.chunk.initBufWithSubpage(buf, handle, reqCapacity);
47:                 // 增加 allocationsTiny 或 allocationsSmall 计数
48:                 incTinySmallAllocation(tiny);
49:                 // 返回，因为已经分配成功
50:                 return;
51:             }
52:         }
53:         // 申请 Normal Page 内存块。实际上，只占用其中一块 Subpage 内存块。
54:         synchronized (this) { // 同步 arena ，避免并发问题
55:             allocateNormal(buf, reqCapacity, normCapacity);
56:         }
57:         // 增加 allocationsTiny 或 allocationsSmall 计数
58:         incTinySmallAllocation(tiny);
59:         // 返回，因为已经分配成功
60:         return;
61:     }
62:     if (normCapacity <= chunkSize) {
63:         // 从 PoolThreadCache 缓存中，分配 normal 内存块，并初始化到 PooledByteBuf 中。
64:         if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) {
65:             // was able to allocate out of the cache so move on
66:             return;
67:         }
68:         // 申请 Normal Page 内存块
69:         synchronized (this) { // 同步 arena ，避免并发问题
70:             allocateNormal(buf, reqCapacity, normCapacity);
71:             // 增加 allocationsNormal
72:             ++allocationsNormal;
73:         }
74:     } else {
75:         // 申请 Huge Page 内存块
76:         // Huge allocations are never served via the cache so just call allocateHuge
77:         allocateHuge(buf, reqCapacity);
78:     }
79: }
```

- 第 3 行：调用 `#normalizeCapacity(int reqCapacity)` 方法，标准化请求分配的内存大小。

- 第 5 至 61 行：上述“1、PoolSubpage ，用于分配小于 8KB 的内存块”。

  - 第 5 行：调用

     

    ```
    #isTinyOrSmall(int normCapacity)
    ```

     

    方法，判断请求分配的内存类型是否为 tiny 或 small 类型。

    - 第 9 行：调用 `#isTiny(int normCapacity)` 方法，判断请求分配的内存类型是否为 tiny 类型。

  - 第 10 至 31 行：获得 PoolSubpage 链表的头节点。从实现上，和

     

    「2.3 findSubpagePoolHead」

     

    功能上是一致的。

    - 第 11 至 15 行：调用 `PoolThreadCache#allocateTiny(this, buf, reqCapacity, normCapacity)` 方法，从 PoolThreadCache 缓存中，分配 tiny 内存块，并初始化到 PooledByteBuf 中。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache》](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache) 中。
    - 第 20 至 24 行：调用 `PoolThreadCache#allocateSmall(this, buf, reqCapacity, normCapacity)` 方法，从 PoolThreadCache 缓存中，分配 small 内存块，并初始化到 PooledByteBuf 中。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache》](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache) 中。

  - 第 33 至 52 行：从 PoolSubpage 链表中，分配 Subpage 内存块。

    - 第 43 行：调用 `head.next` 节点的 `PoolSubpage#allocate()` 方法，分配一个 Subpage 内存块，并返回该内存块的位置 `handle` 。如果遗忘这个过程的胖友，可以看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（三）PoolSubpage》](http://svip.iocoder.cn/Netty/ByteBuf-3-3-Jemalloc-subpage) 的 [「2.4 allocate」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。
    - 第 46 行：调用 `PoolChunk#initBufWithSubpage(buf, handle, reqCapacity)` 方法，初始化 Subpage 内存块到 PooledByteBuf 对象中。如果遗忘这个过程的胖友，可以看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》](http://svip.iocoder.cn/Netty/ByteBuf-3-2-Jemalloc-chunk)的 [「2.5.1 initBufWithSubpage」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。
    - 第 48 行：调用 `#incTinySmallAllocation(boolean tiny)` 方法，增加 `allocationsTiny` 或 `allocationsSmall` 计数。详细解析，见 [「2.8.1 incTinySmallAllocation」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。
    - 第 50 行：`return` 返回，因为已经分配成功。

  - 第 53 至 60 行：在 PoolSubpage 链表中，分配不到 Subpage 内存块，所以申请 Normal Page 内存块。实际上，只占用其中一块 Subpage 内存块。

    - 第 53 至 56 行：调用 `#allocateNormal(PooledByteBuf<T> buf, int reqCapacity, int normCapacity)` 方法，申请 Normal Page 内存块。详细解析，见 [「2.4.1 allocateNormal」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。

- 第 62 至 73 行：上述“2.1 小于 `32MB` ，分配 normal 内存块，即一个 Chunk 中的 **Page** 内存块”。

  - 第 62 行：通过 `normCapacity <= chunkSize` 判断，判断请求分配的内存类型是否为 normal 类型。
  - 第 63 至 67 行：调用 `PoolThreadCache#allocateNormal(this, buf, reqCapacity, normCapacity)` 方法，从 PoolThreadCache 缓存中，分配 normal 内存块，并初始化到 PooledByteBuf 中。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache》](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache) 中。
  - 第 68 至 70 行：同【第 53 至 56 行】的代码。
  - 第 72 行：增加 `allocationsNormal` 。

- 第 74 至 78 行：上述“2.2 大于等于

   

  ```
  32MB
  
  ```

   

  ，分配 huge 内存块，即一整个

   

  Chunk

   

  内存块。”

  - 第 77 行：调用 `#allocateHuge(PooledByteBuf<T> buf, int reqCapacity)` 方法，申请 Huge 内存块。

### 2.4.1 allocateNormal

`#allocateNormal(PooledByteBuf<T> buf, int reqCapacity, int normCapacity)` 方法，申请 Normal Page 内存块。代码如下：

```
   // Method must be called inside synchronized(this) { ... } block // 必须在 synchronized(this) { ... } 中执行
 1: private void allocateNormal(PooledByteBuf<T> buf, int reqCapacity, int normCapacity) {
 2:     // 按照优先级，从多个 ChunkList 中，分配 Normal Page 内存块。如果有一分配成功，返回
 3:     if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) ||
 4:         q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) ||
 5:         q075.allocate(buf, reqCapacity, normCapacity)) {
 6:         return;
 7:     }
 8: 
 9:     // Add a new chunk.
10:     // 新建 Chunk 内存块
11:     PoolChunk<T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize);
12:     // 申请对应的 Normal Page 内存块。实际上，如果申请分配的内存类型为 tiny 或 small 类型，实际申请的是 Subpage 内存块。
13:     long handle = c.allocate(normCapacity);
14:     assert handle > 0;
15:     // 初始化 Normal Page / Subpage 内存块到 PooledByteBuf 对象中
16:     c.initBuf(buf, handle, reqCapacity);
17:     // 添加到 ChunkList 双向链中。
18:     qInit.add(c);
19: }

```

- 按照优先级，从多个 ChunkList 中，调用 `PoolChunkList#allocate(normCapacity)` 方法，分配 Normal Page 内存块。如果有一分配成功，`return` 返回。如果遗忘这个过程的胖友，可以看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（四）PoolChunkList》](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList) 的 [「2.2 allocate」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。

  > FROM [《深入浅出Netty内存管理 PoolArena》](https://www.jianshu.com/p/4856bd30dd56)
  >
  > 分配内存时，为什么不从内存使用率较低的 `q000` 开始？在 ChunkList 中，我们知道一个 chunk 随着内存的释放，会往当前 ChunkList 的前一个节点移动。
  >
  > **q000 存在的目的是什么？**
  >
  > `q000` 是用来保存内存利用率在 `1%-50%` 的 chunk ，那么这里为什么不包括 `0%` 的chunk？
  > 直接弄清楚这些，才好理解为什么不从 `q000` 开始分配。`q000 中的chunk，当内存利用率为 0 时，就从链表中删除，直接释放物理内存，避免越来越多的 chunk 导致内存被占满。
  >
  > 想象一个场景，当应用在实际运行过程中，碰到访问高峰，这时需要分配的内存是平时的好几倍，当然也需要创建好几倍的 chunk ，如果先从 `q0000` 开始，这些在高峰期创建的 chunk 被回收的概率会大大降低，延缓了内存的回收进度，造成内存使用的浪费。
  >
  > **那么为什么选择从 q050 开始？**
  >
  > - 1、`q050` 保存的是内存利用率 `50%~100%` 的 chunk ，这应该是个折中的选择！这样大部分情况下，chunk 的利用率都会保持在一个较高水平，提高整个应用的内存利用率；
  > - 2、`qinit` 的 chunk 利用率低，但不会被回收；
  > - 3、`q075` 和 `q100` 由于内存利用率太高，导致内存分配的成功率大大降低，因此放到最后；

- 第 11 行：调用 `#newChunk(pageSize, maxOrder, pageShifts, chunkSize)` **抽象**方法，新建 Chunk 内存块。需要 PoolArea 子类实现该方法，代码如下：

  ```
  protected abstract PoolChunk<T> newChunk(int pageSize, int maxOrder, int pageShifts, int chunkSize);
  
  ```

  - 第 13 行：调用新申请的 Chunk 内存块的

     

    ```
    PoolChunk#allocate(normCapacity)
    
    ```

     

    方法，申请对应的 Normal Page 内存块。实际上，如果申请分配的内存类型为 tiny 或 small 类型，实际申请的是 Subpage 内存块。如果遗忘这个过程的胖友，可以看看

     

    《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（二）PoolChunk》

     

    的

     

    「2.2 allocate」

     

    。

    - 第 16 行：调用 `PoolChunk#initBuf(buf, handle, reqCapacity)` 方法，初始化 Normal Page / Subpage 内存块到 PooledByteBuf 对象中。

  - 第 18 行：调用 `PoolChunkList#add(PoolChunk)` 方法，添加到 ChunkList 双向链中。

### 2.4.2 allocateHuge

`#allocateHuge(PooledByteBuf<T> buf, int reqCapacity)` 方法，申请 Huge 内存块。

```
 1: private void allocateHuge(PooledByteBuf<T> buf, int reqCapacity) {
 2:     // 新建 Chunk 内存块，它是 unpooled 的
 3:     PoolChunk<T> chunk = newUnpooledChunk(reqCapacity);
 4:     // 增加 activeBytesHuge
 5:     activeBytesHuge.add(chunk.chunkSize());
 6:     // 初始化 Huge 内存块到 PooledByteBuf 对象中
 7:     buf.initUnpooled(chunk, reqCapacity);
 8:     // 增加 allocationsHuge
 9:     allocationsHuge.increment();
10: }

```

- 第 3 行：调用 `#newUnpooledChunk(int capacity)` **抽象**方法，新建 **unpooled** Chunk 内存块。需要 PoolArea 子类实现该方法，代码如下：

  ```
  protected abstract PoolChunk<T> newUnpooledChunk(int capacity); //
  
  ```

- 第 7 行：调用 `PoolChunk#initUnpooled(chunk, reqCapacity)` 方法，初始化 Huge 内存块到 PooledByteBuf 对象中。

- 第 5 行：增加 `activeBytesHuge` 计数。

- 第 9 行：增加 `allocationsHuge` 计数。

## 2.5 reallocate

`#reallocate(PooledByteBuf<T> buf, int newCapacity, boolean freeOldMemor)` 方法，因为要扩容或缩容，所以重新分配合适的内存块给 PooledByteBuf 对象。代码如下：

```
 1: void reallocate(PooledByteBuf<T> buf, int newCapacity, boolean freeOldMemory) {
 2:     if (newCapacity < 0 || newCapacity > buf.maxCapacity()) {
 3:         throw new IllegalArgumentException("newCapacity: " + newCapacity);
 4:     }
 5: 
 6:     // 容量大小没有变化，直接返回
 7:     int oldCapacity = buf.length;
 8:     if (oldCapacity == newCapacity) {
 9:         return;
10:     }
11: 
12:     // 记录老的内存块的信息
13:     PoolChunk<T> oldChunk = buf.chunk;
14:     long oldHandle = buf.handle;
15:     T oldMemory = buf.memory;
16:     int oldOffset = buf.offset;
17:     int oldMaxLength = buf.maxLength;
18: 
19:     // 记录读写索引
20:     int readerIndex = buf.readerIndex();
21:     int writerIndex = buf.writerIndex();
22: 
23:     // 分配新的内存块给 PooledByteBuf 对象
24:     allocate(parent.threadCache(), buf, newCapacity);
25: 
26:     // 扩容
27:     if (newCapacity > oldCapacity) {
28:         // 将老的内存块的数据，复制到新的内存块中
29:         memoryCopy(
30:                 oldMemory, oldOffset,
31:                 buf.memory, buf.offset, oldCapacity);
32:     // 缩容
33:     } else {
34:         // 有部分数据未读取完
35:         if (readerIndex < newCapacity) {
36:             // 如果 writerIndex 大于 newCapacity ，重置为 newCapacity ，避免越界
37:             if (writerIndex > newCapacity) {
38:                 writerIndex = newCapacity;
39:             }
40:             // 将老的内存块的数据，复制到新的内存块中
41:             memoryCopy(
42:                     oldMemory, oldOffset + readerIndex,
43:                     buf.memory, buf.offset + readerIndex, writerIndex - readerIndex);
44:         // 全部读完，重置 readerIndex 和 writerIndex 为 newCapacity ，避免越界
45:         } else {
46:             readerIndex = writerIndex = newCapacity;
47:         }
48:     }
49: 
50:     // 设置读写索引
51:     buf.setIndex(readerIndex, writerIndex);
52: 
53:     // 释放老的内存块
54:     if (freeOldMemory) {
55:         free(oldChunk, oldHandle, oldMaxLength, buf.cache);
56:     }
57: }

```

- 第 2 至 4 行：新的容量( `newCapacity` ) ，不能**超过** PooledByteBuf 对象的可分配的最大容量( `maxCapacity` ) 。

- 第 6 至 10 行：容量大小没有变化，直接返回。

- 第 12 至 17 行：记录

  老的

  内存块的信息。

  - 第 20 至 21 行：记录读写索引。

- 第 26 至 31 行：容量变大，说明是扩容，调用 `#memoryCopy(T src, int srcOffset, T dst, int dstOffset, int length)` **抽象**方法，将老的内存块的数据( 此处的复制，是全部数据 )，**复制到新的内存块中**。需要 PoolArea 子类实现该方法，代码如下：

  ```
  protected abstract void memoryCopy(T src, int srcOffset, T dst, int dstOffset, int length);
  
  ```

- 第 33 至 48 行：容量变小，说明是缩容。

  - 第 34 至 44 行：有

    部分

    数据

    未读取完

    ，调用

     

    ```
    #memoryCopy(T src, int srcOffset, T dst, int dstOffset, int length)
    
    ```

     

    抽象

    方法，将老的内存块的数据( 此处的复制，是全部数据 )，复制到新的内存块中。😈 注意，

    此处复制的只有未读取完的部分数据

    。

    - 第 36 至 39 行：如果 `writerIndex` 大于 `newCapacity` ，重置为 `newCapacity` ，避免越界。

  - 第 44 至 47 行：全部读完，

    无需复制

    。

    - 第 46 行: 全部读完，重置 `readerIndex` 和 `writerIndex` 为 `newCapacity` ，避免越界。

- 第 51 行：设置读写索引。

- 第 53 至 56 行：如果需要释放老的内存块( `freeOldMemory` 为 `true` ) 时，调用 `#free(PoolChunk<T> chunk, long handle, int normCapacity, PoolThreadCache cache)` 方法，进行释放。详细解析，见 [「2.6 free」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。

## 2.6 free

`#free(PoolChunk<T> chunk, long handle, int normCapacity, PoolThreadCache cache)` 方法，释放内存块。代码如下：

```
 1: void free(PoolChunk<T> chunk, long handle, int normCapacity, PoolThreadCache cache) {
 2:     if (chunk.unpooled) {
 3:         int size = chunk.chunkSize();
 4:         // 直接销毁 Chunk 内存块，因为占用空间较大
 5:         destroyChunk(chunk);
 6:         // 减少 activeBytesHuge 计数
 7:         activeBytesHuge.add(-size);
 8:         // 减少 deallocationsHuge 计数
 9:         deallocationsHuge.increment();
10:     } else {
11:         // 计算内存的 SizeClass
12:         SizeClass sizeClass = sizeClass(normCapacity);
13:         // 添加内存块到 PoolThreadCache 缓存
14:         if (cache != null && cache.add(this, chunk, handle, normCapacity, sizeClass)) {
15:             // cached so not free it.
16:             return;
17:         }
18:         // 释放 Page / Subpage 内存块回 Chunk 中
19:         freeChunk(chunk, handle, sizeClass);
20:     }
21: }

```

- 第 2 至 9 行：

  unpooled

   

  类型的 Chunk 对象，目前是 Huge 内存块。

  - 第 5 行：调用 `#destroyChunk(PoolChunk<T> chunk)` 方法，直接销毁 Chunk 内存块，因为占用空间较大。详细解析，见 [「2.7 finalize」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。
  - 第 6 至 9 行：减少 `activeBytesHuge`、`deallocationsHuge` 计数。

- 第 10 至 20 行：

  pooled

   

  类型的 Chunk 对象，目前是 Page / Subpage 内存块。

  - 第 12 行：调用 `#size(normCapacity)` 方法，计算内存的 SizeClass 内存类型。
  - 第 12 行：计算内存的 SizeClass 。
  - 第 13 至 17 行：调用 `PoolThreadCache#add(PoolArena<?> area, PoolChunk chunk, long handle, int normCapacity, SizeClass sizeClass)` 方法，添加内存块到 PoolThreadCache 的指定 MemoryRegionCache 的队列中，进行缓存。并且，返回是否添加成功。详细解析，见 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（六）PoolThreadCache》](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/) 。
  - 第 19 行：调用 `#freeChunk(PoolChunk<T> chunk, long handle, SizeClass sizeClass)` 方法，释放指定位置的 Page / Subpage 内存块回 Chunk 中。

### 2.6.1 freeChunk

`#freeChunk(PoolChunk<T> chunk, long handle, SizeClass sizeClass)` 方法，释放指定位置的 Page / Subpage 内存块回 Chunk 中。代码如下：

```
 1: void freeChunk(PoolChunk<T> chunk, long handle, SizeClass sizeClass) {
 2:     final boolean destroyChunk;
 3:     synchronized (this) { // 锁，避免并发
 4:         // 减小相应的计数
 5:         switch (sizeClass) {
 6:         case Normal:
 7:             ++deallocationsNormal;
 8:             break;
 9:         case Small:
10:             ++deallocationsSmall;
11:             break;
12:         case Tiny:
13:             ++deallocationsTiny;
14:             break;
15:         default:
16:             throw new Error();
17:         }
18:         // 释放指定位置的内存块
19:         destroyChunk = !chunk.parent.free(chunk, handle);
20:     }
21:     // 当 destroyChunk 为 true 时，意味着 Chunk 中不存在在使用的 Page / Subpage 内存块。也就是说，内存使用率为 0 ，所以销毁 Chunk
22:     if (destroyChunk) {
23:         // destroyChunk not need to be called while holding the synchronized lock.
24:         destroyChunk(chunk);
25:     }
26: }

```

- 第 4 至 17 行：减小**相应**的计数。
- 第 19 行：调用 Chunk 对象所在的 ChunList 的 `ChunkList#free(chunk, handle)` 方法，释放指定位置的内存块。如果遗忘这个过程的胖友，可以看看 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（四）PoolChunkList》](http://svip.iocoder.cn/Netty/ByteBuf-3-4-Jemalloc-chunkList) 的 [「2.3 free」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。
- 第 21 至 25 行：当 `destroyChunk` 为 `true` 时，意味着 Chunk 中不存在在使用的 Page / Subpage 内存块。也就是说，内存使用率为 0 ，所以调用 `#destroyChunk(PoolChunk<T> chunk)` 方法，直接销毁 Chunk 内存块，回收对应的空间。详细解析，见 [「2.7 finalize」](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena/#) 。

## 2.7 finalize

在 PoolArena 对象被 GC 回收时，清理其管理的内存。😈 实际上，主要是为了清理对外内存。代码如下：

```
@Override
protected final void finalize() throws Throwable {
    try {
        // 调用父方法
        super.finalize();
    } finally {
        // 清理 tiny Subpage 们
        destroyPoolSubPages(smallSubpagePools);
        // 清理 small Subpage 们
        destroyPoolSubPages(tinySubpagePools);
        // 清理 ChunkList 们
        destroyPoolChunkLists(qInit, q000, q025, q050, q075, q100);
    }
}

private static void destroyPoolSubPages(PoolSubpage<?>[] pages) {
    for (PoolSubpage<?> page : pages) {
        page.destroy();
    }
}

private void destroyPoolChunkLists(PoolChunkList<T>... chunkLists) {
    for (PoolChunkList<T> chunkList: chunkLists) {
        chunkList.destroy(this);
    }
}

```

## 2.8 PoolArenaMetric

> 老艿艿：这个小节，主要是读取 Metric 数据的方法，快速浏览或跳过都可以。

`io.netty.buffer.PoolArenaMetric` ，PoolArena Metric 接口。代码如下：

```
public interface PoolArenaMetric {

    /**
     * Returns the number of thread caches backed by this arena.
     */
    int numThreadCaches();

    /**
     * Returns the number of tiny sub-pages for the arena.
     */
    int numTinySubpages();
    /**
     * Returns the number of small sub-pages for the arena.
     */
    int numSmallSubpages();
    /**
     * Returns the number of chunk lists for the arena.
     */
    int numChunkLists();

    /**
     * Returns an unmodifiable {@link List} which holds {@link PoolSubpageMetric}s for tiny sub-pages.
     */
    List<PoolSubpageMetric> tinySubpages();
    /**
     * Returns an unmodifiable {@link List} which holds {@link PoolSubpageMetric}s for small sub-pages.
     */
    List<PoolSubpageMetric> smallSubpages();
    /**
     * Returns an unmodifiable {@link List} which holds {@link PoolChunkListMetric}s.
     */
    List<PoolChunkListMetric> chunkLists();

    /**
     * Return the number of allocations done via the arena. This includes all sizes.
     */
    long numAllocations();
    /**
     * Return the number of tiny allocations done via the arena.
     */
    long numTinyAllocations();
    /**
     * Return the number of small allocations done via the arena.
     */
    long numSmallAllocations();
    /**
     * Return the number of normal allocations done via the arena.
     */
    long numNormalAllocations();
    /**
     * Return the number of huge allocations done via the arena.
     */
    long numHugeAllocations();

    /**
     * Return the number of deallocations done via the arena. This includes all sizes.
     */
    long numDeallocations();
    /**
     * Return the number of tiny deallocations done via the arena.
     */
    long numTinyDeallocations();
    /**
     * Return the number of small deallocations done via the arena.
     */
    long numSmallDeallocations();
    /**
     * Return the number of normal deallocations done via the arena.
     */
    long numNormalDeallocations();
    /**
     * Return the number of huge deallocations done via the arena.
     */
    long numHugeDeallocations();

    /**
     * Return the number of currently active allocations.
     */
    long numActiveAllocations();

    /**
     * Return the number of currently active tiny allocations.
     */
    long numActiveTinyAllocations();
    /**
     * Return the number of currently active small allocations.
     */
    long numActiveSmallAllocations();
    /**
     * Return the number of currently active normal allocations.
     */
    long numActiveNormalAllocations();
    /**
     * Return the number of currently active huge allocations.
     */
    long numActiveHugeAllocations();

    /**
     * Return the number of active bytes that are currently allocated by the arena.
     */
    long numActiveBytes();
}

```

------

PoolArena 对 PoolArenaMetric 接口的实现，代码如下：

```
@Override
public int numThreadCaches() {
    return numThreadCaches.get();
}

@Override
public int numTinySubpages() {
    return tinySubpagePools.length;
}

@Override
public int numSmallSubpages() {
    return smallSubpagePools.length;
}

@Override
public int numChunkLists() {
    return chunkListMetrics.size();
}

@Override
public List<PoolSubpageMetric> tinySubpages() {
    return subPageMetricList(tinySubpagePools);
}

@Override
public List<PoolSubpageMetric> smallSubpages() {
    return subPageMetricList(smallSubpagePools);
}

@Override
public List<PoolChunkListMetric> chunkLists() {
    return chunkListMetrics;
}

private static List<PoolSubpageMetric> subPageMetricList(PoolSubpage<?>[] pages) {
    List<PoolSubpageMetric> metrics = new ArrayList<PoolSubpageMetric>();
    for (PoolSubpage<?> head : pages) {
        if (head.next == head) {
            continue;
        }
        PoolSubpage<?> s = head.next;
        for (;;) {
            metrics.add(s);
            s = s.next;
            if (s == head) {
                break;
            }
        }
    }
    return metrics;
}

@Override
public long numAllocations() {
    final long allocsNormal;
    synchronized (this) {
        allocsNormal = allocationsNormal;
    }
    return allocationsTiny.value() + allocationsSmall.value() + allocsNormal + allocationsHuge.value();
}

@Override
public long numTinyAllocations() {
    return allocationsTiny.value();
}

@Override
public long numSmallAllocations() {
    return allocationsSmall.value();
}

@Override
public synchronized long numNormalAllocations() {
    return allocationsNormal;
}

@Override
public long numDeallocations() {
    final long deallocs;
    synchronized (this) {
        deallocs = deallocationsTiny + deallocationsSmall + deallocationsNormal;
    }
    return deallocs + deallocationsHuge.value();
}

@Override
public synchronized long numTinyDeallocations() {
    return deallocationsTiny;
}

@Override
public synchronized long numSmallDeallocations() {
    return deallocationsSmall;
}

@Override
public synchronized long numNormalDeallocations() {
    return deallocationsNormal;
}

@Override
public long numHugeAllocations() {
    return allocationsHuge.value();
}

@Override
public long numHugeDeallocations() {
    return deallocationsHuge.value();
}

@Override
public  long numActiveAllocations() {
    long val = allocationsTiny.value() + allocationsSmall.value() + allocationsHuge.value()
            - deallocationsHuge.value();
    synchronized (this) {
        val += allocationsNormal - (deallocationsTiny + deallocationsSmall + deallocationsNormal);
    }
    return max(val, 0);
}

@Override
public long numActiveTinyAllocations() {
    return max(numTinyAllocations() - numTinyDeallocations(), 0);
}

@Override
public long numActiveSmallAllocations() {
    return max(numSmallAllocations() - numSmallDeallocations(), 0);
}

@Override
public long numActiveNormalAllocations() {
    final long val;
    synchronized (this) {
        val = allocationsNormal - deallocationsNormal;
    }
    return max(val, 0);
}

@Override
public long numActiveHugeAllocations() {
    return max(numHugeAllocations() - numHugeDeallocations(), 0);
}

@Override
public long numActiveBytes() {
    long val = activeBytesHuge.value();
    synchronized (this) {
        for (int i = 0; i < chunkListMetrics.size(); i++) {
            for (PoolChunkMetric m: chunkListMetrics.get(i)) {
                val += m.chunkSize();
            }
        }
    }
    return max(0, val);
}

```

### 2.8.1 incTinySmallAllocation

`#incTinySmallAllocation(boolean tiny)` 方法，增加 `allocationsTiny` 或 `allocationsSmall` 计数。代码如下：

```
private void incTinySmallAllocation(boolean tiny) {
    if (tiny) {
        allocationsTiny.increment();
    } else {
        allocationsSmall.increment();
    }
}

```

## 2.9 抽象方法

虽然上文中，已经提到了几个抽象方法，这里还是同一整理如下：

```
abstract boolean isDirect();

protected abstract PoolChunk<T> newChunk(int pageSize, int maxOrder, int pageShifts, int chunkSize); //
protected abstract PoolChunk<T> newUnpooledChunk(int capacity); //

protected abstract PooledByteBuf<T> newByteBuf(int maxCapacity);

protected abstract void memoryCopy(T src, int srcOffset, T dst, int dstOffset, int length); //
    
protected abstract void destroyChunk(PoolChunk<T> chunk);

```

# 3. HeapArena

HeapArena ，继承 PoolArena 抽象类，对 Heap 类型的内存分配。

> HeapArena 是 PoolArena 的内部静态类。代码比较简单，胖友自己看看就成。

```
static final class HeapArena extends PoolArena<byte[]> { // 管理 byte[] 数组

    HeapArena(PooledByteBufAllocator parent, int pageSize, int maxOrder, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {
        super(parent, pageSize, maxOrder, pageShifts, chunkSize, directMemoryCacheAlignment);
    }

    private static byte[] newByteArray(int size) {
        return PlatformDependent.allocateUninitializedArray(size); // 创建 byte[] 数组
    }

    @Override
    boolean isDirect() {
        return false;
    }

    @Override
    protected PoolChunk<byte[]> newChunk(int pageSize, int maxOrder, int pageShifts, int chunkSize) {
        return new PoolChunk<byte[]>(this, newByteArray(chunkSize), pageSize, maxOrder, pageShifts, chunkSize, 0);
    }

    @Override
    protected PoolChunk<byte[]> newUnpooledChunk(int capacity) {
        return new PoolChunk<byte[]>(this, newByteArray(capacity), capacity, 0);
    }

    @Override
    protected void destroyChunk(PoolChunk<byte[]> chunk) {
        // Rely on GC. 依赖 GC
    }

    @Override
    protected PooledByteBuf<byte[]> newByteBuf(int maxCapacity) {
        return HAS_UNSAFE ? PooledUnsafeHeapByteBuf.newUnsafeInstance(maxCapacity)
                : PooledHeapByteBuf.newInstance(maxCapacity);
    }

    @Override
    protected void memoryCopy(byte[] src, int srcOffset, byte[] dst, int dstOffset, int length) {
        if (length == 0) {
            return;
        }

        System.arraycopy(src, srcOffset, dst, dstOffset, length);
    }
}

```

# 4. DirectArena

DirectArena ，继承 PoolArena 抽象类，对 Direct 类型的内存分配。

> DirectArena 是 PoolArena 的内部静态类。代码比较简单，胖友自己看看就成。

```
static final class DirectArena extends PoolArena<ByteBuffer> { // 管理 Direct ByteBuffer 对象

    DirectArena(PooledByteBufAllocator parent, int pageSize, int maxOrder,
            int pageShifts, int chunkSize, int directMemoryCacheAlignment) {
        super(parent, pageSize, maxOrder, pageShifts, chunkSize, directMemoryCacheAlignment);
    }

    @Override
    boolean isDirect() {
        return true;
    }

    private int offsetCacheLine(ByteBuffer memory) {
        // We can only calculate the offset if Unsafe is present as otherwise directBufferAddress(...) will
        // throw an NPE.
        return HAS_UNSAFE ?
                (int) (PlatformDependent.directBufferAddress(memory) & directMemoryCacheAlignmentMask) : 0;
    }

    @Override
    protected PoolChunk<ByteBuffer> newChunk(int pageSize, int maxOrder,
            int pageShifts, int chunkSize) {
        if (directMemoryCacheAlignment == 0) {
            return new PoolChunk<ByteBuffer>(this, allocateDirect(chunkSize), pageSize, maxOrder, pageShifts, chunkSize, 0);
        }
        final ByteBuffer memory = allocateDirect(chunkSize + directMemoryCacheAlignment);
        return new PoolChunk<ByteBuffer>(this, memory, pageSize, maxOrder, pageShifts, chunkSize, offsetCacheLine(memory));
    }

    @Override
    protected PoolChunk<ByteBuffer> newUnpooledChunk(int capacity) {
        if (directMemoryCacheAlignment == 0) {
            return new PoolChunk<ByteBuffer>(this,
                    allocateDirect(capacity), capacity, 0);
        }
        final ByteBuffer memory = allocateDirect(capacity + directMemoryCacheAlignment);
        return new PoolChunk<ByteBuffer>(this, memory, capacity, offsetCacheLine(memory));
    }

    private static ByteBuffer allocateDirect(int capacity) { // 创建 Direct ByteBuffer 对象
        return PlatformDependent.useDirectBufferNoCleaner() ?
                PlatformDependent.allocateDirectNoCleaner(capacity) : ByteBuffer.allocateDirect(capacity);
    }

    @Override
    protected void destroyChunk(PoolChunk<ByteBuffer> chunk) {
        if (PlatformDependent.useDirectBufferNoCleaner()) {
            PlatformDependent.freeDirectNoCleaner(chunk.memory);
        } else {
            PlatformDependent.freeDirectBuffer(chunk.memory);
        }
    }

    @Override
    protected PooledByteBuf<ByteBuffer> newByteBuf(int maxCapacity) {
        if (HAS_UNSAFE) {
            return PooledUnsafeDirectByteBuf.newInstance(maxCapacity);
        } else {
            return PooledDirectByteBuf.newInstance(maxCapacity);
        }
    }

    @Override
    protected void memoryCopy(ByteBuffer src, int srcOffset, ByteBuffer dst, int dstOffset, int length) {
        if (length == 0) {
            return;
        }

        if (HAS_UNSAFE) {
            PlatformDependent.copyMemory(
                    PlatformDependent.directBufferAddress(src) + srcOffset,
                    PlatformDependent.directBufferAddress(dst) + dstOffset, length);
        } else {
            // We must duplicate the NIO buffers because they may be accessed by other Netty buffers.
            src = src.duplicate();
            dst = dst.duplicate();
            src.position(srcOffset).limit(srcOffset + length);
            dst.position(dstOffset);
            dst.put(src);
        }
    }
}

```

# 666. 彩蛋

终于看懂 Jemalloc 算法的大体的实现。一开始看，一脸懵逼！！！其实耐下性子，慢慢看，总能看懂的。

当然，如果这个时候让自己手写 Jemalloc 算法，估计还是会泪崩。哈哈哈，相比写代码来说，读懂代码还是容易很多的。

嘿嘿，找了一张厉害的图，胖友在结合这个图，理解理解。

> FROM [《Netty Buffer - 内存管理 PoolArena》](http://www.woowen.com/源码/2016/08/01/Netty buffer - 内存管理 PoolArena/)
>
> ![内存分配](http://static2.iocoder.cn/images/Netty/2018_09_13/04.png)

------

参考如下文章：

- 占小狼 [《深入浅出Netty内存管理 PoolArena》](https://www.jianshu.com/p/4856bd30dd56)
- Hypercube [《自顶向下深入分析Netty（十）–PoolArena》](https://www.jianshu.com/p/86fbacdb68bd)

# Buffer 之 Jemalloc（六）PoolThreadCache



# 1. 概述

在 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena) 一文中，我们看到 PoolArena 在分配( `#allocate(...)` )和释放( `#free(...)` )内存的过程中，无可避免会出现 `synchronized` 的身影。虽然锁的粒度不是很大，但是如果一个 PoolArena 如果被**多个**线程引用，带来的线程锁的同步和竞争。并且，如果在锁竞争的过程中，申请 Direct ByteBuffer ，那么带来的线程等待就可能是**几百毫秒**的时间。

那么该如何解决呢？如下图红框所示：

> FROM [《jemalloc源码解析-内存管理》](http://brionas.github.io/2015/01/31/jemalloc源码解析-内存管理/)
>
> ![大体结构](http://static2.iocoder.cn/images/Netty/2018_09_16/01.png)

给**每个**线程引入其**独有**的 tcache 线程缓存。

- 在释放已分配的内存块时，不放回到 Chunk 中，而是缓存到 tcache 中。
- 在分配内存块时，优先从 tcache 获取。无法获取到，再从 Chunk 中分配。

通过这样的方式，尽可能的避免多线程的同步和竞争。

# 2. PoolThreadCache

`io.netty.buffer.PoolThreadCache` ，Netty 对 Jemalloc tcache 的实现类，内存分配的线程缓存。

## 2.1 构造方法

```
/**
 * 对应的 Heap PoolArena 对象
 */
final PoolArena<byte[]> heapArena;
/**
 * 对应的 Direct PoolArena 对象
 */
final PoolArena<ByteBuffer> directArena;

// Hold the caches for the different size classes, which are tiny, small and normal.
/**
 * Heap 类型的 tiny Subpage 内存块缓存数组
 */
private final MemoryRegionCache<byte[]>[] tinySubPageHeapCaches;
/**
 * Heap 类型的 small Subpage 内存块缓存数组
 */
private final MemoryRegionCache<byte[]>[] smallSubPageHeapCaches;
/**
 * Heap 类型的 normal 内存块缓存数组
 */
private final MemoryRegionCache<byte[]>[] normalHeapCaches;
/**
 * Direct 类型的 tiny Subpage 内存块缓存数组
 */
private final MemoryRegionCache<ByteBuffer>[] tinySubPageDirectCaches;
/**
 * Direct 类型的 small Subpage 内存块缓存数组
 */
private final MemoryRegionCache<ByteBuffer>[] smallSubPageDirectCaches;
/**
 * Direct 类型的 normal 内存块缓存数组
 */
private final MemoryRegionCache<ByteBuffer>[] normalDirectCaches;

// Used for bitshifting when calculate the index of normal caches later
/**
 * 用于计算请求分配的 normal 类型的内存块，在 {@link #normalDirectCaches} 数组中的位置
 *
 * 默认为 log2(pageSize) = log2(8192) = 13
 */
private final int numShiftsNormalDirect;
/**
 * 用于计算请求分配的 normal 类型的内存块，在 {@link #normalHeapCaches} 数组中的位置
 *
 * 默认为 log2(pageSize) = log2(8192) = 13
 */
private final int numShiftsNormalHeap;

/**
 * 分配次数
 */
private int allocations;
/**
 * {@link #allocations} 到达该阀值，释放缓存
 *  
 * 默认为 8192 次
 * 
 * @see #free()
 */
private final int freeSweepAllocationThreshold;

  1: PoolThreadCache(PoolArena<byte[]> heapArena, PoolArena<ByteBuffer> directArena,
  2:                 int tinyCacheSize, int smallCacheSize, int normalCacheSize,
  3:                 int maxCachedBufferCapacity, int freeSweepAllocationThreshold) {
  4:     if (maxCachedBufferCapacity < 0) {
  5:         throw new IllegalArgumentException("maxCachedBufferCapacity: "
  6:                 + maxCachedBufferCapacity + " (expected: >= 0)");
  7:     }
  8:     this.freeSweepAllocationThreshold = freeSweepAllocationThreshold;
  9:     this.heapArena = heapArena;
 10:     this.directArena = directArena;
 11: 
 12:     // 初始化 Direct 类型的内存块缓存
 13:     if (directArena != null) {
 14:         // 创建 tinySubPageDirectCaches
 15:         tinySubPageDirectCaches = createSubPageCaches(tinyCacheSize, PoolArena.numTinySubpagePools, SizeClass.Tiny);
 16:         // 创建 smallSubPageDirectCaches
 17:         smallSubPageDirectCaches = createSubPageCaches(smallCacheSize, directArena.numSmallSubpagePools, SizeClass.Small);
 18: 
 19:         // 计算 numShiftsNormalDirect
 20:         numShiftsNormalDirect = log2(directArena.pageSize);
 21:         // 创建 normalDirectCaches
 22:         normalDirectCaches = createNormalCaches(normalCacheSize, maxCachedBufferCapacity, directArena);
 23: 
 24:         // 增加 directArena 的线程引用计数
 25:         directArena.numThreadCaches.getAndIncrement();
 26:     } else {
 27:         // No directArea is configured so just null out all caches
 28:         tinySubPageDirectCaches = null;
 29:         smallSubPageDirectCaches = null;
 30:         normalDirectCaches = null;
 31:         numShiftsNormalDirect = -1;
 32:     }
 33:     // 初始化 Heap 类型的内存块缓存。同上面部分。
 34:     if (heapArena != null) {
 35:         // Create the caches for the heap allocations
 36:         tinySubPageHeapCaches = createSubPageCaches(tinyCacheSize, PoolArena.numTinySubpagePools, SizeClass.Tiny);
 37:         smallSubPageHeapCaches = createSubPageCaches(smallCacheSize, heapArena.numSmallSubpagePools, SizeClass.Small);
 38: 
 39:         numShiftsNormalHeap = log2(heapArena.pageSize);
 40:         normalHeapCaches = createNormalCaches(normalCacheSize, maxCachedBufferCapacity, heapArena);
 41: 
 42:         heapArena.numThreadCaches.getAndIncrement();
 43:     } else {
 44:         // No heapArea is configured so just null out all caches
 45:         tinySubPageHeapCaches = null;
 46:         smallSubPageHeapCaches = null;
 47:         normalHeapCaches = null;
 48:         numShiftsNormalHeap = -1;
 49:     }
 50: 
 51:     // 校验参数，保证 PoolThreadCache 可缓存内存块。
 52:     // Only check if there are caches in use.
 53:     if ((tinySubPageDirectCaches != null || smallSubPageDirectCaches != null || normalDirectCaches != null
 54:             || tinySubPageHeapCaches != null || smallSubPageHeapCaches != null || normalHeapCaches != null)
 55:             && freeSweepAllocationThreshold < 1) {
 56:         throw new IllegalArgumentException("freeSweepAllocationThreshold: " + freeSweepAllocationThreshold + " (expected: > 0)");
 57:     }
 58: }
```

- 虽然代码比较多，主要分为 Heap 和 Direct 两种内存。

- Direct 相关

  - `directArena` 属性，对应的 Heap PoolArena 对象。

  - ```
    tinySubPageDirectCaches
    ```

     

    属性，Direct 类型的 tiny Subpage 内存块缓存数组。

    - 默认情况下，数组大小为 512 。
    - 在【第 15 行】的代码，调用 `#createSubPageCaches(int cacheSize, int numCaches, SizeClass sizeClass)`方法，创建 MemoryRegionCache 数组。详细解析，见 [「2.2 createSubPageCaches」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

  - ```
    smallSubPageDirectCaches
    ```

     

    属性，Direct 类型的 small Subpage 内存块缓存数组。

    - 默认情况下，数组大小为 256 。
    - 在【第 17 行】的代码，调用 `#createSubPageCaches(int cacheSize, int numCaches, SizeClass sizeClass)`方法，创建 MemoryRegionCache 数组。详细解析，见 [「2.2 createSubPageCaches」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

  - ```
    normalDirectCaches
    ```

     

    属性，Direct 类型的 normal Page 内存块缓存数组。

    - 默认情况下，数组大小为 64 。

    - 在【第 22 行】的代码，调用 `#createNormalCaches(int cacheSize, int maxCachedBufferCapacity, PoolArena<T> area)` 方法，创建 MemoryRegionCache 数组。详细解析，见 [「2.3 createNormalCaches」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

    - ```
      numShiftsNormalDirect
      ```

       

      属性，用于计算请求分配的 normal 类型的内存块，在

       

      ```
      normalDirectCaches
      ```

       

      数组中的位置。

      - 默认情况下，数值为 13 。
      - 在【第 20 行】的代码，调用 `#log2(int pageSize)` 方法， `log2(pageSize) = log2(8192) = 13` 。

  - 在【第 25 行】的代码，增加 `directArena` 的线程引用计数。通过这样的方式，我们能够知道，一个 PoolArena 对象，被多少线程所引用。

- Heap 相关，和【Direct 相关】基本**类似**。

- ```
  allocations
  ```

   

  属性，分配次数计数器。每次分配时，该计数器 + 1 。

  - `freeSweepAllocationThreshold` 属性，当 `allocations` 到达该阀值时，调用 `#free()` 方法，释放缓存。同时，会重置 `allocations` 计数器为 0 。

## 2.2 createSubPageCaches

`#createSubPageCaches(int cacheSize, int numCaches, SizeClass sizeClass)` 方法，创建 Subpage 内存块缓存数组。代码如下：

```
// tiny 类型，默认 cacheSize = PooledByteBufAllocator.DEFAULT_TINY_CACHE_SIZE = 512 , numCaches = PoolArena.numTinySubpagePools = 512 >>> 4 = 32
// small 类型，默认 cacheSize = PooledByteBufAllocator.DEFAULT_SMALL_CACHE_SIZE = 256 , numCaches = pageSize - 9 = 13 - 9 = 4
private static <T> MemoryRegionCache<T>[] createSubPageCaches(int cacheSize, int numCaches, SizeClass sizeClass) {
    if (cacheSize > 0 && numCaches > 0) {
        @SuppressWarnings("unchecked")
        MemoryRegionCache<T>[] cache = new MemoryRegionCache[numCaches];
        for (int i = 0; i < cache.length; i++) {
            // TODO: maybe use cacheSize / cache.length
            cache[i] = new SubPageMemoryRegionCache<T>(cacheSize, sizeClass);
        }
        return cache;
    } else {
        return null;
    }
}
```

- 创建的 Subpage 内存块缓存数组，实际和

   

  ```
  PoolArena.tinySubpagePools
  ```

   

  和

   

  ```
  PoolArena.smallSubpagePools
  ```

   

  数组

  大小保持一致

  。从而实现，相同大小的内存，能对应相同的数组下标。

  - `sizeClass` = `tiny` 时， 默认 `cacheSize` = `PooledByteBufAllocator.DEFAULT_TINY_CACHE_SIZE = 512` , `numCaches` = `PoolArena.numTinySubpagePools = 512 >>> 4 = 32` 。
  - `sizeClass` = `small` 时，默认 `cacheSize` = `PooledByteBufAllocator.DEFAULT_SMALL_CACHE_SIZE = 256` , `numCaches` = `pageSize - 9 = 13 - 9 = 4` 。

- 创建的数组，每个元素的类型为 SubPageMemoryRegionCache 。详细解析，见 [「3.X.1 SubPageMemoryRegionCache」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

## 2.3 createNormalCaches

`#createSubPageCaches(int cacheSize, int numCaches, SizeClass sizeClass)` 方法，创建 Normal Page 内存块缓存数组。代码如下：

```
 // normal 类型，默认 cacheSize = PooledByteBufAllocator.DEFAULT_NORMAL_CACHE_SIZE = 64 , maxCachedBufferCapacity = PoolArena.DEFAULT_MAX_CACHED_BUFFER_CAPACITY = 32 * 1024 = 32KB
private static <T> MemoryRegionCache<T>[] createNormalCaches(int cacheSize, int maxCachedBufferCapacity, PoolArena<T> area) {
    if (cacheSize > 0 && maxCachedBufferCapacity > 0) {
        // <1> 计算数组大小
        int max = Math.min(area.chunkSize, maxCachedBufferCapacity);
        int arraySize = Math.max(1, log2(max / area.pageSize) + 1);

        @SuppressWarnings("unchecked")
        MemoryRegionCache<T>[] cache = new MemoryRegionCache[arraySize];
        for (int i = 0; i < cache.length; i++) {
            cache[i] = new NormalMemoryRegionCache<T>(cacheSize);
        }
        return cache;
    } else {
        return null;
    }
}
```

- `maxCachedBufferCapacity` 属性，缓存的 Normal 内存块的最大容量，避免过大的 Normal 内存块被缓存，占用过多通过。默认情况下，`maxCachedBufferCapacity = PoolArena.DEFAULT_MAX_CACHED_BUFFER_CAPACITY = 32 * 1024 = 32KB` 。也就说，在 `<1>` 处，`arraySize` 的计算**数组大小**的结果为 3 。刚好是 `cache[0] = 8KB`、`cache[1] = 16KB`、`cache[2] = 32KB` 。那么，如果申请的 Normal 内存块大小为 `64KB` ，超过了数组大小，所以无法被缓存。😈 是不是和原先自己认为的 `maxCachedBufferCapacity` 实现最大容量的想法，有点不同。
- 创建的数组，每个元素的类型为 SubPageMemoryRegionCache 。详细解析，见 [「3.X.2 NormalMemoryRegionCache」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

## 2.4 cache

```
private MemoryRegionCache<?> cacheForTiny(PoolArena<?> area, int normCapacity) {
    // 获得数组下标
    int idx = PoolArena.tinyIdx(normCapacity);
    if (area.isDirect()) {
        return cache(tinySubPageDirectCaches, idx);
    }
    return cache(tinySubPageHeapCaches, idx);
}

private MemoryRegionCache<?> cacheForSmall(PoolArena<?> area, int normCapacity) {
    // 获得数组下标
    int idx = PoolArena.smallIdx(normCapacity);
    if (area.isDirect()) {
        return cache(smallSubPageDirectCaches, idx);
    }
    return cache(smallSubPageHeapCaches, idx);
}

private MemoryRegionCache<?> cacheForNormal(PoolArena<?> area, int normCapacity) {
    if (area.isDirect()) {
        // 获得数组下标
        int idx = log2(normCapacity >> numShiftsNormalDirect);
        return cache(normalDirectCaches, idx);
    }
    // 获得数组下标
    int idx = log2(normCapacity >> numShiftsNormalHeap);
    return cache(normalHeapCaches, idx);
}
```

- 三个方法，分别获取内存容量对应所在的 MemoryRegionCache 对象。通过调用 `#cache(MemoryRegionCache<T>[] cache, int idx)` 方法，代码如下：

  ```
  private static <T> MemoryRegionCache<T> cache(MemoryRegionCache<T>[] cache, int idx) {
      // 不在范围内，说明不缓存该容量的内存块
      if (cache == null || idx > cache.length - 1) {
          return null;
      }
      // 获得 MemoryRegionCache 对象
      return cache[idx];
  }
  ```

------

当然，考虑到使用便利，封装了 `#cache(PoolArena<?> area, int normCapacity, SizeClass sizeClass)` 方法，支持获取对应内存类型的 MemoryRegionCache 对象。代码如下：

```
private MemoryRegionCache<?> cache(PoolArena<?> area, int normCapacity, SizeClass sizeClass) {
    switch (sizeClass) {
    case Normal:
        return cacheForNormal(area, normCapacity);
    case Small:
        return cacheForSmall(area, normCapacity);
    case Tiny:
        return cacheForTiny(area, normCapacity);
    default:
        throw new Error();
    }
}
```

## 2.5 add

`#add(PoolArena<?> area, PoolChunk chunk, long handle, int normCapacity, SizeClass sizeClass)` 方法，添加内存块到 PoolThreadCache 的指定 MemoryRegionCache 的队列中，进行缓存。并且，返回是否添加成功。代码如下：

```
/**
 * Add {@link PoolChunk} and {@code handle} to the cache if there is enough room.
 * Returns {@code true} if it fit into the cache {@code false} otherwise.
 */
@SuppressWarnings({ "unchecked", "rawtypes" })
boolean add(PoolArena<?> area, PoolChunk chunk, long handle, int normCapacity, SizeClass sizeClass) {
    // 获得对应的 MemoryRegionCache 对象
    MemoryRegionCache<?> cache = cache(area, normCapacity, sizeClass);
    if (cache == null) {
        return false;
    }
    // 添加到 MemoryRegionCache 内存块中
    return cache.add(chunk, handle);
}
```

- 代码比较简单，胖友自己看注释。
- 在 `PoolArea#free(PoolChunk<T> chunk, long handle, int normCapacity, PoolThreadCache cache)` 中，调用该方法。所以，可以结合 [《精尽 Netty 源码解析 —— Buffer 之 Jemalloc（五）PoolArena》](http://svip.iocoder.cn/Netty/ByteBuf-3-5-Jemalloc-Arena) 的 [「2.6 free」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 一起看看罗。

## 2.6 allocate

```
/**
 * Try to allocate a tiny buffer out of the cache. Returns {@code true} if successful {@code false} otherwise
 */
boolean allocateTiny(PoolArena<?> area, PooledByteBuf<?> buf, int reqCapacity, int normCapacity) {
    return allocate(cacheForTiny(area, normCapacity), buf, reqCapacity);
}

/**
 * Try to allocate a small buffer out of the cache. Returns {@code true} if successful {@code false} otherwise
 */
boolean allocateSmall(PoolArena<?> area, PooledByteBuf<?> buf, int reqCapacity, int normCapacity) {
    return allocate(cacheForSmall(area, normCapacity), buf, reqCapacity);
}

/**
 * Try to allocate a small buffer out of the cache. Returns {@code true} if successful {@code false} otherwise
 */
boolean allocateNormal(PoolArena<?> area, PooledByteBuf<?> buf, int reqCapacity, int normCapacity) {
    return allocate(cacheForNormal(area, normCapacity), buf, reqCapacity);
}
```

- 三个方法，从缓存中分别获取不同容量大小的内存块，初始化到 PooledByteBuf 对象中。通过调用 `#allocate(MemoryRegionCache<?> cache, PooledByteBuf buf, int reqCapacity)` 方法，代码如下：

  ```
   1: private boolean allocate(MemoryRegionCache<?> cache, PooledByteBuf buf, int reqCapacity) {
   2:     if (cache == null) {
   3:         // no cache found so just return false here
   4:         return false;
   5:     }
   6:     // 分配内存块，并初始化到 MemoryRegionCache 中
   7:     boolean allocated = cache.allocate(buf, reqCapacity);
   8:     // 到达阀值，整理缓存
   9:     if (++ allocations >= freeSweepAllocationThreshold) {
  10:         allocations = 0;
  11:         trim();
  12:     }
  13:     // 返回是否分配成功
  14:     return allocated;
  15: }
  
  ```

  - 第 7 行：调用 `MemoryRegionCache#allocate(buf, reqCapacity)` 方法，从缓存中分配内存块，并初始化到 MemoryRegionCache 中。
  - 第 8 至 12 行：增加 `allocations` 计数。若到达阀值( `freeSweepAllocationThreshold` )，重置计数，并调用 `#trim()`方法，整理缓存。详细解析，见 [「2.7 trim」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。
  - 第 14 行：返回是否分配成功。如果从缓存中分配失败，后续就从 PoolArena 中获取内存块。

## 2.7 free

`#trim()` 方法，整理缓存，释放使用**频度**较少的内存块缓存。代码如下：

```
private static int free(MemoryRegionCache<?> cache) {
    if (cache == null) {
        return 0;
    }
    return cache.free();
}

void trim() {
    trim(tinySubPageDirectCaches);
    trim(smallSubPageDirectCaches);
    trim(normalDirectCaches);
    trim(tinySubPageHeapCaches);
    trim(smallSubPageHeapCaches);
    trim(normalHeapCaches);
}

private static void trim(MemoryRegionCache<?>[] caches) {
    if (caches == null) {
        return;
    }
    for (MemoryRegionCache<?> c: caches) {
        trim(c);
    }
}

private static void trim(MemoryRegionCache<?> cache) {
    if (cache == null) {
        return;
    }
    cache.trim();
}

```

- 会调用所有 MemoryRegionCache 的 `#trim()` 方法，整理每个内存块缓存。详细解析，见 [「3.6 trim」](http://svip.iocoder.cn/Netty/ByteBuf-3-6-Jemalloc-ThreadCache/#) 。

## 2.8 finalize

`#finalize()` 方法，对象销毁时，清空缓存等等。代码如下：

```
/// TODO: In the future when we move to Java9+ we should use java.lang.ref.Cleaner.
@Override
protected void finalize() throws Throwable {
    try {
        // <1> 调用父 finalize
        super.finalize();
    } finally {
        // 清空缓存
        free();
    }
}

/**
 *  Should be called if the Thread that uses this cache is about to exist to release resources out of the cache
 */
void free() {
    // <2> 清空缓存
    int numFreed = free(tinySubPageDirectCaches) +
            free(smallSubPageDirectCaches) +
            free(normalDirectCaches) +
            free(tinySubPageHeapCaches) +
            free(smallSubPageHeapCaches) +
            free(normalHeapCaches);

    if (numFreed > 0 && logger.isDebugEnabled()) {
        logger.debug("Freed {} thread-local buffer(s) from thread: {}", numFreed, Thread.currentThread().getName());
    }

    // <3.1> 减小 directArena 的线程引用计数
    if (directArena != null) {
        directArena.numThreadCaches.getAndDecrement();
    }

    // <3.2> 减小 heapArena 的线程引用计数
    if (heapArena != null) {
        heapArena.numThreadCaches.getAndDecrement();
    }
}

private static int free(MemoryRegionCache<?>[] caches) {
    if (caches == null) {
        return 0;
    }

    int numFreed = 0;
    for (MemoryRegionCache<?> c: caches) {
        numFreed += free(c);
    }
    return numFreed;
}

```

- 代码比较简单，胖友自己看。主要是 `<1>`、`<2>`、`<3.1>/<3.2>` 三个点。

# 3. MemoryRegionCache

MemoryRegionCache ，是 PoolThreadCache 的内部静态类，**内存块缓存**。在其内部，有一个**队列**，存储缓存的内存块。如下图所示：![MemoryRegionCache](http://static2.iocoder.cn/images/Netty/2018_09_16/02.png)

## 3.1 构造方法

```
private abstract static class MemoryRegionCache<T> {

    /**
     * {@link #queue} 队列大小
     */
    private final int size;
    /**
     * 队列。里面存储内存块
     */
    private final Queue<Entry<T>> queue;
    /**
     * 内存类型
     */
    private final SizeClass sizeClass;
    /**
     * 分配次数计数器
     */
    private int allocations;

    MemoryRegionCache(int size, SizeClass sizeClass) {
        this.size = MathUtil.safeFindNextPositivePowerOfTwo(size);
        queue = PlatformDependent.newFixedMpscQueue(this.size); // <1> MPSC
        this.sizeClass = sizeClass;
    }
    
    // ... 省略其它方法
}

```

- `sizeClass` 属性，内存类型。

- `queue` 属性，队列，里面存储内存块。每个元素为 Entry 对象，对应一个内存块。代码如下：

  ```
  static final class Entry<T> {
  
      /**
       * Recycler 处理器，用于回收 Entry 对象
       */
      final Handle<Entry<?>> recyclerHandle;
      /**
       * PoolChunk 对象
       */
      PoolChunk<T> chunk;
      /**
       * 内存块在 {@link #chunk} 的位置
       */
      long handle = -1;
  
      Entry(Handle<Entry<?>> recyclerHandle) {
          this.recyclerHandle = recyclerHandle;
      }
  
      void recycle() {
          // 置空
          chunk = null;
          handle = -1;
          // 回收 Entry 对象
          recyclerHandle.recycle(this);
      }
  }
  
  ```

  - 通过 `chunk` 和 `handle` 属性，可以唯一确认一个内存块。
  - `recyclerHandle` 属性，用于回收 Entry 对象，用于 `#recycle()` 方法中。

- `size` 属性，队列大小。

- `allocations` 属性，分配次数计数器。

- 在

   

  ```
  <1>
  
  ```

   

  处理，我们可以看到创建的

   

  ```
  queue
  
  ```

   

  属性，类型为 MPSC( Multiple Producer Single Consumer ) 队列，即

  多个

  生产者

  单一

  消费者。为什么使用 MPSC 队列呢?

  - 多个生产者，指的是多个线程，移除( 释放 )内存块出队列。
  - 单个消费者，指的是单个线程，添加( 缓存 )内存块到队列。

## 3.2 newEntry

`#newEntry(PoolChunk<?> chunk, long handle)` 方法，创建 Entry 对象。代码如下：

```
@SuppressWarnings("rawtypes")
private static Entry newEntry(PoolChunk<?> chunk, long handle) {
    // 从 Recycler 对象中，获得 Entry 对象
    Entry entry = RECYCLER.get();
    // 初始化属性
    entry.chunk = chunk;
    entry.handle = handle;
    return entry;
}

@SuppressWarnings("rawtypes")
private static final Recycler<Entry> RECYCLER = new Recycler<Entry>() {

    @SuppressWarnings("unchecked")
    @Override
    protected Entry newObject(Handle<Entry> handle) {
        return new Entry(handle); // 创建 Entry 对象
    }

};

```

## 3.3 add

`#add(PoolChunk<T> chunk, long handle)` 方法，添加( 缓存 )内存块到队列，并返回是否添加成功。代码如下：

```
/**
 * Add to cache if not already full.
 */
@SuppressWarnings("unchecked")
public final boolean add(PoolChunk<T> chunk, long handle) {
    // 创建 Entry 对象
    Entry<T> entry = newEntry(chunk, handle);
    // 添加到队列
    boolean queued = queue.offer(entry);
    // 若添加失败，说明队列已满，回收 Entry 对象
    if (!queued) {
        // If it was not possible to cache the chunk, immediately recycle the entry
        entry.recycle();
    }

    return queued; // 是否添加成功
}

```

## 3.4 allocate

`#allocate(PooledByteBuf<T> buf, int reqCapacity)` 方法，从队列中获取缓存的内存块，初始化到 PooledByteBuf 对象中，并返回是否分配成功。代码如下：

```
/**
 * Allocate something out of the cache if possible and remove the entry from the cache.
 */
public final boolean allocate(PooledByteBuf<T> buf, int reqCapacity) {
    // 获取并移除队列首个 Entry 对象
    Entry<T> entry = queue.poll();
    // 获取失败，返回 false
    if (entry == null) {
        return false;
    }
    // <1> 初始化内存块到 PooledByteBuf 对象中 
    initBuf(entry.chunk, entry.handle, buf, reqCapacity);
    // 回收 Entry 对象
    entry.recycle();

    // 增加 allocations 计数。因为分配总是在相同线程，所以不需要考虑线程安全的问题
    // allocations is not thread-safe which is fine as this is only called from the same thread all time.
    ++ allocations;
    return true; // 返回 true ，分配成功
}

```

- 代码比较简单，胖友自己看注释。

- 在 `<1>` 处，调用 `#initBuf(PoolChunk<T> chunk, long handle, PooledByteBuf<T> buf, int reqCapacity)` **抽象**方法，初始化内存块到 PooledByteBuf 对象中。代码如下：

  ```
  /**
   * Init the {@link PooledByteBuf} using the provided chunk and handle with the capacity restrictions.
   */
  protected abstract void initBuf(PoolChunk<T> chunk, long handle, PooledByteBuf<T> buf, int reqCapacity);
  
  ```

  - 该**抽象**方法需要子类 SubPageMemoryRegionCache 和 NormalMemoryRegionCache 来实现。并且，这也是 MemoryRegionCache 的**唯一**的抽象方法。

## 3.5 free

`#free(...)` 方法，清除队列。代码如下：

```
/**
 * 清除队列中的全部
 *
 * Clear out this cache and free up all previous cached {@link PoolChunk}s and {@code handle}s.
 */
public final int free() {
    return free(Integer.MAX_VALUE);
}

// 清除队列中的指定数量元素
private int free(int max) {
    int numFreed = 0;
    for (; numFreed < max; numFreed++) {
        // 获取并移除首元素
        Entry<T> entry = queue.poll();
        if (entry != null) {
            // 释放缓存的内存块回 Chunk 中
            freeEntry(entry); <1>
        } else {
            // all cleared
            return numFreed;
        }
    }
    return numFreed;
}

```

- 代码比较简单，胖友自己看注释。

- `<1>` 处， 释放缓存的内存块回 Chunk 中。代码如下：

  ```
  private  void freeEntry(Entry entry) {
      PoolChunk chunk = entry.chunk;
      long handle = entry.handle;
  
      // 回收 Entry 对象
      // recycle now so PoolChunk can be GC'ed.
      entry.recycle();
  
      // 释放缓存的内存块回 Chunk 中
      chunk.arena.freeChunk(chunk, handle, sizeClass);
  }
  
  ```

## 3.6 trim

这块当时没太看懂，后来读了 [《自顶向下深入分析Netty（十）–PoolThreadCache》](https://www.jianshu.com/p/9177b7dabd37) 文章后，看懂了 `#trim()` 方法。引用如下：

> 在分配过程还有一个`trim()`方法，当分配操作达到一定阈值（Netty默认8192）时，没有被分配出去的缓存空间都要被释放，以防止内存泄漏，核心代码如下：

```
// 内部类MemoryRegionCache
public final void trim() {
    // allocations 表示已经重新分配出去的ByteBuf个数
    int free = size - allocations;  
    allocations = 0;

    // 在一定阈值内还没被分配出去的空间将被释放
    if (free > 0) {
        free(free); // 释放队列中的节点
    }
}

```

> 也就是说，期望一个 MemoryRegionCache **频繁**进行回收-分配，这样 `allocations` > `size` ，将不会释放队列中的任何一个节点表示的内存空间；
>
> 但如果长时间没有分配，则应该释放这一部分空间，防止内存占据过多。Tiny请求缓存512 个节点，由此可知当使用率超过 `512 / 8192 = 6.25%` 时就不会释放节点。

## 3.X1 SubPageMemoryRegionCache

SubPageMemoryRegionCache ，是 PoolThreadCache 的内部静态类，继承 MemoryRegionCache 抽象类，**Subpage**MemoryRegionCache 实现类。代码如下：

```
/**
 * Cache used for buffers which are backed by TINY or SMALL size.
 */
private static final class SubPageMemoryRegionCache<T> extends MemoryRegionCache<T> {

    SubPageMemoryRegionCache(int size, SizeClass sizeClass) {
        super(size, sizeClass);
    }

    @Override
    protected void initBuf(PoolChunk<T> chunk, long handle, PooledByteBuf<T> buf, int reqCapacity) {
        // 初始化 Subpage 内存块到 PooledByteBuf 对象中
        chunk.initBufWithSubpage(buf, handle, reqCapacity);
    }

}

```

## 3.X2 NormalMemoryRegionCache

NormalMemoryRegionCache ，是 PoolThreadCache 的内部静态类，继承 MemoryRegionCache 抽象类，**Page**MemoryRegionCache 实现类。代码如下：

```
/**
 * Cache used for buffers which are backed by NORMAL size.
 */
private static final class NormalMemoryRegionCache<T> extends MemoryRegionCache<T> {

    NormalMemoryRegionCache(int size) {
        super(size, SizeClass.Normal);
    }

    @Override
    protected void initBuf(PoolChunk<T> chunk, long handle, PooledByteBuf<T> buf, int reqCapacity) {
        // 初始化 Page 内存块到 PooledByteBuf 对象中
        chunk.initBuf(buf, handle, reqCapacity);
    }

}

```

# 666. 彩蛋

嘿嘿，比想象中简单蛮多的一篇文章。

推荐阅读文章：

- Hypercube [《自顶向下深入分析Netty（十）–PoolThreadCache》](https://www.jianshu.com/p/9177b7dabd37)

# ChannelHandler（一）之简介



# 1. 概述

在 [《精尽 Netty 源码分析 —— Netty 简介（二）之核心组件》](http://svip.iocoder.cn/Netty/intro-2/?self) 中，对 ChannelHandler 做了定义，我们再来回顾下：

> ChannelHandler ，连接通道处理器，我们使用 Netty 中**最常用**的组件。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。

实际上，我们已经在前面的文章看了一遍又一遍 ChannelHandler 的身影，已经是熟悉的老朋友了。当然，我们还是会在这个**专属**于 ChannelHandler 章节里，再更加深入的认识 ChannelHandler 。

`io.netty.channel.ChannelHandler` ，Channel 处理器接口。代码如下：

```java
public interface ChannelHandler {

    /**
     * Gets called after the {@link ChannelHandler} was added to the actual context and it's ready to handle events.
     *
     * ChannelHandler 已经成功被添加到 ChannelPipeline 中，可以进行处理事件。
     *
     * 该方法，一般用于 ChannelHandler 的初始化的逻辑
     */
    void handlerAdded(ChannelHandlerContext ctx) throws Exception;

    /**
     * Gets called after the {@link ChannelHandler} was removed from the actual context and it doesn't handle events
     * anymore.
     *
     * ChannelHandler 已经成功从 ChannelPipeline 中被移除，不再进行处理事件。
     *
     * 该方法，一般用于 ChannelHandler 的销毁的逻辑
     */
    void handlerRemoved(ChannelHandlerContext ctx) throws Exception;

    /**
     * Gets called if a {@link Throwable} was thrown.
     *
     * 抓取到异常。目前被废弃，移到 ChannelInboundHandler 接口中，作为对 Exception Inbound 事件的处理
     *
     * @deprecated is part of {@link ChannelInboundHandler}
     */
    @Deprecated
    void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;

    /**
     * Indicates that the same instance of the annotated {@link ChannelHandler}
     * can be added to one or more {@link ChannelPipeline}s multiple times
     * without a race condition.
     * <p>
     * If this annotation is not specified, you have to create a new handler
     * instance every time you add it to a pipeline because it has unshared
     * state such as member variables.
     * <p>
     * This annotation is provided for documentation purpose, just like
     * <a href="http://www.javaconcurrencyinpractice.com/annotations/doc/">the JCIP annotations</a>.
     */
    @Inherited
    @Documented
    @Target(ElementType.TYPE)
    @Retention(RetentionPolicy.RUNTIME)
    @interface Sharable {
        // no value
    }

}
```

- 关于 `#handlerAdded(...)`、`#handlerRemoved(...)`、`#exceptionCaught(...)` 方法，胖友看方法上的注释。
- `@Sharable` 注解，ChannelHandler 是否可共享，即是否可以被**多次**添加。在 [《精尽 Netty 源码解析 —— ChannelPipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler?self) 的 [「3. checkMultiplicity」](http://svip.iocoder.cn/Netty/ChannelHandler-1-intro/#) 小节，已经有详细解析。

# 2. 核心类

ChannelHandler 的**核心类**的类图如下图：

![核心类图](http://static2.iocoder.cn/images/Netty/2018_10_01/01.png)

- ChannelInboundHandler ，在 [《精尽 Netty 源码解析 —— ChannelPipeline（五）之 Inbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-5-inbound) 有详细解析。

- ChannelOutboundHandler ，在 [《精尽 Netty 源码解析 —— ChannelPipeline（六）之 Outbound 事件的传播》](http://svip.iocoder.cn/Netty/Pipeline-6-outbound) 有详细解析。

- **红框**部分，ChannelHandler Adaptive 实现类，提供默认的骨架( Skeleton )实现。

- **绿框**部分，用于编解码消息的 ChannelHandler 实现类。关于这部分，我们会在 《Codec》专属的章节，而不是在《ChannelHandler》章节。

- 黄框

  部分

  - SimpleChannelInboundHandler ，抽象类，处理**指定类型**的消息。应用程序中，我们可以实现 SimpleChannelInboundHandler 后，实现对**指定类型**的消息的自定义处理。
  - Simple**UserEvent**ChannelHandler ，和 SimpleChannelInboundHandler 基本一致，差别在于将指定类型的消息，改成了制定类型的事件。
  - 详细解析，见 [《精尽 Netty 源码解析 —— ChannelHandler（三）之 SimpleChannelInboundHandler》](http://svip.iocoder.cn/Netty/ChannelHandler-3-SimpleChannelInboundHandler) 。

- ChannelInitializer ，一个**特殊**的 ChannelHandler ，用于 Channel 注册到 EventLoop 后，**执行自定义的初始化操作**。一般情况下，初始化自定义的 ChannelHandler 到 Channel 中。详细解析，见 [《精尽 Netty 源码解析 —— ChannelHandler（二）之 ChannelInitializer》](http://svip.iocoder.cn/Netty/ChannelHandler-2-ChannelInitializer) 。

# 3. ChannelHandlerAdaptive

在看看 ChannelHandlerAdaptive 的具体代码实现之前，我们先一起了解 ChannelHandlerAdaptive 的设计思想。在《Netty 权威指南》如是说：

> 对于大多数的 ChannelHandler 会选择性地拦截和处理某个或者某些事件，其他的事件会忽略，由下一个 ChannelHandler 进行拦截和处理。这就会导致一个问题：用户 ChannelHandler 必须要实现 ChannelHandler 的所有接口，包括它不关心的那些事件处理接口，这会导致用户代码的冗余和臃肿，代码的可维护性也会变差。
>
> 为了解决这个问题，Netty提供了ChannelHandlerAdapter基类，它的所有接口实现都是事件透传，如果用户ChannelHandler关心某个事件，只需要覆盖ChannelHandlerAdapter对应的方法即可，对于不关心的，可以直接继承使用父类的方法，这样子类的代码就会非常简洁和清晰。

😈 下面，我们看到的其它 Adaptive 实现类，也是这样的设计思想。

------

`io.netty.channel.ChannelHandlerAdapter` ，实现 ChannelHandler 接口，ChannelHandler Adapter 抽象类。

## 3.1 isSharable

```
// Not using volatile because it's used only for a sanity check.
/**
 * 是否已经初始化
 */
boolean added;

/**
 * Throws {@link IllegalStateException} if {@link ChannelHandlerAdapter#isSharable()} returns {@code true}
 */
protected void ensureNotSharable() {
    if (isSharable()) {
        throw new IllegalStateException("ChannelHandler " + getClass().getName() + " is not allowed to be shared");
    }
}

/**
 * Return {@code true} if the implementation is {@link Sharable} and so can be added
 * to different {@link ChannelPipeline}s.
 */
public boolean isSharable() {
    /**
     * Cache the result of {@link Sharable} annotation detection to workaround a condition. We use a
     * {@link ThreadLocal} and {@link WeakHashMap} to eliminate the volatile write/reads. Using different
     * {@link WeakHashMap} instances per {@link Thread} is good enough for us and the number of
     * {@link Thread}s are quite limited anyway.
     *
     * See <a href="https://github.com/netty/netty/issues/2289">#2289</a>.
     */
    Class<?> clazz = getClass();
    Map<Class<?>, Boolean> cache = InternalThreadLocalMap.get().handlerSharableCache();
    Boolean sharable = cache.get(clazz);
    if (sharable == null) {
        sharable = clazz.isAnnotationPresent(Sharable.class);
        cache.put(clazz, sharable);
    }
    return sharable;
}
```

- 这块内容，和 `@Sharable` 注解相关。在 [《精尽 Netty 源码解析 —— ChannelPipeline（二）之添加 ChannelHandler》](http://svip.iocoder.cn/Netty/Pipeline-2-add-channel-handler?self) 的 [「3. checkMultiplicity」](http://svip.iocoder.cn/Netty/ChannelHandler-1-intro/#) 小节，已经有详细解析。

## 3.2 具体实现

```
/**
 * Do nothing by default, sub-classes may override this method.
 */
@Override
public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
    // NOOP
}

/**
 * Do nothing by default, sub-classes may override this method.
 */
@Override
public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
    // NOOP
}

/**
 * Calls {@link ChannelHandlerContext#fireExceptionCaught(Throwable)} to forward
 * to the next {@link ChannelHandler} in the {@link ChannelPipeline}.
 *
 * Sub-classes may override this method to change behavior.
 */
@Override
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
    ctx.fireExceptionCaught(cause);
}
```

- 对于 `#handlerAdded(ChannelHandlerContext ctx)` 和 `#handlerRemoved(ChannelHandlerContext ctx)` 方法，默认无任何逻辑。子类如果有自定义的逻辑，可以进行覆写对应的方法。
- `#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法，直接转发到下一个节点，**实际上**也是默认无任何逻辑。子类如果有自定义的逻辑，可以进行覆写对应的方法。

# 4. ChannelOutboundHandlerAdapter

`io.netty.channel.ChannelOutboundHandlerAdapter` ，实现 ChannelOutboundHandler 接口，继承 ChannelHandlerAdapter 抽象类，ChannelOutboundHandler Adapter 实现类。代码如下：

```
public class ChannelOutboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelOutboundHandler {

    /**
     * Calls {@link ChannelHandlerContext#bind(SocketAddress, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
        ctx.bind(localAddress, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#connect(SocketAddress, SocketAddress, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception {
        ctx.connect(remoteAddress, localAddress, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#disconnect(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.disconnect(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#close(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.close(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#deregister(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.deregister(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#read()} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void read(ChannelHandlerContext ctx) throws Exception {
        ctx.read();
    }

    /**
     * Calls {@link ChannelHandlerContext#write(Object, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
        ctx.write(msg, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#flush()} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void flush(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();
    }

}
```

- 每个实现方法，直接转发到下一个节点，**实际上**也是默认无任何逻辑。子类如果有自定义的逻辑，可以进行覆写对应的方法。

# 5. ChannelInboundHandlerAdapter

`io.netty.channel.ChannelInboundHandlerAdapter` ，实现 ChannelInboundHandler 接口，继承 ChannelHandlerAdapter 抽象类，ChannelInboundHandler Adapter 实现类。代码如下：

```
public class ChannelInboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelInboundHandler {

    /**
     * Calls {@link ChannelHandlerContext#fireChannelRegistered()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelRegistered(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelRegistered();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelUnregistered()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelUnregistered(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelUnregistered();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelActive()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelActive();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelInactive()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelInactive();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelRead(Object)} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        ctx.fireChannelRead(msg);
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelReadComplete()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelReadComplete();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireUserEventTriggered(Object)} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
        ctx.fireUserEventTriggered(evt);
    }

    /**
     * Calls {@link ChannelHandlerContext#fireChannelWritabilityChanged()} to forward
     * to the next {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelWritabilityChanged();
    }

    /**
     * Calls {@link ChannelHandlerContext#fireExceptionCaught(Throwable)} to forward
     * to the next {@link ChannelHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.fireExceptionCaught(cause);
    }
    
}
```

- 每个实现方法，直接转发到下一个节点，**实际上**也是默认无任何逻辑。子类如果有自定义的逻辑，可以进行覆写对应的方法。

# 6. ChannelDuplexHandler

`io.netty.channel.ChannelDuplexHandler` ，实现 ChannelOutboundHandler 接口，继承 ChannelInboundHandlerAdapter 抽象类，Channel Duplex Handler 实现类，支持对 Inbound 和 Outbound 事件的 Adaptive 处理，所以命名上带有“**Duplex**”( 双重 )。代码如下：

```
public class ChannelDuplexHandler extends ChannelInboundHandlerAdapter implements ChannelOutboundHandler {

    /**
     * Calls {@link ChannelHandlerContext#bind(SocketAddress, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
        ctx.bind(localAddress, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#connect(SocketAddress, SocketAddress, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception {
        ctx.connect(remoteAddress, localAddress, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#disconnect(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.disconnect(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#close(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.close(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#close(ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
        ctx.deregister(promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#read()} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void read(ChannelHandlerContext ctx) throws Exception {
        ctx.read();
    }

    /**
     * Calls {@link ChannelHandlerContext#write(Object, ChannelPromise)} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
        ctx.write(msg, promise);
    }

    /**
     * Calls {@link ChannelHandlerContext#flush()} to forward
     * to the next {@link ChannelOutboundHandler} in the {@link ChannelPipeline}.
     *
     * Sub-classes may override this method to change behavior.
     */
    @Override
    public void flush(ChannelHandlerContext ctx) throws Exception {
        ctx.flush();
    }

}
```

- 实现代码上，和 [「4. ChannelOutboundHandlerAdapter」](http://svip.iocoder.cn/Netty/ChannelHandler-1-intro/#) 是一致的。因为 Java 不支持**多继承**的特性，所以不得又重新实现一遍。

😈 大多数情况下，我们会实现 ChannelDuplexHandler 类，覆写部分方法，处理对应的事件。

# 666. 彩蛋

小小水文一篇，主要帮胖友梳理下，对 ChannelHandler 有整体的认识。在后续的文章中，我们会看具体的一个一个 ChannelHandler 的带有“业务”的实现类。

推荐阅读如下文章：

- Hypercube [《自顶向下深入分析Netty（八）–ChannelHandler》](https://www.jianshu.com/p/a9bcd89553f5)

# ChannelHandler（二）之 ChannelInitializer



# 1. 概述

本文，我们来分享 **ChannelInitializer** 。它是一个**特殊**的ChannelInboundHandler 实现类，用于 Channel 注册到 EventLoop 后，**执行自定义的初始化操作**。一般情况下，初始化自定义的 ChannelHandler 到 Channel 中。例如：

- 在 [《精尽 Netty 源码分析 —— 启动（一）之服务端》](http://svip.iocoder.cn/Netty/bootstrap-1-server) 一文中，ServerBootstrap 初始化时，通过 ChannelInitializer 初始化了用于接受( accept )新连接的 ServerBootstrapAcceptor 。
- 在有新连接接入时，服务端通过 ChannelInitializer 初始化，为客户端的 Channel 添加自定义的 ChannelHandler ，用于处理该 Channel 的读写( read/write ) 事件。

OK，让我们看看具体的代码实现落。

# 2. ChannelInitializer

`io.netty.channel.ChannelInitializer` ，继承 ChannelInboundHandlerAdapter 类，Channel Initializer **抽象类**。代码如下：

```
@Sharable
public abstract class ChannelInitializer<C extends Channel> extends ChannelInboundHandlerAdapter {
```

- 通过 `@Sharable` 注解，支持共享。

## 2.1 initChannel

`#initChannel(ChannelHandlerContext ctx)` 方法，执行行自定义的初始化操作。代码如下：

```
// We use a ConcurrentMap as a ChannelInitializer is usually shared between all Channels in a Bootstrap /
// ServerBootstrap. This way we can reduce the memory usage compared to use Attributes.
/**
 * 由于 ChannelInitializer 可以在 Bootstrap/ServerBootstrap 的所有通道中共享，所以我们用一个 ConcurrentMap 作为初始化器。
 * 这种方式，相对于使用 {@link io.netty.util.Attribute} 方式，减少了内存的使用。
 */
private final ConcurrentMap<ChannelHandlerContext, Boolean> initMap = PlatformDependent.newConcurrentHashMap();

  1: private boolean initChannel(ChannelHandlerContext ctx) throws Exception {
  2:     if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) { // Guard against re-entrance. 解决并发问题
  3:         try {
  4:             // 初始化通道
  5:             initChannel((C) ctx.channel());
  6:         } catch (Throwable cause) {
  7:             // 发生异常时，执行异常处理
  8:             // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...).
  9:             // We do so to prevent multiple calls to initChannel(...).
 10:             exceptionCaught(ctx, cause);
 11:         } finally {
 12:             // 从 pipeline 移除 ChannelInitializer
 13:             remove(ctx);
 14:         }
 15:         return true; // 初始化成功
 16:     }
 17:     return false; // 初始化失败
 18: }
```

- 第 2 行：通过 `initMap` 属性，解决并发问题。对应 Netty Git 提交是 <https://github.com/netty/netty/commit/26aa34853a8974d212e12b98e708790606bea5fa> 。

- 第 5 行：调用 `#initChannel(C ch)` **抽象**方法，执行行自定义的初始化操作。代码如下：

  ```
  /**
   * This method will be called once the {@link Channel} was registered. After the method returns this instance
   * will be removed from the {@link ChannelPipeline} of the {@link Channel}.
   *
   * @param ch            the {@link Channel} which was registered.
   * @throws Exception    is thrown if an error occurs. In that case it will be handled by
   *                      {@link #exceptionCaught(ChannelHandlerContext, Throwable)} which will by default close
   *                      the {@link Channel}.
   */
  protected abstract void initChannel(C ch) throws Exception;
  ```

  - 子类继承 ChannelInitializer 抽象类后，实现该方法，自定义 Channel 的初始化逻辑。

- 第 6 至 10 行：调用 `#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法，发生异常时，执行异常处理。代码如下：

  ```
  /**
   * Handle the {@link Throwable} by logging and closing the {@link Channel}. Sub-classes may override this.
   */
  @Override
  public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
      if (logger.isWarnEnabled()) {
          logger.warn("Failed to initialize a channel. Closing: " + ctx.channel(), cause);
      }
      ctx.close();
  }
  ```

  - 打印**告警**日志。
  - **关闭** Channel 通道。因为，初始化 Channel 通道发生异常，意味着很大可能，无法正常处理该 Channel 后续的读写事件。
  - 😈 当然，`#exceptionCaught(...)` 方法，并非使用 `final` 修饰。所以也可以在子类覆写该方法。当然，笔者在实际使用并未这么做过。

- 第 11 至 14 行：最终，调用 `#remove(ChannelHandlerContext ctx)` 方法，从 pipeline 移除 ChannelInitializer。代码如下：

  ```
  private void remove(ChannelHandlerContext ctx) {
      try {
          // 从 pipeline 移除 ChannelInitializer
          ChannelPipeline pipeline = ctx.pipeline();
          if (pipeline.context(this) != null) {
              pipeline.remove(this);
          }
      } finally {
          initMap.remove(ctx); // 从 initMap 移除
      }
  }
  ```

  - 从 pipeline 移除 ChannelInitializer 后，避免重新初始化的问题。

- 第 15 行：返回 `true` ，表示**有**执行初始化。

- 第 17 行：返回 `false` ，表示**未**执行初始化。

## 2.2 channelRegistered

在 Channel 注册到 EventLoop 上后，会触发 Channel Registered 事件。那么 `ChannelInitializer` 的 `#channelRegistered(ChannelHandlerContext ctx)` 方法，就会处理该事件。而 ChannelInitializer 对该事件的处理逻辑是，初始化 Channel 。代码如下：

```
@Override
@SuppressWarnings("unchecked")
public final void channelRegistered(ChannelHandlerContext ctx) throws Exception {
    // Normally this method will never be called as handlerAdded(...) should call initChannel(...) and remove
    // the handler.
    // <1> 初始化 Channel
    if (initChannel(ctx)) {
        // we called initChannel(...) so we need to call now pipeline.fireChannelRegistered() to ensure we not
        // miss an event.
        // <2.1> 重新触发 Channel Registered 事件
        ctx.pipeline().fireChannelRegistered();
    } else {
        // <2.2> 继续向下一个节点的 Channel Registered 事件
        // Called initChannel(...) before which is the expected behavior, so just forward the event.
        ctx.fireChannelRegistered();
    }
}
```

- `<1>` 处，调用 `#initChannel(ChannelHandlerContext ctx)` 方法，初始化 Channel 。
- `<2.1>` 处，若有初始化，**重新触发** Channel Registered 事件。因为，很有可能添加了新的 ChannelHandler 到 pipeline 中。
- `<2.2>` 处，若无初始化，**继续向下一个节点**的 Channel Registered 事件。

## 2.3 handlerAdded

`ChannelInitializer#handlerAdded(ChannelHandlerContext ctx)` 方法，代码如下：

```
@Override
public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
    if (ctx.channel().isRegistered()) { // 已注册
        // This should always be true with our current DefaultChannelPipeline implementation.
        // The good thing about calling initChannel(...) in handlerAdded(...) is that there will be no ordering
        // surprises if a ChannelInitializer will add another ChannelInitializer. This is as all handlers
        // will be added in the expected order.
        initChannel(ctx);
    }
}
```

- 诶？怎么这里又调用了 `#initChannel(ChannelHandlerContext ctx)` 方法，初始化 Channel 呢？实际上，绝绝绝大多数情况下，因为 Channel Registered 事件触发在 Added **之后**，如果说在 `#handlerAdded(ChannelHandlerContext ctx)` 方法中，初始化 Channel 完成，那么 ChannelInitializer 便会从 pipeline 中移除。也就说，不会执行 `#channelRegistered(ChannelHandlerContext ctx)` 方法。

- ↑↑↑ 上面这段话听起来非常绕噢。简单来说，ChannelInitializer 调用 `#initChannel(ChannelHandlerContext ctx)` 方法，初始化 Channel 的调用来源，是来自 `#handlerAdded(...)` 方法，而不是 `#channelRegistered(...)` 方法。

- 还是不理解？胖友在

   

  ```
  #handlerAdded(ChannelHandlerContext ctx)
  ```

   

  方法上打上“

  断点

  ”，并调试启动

   

  ```
  io.netty.example.echo.EchoServer
  ```

   

  ，就能触发这种情况。原因是什么呢？如下图所示：

  ![register0](http://static2.iocoder.cn/images/Netty/2018_10_04/02.png)

  - 😈 红框部分，看到否？明白了哇。

至于说，什么时候使用 ChannelInitializer 调用 `#initChannel(ChannelHandlerContext ctx)` 方法，初始化 Channel 的调用来源，是来自 `#channelRegistered(...)` 方法，笔者暂未发现。如果有知道的胖友，麻烦深刻教育我下。

TODO 1020 ChannelInitializer 对 channelRegistered 的触发

# 666. 彩蛋

小水文一篇。同时也推荐阅读：

- Donald_Draper [《netty 通道初始化器ChannelInitializer》](http://donald-draper.iteye.com/blog/2389352)

# ChannelHandler（三）之 SimpleChannelInboundHandler



# 1. 概述

在本文，我们来分享 SimpleChannelInboundHandler 处理器。考虑到 Simple**UserEvent**ChannelHandler 和 SimpleChannelInboundHandler 的实现基本一致，所以也会在本文中分享。

如果胖友对 SimpleChannelInboundHandler 的使用不了解，请先看下 [《一起学Netty（三）之 SimpleChannelInboundHandler》](https://blog.csdn.net/linuu/article/details/51307060) ，嘿嘿。

# 2. SimpleChannelInboundHandler

`io.netty.channel.SimpleChannelInboundHandler` ，继承 ChannelInboundHandlerAdapter 类，抽象类，处理**指定类型**的消息。应用程序中，我们可以实现 SimpleChannelInboundHandler 后，实现对**指定类型**的消息的自定义处理。

## 2.1 构造方法

```
public abstract class SimpleChannelInboundHandler<I> extends ChannelInboundHandlerAdapter {

    /**
     * 类型匹配器
     */
    private final TypeParameterMatcher matcher;
    /**
     * 使用完消息，是否自动释放
     *
     * @see #channelRead(ChannelHandlerContext, Object)
     */
    private final boolean autoRelease;

    /**
     * see {@link #SimpleChannelInboundHandler(boolean)} with {@code true} as boolean parameter.
     */
    protected SimpleChannelInboundHandler() {
        this(true);
    }

    /**
     * Create a new instance which will try to detect the types to match out of the type parameter of the class.
     *
     * @param autoRelease   {@code true} if handled messages should be released automatically by passing them to
     *                      {@link ReferenceCountUtil#release(Object)}.
     */
    protected SimpleChannelInboundHandler(boolean autoRelease) {
        // <1> 获得 matcher
        matcher = TypeParameterMatcher.find(this, SimpleChannelInboundHandler.class, "I");
        this.autoRelease = autoRelease;
    }

    /**
     * see {@link #SimpleChannelInboundHandler(Class, boolean)} with {@code true} as boolean value.
     */
    protected SimpleChannelInboundHandler(Class<? extends I> inboundMessageType) {
        this(inboundMessageType, true);
    }

    /**
     * Create a new instance
     *
     * @param inboundMessageType    The type of messages to match
     * @param autoRelease           {@code true} if handled messages should be released automatically by passing them to
     *                              {@link ReferenceCountUtil#release(Object)}.
     */
    protected SimpleChannelInboundHandler(Class<? extends I> inboundMessageType, boolean autoRelease) {
        // <2> 获得 matcher
        matcher = TypeParameterMatcher.get(inboundMessageType);
        this.autoRelease = autoRelease;
    }
    
    // ... 省略其它方法
}
```

- ```
  matcher
  ```

   

  属性，有

  两种

  方式赋值。

  - 【常用】`<1>` 处，使用类的 `I` 泛型对应的 TypeParameterMatcher 类型匹配器。
  - `<2>` 处，使用 `inboundMessageType` 参数对应的 TypeParameterMatcher 类型匹配器。
  - 在大多数情况下，我们不太需要特别详细的了解 `io.netty.util.internal.TypeParameterMatcher` 的代码实现，感兴趣的胖友可以自己看看 [《netty 简单Inbound通道处理器（SimpleChannelInboundHandler）》](http://donald-draper.iteye.com/blog/2387772) 的 [「TypeParameterMatcher」](http://svip.iocoder.cn/Netty/ChannelHandler-3-SimpleChannelInboundHandler/#)部分。

- `autoRelease` 属性，使用完消息，是否自动释放。

## 2.2 acceptInboundMessage

`#acceptInboundMessage(Object msg)` 方法，判断消息是否匹配。代码如下：

```
/**
 * Returns {@code true} if the given message should be handled. If {@code false} it will be passed to the next
 * {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
 */
public boolean acceptInboundMessage(Object msg) {
    return matcher.match(msg);
}
```

一般情况下，`matcher` 的类型是 ReflectiveMatcher( 它是 TypeParameterMatcher 的内部类 )。代码如下：

```
private static final class ReflectiveMatcher extends TypeParameterMatcher {
    
    /**
     * 类型
     */
    private final Class<?> type;
    
    ReflectiveMatcher(Class<?> type) {
        this.type = type;
    }
    
    @Override
    public boolean match(Object msg) {
        return type.isInstance(msg); // <1>
    }
    
}
```

- 匹配逻辑，看 `<1>` 处，使用 `Class#isInstance(Object obj)` 方法。对于这个方法，如果我们定义的 `I` 泛型是个父类，那可以匹配所有的子类。例如 `I` 设置为 Object 类，那么所有消息，都可以被匹配列。

## 2.3 channelRead

```
 1: @Override
 2: public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
 3:     // 是否要释放消息
 4:     boolean release = true;
 5:     try {
 6:         // 判断是否为匹配的消息
 7:         if (acceptInboundMessage(msg)) {
 8:             @SuppressWarnings("unchecked")
 9:             I imsg = (I) msg;
10:             // 处理消息
11:             channelRead0(ctx, imsg);
12:         } else {
13:             // 不需要释放消息
14:             release = false;
15:             // 触发 Channel Read 到下一个节点
16:             ctx.fireChannelRead(msg);
17:         }
18:     } finally {
19:         // 判断，是否要释放消息
20:         if (autoRelease && release) {
21:             ReferenceCountUtil.release(msg);
22:         }
23:     }
24: }
```

- 第 4 行：`release` 属性，是否需要释放消息。

- 第 7 行：调用 `#acceptInboundMessage(Object msg)` 方法，判断是否为匹配的消息。

  - ① **匹配**，调用 `#channelRead0(ChannelHandlerContext ctx, I msg)` **抽象**方法，处理消息。代码如下：

    ```
    /**
     * <strong>Please keep in mind that this method will be renamed to
     * {@code messageReceived(ChannelHandlerContext, I)} in 5.0.</strong>
     *
     * Is called for each message of type {@link I}.
     *
     * @param ctx           the {@link ChannelHandlerContext} which this {@link SimpleChannelInboundHandler}
     *                      belongs to
     * @param msg           the message to handle
     * @throws Exception    is thrown if an error occurred
     */
    protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception;
    ```

    - 子类实现 SimpleChannelInboundHandler 类后，实现该方法，就能很方便的处理消息。

  - ② **不匹配**，标记不需要释放消息，并触发 Channel Read 到**下一个节点**。

- 第 18 至 23 行：通过 `release` 变量 + `autoRelease` 属性，判断是否需要释放消息。若需要，调用 `ReferenceCountUtil#release(Object msg)` 方法，释放消息。😈 还是蛮方便的。

# 3. SimpleUserEventChannelHandler

`io.netty.channel.SimpleUserEventChannelHandler` ，继承 ChannelInboundHandlerAdapter 类，抽象类，处理**指定事件**的消息。

SimpleUserEventChannelHandler 和 SimpleChannelInboundHandler 基本一致，差别在于将指定类型的消息，改成了制定类型的事件。😈 所以，笔者就不详细解析了。

代码如下：

```
public abstract class SimpleUserEventChannelHandler<I> extends ChannelInboundHandlerAdapter {

    /**
     * 类型匹配器
     */
    private final TypeParameterMatcher matcher;
    /**
     * 使用完消息，是否自动释放
     *
     * @see #channelRead(ChannelHandlerContext, Object)
     */
    private final boolean autoRelease;

    /**
     * see {@link #SimpleUserEventChannelHandler(boolean)} with {@code true} as boolean parameter.
     */
    protected SimpleUserEventChannelHandler() {
        this(true);
    }

    /**
     * Create a new instance which will try to detect the types to match out of the type parameter of the class.
     *
     * @param autoRelease   {@code true} if handled events should be released automatically by passing them to
     *                      {@link ReferenceCountUtil#release(Object)}.
     */
    protected SimpleUserEventChannelHandler(boolean autoRelease) {
        matcher = TypeParameterMatcher.find(this, SimpleUserEventChannelHandler.class, "I");
        this.autoRelease = autoRelease;
    }

    /**
     * see {@link #SimpleUserEventChannelHandler(Class, boolean)} with {@code true} as boolean value.
     */
    protected SimpleUserEventChannelHandler(Class<? extends I> eventType) {
        this(eventType, true);
    }

    /**
     * Create a new instance
     *
     * @param eventType      The type of events to match
     * @param autoRelease    {@code true} if handled events should be released automatically by passing them to
     *                       {@link ReferenceCountUtil#release(Object)}.
     */
    protected SimpleUserEventChannelHandler(Class<? extends I> eventType, boolean autoRelease) {
        matcher = TypeParameterMatcher.get(eventType);
        this.autoRelease = autoRelease;
    }

    /**
     * Returns {@code true} if the given user event should be handled. If {@code false} it will be passed to the next
     * {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
     */
    protected boolean acceptEvent(Object evt) throws Exception {
        return matcher.match(evt);
    }

    @Override
    public final void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
        // 是否要释放消息
        boolean release = true;
        try {
            // 判断是否为匹配的消息
            if (acceptEvent(evt)) {
                @SuppressWarnings("unchecked")
                I ievt = (I) evt;
                // 处理消息
                eventReceived(ctx, ievt);
            } else {
                // 不需要释放消息
                release = false;
                // 触发 Channel Read 到下一个节点
                ctx.fireUserEventTriggered(evt);
            }
        } finally {
            // 判断，是否要释放消息
            if (autoRelease && release) {
                ReferenceCountUtil.release(evt);
            }
        }
    }

    /**
     * Is called for each user event triggered of type {@link I}.
     *
     * @param ctx the {@link ChannelHandlerContext} which this {@link SimpleUserEventChannelHandler} belongs to
     * @param evt the user event to handle
     *
     * @throws Exception is thrown if an error occurred
     */
    protected abstract void eventReceived(ChannelHandlerContext ctx, I evt) throws Exception;

}
```

# 666. 彩蛋

木有彩蛋，hoho 。

# ChannelHandler（四）之 LoggingHandler



# 1. 概述

在 `netty-handler` 模块中，提供了多种 ChannelHandler 的实现类。如下图所示：![`netty-handler`](http://static2.iocoder.cn/images/Netty/2018_10_10/01.png)

- 每个 `package` 包，对应一个**功能特性**的 ChannelHandler 实现。

本文，我们来分享 `logger` 包下 `logging` 包的 LoggerHandler 。

# 2. LogLevel

`io.netty.handler.logging.LogLevel` ，日志级别枚举类。代码如下：

```
/**
 * Maps the regular {@link LogLevel}s with the {@link InternalLogLevel} ones.
 */
public enum LogLevel {

    TRACE(InternalLogLevel.TRACE),
    DEBUG(InternalLogLevel.DEBUG),
    INFO(InternalLogLevel.INFO),
    WARN(InternalLogLevel.WARN),
    ERROR(InternalLogLevel.ERROR);

    /**
     * Netty 内部日志级别
     */
    private final InternalLogLevel internalLevel;

    LogLevel(InternalLogLevel internalLevel) {
        this.internalLevel = internalLevel;
    }

    /**
     * For internal use only.
     *
     * <p/>Converts the specified {@link LogLevel} to its {@link InternalLogLevel} variant.
     *
     * @return the converted level.
     */
    public InternalLogLevel toInternalLevel() {
        return internalLevel;
    }

}
```

- Netty 提供了一套日志框架，方便接入 slf4j、log4j、jdk logger 等等日志框架。感兴趣的胖友，可以看看 [《Netty4.x Internal Logger机制》](https://segmentfault.com/a/1190000005797595) 。😈 现在，不看也不影响对本文的理解。
- LogLevel 实现对 `io.netty.util.internal.logging.InternalLogLevel` 的**一一**映射。笔者暂时看不出有什么神奇的用途，难道是为了可以灵活的修改映射关系？！有了解的胖友，可以深刻教育下我噢。

# 3. LoggingHandler

`io.netty.handler.logging.LoggingHandler` ，继承 ChannelDuplexHandler 类，日志处理器，对 Inbound/Outbound 事件进行日志的记录。一般情况下，用于开发测试时的调试之用。

## 3.1 构造方法

```
@Sharable
public class LoggingHandler extends ChannelDuplexHandler {

    /**
     * 默认 {@link #level} 日志级别
     */
    private static final LogLevel DEFAULT_LEVEL = LogLevel.DEBUG;

    /**
     * Netty 内部 Logger 对象
     */
    protected final InternalLogger logger;
    /**
     * Netty 内部 LogLevel 级别
     */
    protected final InternalLogLevel internalLevel;

    /**
     * 配置的 LogLevel 级别
     */
    private final LogLevel level;

    /**
     * Creates a new instance whose logger name is the fully qualified class
     * name of the instance with hex dump enabled.
     */
    public LoggingHandler() {
        this(DEFAULT_LEVEL);
    }

    /**
     * Creates a new instance whose logger name is the fully qualified class
     * name of the instance.
     *
     * @param level the log level
     */
    public LoggingHandler(LogLevel level) {
        if (level == null) {
            throw new NullPointerException("level");
        }

        // 获得 logger
        logger = InternalLoggerFactory.getInstance(getClass());
        this.level = level;
        internalLevel = level.toInternalLevel();
    }

    /**
     * Creates a new instance with the specified logger name and with hex dump
     * enabled.
     *
     * @param clazz the class type to generate the logger for
     */
    public LoggingHandler(Class<?> clazz) {
        this(clazz, DEFAULT_LEVEL);
    }

    /**
     * Creates a new instance with the specified logger name.
     *
     * @param clazz the class type to generate the logger for
     * @param level the log level
     */
    public LoggingHandler(Class<?> clazz, LogLevel level) {
        if (clazz == null) {
            throw new NullPointerException("clazz");
        }
        if (level == null) {
            throw new NullPointerException("level");
        }

        // 获得 logger
        logger = InternalLoggerFactory.getInstance(clazz);
        this.level = level;
        internalLevel = level.toInternalLevel();
    }

    /**
     * Creates a new instance with the specified logger name using the default log level.
     *
     * @param name the name of the class to use for the logger
     */
    public LoggingHandler(String name) {
        this(name, DEFAULT_LEVEL);
    }

    /**
     * Creates a new instance with the specified logger name.
     *
     * @param name the name of the class to use for the logger
     * @param level the log level
     */
    public LoggingHandler(String name, LogLevel level) {
        if (name == null) {
            throw new NullPointerException("name");
        }
        if (level == null) {
            throw new NullPointerException("level");
        }

        // 获得 logger
        logger = InternalLoggerFactory.getInstance(name);
        this.level = level;
        internalLevel = level.toInternalLevel();
    }
    
    // ... 省略其他方法
}
```

- 通过 `@Sharable` 注解，支持共享。

- ```
  level
  ```

   

  属性，配置的 LogLevel 级别。

  - `DEFAULT_LEVEL` **静态**属性，默认的 `level` 级别。构造方法如果未传递 `LogLevel level` 方法参数，则使用默认值。
  - `internalLevel` 属性，Netty 内部 LogLevel 级别。通过 `LogLevel#toInternalLevel()` 方法，将 `level` 转化成 `internalLevel` 。

- `logger` 属性，Netty 内部 Logger 对象。通过 `Class<?> clazz` 或 `String name` 方法参数，进行获得。

## 3.2 具体实现

```
@Override
public void channelRegistered(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "REGISTERED"));
    }
    //
    ctx.fireChannelRegistered();
}

@Override
public void channelUnregistered(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "UNREGISTERED"));
    }
    ctx.fireChannelUnregistered();
}

@Override
public void channelActive(ChannelHandlerContext ctx) throws Exception {
    // 打印日志
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "ACTIVE"));
    }
    // 传递 Channel active 事件，给下一个节点
    ctx.fireChannelActive();
}

@Override
public void channelInactive(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "INACTIVE"));
    }
    ctx.fireChannelInactive();
}

@Override
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "EXCEPTION", cause), cause);
    }
    ctx.fireExceptionCaught(cause);
}

@Override
public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "USER_EVENT", evt));
    }
    ctx.fireUserEventTriggered(evt);
}

@Override
public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "BIND", localAddress));
    }
    ctx.bind(localAddress, promise);
}

@Override
public void connect(
        ChannelHandlerContext ctx,
        SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "CONNECT", remoteAddress, localAddress));
    }
    ctx.connect(remoteAddress, localAddress, promise);
}

@Override
public void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "DISCONNECT"));
    }
    ctx.disconnect(promise);
}

@Override
public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "CLOSE"));
    }
    ctx.close(promise);
}

@Override
public void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "DEREGISTER"));
    }
    ctx.deregister(promise);
}

@Override
public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "READ COMPLETE"));
    }
    ctx.fireChannelReadComplete();
}

@Override
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "READ", msg));
    }
    ctx.fireChannelRead(msg);
}

@Override
public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "WRITE", msg));
    }
    ctx.write(msg, promise);
}

@Override
public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "WRITABILITY CHANGED"));
    }
    ctx.fireChannelWritabilityChanged();
}

@Override
public void flush(ChannelHandlerContext ctx) throws Exception {
    if (logger.isEnabled(internalLevel)) {
        logger.log(internalLevel, format(ctx, "FLUSH"));
    }
    ctx.flush();
}
```

里面的每个方法，都是使用 `logger` 打印日志，并继续传播事件到下一个节点。

而打印的日志的格式，通过 `#format(...)` 方法，进行拼接。

## 3.3 format

`#format(...)` 方法，根据参数的不同，分成三种。

① `#format(ChannelHandlerContext ctx, String eventName)` 方法，代码如下：

```
/**
 * Formats an event and returns the formatted message.
 *
 * @param eventName the name of the event
 */
protected String format(ChannelHandlerContext ctx, String eventName) {
    String chStr = ctx.channel().toString();
    return new StringBuilder(chStr.length() + 1 + eventName.length())
        .append(chStr)
        .append(' ')
        .append(eventName)
        .toString();
}
```

② `#format(ChannelHandlerContext ctx, String eventName, Object arg)` 方法，代码如下：

```
/**
 * Formats an event and returns the formatted message.
 *
 * @param eventName the name of the event
 * @param arg       the argument of the event
 */
protected String format(ChannelHandlerContext ctx, String eventName, Object arg) {
    if (arg instanceof ByteBuf) {
        return formatByteBuf(ctx, eventName, (ByteBuf) arg);
    } else if (arg instanceof ByteBufHolder) {
        return formatByteBufHolder(ctx, eventName, (ByteBufHolder) arg);
    } else {
        return formatSimple(ctx, eventName, arg);
    }
}
```

- 根据参数不同，会调用不同的 format 方法。

③ `#format(ChannelHandlerContext ctx, String eventName, Object firstArg, Object secondArg)` 方法，代码如下：

```
/**
 * Formats an event and returns the formatted message.  This method is currently only used for formatting
 * {@link ChannelOutboundHandler#connect(ChannelHandlerContext, SocketAddress, SocketAddress, ChannelPromise)}.
 *
 * @param eventName the name of the event
 * @param firstArg  the first argument of the event
 * @param secondArg the second argument of the event
 */
protected String format(ChannelHandlerContext ctx, String eventName, Object firstArg, Object secondArg) {
    if (secondArg == null) {
        return formatSimple(ctx, eventName, firstArg);
    }

    String chStr = ctx.channel().toString();
    String arg1Str = String.valueOf(firstArg);
    String arg2Str = secondArg.toString();
    StringBuilder buf = new StringBuilder(
            chStr.length() + 1 + eventName.length() + 2 + arg1Str.length() + 2 + arg2Str.length());
    buf.append(chStr).append(' ').append(eventName).append(": ").append(arg1Str).append(", ").append(arg2Str);
    return buf.toString();
}
```

### 3.3.1 formatByteBuf

`#formatByteBuf(ChannelHandlerContext ctx, String eventName, ByteBuf msg)` 方法，代码如下：

```
/**
 * Generates the default log message of the specified event whose argument is a {@link ByteBuf}.
 */
private static String formatByteBuf(ChannelHandlerContext ctx, String eventName, ByteBuf msg) {
    String chStr = ctx.channel().toString();
    int length = msg.readableBytes();
    if (length == 0) {
        StringBuilder buf = new StringBuilder(chStr.length() + 1 + eventName.length() + 4);
        buf.append(chStr).append(' ').append(eventName).append(": 0B");
        return buf.toString();
    } else {
        int rows = length / 16 + (length % 15 == 0? 0 : 1) + 4;
        StringBuilder buf = new StringBuilder(chStr.length() + 1 + eventName.length() + 2 + 10 + 1 + 2 + rows * 80);

        buf.append(chStr).append(' ').append(eventName).append(": ").append(length).append('B').append(NEWLINE);
        appendPrettyHexDump(buf, msg); // <1>

        return buf.toString();
    }
}
```

- `<1>` 处的 `appendPrettyHexDump(buf, msg)` ，实际调用的是 `ByteBufUtil#appendPrettyHexDump(StringBuilder dump, ByteBuf buf)` 方法。

如下是一个打印的示例：

> FROM [《自顶向下深入分析Netty（八）–ChannelHandler》](https://www.jianshu.com/p/a9bcd89553f5)
>
> ![示例](http://static2.iocoder.cn/images/Netty/2018_10_10/02.png)

### 3.3.2 formatByteBufHolder

`#formatByteBufHolder(ChannelHandlerContext ctx, String eventName, ByteBufHolder msg)` 方法，代码如下：

```
/**
 * Generates the default log message of the specified event whose argument is a {@link ByteBufHolder}.
 */
private static String formatByteBufHolder(ChannelHandlerContext ctx, String eventName, ByteBufHolder msg) {
    String chStr = ctx.channel().toString();
    String msgStr = msg.toString();
    ByteBuf content = msg.content();
    int length = content.readableBytes();
    if (length == 0) {
        StringBuilder buf = new StringBuilder(chStr.length() + 1 + eventName.length() + 2 + msgStr.length() + 4);
        buf.append(chStr).append(' ').append(eventName).append(", ").append(msgStr).append(", 0B");
        return buf.toString();
    } else {
        int rows = length / 16 + (length % 15 == 0? 0 : 1) + 4;
        StringBuilder buf = new StringBuilder(chStr.length() + 1 + eventName.length() + 2 + msgStr.length() + 2 + 10 + 1 + 2 + rows * 80);

        buf.append(chStr).append(' ').append(eventName).append(": ").append(msgStr).append(", ").append(length).append('B').append(NEWLINE);
        appendPrettyHexDump(buf, content);

        return buf.toString();
    }
}
```

- 和 `#formatByteBuf(ChannelHandlerContext ctx, String eventName, ByteBuf msg)` 方法，实际打印的效果，非常相似。

### 3.3.3 formatSimple

`#formatSimple(ChannelHandlerContext ctx, String eventName, Object msg)` 方法，代码如下：

```
/**
 * Generates the default log message of the specified event whose argument is an arbitrary object.
 */
private static String formatSimple(ChannelHandlerContext ctx, String eventName, Object msg) {
    String chStr = ctx.channel().toString();
    String msgStr = String.valueOf(msg);
    StringBuilder buf = new StringBuilder(chStr.length() + 1 + eventName.length() + 2 + msgStr.length());
    return buf.append(chStr).append(' ').append(eventName).append(": ").append(msgStr).toString();
}
```

# 666. 彩蛋

还是没有彩蛋。

# ChannelHandler（五）之 IdleStateHandler



# 1. 概述

在 `netty-handler` 模块的 `timeout` 包，实现 Channel 的读写操作的**空闲**检测。可能有胖友不太了解空闲检测的具体用途。请先研读理解下 [《简易RPC框架-心跳与重连机制》](https://www.cnblogs.com/ASPNET2008/p/7615973.html) 。

# 2. 类

`timeout` 包，包含的类，如下图所示：![`timeout` 包](http://static2.iocoder.cn/images/Netty/2018_10_13/01.png)

一共有 3 个 ChannelHandler 实现类：

- IdleStateHandler ，当 Channel 的

  读或者写

  空闲时间太长时，将会触发一个 IdleStateEvent 事件。然后，你可以自定义一个 ChannelInboundHandler ，重写

   

  ```
  #userEventTriggered(ChannelHandlerContext ctx, Object evt)
  ```

   

  方法，处理该事件。

  - ReadTimeoutHandler ，继承 IdleStateHandler 类，当 Channel 的**读**空闲时间( 读或者写 )太长时，抛出 ReadTimeoutException 异常，并自动关闭该 Channel 。然后，你可以自定一个 ChannelInboundHandler ，重写 `#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法，处理该异常。

- WriteTimeoutHandler ，当一个**写**操作不能在指定时间内完成时，抛出 WriteTimeoutException 异常，并自动关闭对应 Channel 。然后，你可以自定一个 ChannelInboundHandler ，重写 `#exceptionCaught(ChannelHandlerContext ctx, Throwable cause)` 方法，处理该异常。

😈 从 WriteTimeoutHandler 可以看出，本文实际不仅仅分享 IdleStateHandler ，更准确的是分享 Timeout 相关的 ChannelHandler 。考虑到大多数胖友对 IdleStateHandler 比较熟悉，也相对常用，所以标题才取了 [《精尽 Netty 源码解析 —— ChannelHandler（五）之 IdleStateHandler》](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 。

# 3. IdleState

`io.netty.handler.timeout.IdleState` ，空闲状态**枚举**。代码如下：

```
/**
 * 空闲状态枚举
 *
 * An {@link Enum} that represents the idle state of a {@link Channel}.
 */
public enum IdleState {

    /**
     * No data was received for a while.
     *
     * 读空闲
     */
    READER_IDLE,
    /**
     * No data was sent for a while.
     *
     * 写空闲
     */
    WRITER_IDLE,
    /**
     * No data was either received or sent for a while.
     *
     * 读或写任一空闲
     */
    ALL_IDLE

}
```

- 一共有 3 种状态。其中，`ALL_IDLE` 表示的是，读**或**写任一空闲，注意是“或”。

## 3.1 IdleStateEvent

`io.netty.handler.timeout.IdleStateEvent` ，空闲事件。代码如下：

```
public class IdleStateEvent {

    // READ
    public static final IdleStateEvent FIRST_READER_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.READER_IDLE, true); // 首次
    public static final IdleStateEvent READER_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.READER_IDLE, false);
    // WRITE
    public static final IdleStateEvent FIRST_WRITER_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.WRITER_IDLE, true); // 首次
    public static final IdleStateEvent WRITER_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.WRITER_IDLE, false);
    // ALL
    public static final IdleStateEvent FIRST_ALL_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.ALL_IDLE, true); // 首次
    public static final IdleStateEvent ALL_IDLE_STATE_EVENT = new IdleStateEvent(IdleState.ALL_IDLE, false);

    /**
     * 空闲状态类型
     */
    private final IdleState state;
    /**
     * 是否首次
     */
    private final boolean first;

    /**
     * Constructor for sub-classes.
     *
     * @param state the {@link IdleStateEvent} which triggered the event.
     * @param first {@code true} if its the first idle event for the {@link IdleStateEvent}.
     */
    protected IdleStateEvent(IdleState state, boolean first) {
        this.state = ObjectUtil.checkNotNull(state, "state");
        this.first = first;
    }

    /**
     * Returns the idle state.
     */
    public IdleState state() {
        return state;
    }

    /**
     * Returns {@code true} if this was the first event for the {@link IdleState}
     */
    public boolean isFirst() {
        return first;
    }

}
```

- 3 **类**( `state` )空闲事件，再组合上是否首次( `first` )，一共有 6 种空闲事件。

# 4. TimeoutException

`io.netty.handler.timeout.TimeoutException` ，继承 ChannelException 类，超时异常。代码如下：

```
public class TimeoutException extends ChannelException {

    TimeoutException() { }

    @Override
    public Throwable fillInStackTrace() {
        return this;
    }

}
```

## 4.1 ReadTimeoutException

`io.netty.handler.timeout.ReadTimeoutException` ，继承 TimeoutException 类，读超时( 空闲 )异常。代码如下：

```
public final class ReadTimeoutException extends TimeoutException {

    /**
     * 单例
     */
    public static final ReadTimeoutException INSTANCE = new ReadTimeoutException();

    private ReadTimeoutException() { }

}
```

## 4.2 WriteTimeoutException

`io.netty.handler.timeout.WriteTimeoutException` ，继承 TimeoutException 类，写超时( 空闲 )异常。代码如下：

```
public final class WriteTimeoutException extends TimeoutException {

    /**
     * 单例
     */
    public static final WriteTimeoutException INSTANCE = new WriteTimeoutException();

    private WriteTimeoutException() { }

}
```

# 5. IdleStateHandler

`io.netty.handler.timeout.IdleStateHandler` ，继承 ChannelDuplexHandler 类，当 Channel 的**读或者写**空闲时间太长时，将会触发一个 IdleStateEvent 事件。

## 5.1 构造方法

> 老艿艿：高能预警，IdleStateHandler 的属性有点点多。

```
/**
 * 最小的超时时间，单位：纳秒
 */
private static final long MIN_TIMEOUT_NANOS = TimeUnit.MILLISECONDS.toNanos(1);

/**
 * 写入任务监听器
 */
// Not create a new ChannelFutureListener per write operation to reduce GC pressure.
private final ChannelFutureListener writeListener = new ChannelFutureListener() {

    @Override
    public void operationComplete(ChannelFuture future) throws Exception {
        // 记录最后写时间
        lastWriteTime = ticksInNanos();
        // 重置 firstWriterIdleEvent 和 firstAllIdleEvent 为 true
        firstWriterIdleEvent = firstAllIdleEvent = true;
    }

};

/**
 * 是否观察 {@link ChannelOutboundBuffer} 写入队列
 */
private final boolean observeOutput;
/**
 * 配置的读空闲时间，单位：纳秒
 */
private final long readerIdleTimeNanos;
/**
 * 配置的写空闲时间，单位：纳秒
 */
private final long writerIdleTimeNanos;
/**
 * 配置的All( 读或写任一 )，单位：纳秒
 */
private final long allIdleTimeNanos;

/**
 * 读空闲的定时检测任务
 */
private ScheduledFuture<?> readerIdleTimeout;
/**
 * 最后读时间
 */
private long lastReadTime;
/**
 * 是否首次读空闲
 */
private boolean firstReaderIdleEvent = true;

/**
 * 写空闲的定时检测任务
 */
private ScheduledFuture<?> writerIdleTimeout;
/**
 * 最后写时间
 */
private long lastWriteTime;
/**
 * 是否首次写空闲
 */
private boolean firstWriterIdleEvent = true;

/**
 * All 空闲时间，单位：纳秒
 */
private ScheduledFuture<?> allIdleTimeout;
/**
 * 是否首次 All 空闲
 */
private boolean firstAllIdleEvent = true;

/**
 * 状态
 *
 * 0 - none ，未初始化
 * 1 - initialized ，已经初始化
 * 2 - destroyed ，已经销毁
 */
private byte state; // 0 - none, 1 - initialized, 2 - destroyed
/**
 * 是否正在读取
 */
private boolean reading;

/**
 * 最后检测到 {@link ChannelOutboundBuffer} 发生变化的时间
 */
private long lastChangeCheckTimeStamp;
/**
 * 第一条准备 flash 到对端的消息( {@link ChannelOutboundBuffer#current()} )的 HashCode
 */
private int lastMessageHashCode;
/**
 * 总共等待 flush 到对端的内存大小( {@link ChannelOutboundBuffer#totalPendingWriteBytes()} )
 */
private long lastPendingWriteBytes;

public IdleStateHandler(int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) {
    this(readerIdleTimeSeconds, writerIdleTimeSeconds, allIdleTimeSeconds, TimeUnit.SECONDS);
}

public IdleStateHandler(long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) {
    this(false, readerIdleTime, writerIdleTime, allIdleTime, unit);
}

/**
 * Creates a new instance firing {@link IdleStateEvent}s.
 *
 * @param observeOutput
 *        whether or not the consumption of {@code bytes} should be taken into
 *        consideration when assessing write idleness. The default is {@code false}.
 * @param readerIdleTime
 *        an {@link IdleStateEvent} whose state is {@link IdleState#READER_IDLE}
 *        will be triggered when no read was performed for the specified
 *        period of time.  Specify {@code 0} to disable.
 * @param writerIdleTime
 *        an {@link IdleStateEvent} whose state is {@link IdleState#WRITER_IDLE}
 *        will be triggered when no write was performed for the specified
 *        period of time.  Specify {@code 0} to disable.
 * @param allIdleTime
 *        an {@link IdleStateEvent} whose state is {@link IdleState#ALL_IDLE}
 *        will be triggered when neither read nor write was performed for
 *        the specified period of time.  Specify {@code 0} to disable.
 * @param unit
 *        the {@link TimeUnit} of {@code readerIdleTime},
 *        {@code writeIdleTime}, and {@code allIdleTime}
 */
public IdleStateHandler(boolean observeOutput, long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) {
    if (unit == null) {
        throw new NullPointerException("unit");
    }

    this.observeOutput = observeOutput;

    if (readerIdleTime <= 0) {
        readerIdleTimeNanos = 0;
    } else {
        readerIdleTimeNanos = Math.max(unit.toNanos(readerIdleTime), MIN_TIMEOUT_NANOS); // 保证大于等于 MIN_TIMEOUT_NANOS
    }
    if (writerIdleTime <= 0) {
        writerIdleTimeNanos = 0;
    } else {
        writerIdleTimeNanos = Math.max(unit.toNanos(writerIdleTime), MIN_TIMEOUT_NANOS); // 保证大于等于 MIN_TIMEOUT_NANOS
    }
    if (allIdleTime <= 0) {
        allIdleTimeNanos = 0;
    } else {
        allIdleTimeNanos = Math.max(unit.toNanos(allIdleTime), MIN_TIMEOUT_NANOS); // 保证大于等于 MIN_TIMEOUT_NANOS
    }
}
```

- 属性比较多，保持耐心和淡定，我们继续来整理一波。

- `MIN_TIMEOUT_NANOS` 静态属性，最小的超时时间为 **1** ，单位：纳秒。因为 IdleStateHandler 创建的，检测定时任务的时间，以纳秒为单位。

- `state` 属性，IdleStateHandler 的状态。一共有三种，见注释。

- Read 空闲相关属性

  - `readerIdleTimeNanos` 属性，配置的读空闲时间，单位：纳秒。
  - `readerIdleTimeout` 属性，读空闲的定时检测任务。
  - `lastReadTime` 属性，读空闲的定时检测任务。
  - `firstReaderIdleEvent` 属性，是否首次读空闲。
  - 【**独有**】 `reading` 属性，是否正在读取。

- Write 空闲相关属性

  - `writerIdleTimeNanos` 属性，配置的写空闲时间，单位：纳秒。

  - `writerIdleTimeout` 属性，写空闲的定时检测任务。

  - `lastWriteTime` 属性，最后写时间。

  - `writeListener` 属性，写入操作，完成 flush 到对端的回调监听器。初始时，创建好，避免重复创建，从而减轻 GC 压力。

  - 【

    独有

    】ChannelOutboundBuffer 相关属性

    - `observeOutput` 属性， 是否观察 ChannelOutboundBuffer 写入队列。
    - `lastChangeCheckTimeStamp` 属性，最后检测到 ChannelOutboundBuffer 发生变化的时间。
    - `lastMessageHashCode` 属性，第一条准备 flash 到对端的消息的 HashCode 。
    - `lastPendingWriteBytes` 属性，总共等待 flush 到对端的内存大小。
    - 关于这几个属性，跟着 [「5.7 hasOutputChanged」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 一起理解。

- ALL 空闲相关属性

  - 因为 ALL 是 Write 和 Read 任一，所以共用它们的一些属性。
  - `allIdleTimeNanos` 属性，配置的All( 读或写任一 )，单位：纳秒。

## 5.2 initialize

`#initialize(ChannelHandlerContext ctx)` 方法，初始化 IdleStateHandler 。代码如下：

```
 1: private void initialize(ChannelHandlerContext ctx) {
 2:     // 校验状态，避免因为 `#destroy()` 方法在 `#initialize(ChannelHandlerContext ctx)` 方法，执行之前
 3:     // Avoid the case where destroy() is called before scheduling timeouts.
 4:     // See: https://github.com/netty/netty/issues/143
 5:     switch (state) {
 6:     case 1:
 7:     case 2:
 8:         return;
 9:     }
10: 
11:     // 标记为已初始化
12:     state = 1;
13:     // 初始化 ChannelOutboundBuffer 相关属性
14:     initOutputChanged(ctx);
15: 
16:     // 初始相应的定时任务
17:     lastReadTime = lastWriteTime = ticksInNanos();
18:     if (readerIdleTimeNanos > 0) {
19:         readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS);
20:     }
21:     if (writerIdleTimeNanos > 0) {
22:         writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS);
23:     }
24:     if (allIdleTimeNanos > 0) {
25:         allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS);
26:     }
27: }
```

- 第 2 至 9 行：校验状态，避免因为 `#destroy()` 方法在 `#initialize(ChannelHandlerContext ctx)` 方法，执行之前。

- 第 12 行：标记 `state` 为已初始化。

- 第 14 行：调用 `#initOutputChanged(ChannelHandlerContext ctx)` 方法，初始化 ChannelOutboundBuffer 相关属性。代码如下：

  ```
  private void initOutputChanged(ChannelHandlerContext ctx) {
      if (observeOutput) {
          Channel channel = ctx.channel();
          Unsafe unsafe = channel.unsafe();
          ChannelOutboundBuffer buf = unsafe.outboundBuffer();
  
          if (buf != null) {
              // 记录第一条准备 flash 到对端的消息的 HashCode
              lastMessageHashCode = System.identityHashCode(buf.current());
              // 记录总共等待 flush 到对端的内存大小
              lastPendingWriteBytes = buf.totalPendingWriteBytes();
          }
      }
  }
  ```

  - 初始化 `lastMessageHashCode` 和 `lastPendingWriteBytes` 属性。

- 第 17 至 26 行：根据配置，分别调用 `#schedule(hannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit)` 方法，初始相应的定时任务。代码如下：

  ```
  ScheduledFuture<?> schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit) {
      return ctx.executor().schedule(task, delay, unit);
  }
  ```

- 一共有 ReaderIdleTimeoutTask、WriterIdleTimeoutTask、AllIdleTimeoutTask 三种任务，下文我们详细解析。

------

该方法，会在多个 Channel **事件**中被调用。代码如下：

```
// <2>
@Override
public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
    if (ctx.channel().isActive() && ctx.channel().isRegistered()) {
        // 初始化
        // channelActive() event has been fired already, which means this.channelActive() will
        // not be invoked. We have to initialize here instead.
        initialize(ctx);
    } else {
        // channelActive() event has not been fired yet.  this.channelActive() will be invoked
        // and initialization will occur there.
    }
}

// <3>
@Override
public void channelRegistered(ChannelHandlerContext ctx) throws Exception {
    // 初始化
    // Initialize early if channel is active already.
    if (ctx.channel().isActive()) {
        initialize(ctx);
    }
    // 继续传播 Channel Registered 事件到下一个节点
    super.channelRegistered(ctx);
}

// <1>
@Override
public void channelActive(ChannelHandlerContext ctx) throws Exception {
    // 初始化
    // This method will be invoked only if this handler was added
    // before channelActive() event is fired.  If a user adds this handler
    // after the channelActive() event, initialize() will be called by beforeAdd().
    initialize(ctx);
    // 继续传播 Channel Registered 事件到下一个节点
    super.channelActive(ctx);
}
```

- `<1>` ：当客户端与服务端成功建立连接后，Channel 被激活，此时 channelActive 方法，的初始化被调用。
- `<2>` ：当 Channel 被激活后，动态添加此 Handler ，则 handlerAdded 方法的初始化被调用。
- `<3>` ：当 Channel 被激活后，用户主动切换 Channel 的所在的 EventLoop ，则 channelRegistered 方法的初始化被调用。

## 5.3 destroy

`#destroy()` 方法，销毁 IdleStateHandler 。代码如下：

```
private void destroy() {
    // 标记为销毁
    state = 2;

    // 销毁相应的定时任务
    if (readerIdleTimeout != null) {
        readerIdleTimeout.cancel(false);
        readerIdleTimeout = null;
    }
    if (writerIdleTimeout != null) {
        writerIdleTimeout.cancel(false);
        writerIdleTimeout = null;
    }
    if (allIdleTimeout != null) {
        allIdleTimeout.cancel(false);
        allIdleTimeout = null;
    }
}
```

- 标记 `state` 为已销毁。
- 销毁响应的定时任务。

------

该方法，会在多个 Channel **事件**中被调用。代码如下：

```
@Override
public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
    // 销毁
    destroy();
}

@Override
public void channelInactive(ChannelHandlerContext ctx) throws Exception {
    // 销毁
    destroy();
    // 继续传播 Channel Incative 事件到下一个节点
    super.channelInactive(ctx);
}
```

## 5.4 channelIdle

在定时任务中，如果检测到**空闲**：

① 首先，调用 `#newIdleStateEvent(IdleState state, boolean first)` 方法，创建对应的空闲事件。代码如下：

```
protected IdleStateEvent newIdleStateEvent(IdleState state, boolean first) {
    switch (state) {
        case ALL_IDLE:
            return first ? IdleStateEvent.FIRST_ALL_IDLE_STATE_EVENT : IdleStateEvent.ALL_IDLE_STATE_EVENT;
        case READER_IDLE:
            return first ? IdleStateEvent.FIRST_READER_IDLE_STATE_EVENT : IdleStateEvent.READER_IDLE_STATE_EVENT;
        case WRITER_IDLE:
            return first ? IdleStateEvent.FIRST_WRITER_IDLE_STATE_EVENT : IdleStateEvent.WRITER_IDLE_STATE_EVENT;
        default:
            throw new IllegalArgumentException("Unhandled: state=" + state + ", first=" + first);
    }
}
```

② 然后，调用 `#channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt)` 方法，在 pipeline 中，触发 UserEvent 事件。代码如下：

```
/**
 * Is called when an {@link IdleStateEvent} should be fired. This implementation calls
 * {@link ChannelHandlerContext#fireUserEventTriggered(Object)}.
 */
protected void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception {
    ctx.fireUserEventTriggered(evt);
}
```

## 5.5 channelRead

`#channelRead(ChannelHandlerContext ctx, Object msg)` 方法，代码如下：

```
@Override
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
    // 开启了 read 或 all 的空闲检测
    if (readerIdleTimeNanos > 0 || allIdleTimeNanos > 0) {
        // 标记正在读取
        reading = true;
        // 重置 firstWriterIdleEvent 和 firstAllIdleEvent 为 true
        firstReaderIdleEvent = firstAllIdleEvent = true;
    }
    // 继续传播 Channel Read 事件到下一个节点
    ctx.fireChannelRead(msg);
}
```

在开启 read 或 all 的空闲检测的情况下，在【继续传播 Channel Read 事件到下一个节点】**之前**，会：

- 标记 `reading` 为正在读取。
- 重置 `firstWriterIdleEvent` 和 `firstAllIdleEvent` 为 `true` ，即又变成**首次**。

------

那么什么时候记录 `lastReadTime` 最后读取时间呢？答案在 `#channelReadComplete(ChannelHandlerContext ctx)` 方法中。代码如下：

```
@Override
public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
    // 开启了 read 或 all 的空闲检测
    if ((readerIdleTimeNanos > 0 || allIdleTimeNanos > 0) && reading) {
        // 记录最后读时间
        lastReadTime = ticksInNanos();
        // 标记不在读取
        reading = false;
    }
    // 继续传播 Channel ReadComplete 事件到下一个节点
    ctx.fireChannelReadComplete();
}

```

在开启 read 或 all 的空闲检测的情况下，在【继续传播 Channel ReadComplete 事件到下一个节点】**之前**，会：

- 记录 `lastReadTime` 最后读取时间为 `#ticksInNanos()` 方法，代码如下：

  ```
  long ticksInNanos() {
      return System.nanoTime();
  }
  
  ```

  - 当前时间，单位：纳秒。

- 标记 `reading` 为不在读取。

## 5.6 write

`#write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，代码如下：

```
@Override
public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
    // 开启了 write 或 all 的空闲检测
    // Allow writing with void promise if handler is only configured for read timeout events.
    if (writerIdleTimeNanos > 0 || allIdleTimeNanos > 0) {
        // 写入，并添加写入监听器
        ctx.write(msg, promise.unvoid()).addListener(writeListener);
    } else {
        // 写入，不添加监听器
        ctx.write(msg, promise);
    }
}

```

在开启 write 或 all 的空闲检测的情况下，写入的时候，会添加写入监听器 `writeListener` 。该监听器会在消息( 数据 ) flush 到对端后，**回调**，修改最后写入时间 `lastWriteTime` 为 `#ticksInNanos()` 。代码如下：

```
// Not create a new ChannelFutureListener per write operation to reduce GC pressure.
private final ChannelFutureListener writeListener = new ChannelFutureListener() {

    @Override
    public void operationComplete(ChannelFuture future) throws Exception {
        // 记录最后写时间
        lastWriteTime = ticksInNanos();
        // 重置 firstWriterIdleEvent 和 firstAllIdleEvent 为 true
        firstWriterIdleEvent = firstAllIdleEvent = true;
    }

}

```

## 5.7 hasOutputChanged

> 老艿艿：关于这个方法，看完 [「5.8.2 WriterIdelTimeoutTask」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 后，再回过头理解。

`#hasOutputChanged(ChannelHandlerContext ctx, boolean first)` 方法，判断 ChannelOutboundBuffer 是否发生变化。代码如下：

```
   /**
    * Returns {@code true} if and only if the {@link IdleStateHandler} was constructed
    * with {@link #observeOutput} enabled and there has been an observed change in the
    * {@link ChannelOutboundBuffer} between two consecutive calls of this method.
    *
    * https://github.com/netty/netty/issues/6150
    */
 1: private boolean hasOutputChanged(ChannelHandlerContext ctx, boolean first) {
 2:     // 开启观察 ChannelOutboundBuffer 队列
 3:     if (observeOutput) {
 4: 
 5:         // We can take this shortcut if the ChannelPromises that got passed into write()
 6:         // appear to complete. It indicates "change" on message level and we simply assume
 7:         // that there's change happening on byte level. If the user doesn't observe channel
 8:         // writability events then they'll eventually OOME and there's clearly a different
 9:         // problem and idleness is least of their concerns.
10:         // 如果 lastChangeCheckTimeStamp 和 lastWriteTime 不一样，说明写操作进行过了，则更新此值
11:         if (lastChangeCheckTimeStamp != lastWriteTime) {
12:             lastChangeCheckTimeStamp = lastWriteTime;
13: 
14:             // But this applies only if it's the non-first call.
15:             if (!first) { // 非首次
16:                 return true;
17:             }
18:         }
19: 
20:         Channel channel = ctx.channel();
21:         Unsafe unsafe = channel.unsafe();
22:         ChannelOutboundBuffer buf = unsafe.outboundBuffer();
23: 
24:         if (buf != null) {
25:             // 获得新的 messageHashCode 和 pendingWriteBytes
26:             int messageHashCode = System.identityHashCode(buf.current());
27:             long pendingWriteBytes = buf.totalPendingWriteBytes();
28: 
29:             // 发生了变化
30:             if (messageHashCode != lastMessageHashCode || pendingWriteBytes != lastPendingWriteBytes) {
31:                 // 修改最后一次的 lastMessageHashCode 和 lastPendingWriteBytes
32:                 lastMessageHashCode = messageHashCode;
33:                 lastPendingWriteBytes = pendingWriteBytes;
34: 
35:                 if (!first) { // 非首次
36:                     return true;
37:                 }
38:             }
39:         }
40:     }
41: 
42:     return false;
43: }

```

- 第 3 行：判断开启观察 ChannelOutboundBuffer 队列。

  - 如果 `lastChangeCheckTimeStamp` 和 `lastWriteTime` 不一样，说明写操作进行过了，则更新此值。
  - 第 14 至 17 行：这段逻辑，理论来说不会发生。因为 `lastWriteTime` 属性，只会在 `writeListener` 回调中修改，那么如果发生 `lastChangeCheckTimeStamp` 和 `lastWriteTime` 不相等，`first` 必然为 `true` 。因为，Channel 相关的事件逻辑，都在它所在的 EventLoop 中，不会出现并发的情况。关于这一块，基友【莫那一鲁道】在 <https://github.com/netty/netty/issues/8251> 已经进行提问，坐等结果。

- 第 25 至 27 行：获得新的 `messageHashCode` 和 `pendingWriteBytes` 的。

- 第 29 至 33 行：若发生了变化，则修改最后一次的

   

  ```
  lastMessageHashCode
  
  ```

   

  和

   

  ```
  lastPendingWriteBytes
  
  ```

   

  。

  - `messageHashCode != lastMessageHashCode` 成立，① 有可能对端接收数据比较慢，导致一个消息发送了一部分；② 又或者，发送的消息**非常非常非常大**，导致一个消息发送了一部分，就将发送缓存区写满。如果是这种情况下，可以使用 ChunkedWriteHandler ，一条大消息，拆成多条小消息。
  - `pendingWriteBytes != lastPendingWriteBytes` 成立，① 有新的消息，写到 ChannelOutboundBuffer 内存队列中；② 有几条消息成功写到对端。这种情况，此处不会发生。

- 第 35 至 37 行：当且仅当

   

  ```
  first
  
  ```

   

  为

   

  ```
  true
  
  ```

   

  时，即非首次，才返回

   

  ```
  true
  
  ```

   

  ，表示 ChannelOutboundBuffer 发生变化。

  - 这是一个有点“神奇”的设定，笔者表示不太理解。理论来说，ChannelOutboundBuffer 是否发生变化，只需要考虑【第 30 行】代码的判断。如果加了 `!first` 的判断，导致的结果是在 WriterIdleTimeoutTask 和 AllIdleTimeoutTask 任务中，ChannelOutboundBuffer 即使发生了变化，在**首次**还是会触发 write 和 all 空闲事件，在**非首次**不会触发 write 和 all 空闲事件。
  - 关于上述的困惑，[《Netty 那些事儿 ——— 关于 “Netty 发送大数据包时 触发写空闲超时” 的一些思考》](https://www.jianshu.com/p/8fe70d313d78) 一文的作者，也表达了相同的困惑。后续，找闪电侠面基沟通下。
  - 关于上述的困惑，[《Netty 心跳服务之 IdleStateHandler 源码分析》](https://www.jianshu.com/p/f2ed73cf4df8) 一文的作者，表达了自己的理解。感兴趣的胖友，可以看看。
  - 当然，这块如果不理解的胖友，也不要方。从笔者目前了解下来，`observeOutput` 都是设置为 `false` 。也就说，不会触发这个方法的执行。

- 第 42 行：返回 `false` ，表示 ChannelOutboundBuffer 未发生变化。

## 5.8 AbstractIdleTask

AbstractIdleTask ，实现 Runnable 接口，空闲任务抽象类。代码如下：

> AbstractIdleTask 是 IdleStateHandler 的内部静态类。

```
private abstract static class AbstractIdleTask implements Runnable {

    private final ChannelHandlerContext ctx;

    AbstractIdleTask(ChannelHandlerContext ctx) {
        this.ctx = ctx;
    }

    @Override
    public void run() {
        // <1> 忽略未打开的 Channel
        if (!ctx.channel().isOpen()) {
            return;
        }

        // <2> 执行任务
        run(ctx);
    }

    protected abstract void run(ChannelHandlerContext ctx);

}

```

- `<1>` 处，忽略未打开的 Channel 。
- `<2>` 处，子类实现 `#run()` **抽象**方法，实现自定义的空闲检测逻辑。

### 5.8.1 ReaderIdleTimeoutTask

ReaderIdleTimeoutTask ，继承 AbstractIdleTask 抽象类，检测 Read 空闲超时**定时**任务。代码如下：

> ReaderIdleTimeoutTask 是 IdleStateHandler 的内部静态类。

```
 1: private final class ReaderIdleTimeoutTask extends AbstractIdleTask {
 2: 
 3:     ReaderIdleTimeoutTask(ChannelHandlerContext ctx) {
 4:         super(ctx);
 5:     }
 6: 
 7:     @Override
 8:     protected void run(ChannelHandlerContext ctx) {
 9:         // 计算下一次检测的定时任务的延迟
10:         long nextDelay = readerIdleTimeNanos;
11:         if (!reading) {
12:             nextDelay -= ticksInNanos() - lastReadTime;
13:         }
14: 
15:         // 如果小于等于 0 ，说明检测到读空闲
16:         if (nextDelay <= 0) {
17:             // 延迟时间为 readerIdleTimeNanos ，即再次检测
18:             // Reader is idle - set a new timeout and notify the callback.
19:             readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS);
20: 
21:             // 获得当前是否首次检测到读空闲
22:             boolean first = firstReaderIdleEvent;
23:             // 标记 firstReaderIdleEvent 为 false 。也就说，下次检测到空闲，就非首次了。
24:             firstReaderIdleEvent = false;
25: 
26:             try {
27:                 // 创建读空闲事件
28:                 IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first);
29:                 // 通知通道空闲事件
30:                 channelIdle(ctx, event);
31:             } catch (Throwable t) {
32:                 // 触发 Exception Caught 到下一个节点
33:                 ctx.fireExceptionCaught(t);
34:             }
35:         // 如果大于 0 ，说明未检测到读空闲
36:         } else {
37:             // 延迟时间为 nextDelay ，即按照最后一次读的时间作为开始计数
38:             // Read occurred before the timeout - set a new timeout with shorter delay.
39:             readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS);
40:         }
41:     }
42: }

```

- 第 9 至 13 行：计算下一次检测的定时任务的

  延迟

  。

  - `reading` 为 `true` 时，意味着正在读取，**不会**被检测为读空闲。
  - `reading` 为 `false` 时，实际 `nextDelay` 的计算为 `readerIdleTimeNanos - (ticksInNanos() - lastReadTime)` 。如果小于等于 0 ，意味着 `ticksInNanos() - lastReadTime >= readerIdleTimeNanos` ，超时。

- ① 第 35 至 40 行：如果

  大于

   

  0 ，说明未检测到读空闲。

  - 第 39 行：调用 `#schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit)` 方法，初始**下一次**的 ReaderIdleTimeoutTask 定时任务。其中，延迟时间为 `nextDelay` ，即按照最后一次读的时间作为开始计数。

- ② 第 15 至 34 行：如果

  小于等于

   

  0 ，说明检测到读空闲。

  - 第 19 行：调用 `#schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit)` 方法，初始**下一次**的 ReaderIdleTimeoutTask 定时任务。其中，延迟时间为 `readerIdleTimeNanos` ，即重新计数。

  - 第 21 行：获得当前是否首次检测到读空闲。

    - 第 24 行：标记 `firstReaderIdleEvent` 为 `false` 。也就说，下次检测到空闲，就**非首次**了。

  - 第 28 行：调用

     

    ```
    #newIdleStateEvent(IdleState state, boolean first)
    
    ```

     

    方法，创建创建

    读

    空闲事件。

    - 第 30 行： 调用 `#channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt)` 方法，在 pipeline 中，触发 UserEvent 事件。

  - 第 31 至 34 行：如果**发生异常**，触发 Exception Caught 事件到下一个节点，处理异常。

### 5.8.2 WriterIdleTimeoutTask

WriterIdleTimeoutTask ，继承 AbstractIdleTask 抽象类，检测 Write 空闲超时**定时**任务。代码如下：

> WriterIdleTimeoutTask 是 IdleStateHandler 的内部静态类。

```
 1: private final class WriterIdleTimeoutTask extends AbstractIdleTask {
 2: 
 3:     WriterIdleTimeoutTask(ChannelHandlerContext ctx) {
 4:         super(ctx);
 5:     }
 6: 
 7:     @Override
 8:     protected void run(ChannelHandlerContext ctx) {
 9:         // 计算下一次检测的定时任务的延迟
10:         long lastWriteTime = IdleStateHandler.this.lastWriteTime;
11:         long nextDelay = writerIdleTimeNanos - (ticksInNanos() - lastWriteTime);
12: 
13:         // 如果小于等于 0 ，说明检测到写空闲
14:         if (nextDelay <= 0) {
15:             // 延迟时间为 writerIdleTimeout ，即再次检测
16:             // Writer is idle - set a new timeout and notify the callback.
17:             writerIdleTimeout = schedule(ctx, this, writerIdleTimeNanos, TimeUnit.NANOSECONDS);
18: 
19:             // 获得当前是否首次检测到写空闲
20:             boolean first = firstWriterIdleEvent;
21:             // 标记 firstWriterIdleEvent 为 false 。也就说，下次检测到空闲，就非首次了。
22:             firstWriterIdleEvent = false;
23: 
24:             try {
25:                 // 判断 ChannelOutboundBuffer 是否发生变化
26:                 if (hasOutputChanged(ctx, first)) {
27:                     return;
28:                 }
29: 
30:                 // 创建写空闲事件
31:                 IdleStateEvent event = newIdleStateEvent(IdleState.WRITER_IDLE, first);
32:                 // 通知通道空闲事件
33:                 channelIdle(ctx, event);
34:             } catch (Throwable t) {
35:                 // 触发 Exception Caught 到下一个节点
36:                 ctx.fireExceptionCaught(t);
37:             }
38:         // 如果大于 0 ，说明未检测到读空闲
39:         } else {
40:             // Write occurred before the timeout - set a new timeout with shorter delay.
41:             writerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS);
42:         }
43:     }
44: }

```

- 第 9 至 11 行：计算下一次检测的定时任务的**延迟**。

- ① 第 38 至 42 行：如果

  大于

   

  0 ，说明未检测到写空闲。

  - 第 39 行：调用 `#schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit)` 方法，初始**下一次**的 WriterIdleTimeoutTask 定时任务。其中，延迟时间为 `nextDelay` ，即按照最后一次写的时间作为开始计数。

- ② 第 13 至 37 行：如果

  小于等于

   

  0 ，说明检测到写空闲。

  - 第 17 行：调用 `#schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit)` 方法，初始**下一次**的 WriterIdleTimeoutTask 定时任务。其中，延迟时间为 `readerIdleTimeNanos` ，即重新计数。

  - 第 20 行：获得当前是否首次检测到写空闲。

    - 第 22 行：标记 `firstWriterIdleEvent` 为 `false` 。也就说，下次检测到空闲，就**非首次**了。

  - 第 25 至 28 行：判断 ChannelOutboundBuffer 是否发生变化。如果有变化，不触发写空闲时间。

  - 第 31 行：调用

     

    ```
    #newIdleStateEvent(IdleState state, boolean first)
    
    ```

     

    方法，创建创建

    写

    空闲事件。

    - 第 33 行： 调用 `#channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt)` 方法，在 pipeline 中，触发 UserEvent 事件。

  - 第 34 至 37 行：如果**发生异常**，触发 Exception Caught 事件到下一个节点，处理异常。

### 5.8.3 AllIdleTimeoutTask

AllIdleTimeoutTask ，继承 AbstractIdleTask 抽象类，检测 All 空闲超时**定时**任务。代码如下：

> AllIdleTimeoutTask 是 IdleStateHandler 的内部静态类。

```
private final class AllIdleTimeoutTask extends AbstractIdleTask {

    AllIdleTimeoutTask(ChannelHandlerContext ctx) {
        super(ctx);
    }

    @Override
    protected void run(ChannelHandlerContext ctx) {
        // 计算下一次检测的定时任务的延迟
        long nextDelay = allIdleTimeNanos;
        if (!reading) {
            nextDelay -= ticksInNanos() - Math.max(lastReadTime, lastWriteTime); // <1> 取大值
        }

        // 如果小于等于 0 ，说明检测到 all 空闲
        if (nextDelay <= 0) {
            // 延迟时间为 allIdleTimeNanos ，即再次检测
            // Both reader and writer are idle - set a new timeout and
            // notify the callback.
            allIdleTimeout = schedule(ctx, this, allIdleTimeNanos, TimeUnit.NANOSECONDS);

            // 获得当前是否首次检测到 all 空闲
            boolean first = firstAllIdleEvent;
            // 标记 firstAllIdleEvent 为 false 。也就说，下次检测到空闲，就非首次了。
            firstAllIdleEvent = false;

            try {
                // 判断 ChannelOutboundBuffer 是否发生变化
                if (hasOutputChanged(ctx, first)) {
                    return;
                }

                // 创建 all 空闲事件
                IdleStateEvent event = newIdleStateEvent(IdleState.ALL_IDLE, first);
                // 通知通道空闲事件
                channelIdle(ctx, event);
            } catch (Throwable t) {
                ctx.fireExceptionCaught(t);
            }
        // 如果大于 0 ，说明未检测到 all 空闲
        } else {
            // Either read or write occurred before the timeout - set a new
            // timeout with shorter delay.
            allIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS);
        }
    }
}

```

- 因为 All 是 Write 和 Read **任一**一种空闲即可，所以 AllIdleTimeoutTask 是 ReaderIdleTimeoutTask 和 WriterIdleTimeoutTask 的**综合**。
- `<1>` 处，取 `lastReadTime` 和 `lastWriteTime` 中的**大**值，从而来判断，是否有 Write 和 Read **任一**一种空闲。
- WriterIdleTimeoutTask 就不详细解析，胖友自己读读代码即可。

# 6. ReadTimeoutHandler

`io.netty.handler.timeout.ReadTimeoutHandler` ，继承 IdleStateHandler 类，当 Channel 的**读**空闲时间( 读或者写 )太长时，抛出 ReadTimeoutException 异常，并自动关闭该 Channel 。

## 6.1 构造方法

```
/**
 * Channel 是否关闭
 */
private boolean closed;

public ReadTimeoutHandler(int timeoutSeconds) {
    this(timeoutSeconds, TimeUnit.SECONDS);
}

public ReadTimeoutHandler(long timeout, TimeUnit unit) {
    // 禁用 Write / All 的空闲检测
    super(timeout, 0, 0, unit); // <1>
}

```

- `closed` 属性，Channel 是否关闭。
- `<1>` 处，禁用 Write / All 的空闲检测，只根据 `timeout` 方法参数，开启 Read 的空闲检测。

## 6.2 channelIdle

`#channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt)` 方法，覆写父类方法，代码如下：

```
@Override
protected final void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception {
    assert evt.state() == IdleState.READER_IDLE;
    readTimedOut(ctx);
}

/**
 * Is called when a read timeout was detected.
 */
protected void readTimedOut(ChannelHandlerContext ctx) throws Exception {
    if (!closed) {
        // <1> 触发 Exception Caught 事件到 pipeline 中，异常为 ReadTimeoutException
        ctx.fireExceptionCaught(ReadTimeoutException.INSTANCE);
        // <2> 关闭 Channel 通道
        ctx.close();
        // <3> 标记 Channel 为已关闭
        closed = true;
    }
}

```

- `<1>` 处，触发 Exception Caught 事件到 pipeline 中，异常为 ReadTimeoutException 。
- `<2>` 处，关闭 Channel 通道。
- `<3>` 处，标记 Channel 为已关闭。

# 7. WriteTimeoutHandler

`io.netty.handler.timeout.WriteTimeoutHandler` ，继承 ChannelOutboundHandlerAdapter 类，当一个**写**操作不能在指定时间内完成时，抛出 WriteTimeoutException 异常，并自动关闭对应 Channel 。

😈 **注意，这里写入，指的是 flush 到对端 Channel ，而不仅仅是写到 ChannelOutboundBuffer 队列**。

## 7.1 构造方法

```
/**
 * 最小的超时时间，单位：纳秒
 */
private static final long MIN_TIMEOUT_NANOS = TimeUnit.MILLISECONDS.toNanos(1);

/**
 * 超时时间，单位：纳秒
 */
private final long timeoutNanos;

/**
 * WriteTimeoutTask 双向链表。
 *
 * lastTask 为链表的尾节点
 *
 * A doubly-linked list to track all WriteTimeoutTasks
 */
private WriteTimeoutTask lastTask;

/**
 * Channel 是否关闭
 */
private boolean closed;

public WriteTimeoutHandler(int timeoutSeconds) {
    this(timeoutSeconds, TimeUnit.SECONDS);
}

public WriteTimeoutHandler(long timeout, TimeUnit unit) {
    if (unit == null) {
        throw new NullPointerException("unit");
    }

    if (timeout <= 0) {
        timeoutNanos = 0;
    } else {
        timeoutNanos = Math.max(unit.toNanos(timeout), MIN_TIMEOUT_NANOS); // 保证大于等于 MIN_TIMEOUT_NANOS
    }
}

```

- ```
  timeoutNanos
  
  ```

   

  属性，写入超时时间，单位：纳秒。

  - `MIN_TIMEOUT_NANOS` 属性，最小的超时时间，单位：纳秒。

- `lastTask` 属性，WriteTimeoutTask 双向链表。其中，`lastTask` 为链表的**尾节点**。

- `closed` 属性，Channel 是否关闭。

## 7.2 handlerRemoved

`#handlerRemoved(ChannelHandlerContext ctx)` 方法，移除所有 WriteTimeoutTask 任务，并取消。代码如下：

```
@Override
public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
    WriteTimeoutTask task = lastTask;
    // 置空 lastTask
    lastTask = null;
    // 循环移除，知道为空
    while (task != null) {
        // 取消当前任务的定时任务
        task.scheduledFuture.cancel(false);
        // 记录前一个任务
        WriteTimeoutTask prev = task.prev;
        // 置空当前任务的前后节点
        task.prev = null;
        task.next = null;
        // 跳到前一个任务
        task = prev;
    }
}

```

- 代码比较简单，胖友自己看注释。

## 7.3 write

`#write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，代码如下：

```
@Override
public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
    if (timeoutNanos > 0) {
        // 如果 promise 是 VoidPromise ，则包装成非 VoidPromise ，为了后续的回调。
        promise = promise.unvoid(); <1》
        // 创建定时任务
        scheduleTimeout(ctx, promise);
    }
    // 写入
    ctx.write(msg, promise);
}

```

- `<1>` 处，如果 `promise` 类型是 VoidPromise ，则包装成非 VoidPromise ，为了后续的回调。因为 VoidPromise 无法接收到回调。
- `<2>` 处，调用 `#scheduleTimeout(final ChannelHandlerContext ctx, final ChannelPromise promise)` 方法，创建定时任务。详细解析，见 [「7.4 scheduleTimeout」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 。

## 7.4 scheduleTimeout

`#scheduleTimeout(final ChannelHandlerContext ctx, final ChannelPromise promise)` 方法，创建定时任务。代码如下：

```
 1: private void scheduleTimeout(final ChannelHandlerContext ctx, final ChannelPromise promise) {
 2:     // Schedule a timeout.
 3:     // 创建 WriteTimeoutTask 任务
 4:     final WriteTimeoutTask task = new WriteTimeoutTask(ctx, promise);
 5:     // 定时任务
 6:     task.scheduledFuture = ctx.executor().schedule(task, timeoutNanos, TimeUnit.NANOSECONDS);
 7: 
 8:     if (!task.scheduledFuture.isDone()) {
 9:         // 添加到链表
10:         addWriteTimeoutTask(task);
11: 
12:         // Cancel the scheduled timeout if the flush promise is complete.
13:         // 将 task 作为监听器，添加到 promise 中。在写入完成后，可以移除该定时任务
14:         promise.addListener(task);
15:     }
16: }

```

- 第 2 至 6 行：创建 WriteTimeoutTask 任务，并发起**定时任务**。
- 第 8 行：如果定时任务**已经执行完成**，则不需要进行监听。否则，需要执行【第 10 至 14 行】的代码逻辑。
- 第 10 行：调用 `#addWriteTimeoutTask(WriteTimeoutTask task)` 方法，添加到链表。详细解析，见 [「7.5 addWriteTimeoutTask」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 。
- 第 14 行：将 `task` 作为监听器，添加到 `promise` 中。在写入完成后，可以移除该定时任务。也就说，调用链是 `flush => 回调 => promise => 回调 => task` 。

## 7.5 addWriteTimeoutTask

`#addWriteTimeoutTask(WriteTimeoutTask task)` 方法，添加到链表。代码如下：

```
private void addWriteTimeoutTask(WriteTimeoutTask task) {
    // 添加到链表的尾节点
    if (lastTask != null) {
        lastTask.next = task;
        task.prev = lastTask;
    }
    // 修改 lastTask 为当前任务
    lastTask = task;
}

```

添加到链表的尾节点，并修改 `lastTask` 为**当前**任务。

## 7.6 removeWriteTimeoutTask

`#removeWriteTimeoutTask(WriteTimeoutTask task)` 方法，移除出链表。代码如下：

```
private void removeWriteTimeoutTask(WriteTimeoutTask task) {
    // 从双向链表中，移除自己
    if (task == lastTask) { // 尾节点
        // task is the tail of list
        assert task.next == null;
        lastTask = lastTask.prev;
        if (lastTask != null) {
            lastTask.next = null;
        }
    } else if (task.prev == null && task.next == null) { // 已经被移除
        // Since task is not lastTask, then it has been removed or not been added.
        return;
    } else if (task.prev == null) { // 头节点
        // task is the head of list and the list has at least 2 nodes
        task.next.prev = null;
    } else { // 中间的节点
        task.prev.next = task.next;
        task.next.prev = task.prev;
    }
    // 重置 task 前后节点为空
    task.prev = null;
    task.next = null;
}

```

该方法的调用，在 [「7.8 WriteTimeoutTask」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 会看到。

## 7.7 writeTimedOut

`#writeTimedOut(ChannelHandlerContext ctx)` 方法，写入超时，关闭 Channel 通道。代码如下：

```
/**
 * Is called when a write timeout was detected
 */
protected void writeTimedOut(ChannelHandlerContext ctx) throws Exception {
    if (!closed) {
        // 触发 Exception Caught 事件到 pipeline 中，异常为 WriteTimeoutException
        ctx.fireExceptionCaught(WriteTimeoutException.INSTANCE);
        // 关闭 Channel 通道
        ctx.close();
        // 标记 Channel 为已关闭
        closed = true;
    }
}

```

- 和 `ReadTimeoutHandler#readTimeout(ChannelHandlerContext ctx)` 方法，基本类似。

该方法的调用，在 [「7.8 WriteTimeoutTask」](http://svip.iocoder.cn/Netty/ChannelHandler-5-idle/#) 会看到。

## 7.8 WriteTimeoutTask

WriteTimeoutTask ，实现 Runnable 和 ChannelFutureListener 接口，写入超时任务。

> WriteTimeoutTask 是 WriteTimeoutHandler 的内部类。

### 7.8.1 构造方法

```
private final ChannelHandlerContext ctx;
/**
 * 写入任务的 Promise 对象
 */
private final ChannelPromise promise;

// WriteTimeoutTask is also a node of a doubly-linked list
/**
 * 前一个 task
 */
WriteTimeoutTask prev;
/**
 * 后一个 task
 */
WriteTimeoutTask next;
/**
 * 定时任务
 */
ScheduledFuture<?> scheduledFuture;

WriteTimeoutTask(ChannelHandlerContext ctx, ChannelPromise promise) {
    this.ctx = ctx;
    this.promise = promise;
}

```

### 7.8.2 run

当定时任务执行，说明写入任务执行超时。代码如下：

```
@Override
public void run() {
    // Was not written yet so issue a write timeout
    // The promise itself will be failed with a ClosedChannelException once the close() was issued
    // See https://github.com/netty/netty/issues/2159
    if (!promise.isDone()) { // 未完成，说明写入超时
        try {
            // <1> 写入超时，关闭 Channel 通道
            writeTimedOut(ctx);
        } catch (Throwable t) {
            // 触发 Exception Caught 事件到 pipeline 中
            ctx.fireExceptionCaught(t);
        }
    }
    // <2> 移除出链表
    removeWriteTimeoutTask(this);
}

```

- `<1>` 处，调用 `#writeTimedOut(ChannelHandlerContext ctx)` 方法，写入超时，关闭 Channel 通道。
- `<2>` 处，调用 `#removeWriteTimeoutTask(WriteTimeoutTask task)` 方法，移除出链表。

### 7.8.3 operationComplete

当回调方法执行，说明写入任务执行完成。代码如下：

```
@Override
public void operationComplete(ChannelFuture future) throws Exception {
    // scheduledFuture has already be set when reaching here
    // <1> 取消定时任务
    scheduledFuture.cancel(false);
    // <2> 移除出链表
    removeWriteTimeoutTask(this);
}

```

- `<1>` 处，取消定时任务。
- `<2>` 处，调用 `#removeWriteTimeoutTask(WriteTimeoutTask task)` 方法，移除出链表。

# 666. 彩蛋

和 「5.7 hasOutputChanged」(#) 小节，这个方法较真了好久。感谢中间，基友【莫那一鲁道】的沟通。

推荐阅读文章：

- 莫那一鲁道 [《Netty 心跳服务之 IdleStateHandler 源码分析》](https://www.jianshu.com/p/f2ed73cf4df8)
- Hypercube [自顶向下深入分析Netty（八）–ChannelHandler](https://www.jianshu.com/p/a9bcd89553f5)

# ChannelHandler（六）之 AbstractTrafficShapingHandler



笔者先把 Netty 主要的内容写完，所以关于 AbstractTrafficShapingHandler 的分享，先放在后续的计划里。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- tomas家的小拨浪鼓 [《Netty 那些事儿 ——— Netty实现“流量整形”原理分析及实战》](https://www.jianshu.com/p/bea1b4ea8402)

为避免可能 [《Netty 那些事儿 ——— Netty实现“流量整形”原理分析及实战》](https://www.jianshu.com/p/bea1b4ea8402) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

> 本文是Netty文集中“Netty 那些事儿”系列的文章。主要结合在开发实战中，我们遇到的一些“奇奇怪怪”的问题，以及如何正确且更好的使用Netty框架，并会对Netty中涉及的重要设计理念进行介绍。

### Netty实现“流量整形”原理分析

##### 流量整形

流量整形（Traffic Shaping）是一种主动调整流量输出速率的措施。流量整形与流量监管的主要区别在于，流量整形对流量监管中需要丢弃的报文进行缓存——通常是将它们放入缓冲区或队列内，也称流量整形（Traffic Shaping，简称TS）。当报文的发送速度过快时，首先在缓冲区进行缓存；再通过流量计量算法的控制下“均匀”地发送这些被缓冲的报文。流量整形与流量监管的另一区别是，整形可能会增加延迟，而监管几乎不引入额外的延迟。

Netty提供了GlobalTrafficShapingHandler、ChannelTrafficShapingHandler、GlobalChannelTrafficShapingHandler三个类来实现流量整形，他们都是AbstractTrafficShapingHandler抽象类的实现类，下面我们就对其进行介绍，让我们来了解Netty是如何实现流量整形的。

##### 核心类分析

###### AbstractTrafficShapingHandler

AbstractTrafficShapingHandler允许限制全局的带宽（见GlobalTrafficShapingHandler）或者每个session的带宽（见ChannelTrafficShapingHandler）作为流量整形。
它允许你使用TrafficCounter来实现几乎实时的带宽监控，TrafficCounter会在每个检测间期（checkInterval）调用这个处理器的doAccounting方法。

如果你有任何特别的原因想要停止监控（计数）或者改变读写的限制或者改变检测间期（checkInterval），可以使用如下方法：
① configure：允许你改变读或写的限制，或者检测间期（checkInterval）；
② getTrafficCounter：允许你获得TrafficCounter，并可以停止或启动监控，直接改变检测间期（checkInterval），或去访问它的值。

**TrafficCounter**：对读和写的字节进行计数以用于限制流量。
它会根据给定的检测间期周期性的计算统计入站和出站的流量，并会回调AbstractTrafficShapingHandler的doAccounting方法。
如果检测间期（checkInterval）是0，将不会进行计数并且统计只会在每次读或写操作时进行计算。

- configure

```
public void configure(long newWriteLimit, long newReadLimit,
        long newCheckInterval) {
    configure(newWriteLimit, newReadLimit);
    configure(newCheckInterval);
}
```

配置新的写限制、读限制、检测间期。该方法会尽最大努力进行此更改，这意味着已经被延迟进行的流量将不会使用新的配置，它仅用于新的流量中。

- ReopenReadTimerTask

```
static final class ReopenReadTimerTask implements Runnable {
    final ChannelHandlerContext ctx;
    ReopenReadTimerTask(ChannelHandlerContext ctx) {
        this.ctx = ctx;
    }

    @Override
    public void run() {
        ChannelConfig config = ctx.channel().config();
        if (!config.isAutoRead() && isHandlerActive(ctx)) {
            // If AutoRead is False and Active is True, user make a direct setAutoRead(false)
            // Then Just reset the status
            if (logger.isDebugEnabled()) {
                logger.debug("Not unsuspend: " + config.isAutoRead() + ':' +
                        isHandlerActive(ctx));
            }
            ctx.attr(READ_SUSPENDED).set(false);
        } else {
            // Anything else allows the handler to reset the AutoRead
            if (logger.isDebugEnabled()) {
                if (config.isAutoRead() && !isHandlerActive(ctx)) {
                    logger.debug("Unsuspend: " + config.isAutoRead() + ':' +
                            isHandlerActive(ctx));
                } else {
                    logger.debug("Normal unsuspend: " + config.isAutoRead() + ':'
                            + isHandlerActive(ctx));
                }
            }
            ctx.attr(READ_SUSPENDED).set(false);
            config.setAutoRead(true);
            ctx.channel().read();
        }
        if (logger.isDebugEnabled()) {
            logger.debug("Unsuspend final status => " + config.isAutoRead() + ':'
                    + isHandlerActive(ctx));
        }
    }
}
```

重启读操作的定时任务。该定时任务总会实现：
a) 如果Channel的autoRead为false，并且AbstractTrafficShapingHandler的READ_SUSPENDED属性设置为null或false（说明读暂停未启用或开启），则直接将READ_SUSPENDED属性设置为false。
b) 否则，如果Channel的autoRead为true，或者READ_SUSPENDED属性的值为true（说明读暂停开启了），则将READ_SUSPENDED属性设置为false，并将Channel的autoRead标识为true（该操作底层会将该Channel的OP_READ事件重新注册为感兴趣的事件，这样Selector就会监听该Channel的读就绪事件了），最后触发一次Channel的read操作。
也就说，若“读操作”为“开启”状态（READ_SUSPENDED为null或false）的情况下，Channel的autoRead是保持Channel原有的配置，此时并不会做什么操作。但当“读操作”从“暂停”状态（READ_SUSPENDED为true）转为“开启”状态（READ_SUSPENDED为false）时，则会将Channel的autoRead标志为true，并将“读操作”设置为“开启”状态（READ_SUSPENDED为false）。

- channelRead

```
public void channelRead(final ChannelHandlerContext ctx, final Object msg) throws Exception {
    long size = calculateSize(msg);
    long now = TrafficCounter.milliSecondFromNano();
    if (size > 0) {
        // compute the number of ms to wait before reopening the channel
        long wait = trafficCounter.readTimeToWait(size, readLimit, maxTime, now);
        wait = checkWaitReadTime(ctx, wait, now);
        if (wait >= MINIMAL_WAIT) { // At least 10ms seems a minimal
            // time in order to try to limit the traffic
            // Only AutoRead AND HandlerActive True means Context Active
            ChannelConfig config = ctx.channel().config();
            if (logger.isDebugEnabled()) {
                logger.debug("Read suspend: " + wait + ':' + config.isAutoRead() + ':'
                        + isHandlerActive(ctx));
            }
            if (config.isAutoRead() && isHandlerActive(ctx)) {
                config.setAutoRead(false);
                ctx.attr(READ_SUSPENDED).set(true);
                // Create a Runnable to reactive the read if needed. If one was create before it will just be
                // reused to limit object creation
                Attribute<Runnable> attr = ctx.attr(REOPEN_TASK);
                Runnable reopenTask = attr.get();
                if (reopenTask == null) {
                    reopenTask = new ReopenReadTimerTask(ctx);
                    attr.set(reopenTask);
                }
                ctx.executor().schedule(reopenTask, wait, TimeUnit.MILLISECONDS);
                if (logger.isDebugEnabled()) {
                    logger.debug("Suspend final status => " + config.isAutoRead() + ':'
                            + isHandlerActive(ctx) + " will reopened at: " + wait);
                }
            }
        }
    }
    informReadOperation(ctx, now);
    ctx.fireChannelRead(msg);
}
```

① 『long size = calculateSize(msg);』计算本次读取到的消息的字节数。
② 如果读取到的字节数大于0，则根据数据的大小、设定的readLimit、最大延迟时间等计算（『long wait = trafficCounter.readTimeToWait(size, readLimit, maxTime, now);』）得到下一次开启读操作需要的延迟时间（距当前时间而言）wait(毫秒)。
③ 如果a）wait >= MINIMAL_WAIT(10毫秒)。并且b）当前Channel为自动读取（即，autoRead为true）以及c）当前的READ_SUSPENDED标识为null或false（即，读操作未被暂停），那么将Channel的autoRead设置为false（该操作底层会将该Channel的OP_READ事件从感兴趣的事件中移除，这样Selector就不会监听该Channel的读就绪事件了），并且将READ_SUSPENDED标识为true（说明，接下来的读操作会被暂停），并将“重新开启读操作“封装为一个任务，让入Channel所注册NioEventLoop的定时任务队列中（延迟wait时间后执行）。
也就说，只有当计算出的下一次读操作的时间大于了MINIMAL_WAIT(10毫秒)，并且当前Channel是自动读取的，且“读操作”处于“开启”状态时，才会去暂停读操作，而暂停读操作主要需要完成三件事：[1]将Channel的autoRead标识设置为false，这使得OP_READ会从感兴趣的事件中移除，这样Selector就会不会监听这个Channel的读就绪事件了；[2]将“读操作”状态设置为“暂停”（READ_SUSPENDED为true）；[3]将重启开启“读操作”的操作封装为一个task，在延迟wait时间后执行。
当你将得Channel的autoRead都会被设置为false时，Netty底层就不会再去执行读操作了，也就是说，这时如果有数据过来，会先放入到内核的接收缓冲区，只有我们执行读操作的时候数据才会从内核缓冲区读取到用户缓冲区中。而对于TCP协议来说，你不要担心一次内核缓冲区会溢出。因为如果应用进程一直没有读取，接收缓冲区满了之后，发生的动作是：通知对端TCP协议中的窗口关闭。这个便是滑动窗口的实现。保证TCP套接口接收缓冲区不会溢出，从而保证了TCP是可靠传输。因为对方不允许发出超过所通告窗口大小的数据。 这就是TCP的流量控制，如果对方无视窗口大小而发出了超过窗口大小的数据，则接收方TCP将丢弃它。
④ 将当前的消息发送给ChannelPipeline中的下一个ChannelInboundHandler。

- write

```
public void write(final ChannelHandlerContext ctx, final Object msg, final ChannelPromise promise)
        throws Exception {
    long size = calculateSize(msg);
    long now = TrafficCounter.milliSecondFromNano();
    if (size > 0) {
        // compute the number of ms to wait before continue with the channel
        long wait = trafficCounter.writeTimeToWait(size, writeLimit, maxTime, now);
        if (wait >= MINIMAL_WAIT) {
            if (logger.isDebugEnabled()) {
                logger.debug("Write suspend: " + wait + ':' + ctx.channel().config().isAutoRead() + ':'
                        + isHandlerActive(ctx));
            }
            submitWrite(ctx, msg, size, wait, now, promise);
            return;
        }
    }
    // to maintain order of write
    submitWrite(ctx, msg, size, 0, now, promise);
}
```

① 『long size = calculateSize(msg);』计算待写出的数据大小
② 如果待写出数据的字节数大于0，则根据数据大小、设置的writeLimit、最大延迟时间等计算（『long wait = trafficCounter.writeTimeToWait(size, writeLimit, maxTime, now);』）得到本次写操作需要的延迟时间（距当前时间而言）wait(毫秒)。
③ 如果wait >= MINIMAL_WAIT（10毫秒），则调用『submitWrite(ctx, msg, size, wait, now, promise);』wait即为延迟时间，该方法的具体实现由子类完成；否则，若wait < MINIMAL_WAIT（10毫秒），则调用『submitWrite(ctx, msg, size, 0, now, promise);』注意这里传递的延迟时间为0了。

###### GlobalTrafficShapingHandler

这实现了AbstractTrafficShapingHandler的全局流量整形，也就是说它限制了全局的带宽，无论开启了几个channel。
注意『 OutboundBuffer.setUserDefinedWritability(index, boolean)』中索引使用’2’。

一般用途如下：
创建一个唯一的GlobalTrafficShapingHandler

```
GlobalTrafficShapingHandler myHandler = new GlobalTrafficShapingHandler(executor);
pipeline.addLast(myHandler);
```

executor可以是底层的IO工作池

注意，这个处理器是覆盖所有管道的，这意味着只有一个处理器对象会被创建并且作为所有channel间共享的计数器，它必须于所有的channel共享。
所有你可以见到，该类的定义上面有个`@Sharable`注解。

在你的处理器中，你需要考虑使用『channel.isWritable()』和『channelWritabilityChanged(ctx)』来处理可写性，或通过在ctx.write()返回的future上注册listener来实现。

你还需要考虑读或写操作对象的大小需要和你要求的带宽相对应：比如，你将一个10M大小的对象用于10KB/s的带宽将会导致爆发效果，若你将100KB大小的对象用于在1M/s带宽那么将会被流量整形处理器平滑处理。

一旦不在需要这个处理器时请确保调用『release()』以释放所有内部的资源。这不会关闭EventExecutor，因为它可能是共享的，所以这需要你自己做。

GlobalTrafficShapingHandler中持有一个Channel的哈希表，用于存储当前应用所有的Channel：

```
private final ConcurrentMap<Integer, PerChannel> channelQueues = PlatformDependent.newConcurrentHashMap();
```

key为Channel的hashCode；value是一个PerChannel对象。
PerChannel对象中维护有该Channel的待发送数据的消息队列（ArrayDeque messagesQueue）。

- submitWrite

```
void submitWrite(final ChannelHandlerContext ctx, final Object msg,
        final long size, final long writedelay, final long now,
        final ChannelPromise promise) {
    Channel channel = ctx.channel();
    Integer key = channel.hashCode();
    PerChannel perChannel = channelQueues.get(key);
    if (perChannel == null) {
        // in case write occurs before handlerAdded is raised for this handler
        // imply a synchronized only if needed
        perChannel = getOrSetPerChannel(ctx);
    }
    final ToSend newToSend;
    long delay = writedelay;
    boolean globalSizeExceeded = false;
    // write operations need synchronization
    synchronized (perChannel) {
        if (writedelay == 0 && perChannel.messagesQueue.isEmpty()) {
            trafficCounter.bytesRealWriteFlowControl(size);
            ctx.write(msg, promise);
            perChannel.lastWriteTimestamp = now;
            return;
        }
        if (delay > maxTime && now + delay - perChannel.lastWriteTimestamp > maxTime) {
            delay = maxTime;
        }
        newToSend = new ToSend(delay + now, msg, size, promise);
        perChannel.messagesQueue.addLast(newToSend);
        perChannel.queueSize += size;
        queuesSize.addAndGet(size);
        checkWriteSuspend(ctx, delay, perChannel.queueSize);
        if (queuesSize.get() > maxGlobalWriteSize) {
            globalSizeExceeded = true;
        }
    }
    if (globalSizeExceeded) {
        setUserDefinedWritability(ctx, false);
    }
    final long futureNow = newToSend.relativeTimeAction;
    final PerChannel forSchedule = perChannel;
    ctx.executor().schedule(new Runnable() {
        @Override
        public void run() {
            sendAllValid(ctx, forSchedule, futureNow);
        }
    }, delay, TimeUnit.MILLISECONDS);
}
```

写操作提交上来的数据。
① 如果写延迟为0，且当前该Channel的messagesQueue为空（说明，在此消息前没有待发送的消息了），那么直接发送该消息包。并返回，否则到下一步。
② 『newToSend = new ToSend(delay + now, msg, size, promise);
perChannel.messagesQueue.addLast(newToSend);』
将待发送的数据封装成ToSend对象放入PerChannel的消息队列中（messagesQueue）。注意，这里的messagesQueue是一个ArrayDeque队列，我们总是从队列尾部插入。然后从队列的头获取消息来依次发送，这就保证了消息的有序性。但是，如果一个大数据包前于一个小数据包发送的话，小数据包也会因为大数据包的延迟发送而被延迟到大数据包发送后才会发送。
ToSend 对象中持有带发送的数据对象、发送的相对延迟时间（即，根据数据包大小以及设置的写流量限制值（writeLimit）等计算出来的延迟操作的时间）、消息数据的大小、异步写操作的promise。
③ 『checkWriteSuspend(ctx, delay, perChannel.queueSize);』
检查单个Channel待发送的数据包是否超过了maxWriteSize（默认4M），或者延迟时间是否超过了maxWriteDelay（默认4s）。如果是的话，则调用『setUserDefinedWritability(ctx, false);』该方法会将ChannelOutboundBuffer中的unwritable属性值的相应标志位置位（unwritable关系到isWritable方法是否会返回true。以及会在unwritable从0到非0间变化时触发ChannelWritabilityChanged事件）。
④ 如果所有待发送的数据大小（这里指所有Channel累积的待发送的数据大小）大于了maxGlobalWriteSize（默认400M），则标识globalSizeExceeded为true，并且调用『setUserDefinedWritability(ctx, false)』将ChannelOutboundBuffer中的unwritable属性值相应的标志位置位。
⑤ 根据指定的延迟时间（一个 >= 0 且 <= maxTime 的值，maxTime默认15s）delay，将『sendAllValid(ctx, forSchedule, futureNow);』操作封装成一个任务提交至executor的定时周期任务队列中。
sendAllValid操作会遍历该Channel中待发送的消息队列messagesQueue，依次取出perChannel.messagesQueue中的消息包，将满足发送条件（即，延迟发送的时间已经到了）的消息发送给到ChannelPipeline中的下一个ChannelOutboundHandler（ctx.write(newToSend.toSend, newToSend.promise);），并且将perChannel.queueSize（当前Channel待发送的总数据大小）和queuesSize（所有Channel待发送的总数据大小）减小相应的值（即，被发送出去的这个数据包的大小）。循环遍历前面的操作直到当前的消息不满足发送条件则退出遍历。并且如果该Channel的消息队列中的消息全部都发送出去的话（即，messagesQueue.isEmpty()为true），则会通过调用『releaseWriteSuspended(ctx);』来释放写暂停。而该方法底层会将ChannelOutboundBuffer中的unwritable属性值相应的标志位重置。

###### ChannelTrafficShapingHandler

ChannelTrafficShapingHandler是针对单个Channel的流量整形，和GlobalTrafficShapingHandler的思想是一样的。只是实现中没有对全局概念的检测，仅检测了当前这个Channel的数据。
这里就不再赘述了。

###### GlobalChannelTrafficShapingHandler

相比于GlobalTrafficShapingHandler增加了一个误差概念，以平衡各个Channel间的读/写操作。也就是说，使得各个Channel间的读/写操作尽量均衡。比如，尽量避免不同Channel的大数据包都延迟近乎一样的是时间再操作，以及如果小数据包在一个大数据包后才发送，则减少该小数据包的延迟发送时间等。。

### “流量整形”实战

这里仅展示服务端和客户端中使用“流量整形”功能涉及的关键代码，完整demo可见[github](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2Flinling1%2Fnetty_module_function%2Ftree%2Fmaster%2Fsrc%2Fmain%2Fjava%2Fcom%2Flinling%2Fnetty%2Ftrafficshaping)
**服务端**
使用GlobalTrafficShapingHandler来实现服务端的“流量整形”，每当有客户端连接至服务端时服务端就会开始往这个客户端发送26M的数据包。我们将GlobalTrafficShapingHandler的writeLimit设置为10M/S。并使用了ChunkedWriteHandler来实现大数据包拆分成小数据包发送的功能。

MyServerInitializer实现：在ChannelPipeline中注册了GlobalTrafficShapingHandler

```
public class MyServerInitializer extends ChannelInitializer<SocketChannel> {

    Charset utf8 = Charset.forName("utf-8");
    final int M = 1024 * 1024;

    @Override
    protected void initChannel(SocketChannel ch) throws Exception {

        GlobalTrafficShapingHandler globalTrafficShapingHandler = new GlobalTrafficShapingHandler(ch.eventLoop().parent(), 10 * M, 50 * M);
//        globalTrafficShapingHandler.setMaxGlobalWriteSize(50 * M);
//        globalTrafficShapingHandler.setMaxWriteSize(5 * M);

        ch.pipeline()
                .addLast("LengthFieldBasedFrameDecoder", new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4, true))
                .addLast("LengthFieldPrepender", new LengthFieldPrepender(4, 0))
                .addLast("GlobalTrafficShapingHandler", globalTrafficShapingHandler)
                .addLast("chunkedWriteHandler", new ChunkedWriteHandler())
                .addLast("myServerChunkHandler", new MyServerChunkHandler())
                .addLast("StringDecoder", new StringDecoder(utf8))
                .addLast("StringEncoder", new StringEncoder(utf8))
                .addLast("myServerHandler", new MyServerHandlerForPlain());
    }
}
```

ServerHandler：当有客户端连接上了后就开始给客户端发送消息。并且通过『Channel#isWritable』方法以及『channelWritabilityChanged』事件来监控可写性，以判断啥时需要停止数据的写出，啥时可以开始继续写出数据。同时写了一个简易的task来计算每秒数据的发送速率（并非精确的计算）。

```
public class MyServerHandlerForPlain extends MyServerCommonHandler {

    @Override
    protected void sentData(ChannelHandlerContext ctx) {
        sentFlag = true;
        ctx.writeAndFlush(tempStr, getChannelProgressivePromise(ctx, future -> {
            if(ctx.channel().isWritable() && !sentFlag) {
                sentData(ctx);
            }
        }));
    }

    @Override
    public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {
        if(ctx.channel().isWritable() && !sentFlag) {
//            System.out.println(" ###### 重新开始写数据 ######");
            sentData(ctx);
        } else {
//            System.out.println(" ===== 写暂停 =====");
        }
    }
}

public abstract class MyServerCommonHandler extends SimpleChannelInboundHandler<String> {

    protected final int M = 1024 * 1024;
    protected String tempStr;
    protected AtomicLong consumeMsgLength;
    protected Runnable counterTask;
    private long priorProgress;
    protected boolean sentFlag;

    @Override
    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
        consumeMsgLength = new AtomicLong();
        counterTask = () -> {
          while (true) {
              try {
                  Thread.sleep(1000);
              } catch (InterruptedException e) {

              }

              long length = consumeMsgLength.getAndSet(0);
              System.out.println("*** " + ctx.channel().remoteAddress() + " rate（M/S）：" + (length / M));
          }
        };
        StringBuilder builder = new StringBuilder();
        for (int i = 0; i < M; i++) {
            builder.append("abcdefghijklmnopqrstuvwxyz");
        }
        tempStr = builder.toString();
        super.handlerAdded(ctx);
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        sentData(ctx);
        new Thread(counterTask).start();
    }

    protected ChannelProgressivePromise getChannelProgressivePromise(ChannelHandlerContext ctx, Consumer<ChannelProgressiveFuture> completedAction) {
        ChannelProgressivePromise channelProgressivePromise = ctx.newProgressivePromise();
        channelProgressivePromise.addListener(new ChannelProgressiveFutureListener(){
            @Override
            public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) throws Exception {
                consumeMsgLength.addAndGet(progress - priorProgress);
                priorProgress = progress;
            }

            @Override
            public void operationComplete(ChannelProgressiveFuture future) throws Exception {
                sentFlag = false;
                if(future.isSuccess()){
                    System.out.println("成功发送完成！");
                    priorProgress -= 26 * M;
                    Optional.ofNullable(completedAction).ifPresent(action -> action.accept(future));
                } else {
                    System.out.println("发送失败！！！！！");
                    future.cause().printStackTrace();
                }
            }
        });
        return channelProgressivePromise;
    }

    protected abstract void sentData(ChannelHandlerContext ctx);

    @Override
    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {
        System.out.println("===== receive client msg : " + msg);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        cause.printStackTrace();
        ctx.channel().close();
    }

}
```

**客户端**
客户端比较简单了，使用ChannelTrafficShapingHandler来实现“流量整形”，并将readLimit设置为1M/S。

```
public class MyClientInitializer extends ChannelInitializer<SocketChannel> {

    Charset utf8 = Charset.forName("utf-8");

    final int M = 1024 * 1024;

    @Override
    protected void initChannel(SocketChannel ch) throws Exception {
        ChannelTrafficShapingHandler channelTrafficShapingHandler = new ChannelTrafficShapingHandler(10 * M, 1 * M);
        ch.pipeline()
                .addLast("channelTrafficShapingHandler",channelTrafficShapingHandler)
                .addLast("lengthFieldBasedFrameDecoder", new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4, true))
                .addLast("lengthFieldPrepender", new LengthFieldPrepender(4, 0))
                .addLast("stringDecoder", new StringDecoder(utf8))
                .addLast("stringEncoder", new StringEncoder(utf8))
                .addLast("myClientHandler", new MyClientHandler());
    }
}
```

##### 注意事项

① 注意，trafficShaping是通过程序来达到控制流量的作用，并不是网络层真实的传输流量大小的控制。TrafficShapingHandler仅仅是根据消息大小（待发送出去的数据包大小）和设定的流量限制来得出延迟发送该包的时间，即同一时刻不会发送过大的数据导致带宽负荷不了。但是并没有对大数据包进行拆分的作用，这会使在发送这个大数据包时同样可能会导致带宽爆掉的情况。所以你需要注意一次发送数据包的大小，不要大于你设置限定的写带宽大小(writeLimit)。你可以通过在业务handler中自己控制的方式，或者考虑使用ChunkedWriteHandler，如果它能满足你的要求的话。同时注意，不要将writeLimit和readLimit设置的过小，这是没有意义的，只会导致读/写操作的不断停顿。。
② 注意，不要在非NioEventLoop线程中不停歇的发送非ByteBuf、ByteBufHolder或者FileRegion对象的大数据包，如：

```
new Thread(() -> {
        while (true) {
            if(ctx.channel().isWritable()) {
                ctx.writeAndFlush(tempStr, getChannelProgressivePromise(ctx, null));
            }
        }
    }).start();
```

因为写操作是一个I/O操作，当你在非NioEventLoop线程上执行了Channel的I/O操作的话，该操作会封装为一个task 被提交至NioEventLoop的任务队列中，以使得I/O操作最终是NioEventLoop线程上得到执行。
而提交这个任务的流程，仅会对ByteBuf、ByteBufHolder或者FileRegion对象进行真实数据大小的估计（其他情况默认估计大小为8 bytes），并将估计后的数据大小值对该ChannelOutboundBuffer的totalPendingSize属性值进行累加。而totalPendingSize同WriteBufferWaterMark一起来控制着Channel的unwritable。所以，如果你在一个非NioEventLoop线程中不断地发送一个非ByteBuf、ByteBufHolder或者FileRegion对象的大数据包时，最终就会导致提交大量的任务到NioEventLoop线程的任务队列中，而当NioEventLoop线程在真实执行这些task时可能发生OOM。

### 扩展

##### 关于 “OP_WRITE” 与 “Channel#isWritable()”

首先，我们需要明确的一点是，“OP_WRITE” 与 “Channel#isWritable()” 虽然都是的对数据的可写性进行检测，但是它们是分别针对不同层面的可写性的。

- “OP_WRITE”是当内核的发送缓冲区满的时候，我们程序执行write操作（这里是真实写操作了，将数据通过TCP协议进行网络传输）无法将数据写出，这时我们需要注册OP_WRITE事件。这样当发送缓冲区空闲时就OP_WRITE事件就会触发，我们就可以继续write未写完的数据了。这可以看做是对系统层面的可写性的一种检测。
- 而“Channel#isWritable()”则是检测程序中的缓存的待写出的数据大小超过了我们设定的相关最大写数据大小，如果超过了isWritable()方法将返回false，说明这时我们不应该再继续进行write操作了（这里写操作一般为通过ChannelHandlerContext或Channel进行的写操作）。
  关于“OP_WRITE”前面的[NIO文章](https://www.jianshu.com/p/1af407c043cb)及前面Netty系列文章已经进行过不少介绍了，这里不再赘述。下面我们来看看“Channel#isWritable()”是如果检测可写性的。

```
public boolean isWritable() {
    return unwritable == 0;
}
```

ChannelOutboundBuffer 的 unwritable属性为0时，Channel的isWritable()方法将返回true；否之，返回false；
unwritable可以看做是一个二进制的开关属性值。它的二进制的不同位表示的不同状态的开关。如：

![img](https://upload-images.jianshu.io/upload_images/4235178-5291c64aba1bbaac.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/972/format/jpeg)

ChannelOutboundBuffer有四个方法会对unwritable属性值进行修改：clearUserDefinedWritability、setUnwritable、setUserDefinedWritability、setWritable。并且，当unwritable从0到非0间改变时还会触发ChannelWritabilityChanged事件，以通知ChannelPipeline中的各个ChannelHandler当前Channel可写性发生了改变。

其中setUnwritable、setWritable这对方法是由于待写数据大小高于或低于了WriteBufferWaterMark的水位线而导致的unwritable属性值的改变。
我们所执行的『ChannelHandlerContext#write』和『Channel#write』操作会先将待发送的数据包放到Channel的输出缓冲区（ChannelOutboundBuffer）中，然后在执行flush操作的时候，会从ChannelOutboundBuffer中依次出去数据包进行真实的网络数据传输。而WriteBufferWaterMark控制的就是ChannelOutboundBuffer中待发送的数据总大小（即，totalPendingSize：包含一个个ByteBuf中待发送的数据大小，以及数据包对象占用的大小）。如果totalPendingSize的大小超过了WriteBufferWaterMark高水位（默认为64KB），则会unwritable属性的’WriteBufferWaterMark状态位’置位1；随着数据不断写出（每写完一个ByteBuf后，就会将totalPendingSize减少相应的值），当totalPendingSize的大小小于WriteBufferWaterMark低水位（默认为32KB）时，则会将unwritable属性的’WriteBufferWaterMark状态位’置位0。

而本文的主题“流量整形”则是使用了clearUserDefinedWritability、setUserDefinedWritability这对方法来控制unwritable相应的状态位。
当数据write到GlobalTrafficShapingHandler的时候，估计的数据大小大于0，且通过trafficCounter计算出的延迟时间大于最小延迟时间（MINIMAL_WAIT，默认为10ms）时，满足如下任意条件会使得unwritable的’GlobalTrafficShaping状态位’置为1：

- 当perChannel.queueSize（单个Channel中待写出的总数据大小）设定的最大写数据大小时（默认为4M）
- 当queuesSize（所有Channel的待写出的总数据大小）超过设定的最大写数据大小时（默认为400M）
- 对于Channel发送的单个数据包如果太大，以至于计算出的延迟发送时间大于了最大延迟发送时间（maxWriteDelay，默认为4s）时

随着写延迟时间的到达GlobalTrafficShaping中积压的数据不断被写出，当某个Channel中所有待写出的数据都写出后（注意，这里指将数据写到ChannelPipeline中的下一个ChannelOutboundBuffer中）会将unwritable的’GlobalTrafficShaping状态位’置为0。

# Codec 之 ByteToMessageDecoder（一）Cumulator



# 1. 概述

在 [《精尽 Netty 源码解析 —— ChannelHandler（一）之简介》](http://svip.iocoder.cn/Netty/ChannelHandler-1-intro) 中，我们看了 ChannelHandler 的核心类图，如下：![核心类图](http://static2.iocoder.cn/images/Netty/2018_10_01/01.png)

- **绿框**部分，我们可以看到，Netty 基于 ChannelHandler 实现了读写的数据( 消息 )的编解码。

  > Codec( 编解码 ) = Encode( 编码 ) + Decode( 解码 )。

- 图中有五个和 Codec 相关的类，整理如下：

  - 😈 ，实际应该是六个，漏画了 MessageToMessageDecoder 类。
  - ByteToMessageCodec ，ByteToMessageDecoder + MessageByteEncoder 的**组合**。
    - ByteToMessageDecoder ，将字节**解码**成消息。

- MessageByteEncoder ，将消息**编码**成字节。

- MessageToMessageCodec ，MessageToMessageDecoder + MessageToMessageEncoder 的**组合**。

  - MessageToMessageDecoder ，将消息**解码**成另一种消息。

- MessageToMessageEncoder ，将消息**编码**成另一种消息。

------

而本文，我们来分享 ByteToMessageDecoder 部分的内容。

# 2. ByteToMessageDecoder 核心类图

![核心类图](http://static2.iocoder.cn/images/Netty/2018_12_01/01.png)

ByteToMessageDecoder 本身是个**抽象**类，其下有多个子类，笔者简单整理成三类，可能不全哈：

- **绿框**部分 FrameDecoder ：消息帧( Frame )解码器。也就是说该类解码器，用于处理 TCP 的**粘包**现象，将网络发送的字节流解码为具有确定含义的消息帧。之后的解码器再将消息帧解码为实际的 POJO 对象。 如下图所示：[decode](http://static2.iocoder.cn/images/Netty/2018_12_01/02.png)

- 黄框

  部分，将字节流使用

  指定序列化方式

  反序列化成

  消息

  ，例如：XML、JSON 等等。

  - 对于该类解码器，不处理 TCP 的**粘包**现象，所以需要搭配 FrameDecoder 一起使用。

- 蓝框

  部分，将字节流

  解压

  ，主要涉及相关压缩算法，例如：GZip、BZip 等等。

  - 对于该类解码器，不处理 TCP 的**粘包**现象，所以需要搭配 FrameDecoder 一起使用。

# 3. 为什么要粘包拆包

😈 因为有些朋友不了解粘包和拆包的概念和原理，这里引用笔者的基友【闪电侠】在 [《netty 源码分析之拆包器的奥秘》](https://www.jianshu.com/p/dc26e944da95) 对这块的描述。

## 3.1 为什么要粘包

> 首先你得了解一下 TCP/IP 协议，在用户数据量非常小的情况下，极端情况下，一个字节，该 TCP 数据包的有效载荷非常低，传递 100 字节的数据，需要 100 次TCP传送， 100 次ACK，在应用及时性要求不高的情况下，将这 100 个有效数据拼接成一个数据包，那会缩短到一个TCP数据包，以及一个 ack ，有效载荷提高了，带宽也节省了。
>
> 非极端情况，有可能**两个**数据包拼接成一个数据包，也有可能**一个半**的数据包拼接成一个数据包，也有可能**两个半**的数据包拼接成一个数据包。

## 3.2 为什么要拆包

> 拆包和粘包是相对的，一端粘了包，另外一端就需要将粘过的包拆开。举个栗子，发送端将三个数据包粘成两个TCP数据包发送到接收端，接收端就需要根据应用协议将两个数据包重新组装成三个数据包。
>
> 还有一种情况就是用户数据包超过了 mss(最大报文长度)，那么这个数据包在发送的时候必须拆分成几个数据包，接收端收到之后需要将这些数据包粘合起来之后，再拆开。

## 3.3 拆包的原理

> 数据，每次读取完都需要判断是否是一个完整的数据包：
>
> 1. 如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从tcp缓冲区中读取，直到得到一个完整的数据包。
> 2. 如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，够成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。

# 4. Cumulator

Cumulator ，是 ByteToMessageDecoder 的**内部**接口。中文翻译为“累加器”，用于将读取到的数据进行累加到一起，然后再尝试**解码**，从而实现**拆包**。

也是因为 Cumulator 的累加，所以能将不完整的包累加到一起，从而完整。当然，累加的过程，没准又进入了一个不完整的包。所以，这是一个不断累加，不断解码拆包的过程。

------

Cumulator 接口，代码如下：

```java
/**
 * ByteBuf 累积器接口
 *
 * Cumulate {@link ByteBuf}s.
 */
public interface Cumulator {

    /**
     * Cumulate the given {@link ByteBuf}s and return the {@link ByteBuf} that holds the cumulated bytes.
     * The implementation is responsible to correctly handle the life-cycle of the given {@link ByteBuf}s and so
     * call {@link ByteBuf#release()} if a {@link ByteBuf} is fully consumed.
     *
     * @param alloc ByteBuf 分配器
     * @param cumulation ByteBuf 当前累积结果
     * @param in 当前读取( 输入 ) ByteBuf
     * @return ByteBuf 新的累积结果
     */
    ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in);

}
```

- 对于 `Cumulator#cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in)` 方法，将**原有**`cumulation` 累加上**新的** `in` ，返回“新”的 ByteBuf 对象。
- 如果 `in` 过大，超过 `cumulation` 的空间上限，使用 `alloc` 进行扩容后再累加。

------

Cumulator 有两个实现类，代码如下：

```java
public static final Cumulator MERGE_CUMULATOR = new Cumulator() {
    // ... 省略代码
}

public static final Cumulator COMPOSITE_CUMULATOR = new Cumulator() {
    // ... 省略代码
}
```

两者的累加方式不同，我们来详细解析。

## 4.1 MERGE_CUMULATOR

`MERGE_CUMULATOR` 思路是，不断使用**老的** ByteBuf 累积。如果空间不够，扩容出**新的** ByteBuf ，再继续进行累积。代码如下：

```
// ByteToMessageDecoder.java

    /**
     * Cumulate {@link ByteBuf}s by merge them into one {@link ByteBuf}'s, using memory copies.
     */
  1: public static final Cumulator MERGE_CUMULATOR = new Cumulator() {
  2: 
  3:     @Override
  4:     public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) {
  5:         final ByteBuf buffer;
  6:         if (cumulation.writerIndex() > cumulation.maxCapacity() - in.readableBytes() // 超过空间大小，需要扩容
  7:                 || cumulation.refCnt() > 1 // 引用大于 1 ，说明用户使用了 slice().retain() 或 duplicate().retain() 使refCnt增加并且大于 1 ，
  8:                                            // 此时扩容返回一个新的累积区ByteBuf，方便用户对老的累积区ByteBuf进行后续处理。
  9:                 || cumulation.isReadOnly()) { // 只读，不可累加，所以需要改成可写
 10:             // Expand cumulation (by replace it) when either there is not more room in the buffer
 11:             // or if the refCnt is greater then 1 which may happen when the user use slice().retain() or
 12:             // duplicate().retain() or if its read-only.
 13:             //
 14:             // See:
 15:             // - https://github.com/netty/netty/issues/2327
 16:             // - https://github.com/netty/netty/issues/1764
 17:             // 扩容，返回新的 buffer
 18:             buffer = expandCumulation(alloc, cumulation, in.readableBytes());
 19:         } else {
 20:             // 使用老的 buffer
 21:             buffer = cumulation;
 22:         }
 23:         // 写入 in 到 buffer 中
 24:         buffer.writeBytes(in);
 25:         // 释放输入 in
 26:         in.release();
 27:         // 返回 buffer
 28:         return buffer;
 29:     }
 30: 
 31: };
```

- 获取 `buffer` 对象。

  - 第 6 至 9 行：如下三个条件，满足任意，需要进行扩容。

    - ① 第 6 行：

      ```
      cumulation.writerIndex() > cumulation.maxCapacity() - in.readableBytes()
      ```

       

      ，超过空间大小，需要扩容。

      - 这个比较好理解。

    - ② 第 7 行：

      ```
      cumulation.refCnt() > 1
      ```

       

      ，引用大于 1 ，说明用户使用了

       

      ```
      ByteBuf#slice()#retain()
      ```

       

      或

       

      ```
      ByteBuf#duplicate()#retain()
      ```

       

      方法，使

       

      ```
      refCnt
      ```

       

      增加并且大于 1 。

      - 关于这块，在【第 11 行】的英文注释，也相应的提到。

    - ③ 第 9 行：只读，不可累加，所以需要改成可写。

      - 这个比较好理解。

  - 【需要扩容】第 18 行：调用 `ByteToMessageDecoder#expandCumulation(ByteBufAllocator alloc, ByteBuf cumulation, int readable)` **静态**方法，扩容，并返回新的，并赋值给 `buffer` 。代码如下：

    ```
    static ByteBuf expandCumulation(ByteBufAllocator alloc, ByteBuf cumulation, int readable) {
        // 记录老的 ByteBuf 对象
        ByteBuf oldCumulation = cumulation;
        // 分配新的 ByteBuf 对象
        cumulation = alloc.buffer(oldCumulation.readableBytes() + readable);
        // 将老的数据，写入到新的 ByteBuf 对象
        cumulation.writeBytes(oldCumulation);
        // 释放老的 ByteBuf 对象
        oldCumulation.release();
        // 返回新的 ByteBuf 对象
        return cumulation;
    }
    ```

    - 标准的扩容，并复制老数据的过程。胖友自己看下注释噢。

  - 【无需扩容】第 21 行：`buffer` 直接使用的 `cumulation` 对象。

- 第 24 行：写入

   

  ```
  in
  ```

   

  到

   

  ```
  buffer
  ```

   

  中，进行累积。

  - 第 26 行：释放 `in` 。

- 第 28 行：返回 `buffer` 。

## 4.2 COMPOSITE_CUMULATOR

`COMPOSITE_CUMULATOR` 思路是，使用 CompositeByteBuf ，组合新输入的 ByteBuf 对象，从而避免内存拷贝。代码如下：

```
// ByteToMessageDecoder.java

    /**
     * Cumulate {@link ByteBuf}s by add them to a {@link CompositeByteBuf} and so do no memory copy whenever possible.
     * Be aware that {@link CompositeByteBuf} use a more complex indexing implementation so depending on your use-case
     * and the decoder implementation this may be slower then just use the {@link #MERGE_CUMULATOR}.
     *
     * 相比 MERGE_CUMULATOR 来说：
     *
     * 好处是，内存零拷贝
     * 坏处是，因为维护复杂索引，所以某些使用场景下，慢于 MERGE_CUMULATOR
     */
  1: public static final Cumulator COMPOSITE_CUMULATOR = new Cumulator() {
  2: 
  3:     @Override
  4:     public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) {
  5:         ByteBuf buffer;
  6:         // 和 MERGE_CUMULATOR 的情况类似
  7:         if (cumulation.refCnt() > 1) {
  8:             // Expand cumulation (by replace it) when the refCnt is greater then 1 which may happen when the user
  9:             // use slice().retain() or duplicate().retain().
 10:             //
 11:             // See:
 12:             // - https://github.com/netty/netty/issues/2327
 13:             // - https://github.com/netty/netty/issues/1764
 14:             buffer = expandCumulation(alloc, cumulation, in.readableBytes());
 15:             buffer.writeBytes(in);
 16:             in.release();
 17:         } else {
 18:             CompositeByteBuf composite;
 19:             // 原来是 CompositeByteBuf 类型，直接使用
 20:             if (cumulation instanceof CompositeByteBuf) {
 21:                 composite = (CompositeByteBuf) cumulation;
 22:             // 原来不是 CompositeByteBuf 类型，创建，并添加到其中
 23:             } else {
 24:                 composite = alloc.compositeBuffer(Integer.MAX_VALUE);
 25:                 composite.addComponent(true, cumulation);
 26:             }
 27:             // 添加 in 到 composite 中
 28:             composite.addComponent(true, in);
 29:             // 赋值给 buffer
 30:             buffer = composite;
 31:         }
 32:         // 返回 buffer
 33:         return buffer;
 34:     }
 35: 
 36: };
```

- 第 7 至 16 行：`cumulation.refCnt() > 1` 成立，和 `MERGE_CUMULATOR` 的情况一致，创建一个新的 ByteBuf 对象。这样，再下一次 `#cumulate(...)` 时，就会走【第 22 至 26 行】的情况。

- 获得

   

  ```
  composite
  ```

   

  对象

  - 第 19 至 21 行：如果原来**就是** CompositeByteBuf 类型，直接使用。
  - 第 22 至 26 行：如果原来**不是** CompositeByteBuf 类型，创建 CompositeByteBuf 对象，并添加 `cumulation` 到其中。

- 第 28 行：添加 `in` 到 `composite` 中，避免内存拷贝。

## 4.3 对比

关于 `MERGE_CUMULATOR` 和 `COMPOSITE_CUMULATOR` 的对比，已经写在 `COMPOSITE_CUMULATOR` 的**头上**的注释。

默认情况下，ByteToMessageDecoder 使用 `MERGE_CUMULATOR` 作为累加器。

# 5. ByteToMessageDecoder

`io.netty.handler.codec.ByteToMessageDecoder` ，继承 ChannelInboundHandlerAdapter 类，**抽象基类**，负责将 Byte 解码成 Message 。

> 老艿艿：ByteToMessageDecoder 的细节比较多，建议胖友理解如下小节即可：
>
> - [5.1 构造方法](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)
> - [5.2 channelRead](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)
> - [5.3 callDecode](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)
> - [5.4 channelReadComplete](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)

## 5.1 构造方法

```
private static final byte STATE_INIT = 0;
private static final byte STATE_CALLING_CHILD_DECODE = 1;
private static final byte STATE_HANDLER_REMOVED_PENDING = 2;

/**
 * 已累积的 ByteBuf 对象
 */
ByteBuf cumulation;
/**
 * 累计器
 */
private Cumulator cumulator = MERGE_CUMULATOR;
/**
 * 是否每次只解码一条消息，默认为 false 。
 *
 * 部分解码器为 true ，例如：Socks4ClientDecoder
 *
 * @see #callDecode(ChannelHandlerContext, ByteBuf, List)
 */
private boolean singleDecode;
/**
 * 是否解码到消息。
 *
 * WasNull ，说明就是没解码到消息
 *
 * @see #channelReadComplete(ChannelHandlerContext)
 */
private boolean decodeWasNull;
/**
 * 是否首次读取，即 {@link #cumulation} 为空
 */
private boolean first;
/**
 * A bitmask where the bits are defined as
 * <ul>
 *     <li>{@link #STATE_INIT}</li>
 *     <li>{@link #STATE_CALLING_CHILD_DECODE}</li>
 *     <li>{@link #STATE_HANDLER_REMOVED_PENDING}</li>
 * </ul>
 *
 * 解码状态
 *
 * 0 - 初始化
 * 1 - 调用 {@link #decode(ChannelHandlerContext, ByteBuf, List)} 方法中，正在进行解码
 * 2 - 准备移除
 */
private byte decodeState = STATE_INIT;
/**
 * 读取释放阀值
 */
private int discardAfterReads = 16;
/**
 * 已读取次数。
 *
 * 再读取 {@link #discardAfterReads} 次数据后，如果无法全部解码完，则进行释放，避免 OOM
 */
private int numReads;

protected ByteToMessageDecoder() {
    // 校验，不可共享
    ensureNotSharable();
}
```

属性比较简单，胖友自己看注释。

## 5.2 channelRead

`#channelRead(ChannelHandlerContext ctx, Object msg)` 方法，读取到新的数据，进行解码。代码如下：

```
 1: @Override
 2: public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
 3:     if (msg instanceof ByteBuf) {
 4:         // 创建 CodecOutputList 对象
 5:         CodecOutputList out = CodecOutputList.newInstance();
 6:         try {
 7:             ByteBuf data = (ByteBuf) msg;
 8:             // 判断是否首次
 9:             first = cumulation == null;
10:             // 若首次，直接使用读取的 data
11:             if (first) {
12:                 cumulation = data;
13:             // 若非首次，将读取的 data ，累积到 cumulation 中
14:             } else {
15:                 cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data);
16:             }
17:             // 执行解码
18:             callDecode(ctx, cumulation, out);
19:         } catch (DecoderException e) {
20:             throw e; // 抛出异常
21:         } catch (Exception e) {
22:             throw new DecoderException(e); // 封装成 DecoderException 异常，抛出
23:         } finally {
24:             // cumulation 中所有数据被读取完，直接释放全部
25:             if (cumulation != null && !cumulation.isReadable()) {
26:                 numReads = 0; // 重置 numReads 次数
27:                 cumulation.release(); // 释放 cumulation
28:                 cumulation = null; // 置空 cumulation
29:             // 读取次数到达 discardAfterReads 上限，释放部分的已读
30:             } else if (++ numReads >= discardAfterReads) {
31:                 // We did enough reads already try to discard some bytes so we not risk to see a OOME.
32:                 // See https://github.com/netty/netty/issues/4275
33:                 numReads = 0; // 重置 numReads 次数
34:                 discardSomeReadBytes(); // 释放部分的已读
35:             }
36: 
37:             // 解码消息的数量
38:             int size = out.size();
39:             // 是否解码到消息
40:             decodeWasNull = !out.insertSinceRecycled();
41: 
42:             // 触发 Channel Read 事件。可能是多条消息
43:             fireChannelRead(ctx, out, size);
44: 
45:             // 回收 CodecOutputList 对象
46:             out.recycle();
47:         }
48:     } else {
49:         // 触发 Channel Read 事件到下一个节点
50:         ctx.fireChannelRead(msg);
51:     }
52: }
```

- 第 48 至 51 行：消息的类型**不是** ByteBuf 类，直接触发 Channel Read 事件到下一个节点。也就说，不进行解码。

- 第 3 行：消息的类型**是** ByteBuf 类，开始解码。

- 第 5 行：创建 CodecOutputList 对象。CodecOutputList 的简化代码如下：

  ```
  /**
   * Special {@link AbstractList} implementation which is used within our codec base classes.
   */
  final class CodecOutputList extends AbstractList<Object> implements RandomAccess {
  
      // ... 省略代码
  }
  ```

  - 如下内容，引用自 [《自顶向下深入分析Netty（八）–CodecHandler》](https://www.jianshu.com/p/7c439cc7b01c)

    > 解码结果列表 CodecOutputList 是 Netty 定制的一个特殊列表，该列表在线程中被缓存，可循环使用来存储解码结果，减少不必要的列表实例创建，从而提升性能。由于解码结果需要频繁存储，普通的 ArrayList 难以满足该需求，故定制化了一个特殊列表，由此可见 Netty 对优化的极致追求。

  - 第 7 至 9 行：通过

     

    ```
    cumulation
    
    ```

     

    是否为

     

    ```
    null
    
    ```

     

    来判断，是否为首次

     

    ```
    first
    
    ```

     

    。

    - 若**是**首次，直接使用读取的 `data` ( `ByteBuf data = (ByteBuf) msg` )。
    - 若**非**首次，将读取的 `data` ，累积到 `cumulation` 中。在 [「4. Cumulator」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) 中，我们已经详细解析。

- 第 18 行：调用 `#callDecode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。而解码的结果，会添加到 `out` 数组中。详细解析，见 [「5.3 callDecode」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) 。

- 第 19 至 22 行：若发生异常，抛出 DecoderException 异常。

- 第 24 至 35 行：根据 `cumulation` 的情况，释放 `cumulation` 。

  - 第 24 至 28 行：`cumulation` 中所有数据被读取完，直接**释放全部**。

  - 第 29 至 35 行：读取次数( `numReads` )到达 `discardAfterReads` 上限，重置计数，并调用 `#discardSomeReadBytes()` 方法，释放部分的已读。😈 如果一直不去释放，等到满足【第 24 至 28 行】的条件，很有可能会出现 OOM 的情况。代码如下：

    ```
    protected final void discardSomeReadBytes() {
        if (cumulation != null && !first
                && cumulation.refCnt() == 1) { // <1> 如果用户使用了 slice().retain() 和 duplicate().retain() 使 refCnt > 1 ，表明该累积区还在被用户使用，丢弃数据可能导致用户的困惑，所以须确定用户不再使用该累积区的已读数据，此时才丢弃。
            // discard some bytes if possible to make more room in the
            // buffer but only if the refCnt == 1  as otherwise the user may have
            // used slice().retain() or duplicate().retain().
            //
            // See:
            // - https://github.com/netty/netty/issues/2327
            // - https://github.com/netty/netty/issues/1764
            // <2> 释放部分
            cumulation.discardSomeReadBytes();
        }
    }
    
    ```

    - `<1>` 处，原因见中文注释。
    - `<2>` 处，释放**部分**已读字节区。注意，是“部分”，而不是“全部”，避免一次性释放全部，时间过长。并且，能够读取到这么“大”，往往字节数容量不小。如果直接释放掉“全部”，那么后续还需要再重复扩容，反倒不好。

- 第 38 行：获得解码消息的数量。

  - 第 40 行：是否解码到消息。为什么不直接使用

     

    ```
    size
    
    ```

     

    来判断呢？因为如果添加了消息，然后又移除该消息，此时

     

    ```
    size
    
    ```

     

    为 0 ，但是

     

    ```
    !out.insertSinceRecycled()
    
    ```

     

    为

     

    ```
    true
    
    ```

     

    。

    - 另外，我们在 [「5.3 callDecode」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) 中，将会看到一个 `out` 的清理操作，到时会更加明白。

- 第 43 行：调用 `#fireChannelRead(ChannelHandlerContext ctx, List<Object> msgs, int numElements)` **静态**方法，触发 Channel Read 事件。可能是多条消息。代码如下：

  ```
  /**
   * Get {@code numElements} out of the {@link List} and forward these through the pipeline.
   */
  static void fireChannelRead(ChannelHandlerContext ctx, List<Object> msgs, int numElements) {
      if (msgs instanceof CodecOutputList) { // 如果是 CodecOutputList 类型，特殊优化
          fireChannelRead(ctx, (CodecOutputList) msgs, numElements);
      } else {
          for (int i = 0; i < numElements; i++) {
              ctx.fireChannelRead(msgs.get(i));
          }
      }
  }
  
  /**
   * Get {@code numElements} out of the {@link CodecOutputList} and forward these through the pipeline.
   */
  static void fireChannelRead(ChannelHandlerContext ctx, CodecOutputList msgs, int numElements) {
      for (int i = 0; i < numElements; i ++) {
          ctx.fireChannelRead(msgs.getUnsafe(i)); // getUnsafe 是自定义的方法，减少越界判断，效率更高
      }
  }
  
  ```

  - 遍历 `msgs` 数组，每条消息触发一次 Channel Read 事件。

- 第 46 行：回收 CodecOutputList 对象。

## 5.3 callDecode

`#callDecode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。而解码的结果，会添加到 `out` 数组中。代码如下：

```
 1: protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) {
 2:     try {
 3:         // 循环读取，直到不可读
 4:         while (in.isReadable()) {
 5:             // 记录
 6:             int outSize = out.size();
 7:             // out 非空，说明上一次解码有解码到消息
 8:             if (outSize > 0) {
 9:                 // 触发 Channel Read 事件。可能是多条消息
10:                 fireChannelRead(ctx, out, outSize);
11:                 // 清空
12:                 out.clear();
13: 
14:                 // 用户主动删除该 Handler ，继续操作 in 是不安全的
15:                 // Check if this handler was removed before continuing with decoding.
16:                 // If it was removed, it is not safe to continue to operate on the buffer.
17:                 //
18:                 // See:
19:                 // - https://github.com/netty/netty/issues/4635
20:                 if (ctx.isRemoved()) {
21:                     break;
22:                 }
23:                 outSize = 0;
24:             }
25: 
26:             // 记录当前可读字节数
27:             int oldInputLength = in.readableBytes();
28: 
29:             // 执行解码。如果 Handler 准备移除，在解码完成后，进行移除。
30:             decodeRemovalReentryProtection(ctx, in, out);
31: 
32:             // 用户主动删除该 Handler ，继续操作 in 是不安全的
33:             // Check if this handler was removed before continuing the loop.
34:             // If it was removed, it is not safe to continue to operate on the buffer.
35:             //
36:             // See https://github.com/netty/netty/issues/1664
37:             if (ctx.isRemoved()) {
38:                 break;
39:             }
40: 
41:             // 整列判断 `out.size() == 0` 比较合适。因为，如果 `outSize > 0` 那段，已经清理了 out 。
42:             if (outSize == out.size()) {
43:                 // 如果未读取任何字节，结束循环
44:                 if (oldInputLength == in.readableBytes()) {
45:                     break;
46:                 // 如果可读字节发生变化，继续读取
47:                 } else {
48:                     continue;
49:                 }
50:             }
51: 
52:             // 如果解码了消息，但是可读字节数未变，抛出 DecoderException 异常。说明，有问题。
53:             if (oldInputLength == in.readableBytes()) {
54:                 throw new DecoderException(StringUtil.simpleClassName(getClass()) + ".decode() did not read anything but decoded a message.");
55:             }
56: 
57:             // 如果开启 singleDecode ，表示只解析一次，结束循环
58:             if (isSingleDecode()) {
59:                 break;
60:             }
61:         }
62:     } catch (DecoderException e) {
63:         throw e;
64:     } catch (Exception cause) {
65:         throw new DecoderException(cause);
66:     }
67: }

```

- 第 4 行：循环读取 `in` ，直到不可读。

- 第 5 行：记录

   

  ```
  out
  
  ```

   

  的大小。

  - 第 8 行：如果 `out` 非空，说明上一次解码有解码到消息。
  - 第 10 行：调用 `#fireChannelRead(ChannelHandlerContext ctx, List<Object> msgs, int numElements)`**静态**方法，触发 Channel Read 事件。可能是多条消息。😈 关于该方法，上文已经详细解析。
  - 第 12 行：清空 `out` 。所以，有可能会出现 `#channelRead(ChannelHandlerContext ctx, Object msg)` 方法的【第 40 行】的情况。
  - 第 14 至 22 行：用户主动删除该 Handler ，继续操作 `in` 是不安全的，所以结束循环。
  - 第 23 行：记录 `out` 的大小为**零**。所以，实际上，`outSize` 没有必要记录。因为，一定是为**零**。

- 第 27 行：记录当前可读字节数。

- 第 30 行：调用 `#decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。如果 Handler 准备移除，在解码完成后，进行移除。详细解析，见 [「5.3.1 decodeRemovalReentryProtection」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) 中。

- 第 32 至 39 行：用户主动删除该 Handler ，继续操作 `in` 是不安全的，所以结束循环。

- 第 42 行：直接判断

   

  ```
  out.size() == 0
  
  ```

   

  比较合适。因为【第 8 至 24 行】的代码，能够保证

   

  ```
  outSize
  
  ```

   

  等于

  零

  。

  - 第 43 至 45 行：如果**未读取**任何字节，`break` 结束循环。
  - 第 46 至 49 行：如果可读字节**发生变化**，`continue` 重新开始循环，即继续读取。

- 第 52 至 55 行：如果解码了消息，但是可读字节数未变，抛出 DecoderException 异常。说明，有问题。

- 第 57 至 60 行：如果开启 `singleDecode` ，表示只解析一次，`break` 结束循环。

- 第 62 至 66 行：如果发生异常，抛出 DecoderException 异常。

😈 代码有一些长，胖友保持耐心看完哈。其实，蛮简单的。

### 5.3.1 decodeRemovalReentryProtection

`#decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。如果 Handler 准备移除，在解码完成后，进行移除。代码如下：

```
 1: final void decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {
 2:     // 设置状态为 STATE_CALLING_CHILD_DECODE
 3:     decodeState = STATE_CALLING_CHILD_DECODE;
 4:     try {
 5:         // 执行解码
 6:         decode(ctx, in, out);
 7:     } finally {
 8:         // 判断是否准备移除
 9:         boolean removePending = decodeState == STATE_HANDLER_REMOVED_PENDING;
10:         // 设置状态为 STATE_INIT
11:         decodeState = STATE_INIT;
12:         // 移除当前 Handler
13:         if (removePending) {
14:             handlerRemoved(ctx);
15:         }
16:     }
17: }

```

- 第 3 行：设置状态(`decodeState`) 为 `STATE_CALLING_CHILD_DECODE` 。

- 第 6 行：调用 `#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。代码如下：

  ```
  /**
   * Decode the from one {@link ByteBuf} to an other. This method will be called till either the input
   * {@link ByteBuf} has nothing to read when return from this method or till nothing was read from the input
   * {@link ByteBuf}.
   *
   * @param ctx           the {@link ChannelHandlerContext} which this {@link ByteToMessageDecoder} belongs to
   * @param in            the {@link ByteBuf} from which to read data
   * @param out           the {@link List} to which decoded messages should be added
   * @throws Exception    is thrown if an error occurs
   */
  protected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception;
  
  ```

  - 子类实现该方法，就可以愉快的解码消息了，**并且，也只需要实现该方法**。其它的逻辑，ByteToMessageDecoder 已经全部帮忙实现了。

- 第 9 行：判断是否准备移除。那么什么情况下，会出现`decodeState ==STATE_HANDLER_REMOVED_PENDING`成立呢？详细解析，见「5.7 handlerRemoved」。

  - 第 11 行：设置状态(`decodeState`) 为 `STATE_HANDLER_REMOVED_PENDING` 。
  - 第 12 至 15 行：如果准备移除，则调用 `#handlerRemoved(ChannelHandlerContext ctx)` 方法，移除当前 Handler 。详细解析，见 [「5.7 handlerRemoved」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) 。

## 5.4 channelReadComplete

`#channelReadComplete(ChannelHandlerContext ctx)` 方法，代码如下：

```
 1: @Override
 2: public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
 3:     // 重置 numReads
 4:     numReads = 0;
 5:     // 释放部分的已读
 6:     discardSomeReadBytes();
 7:     // 未解码到消息，并且未开启自动读取，则再次发起读取，期望读取到更多数据，以便解码到消息
 8:     if (decodeWasNull) {
 9:         decodeWasNull = false; // 重置 decodeWasNull
10:         if (!ctx.channel().config().isAutoRead()) {
11:             ctx.read();
12:         }
13:     }
14:     // 触发 Channel ReadComplete 事件到下一个节点
15:     ctx.fireChannelReadComplete();
16: }

```

- 第 4 行：重置 `numReads` 。
- 第 6 行：调用 `#discardSomeReadBytes()` 方法，释放部分的已读。
- 第 7 至 13 行：未解码到消息( `decodeWasNull == true` )，并且未开启自动读取( `ctx.channel().config().isAutoRead() == false` )，则再次发起读取，期望读取到更多数据，以便解码到消息。
- 第 15 行：触发 Channel ReadComplete 事件到下一个节点。

## 5.5 channelInactive

`#channelInactive(ChannelHandlerContext ctx)` 方法，通道处于未激活( Inactive )，解码完剩余的消息，并释放相关资源。代码如下：

```
@Override
public void channelInactive(ChannelHandlerContext ctx) throws Exception {
    channelInputClosed(ctx, true);
}

```

- 调用 `#channelInputClosed(ChannelHandlerContext ctx, boolean callChannelInactive)` 方法，执行 Channel 读取关闭的逻辑。代码如下：

  ```
   1: private void channelInputClosed(ChannelHandlerContext ctx, boolean callChannelInactive) throws Exception {
   2:     // 创建 CodecOutputList 对象
   3:     CodecOutputList out = CodecOutputList.newInstance();
   4:     try {
   5:         // 当 Channel 读取关闭时，执行解码剩余消息的逻辑
   6:         channelInputClosed(ctx, out);
   7:     } catch (DecoderException e) {
   8:         throw e;
   9:     } catch (Exception e) {
  10:         throw new DecoderException(e);
  11:     } finally {
  12:         try {
  13:             // 释放 cumulation
  14:             if (cumulation != null) {
  15:                 cumulation.release();
  16:                 cumulation = null;
  17:             }
  18:             int size = out.size();
  19:             // 触发 Channel Read 事件到下一个节点。可能是多条消息
  20:             fireChannelRead(ctx, out, size);
  21:             // 如果有解码到消息，则触发 Channel ReadComplete 事件到下一个节点。
  22:             if (size > 0) {
  23:                 // Something was read, call fireChannelReadComplete()
  24:                 ctx.fireChannelReadComplete();
  25:             }
  26:             // 如果方法调用来源是 `#channelInactive(...)` ，则触发 Channel Inactive 事件到下一个节点
  27:             if (callChannelInactive) {
  28:                 ctx.fireChannelInactive();
  29:             }
  30:         } finally {
  31:             // 回收 CodecOutputList 对象
  32:             // Recycle in all cases
  33:             out.recycle();
  34:         }
  35:     }
  36: }
  
  ```

  - 第 3 行：创建 CodecOutputList 对象。

    - 第 6 行：调用 `#channelInputClosed(ChannelHandlerContext ctx, List<Object> out)` 方法，当 Channel 读取关闭时，执行解码剩余消息的逻辑。代码如下：

      ```
      /**
       * Called when the input of the channel was closed which may be because it changed to inactive or because of
       * {@link ChannelInputShutdownEvent}.
       */
      void channelInputClosed(ChannelHandlerContext ctx, List<Object> out) throws Exception {
          if (cumulation != null) {
              // 执行解码
              callDecode(ctx, cumulation, out);
              // 最后一次，执行解码
              decodeLast(ctx, cumulation, out);
          } else {
              // 最后一次，执行解码
              decodeLast(ctx, Unpooled.EMPTY_BUFFER, out);
          }
      }
      
      /**
       * Is called one last time when the {@link ChannelHandlerContext} goes in-active. Which means the
       * {@link #channelInactive(ChannelHandlerContext)} was triggered.
       *
       * By default this will just call {@link #decode(ChannelHandlerContext, ByteBuf, List)} but sub-classes may
       * override this for some special cleanup operation.
       */
      protected void decodeLast(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {
          if (in.isReadable()) {
              // Only call decode() if there is something left in the buffer to decode.
              // See https://github.com/netty/netty/issues/4386
              decodeRemovalReentryProtection(ctx, in, out);
          }
      }
      
      ```

      - 其中，`#decodeLast(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，是可以被重写的。例如，HttpObjectDecoder 就重写了该方法。

    - 第 7 至 10 行：如果发生异常，就抛出 DecoderException 异常。

  - 第 13 至 17 行：释放 `cumulation` 。

  - 第 20 行：调用 `#fireChannelRead(ChannelHandlerContext ctx, List<Object> msgs, int numElements)`**静态**方法，触发 Channel Read 事件。可能是多条消息。

  - 第 21 至 25 行：如果有解码到消息( `size > 0` )，则触发 Channel ReadComplete 事件到下一个节点。

  - 第 26 至 29 行：如果方法调用来源是 `#channelInactive(...)` ，则触发 Channel Inactive 事件到下一个节点。

  - 第 30 至 35 行：回收 CodecOutputList 对象。

😈 对于该方法的目的，笔者的理解是，尽可能在解码一次剩余的 `cumulation` ，在 Channel 变成未激活时。细节好多呀！！！

## 5.6 userEventTriggered

`#userEventTriggered(ChannelHandlerContext ctx, Object evt)` 方法，处理 ChannelInputShutdownEvent 事件，即 Channel 关闭读取。代码如下：

```
@Override
public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
    if (evt instanceof ChannelInputShutdownEvent) {
        // The decodeLast method is invoked when a channelInactive event is encountered.
        // This method is responsible for ending requests in some situations and must be called
        // when the input has been shutdown.
        channelInputClosed(ctx, false);
    }
    // 继续传播 evt 到下一个节点
    super.userEventTriggered(ctx, evt);
}

```

- 调用 `#channelInputClosed(ChannelHandlerContext ctx, boolean callChannelInactive)` 方法，执行 Channel 读取关闭的逻辑。
- 继续传播 `evt` 到下一个节点。

😈 对于该方法的目的，笔者的理解是，尽可能在解码一次剩余的 `cumulation` ，在 Channel 关闭读取。细节好多呀！！！

## 5.7 handlerRemoved

`#handlerRemoved(ChannelHandlerContext ctx)` 方法，代码如下：

```
 1: @Override
 2: public final void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
 3:     // 状态处于 STATE_CALLING_CHILD_DECODE 时，标记状态为 STATE_HANDLER_REMOVED_PENDING
 4:     if (decodeState == STATE_CALLING_CHILD_DECODE) {
 5:         decodeState = STATE_HANDLER_REMOVED_PENDING;
 6:         return; // 返回！！！！结合 `#decodeRemovalReentryProtection(...)` 方法，一起看。
 7:     }
 8:     ByteBuf buf = cumulation;
 9:     if (buf != null) {
10:         // 置空 cumulation
11:         // Directly set this to null so we are sure we not access it in any other method here anymore.
12:         cumulation = null;
13: 
14:         int readable = buf.readableBytes();
15:         // 有可读字节
16:         if (readable > 0) {
17:             // 读取剩余字节，并释放 buf
18:             ByteBuf bytes = buf.readBytes(readable);
19:             buf.release();
20:             // 触发 Channel Read 到下一个节点
21:             ctx.fireChannelRead(bytes);
22:         // 无可读字节
23:         } else {
24:             // 释放 buf
25:             buf.release();
26:         }
27: 
28:         // 置空 numReads
29:         numReads = 0;
30:         // 触发 Channel ReadComplete 到下一个节点
31:         ctx.fireChannelReadComplete();
32:     }
33:     // 执行移除逻辑
34:     handlerRemoved0(ctx);
35: }

```

- 第 3 至 7 行：如果状态( `decodeState` )处于 `STATE_CALLING_CHILD_DECODE` 时，说明正在执行 `#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法中。如果此时，直接往下执行，`cumulation` 将被直接释放，而 `#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法可能正在解码中，很大可能性造成影响，导致错误。所以，此处仅仅标记状态( `decodeState` )为 `STATE_HANDLER_REMOVED_PENDING` 。等到 `#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法执行完成后，在进行移除。胖友，此时可以再跳回 [「5.3.1 decodeRemovalReentryProtection」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#) ，进行再次理解。

- 【有可读字节】第 15 至 21 行：读取剩余字节，并释放 `buf` 。然后，触发 Channel Read 到下一个节点。通过这样的方式，避免 `cumulation` 中，有字节被“丢失”，即使当前可能无法解码成一个数据包。

- 【无可读字节】第 22 至 26 行：直接释放 `buf` 。

- 第 29 行：置空 `numReads` 。

- 第 34 行：调用 `#handlerRemoved0(ChannelHandlerContext ctx)` 方法，执行移除逻辑。代码如下：

  ```
  /**
   * Gets called after the {@link ByteToMessageDecoder} was removed from the actual context and it doesn't handle
   * events anymore.
   */
  protected void handlerRemoved0(ChannelHandlerContext ctx) throws Exception { }
  
  ```

  - 默认情况下，该方法实现为空。目前可重写该方法，实现自定义的资源释放。目前重写该方法的类，例如：Http2ConnectionHandler、SslHandler 等等。

## 5.8 internalBuffer

`#internalBuffer()` 方法，获得 ByteBuf 对象。代码如下：

```java
/**
 * Returns the internal cumulative buffer of this decoder. You usually
 * do not need to access the internal buffer directly to write a decoder.
 * Use it only when you must use it at your own risk.
 */
protected ByteBuf internalBuffer() {
    if (cumulation != null) {
        return cumulation;
    } else {
        return Unpooled.EMPTY_BUFFER;
    }
}

```

## 5.9 actualReadableBytes

`#actualReadableBytes()` 方法，获得可读字节数。代码如下：

```java
/**
 * Returns the actual number of readable bytes in the internal cumulative
 * buffer of this decoder. You usually do not need to rely on this value
 * to write a decoder. Use it only when you must use it at your own risk.
 * This method is a shortcut to {@link #internalBuffer() internalBuffer().readableBytes()}.
 */
protected int actualReadableBytes() {
    return internalBuffer().readableBytes();
}

```

# 666. 彩蛋

细节有点多，可能对如下小节理解不够到位。如有错误，烦请胖友教育。

- [「5.5 channelInactive」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)
- [「5.6 userEventTriggered」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)
- [「5.7 handlerRemoved」](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl/#)

------

本文参考如下文章：

- 简书闪电侠 [《netty源码分析之拆包器的奥秘》](https://www.jianshu.com/p/dc26e944da95)
- Hypercube [《自顶向下深入分析Netty（八）–CodecHandler》](https://www.jianshu.com/p/7c439cc7b01c)

# Codec 之 ByteToMessageDecoder（二）FrameDecoder



# 1. 概述

在 [《精尽 Netty 源码解析 —— Codec 之 ByteToMessageDecoder（一）》](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl) 中，我们看到 ByteToMessageDecoder 有四个 FrameDecoder 实现类：

- ① FixedLengthFrameDecoder ，基于**固定长度**消息进行粘包拆包处理的。
- ② LengthFieldBasedFrameDecoder ，基于**消息头指定消息长度**进行粘包拆包处理的。
- ③ LineBasedFrameDecoder ，基于**换行**来进行消息粘包拆包处理的。
- ④ DelimiterBasedFrameDecoder ，基于**指定消息边界方式**进行粘包拆包处理的。

实际上，上述四个 FrameDecoder 实现可以进行规整：

- ① 是 ② 的特例，**固定长度**是**消息头指定消息长度**的一种形式。
- ③ 是 ④ 的特例，**换行**是于**指定消息边界方式**的一种形式。

本文，笔者只分享 ① 和 ③ 。对于 ② 和 ④ ，会提供相关的文章。

# 2. FixedLengthFrameDecoder

`io.netty.handler.codec.FixedLengthFrameDecoder` ，继承 ByteToMessageDecoder 抽象类，基于**固定长度**消息进行粘包拆包处理的。

如果下是固定长度为 3 的数据流解码：

```
+---+----+------+----+      +-----+-----+-----+
| A | BC | DEFG | HI |  ->  | ABC | DEF | GHI |
+---+----+------+----+      +-----+-----+-----+
```

## 2.1 构造方法

```java
/**
 * 固定长度
 */
private final int frameLength;

/**
 * Creates a new instance.
 *
 * @param frameLength the length of the frame
 */
public FixedLengthFrameDecoder(int frameLength) {
    if (frameLength <= 0) {
        throw new IllegalArgumentException("frameLength must be a positive integer: " + frameLength);
    }
    this.frameLength = frameLength;
}
```

- `frameLength` 属性，固定长度。

## 2.2 decode

`#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。代码如下：

```java
1: @Override
2: protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {
3:     // 解码消息
4:     Object decoded = decode(ctx, in);
5:     // 添加到 out 结果中
6:     if (decoded != null) {
7:         out.add(decoded);
8:     }
9: }
```

- 第 4 行：调用 `#decode(ChannelHandlerContext ctx, ByteBuf in)` 方法，解码消息。代码如下：

  ```java
  /**
   * Create a frame out of the {@link ByteBuf} and return it.
   *
   * @param   ctx             the {@link ChannelHandlerContext} which this {@link ByteToMessageDecoder} belongs to
   * @param   in              the {@link ByteBuf} from which to read data
   * @return  frame           the {@link ByteBuf} which represent the frame or {@code null} if no frame could
   *                          be created.
   */
  protected Object decode(@SuppressWarnings("UnusedParameters") ChannelHandlerContext ctx, ByteBuf in) throws Exception {
      // 可读字节不够 frameLength 长度，无法解码出消息。
      if (in.readableBytes() < frameLength) {
          return null;
      // 可读字节足够 frameLength 长度，解码出一条消息。
      } else {
          return in.readRetainedSlice(frameLength);
      }
  }
  ```

  - 当可读字节足够 `frameLength` 长度时，调用 `ByteBuf#readRetainedSlice(int length)` 方法，读取一个 Slice ByteBuf 对象，并增加引用计数。并且该 Slice ByteBuf 作为解码的一条消息。另外，`ByteBuf#readRetainedSlice(int length)` 的过程，因为是共享原有 ByteBuf `in` 数组，所以不存在数据拷贝。

- 第 5 至 8 行：若解码到消息，添加到 `out` 结果中。

# 3. LineBasedFrameDecoder

`io.netty.handler.codec.LineBasedFrameDecoder` ，继承 ByteToMessageDecoder 抽象类，基于**换行**来进行消息粘包拆包处理的。

它会处理 `"\n"` 和 `"\r\n"` 两种换行符。

## 3.1 构造方法

```java
/**
 * 一条消息的最大长度
 *
 * Maximum length of a frame we're willing to decode.
 */
private final int maxLength;
/**
 * 是否快速失败
 *
 * 当 true 时，未找到消息，但是超过最大长度，则马上触发 Exception 到下一个节点
 * 当 false 时，未找到消息，但是超过最大长度，需要匹配到一条消息后，再触发 Exception 到下一个节点
 *
 * Whether or not to throw an exception as soon as we exceed maxLength.
 */
private final boolean failFast;
/**
 * 是否过滤掉换行分隔符。
 *
 * 如果为 true ，解码的消息不包含换行符。
 */
private final boolean stripDelimiter;

/**
 * 是否处于废弃模式
 *
 * 如果为 true ，说明解析超过最大长度( maxLength )，结果还是找不到换行符
 *
 * True if we're discarding input because we're already over maxLength.
 */
private boolean discarding;
/**
 * 废弃的字节数
 */
private int discardedBytes;

/**
 * 最后扫描的位置
 *
 * Last scan position.
 */
private int offset;

/**
 * Creates a new decoder.
 * @param maxLength  the maximum length of the decoded frame.
 *                   A {@link TooLongFrameException} is thrown if
 *                   the length of the frame exceeds this value.
 */
public LineBasedFrameDecoder(final int maxLength) {
    this(maxLength, true, false);
}

/**
 * Creates a new decoder.
 * @param maxLength  the maximum length of the decoded frame.
 *                   A {@link TooLongFrameException} is thrown if
 *                   the length of the frame exceeds this value.
 * @param stripDelimiter  whether the decoded frame should strip out the
 *                        delimiter or not
 * @param failFast  If <tt>true</tt>, a {@link TooLongFrameException} is
 *                  thrown as soon as the decoder notices the length of the
 *                  frame will exceed <tt>maxFrameLength</tt> regardless of
 *                  whether the entire frame has been read.
 *                  If <tt>false</tt>, a {@link TooLongFrameException} is
 *                  thrown after the entire frame that exceeds
 *                  <tt>maxFrameLength</tt> has been read.
 */
public LineBasedFrameDecoder(final int maxLength, final boolean stripDelimiter, final boolean failFast) {
    this.maxLength = maxLength;
    this.failFast = failFast;
    this.stripDelimiter = stripDelimiter;
}
```

- `maxLength`属性，一条消息的最大长度。原本以为 LineBasedFrameDecoder 会比较简单，但是因为多了`maxLength`复杂很多。为什么这么说呢？

  - 假设 `maxLength = 2` ，接收到的数据为 `"abcd\nEF\n"`( 直接以字符串举例，为了可阅读性 )，那么 `"abcd"` 是不符合条件的消息，因为长度为 4 ，超过最大长度 `maxLength` 。
  - 但是考虑到拆粘包的情况，可能初始化接收到的是 `"abc"` ，那么无法匹配到 `\n` 换行符。但是呢，`"abc"` 的长度为 3，超过最大长度 `maxLength` ，需要等待读取到 `"d\n"` 部分，然后抛弃 `"abcd"` 整条。再之后，继续读取符合条件的 `"EF"`段。
  - 😈 比较绕，胖友好好理解下。

- `failFast`属性，是否快速失败。

  - `true` 时，未找到消息，但是超过最大长度，则马上触发 Exception 到下一个节点。
  - 当 `false` 时，未找到消息，但是超过最大长度，需要匹配到一条消息后，再触发 Exception 到下一个节点。
  - 😈 也有点绕，等下结合代码具体理解。

- `stripDelimiter` 属性，是否过滤掉换行分隔符。如果为 `true` ，解码的消息不包含换行符。

- ```
  discarding
  ```

   

  属性，是否处于废弃模式。如果为

   

  ```
  true
  ```

   

  ，说明解析超过最大长度(

   

  ```
  maxLength
  ```

   

  )，结果还是找不到换行符。

  - 😈 也有点绕，等下结合代码具体理解。
  - `discardedBytes` 属性，废弃的字节数。
  - `offset` 属性，最后扫描的位置。

## 3.2 decode

`#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，执行解码。代码如下：

```
@Override
protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {
    Object decoded = decode(ctx, in);
    if (decoded != null) {
        out.add(decoded);
    }
}
```

- 这段代码，和 `FixedLengthFrameDecoder#decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)` 方法，是一样的。

------

`#decode(ChannelHandlerContext ctx, ByteBuf buffer)` 方法，执行解码。代码如下：

```
 1: protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception {
 2:     // 获得换行符的位置
 3:     final int eol = findEndOfLine(buffer);
 4:     if (!discarding) { // 未处于废弃模式
 5:         if (eol >= 0) { // 找到
 6:             final ByteBuf frame;
 7:             final int length = eol - buffer.readerIndex(); // 读取长度
 8:             final int delimLength = buffer.getByte(eol) == '\r' ? 2 : 1; // 分隔符的长度。2 为 `\r\n` ，1 为 `\n`
 9: 
10:             // 超过最大长度
11:             if (length > maxLength) {
12:                 // 设置新的读取位置
13:                 buffer.readerIndex(eol + delimLength);
14:                 // 触发 Exception 到下一个节点
15:                 fail(ctx, length);
16:                 // 返回 null ，即未解码到消息
17:                 return null;
18:             }
19: 
20:             // 解码出一条消息。
21:             if (stripDelimiter) {
22:                 frame = buffer.readRetainedSlice(length);
23:                 buffer.skipBytes(delimLength); // 忽略换行符
24:             } else {
25:                 frame = buffer.readRetainedSlice(length + delimLength);
26:             }
27: 
28:             // 返回解码的消息
29:             return frame;
30:         } else { // 未找到
31:             final int length = buffer.readableBytes();
32:             // 超过最大长度
33:             if (length > maxLength) {
34:                 // 记录 discardedBytes
35:                 discardedBytes = length;
36:                 // 跳到写入位置
37:                 buffer.readerIndex(buffer.writerIndex());
38:                 // 标记 discarding 为废弃模式
39:                 discarding = true;
40:                 // 重置 offset
41:                 offset = 0;
42:                 // 如果快速失败，则触发 Exception 到下一个节点
43:                 if (failFast) {
44:                     fail(ctx, "over " + discardedBytes);
45:                 }
46:             }
47:             return null;
48:         }
49:     } else { // 处于废弃模式
50:         if (eol >= 0) { // 找到
51:             final int length = discardedBytes + eol - buffer.readerIndex(); // 读取长度
52:             final int delimLength = buffer.getByte(eol) == '\r' ? 2 : 1; // 分隔符的长度。2 为 `\r\n` ，1 为 `\n`
53:             // 设置新的读取位置
54:             buffer.readerIndex(eol + delimLength);
55:             // 重置 discardedBytes
56:             discardedBytes = 0;
57:             // 设置 discarding 不为废弃模式
58:             discarding = false;
59:             // 如果不为快速失败，则触发 Exception 到下一个节点
60:             if (!failFast) {
61:                 fail(ctx, length);
62:             }
63:         } else { // 未找到
64:             // 增加 discardedBytes
65:             discardedBytes += buffer.readableBytes();
66:             // 跳到写入位置
67:             buffer.readerIndex(buffer.writerIndex());
68:         }
69:         return null;
70:     }
71: }
```

- 第 3 行：调用 `#findEndOfLine(final ByteBuf buffer)` 方法，获得换行符的位置。详细解析，这里胖友先跳到 [「3.3 findEndOfLine」](http://svip.iocoder.cn/Netty/Codec-1-2-ByteToMessageDecoder-FrameDecoder/#) 中。

- =============== 未处于 `discarding` 模式 ===============

- 根据是否找到换行符，分成 ① ② 两种情况。

- ① 第 5 行：**找到**换行符。

- 第 7 至 8 行：获得读取消息的长度、换行符的长度。

- 第 11 行：读取消息的长度，超过最大长度，则

  丢弃

  该消息。

  - 第 13 行：`buffer` 设置新的读取位置。
  - 第 15 行：调用 `#fail(...)` 方法，触发 Exception 到下一个节点。详细解析，见 [「3.4 fail」](http://svip.iocoder.cn/Netty/Codec-1-2-ByteToMessageDecoder-FrameDecoder/#) 。😈 注意，此处和 `failFast` 没有关系。
  - 【失败】第 17 行：返回 `null` ，即未解码到消息。

- 【成功】第 20 至 26 行：解码出一条消息。调用 `ByteBuf#readRetainedSlice(int length)` 方法，读取一个 Slice ByteBuf 对象，并增加引用计数。并且该 Slice ByteBuf 作为解码的一条消息。另外，`ByteBuf#readRetainedSlice(int length)` 的过程，因为是共享原有 ByteBuf `in` 数组，所以不存在数据拷贝。

- ② 第 30 行：**未找到**换行符，说明当前 `buffer` **不存在**完整的消息。需要继续读取新的数据，再次解码拆包。

- 第 33 行：可读字节，超过最大长度，那么即使后续找到换行符，消息也**一定**超过最大长度。

- 第 35 行：记录 `discardedBytes` 。因为【第 37 行】的代码，`buffer` 跳到写入位置，也就是抛弃了 `discardedBytes`字节数。

- 第 39 行：标记

   

  ```
  discarding
  ```

   

  为

   

  ```
  true
  ```

   

  ，进入废弃模式。那么，后续就会执行【第 49 至 70 行】的代码逻辑，寻找到换行符，解码拆包出该消息，并

  抛弃

  它。

  - 😈 这段，好好理解下。

- 第 41 行：重置 `offset` 为 0 。

- 第 42 至 45 行：如果快速失败( `failFast = true` )，调用 `#fail(...)` 方法，触发 Exception 到下一个节点。那么，不快速失败( `failFast = false` )呢？继续往下走，答案在【第 59 至 61 行】的代码，见分晓。

- 第 47 行：【失败】第 17 行：返回 `null` ，即未解码到消息。

- =============== 正处于 `discarding` 模式 ===============

- `discarding` 模式是什么呢？在【第 33 至 46 行】的代码，如果已读取的字节数，超过最大长度，那么进入 `discarding` 模式，继续寻找到换行符，解码拆包出该消息，并**抛弃**它。😈 实际上，它的效果是【第 30 至 48 行】+【第 49 至 69 行】和【第 10 至 18 行】的代码的效果是**等价的**，只是说【第 30 至 48 行】的代码，因为数据包是**不完整**( 找不到换行符 )的，所以进入【第 49 至 69 行】的代码。

- 根据是否找到换行符，分成 ① ② 两种情况。

- ① 第 50 行：**找到**换行符。

- 第 51 行：读取长度。此处的长度，算上了

   

  ```
  discardedBytes
  ```

   

  的部分。

  - 第 52 行：获得换行符的长度。

- 第 54 行：设置新的读取位置。因为，**找到**换行符。

- 第 56 行：重置 `discardedBytes` 为 0 。因为，**找到**换行符。

- 第 58 行：重置 `offset` 为 0 。因为，**找到**换行符。

- 第 59 至 62 行：如果不为快速失败(

   

  ```
  failFast = false
  ```

   

  )，调用

   

  ```
  #fail(...)
  ```

   

  方法，触发 Exception 到下一个节点。

  - 和【第 42 至 45 行】的代码，相对。
  - 也就说，`failFast = false` 的情况下，只有在解析到完整的消息，**才**触发 Exception 到下一个节点。😈 是不是很绕，哈哈哈哈。

- 【失败】第 69 行：返回 `null` ，虽然解码到消息，但是因为消息长度超过最大长度，所以进行**丢失**。和【第 17 行】的代码，是一个目的。

- ② 第 63 行：**未找到**换行符，说明当前 `buffer` **不存在**完整的消息。需要继续读取新的数据，再次解码拆包。

- 第 65 行：增加 `discardedBytes` 。

- 第 67 行：`buffer` 跳到写入位置。

- 第 69 行：返回 `null` ，即未解码到消息。

😈 整体逻辑，有点绕，不过很有趣。

## 3.3 findEndOfLine

`#findEndOfLine(final ByteBuf buffer)` 方法，获得换行符的位置。代码如下：

```
   /**
    * Returns the index in the buffer of the end of line found.
    * Returns -1 if no end of line was found in the buffer.
    */
 1: private int findEndOfLine(final ByteBuf buffer) {
 2:     int totalLength = buffer.readableBytes();
 3:     int i = buffer.forEachByte(buffer.readerIndex() + offset, totalLength - offset, ByteProcessor.FIND_LF);
 4:     // 找到
 5:     if (i >= 0) {
 6:         // 重置 offset
 7:         offset = 0;
 8:         // 如果前一个字节位 `\r` ，说明找到的是 `\n` ，所以需要 -1 ，因为寻找的是首个换行符的位置
 9:         if (i > 0 && buffer.getByte(i - 1) == '\r') {
10:             i--;
11:         }
12:     // 未找到，记录 offset
13:     } else {
14:         offset = totalLength;
15:     }
16:     return i;
17: }
```

- 关于 `offset` 的逻辑，笔者觉得有点问题。在这里，胖友先无视掉它。稍后，我们在统一分享。
- 第 3 行：在 `buffer` 的 `[readerIndex, readerIndex + readableBytes)` 位置范围内，查找 `\n` 换行符的位置。😈 在忽略 `offset` 的前提下。
- 【有找到】
  - 第 7 行：重置 `offset` 。
  - 第 8 至 11 行：如果前一个字节位 `\r` ，说明找到的是 `\n` ，所以需要 -1 ，因为寻找的是首个换行符的位置。
- 【没找到】
  - 第 14 行：记录 `offset` 。
- 第 16 行：返回位置 `i` 。

## 3.4 fail

`#fail(...)` 方法，触发 Exception 到下一个节点。代码如下：

```
private void fail(final ChannelHandlerContext ctx, int length) {
    fail(ctx, String.valueOf(length));
}

private void fail(final ChannelHandlerContext ctx, String length) {
    ctx.fireExceptionCaught(new TooLongFrameException("frame length (" + length + ") exceeds the allowed maximum (" + maxLength + ')'));
}

```

## 3.5 可能是 offset 的一个 bug

这里，只能说是 `offset` 的一个 bug ，也是笔者的一个推测。下面，我们来推导下。

![代码图](http://static2.iocoder.cn/images/Netty/2018_10_01/01.png)

- 第一根红线，在 `discarding` 模式下，如果读取不到换行符，每次 `buffer` 的读取位置，都会跳到写入位置。
- 第三根红线，`offset` 记录**上一次**读取的字节数。
- 第二根红线，如果查找的范围 `+ offset` ，但是 `buffer` 的读取位置已经跳到写入位置，岂不是和 `offset` 的重复了？？

所以，笔者认为，应该去掉 `offset` 的相关逻辑。

------

下面，我们以一个实际情况，举个例子。如下图所示：

![例子](http://static2.iocoder.cn/images/Netty/2018_12_04/02.png)

- 假设 `maxLength` 等于 1 。
- 第一次接收到数据 `"012"` ，未找到换行符，但是超过最大长度，所以进入 `discarding` 模式。
- 第二次接收到数据 `"34"` ，未找到换行符，`r = w = 4` ，并且 `offset = 2` 。
- 第三次接收到数据 `"\n"` ，但是查找范围是 `buffer.readerIndex() + offset = 4 + 2 > 5` ，超过范围。

因此，笔者觉得，这个可能是 offset 的一个 bug 。

# 4. LengthFieldBasedFrameDecoder

`io.netty.handler.codec.LengthFieldBasedFrameDecoder` ，继承 ByteToMessageDecoder 抽象类，基于**消息头指定消息长度**进行粘包拆包处理的。

详细解析，见基友【闪电侠】的 [《netty源码分析之LengthFieldBasedFrameDecoder》](https://www.jianshu.com/p/a0a51fd79f62) 一文。

或者，【Hypercube】的 [《自顶向下深入分析Netty（八）– LengthFieldBasedFrameDecoder》](https://www.jianshu.com/p/c3fbd6113dd6) 一文。

# 5. DelimiterBasedFrameDecoder

`io.netty.handler.codec.DelimiterBasedFrameDecoder` ，继承 ByteToMessageDecoder 抽象类，基于**指定消息边界方式**进行粘包拆包处理的。

> FROM [《自顶向下深入分析Netty（八）–CodecHandler》](https://www.jianshu.com/p/7c439cc7b01c) 的 [「8.1.2 DelimiterBasedFrameDecoder」](http://svip.iocoder.cn/Netty/Codec-1-2-ByteToMessageDecoder-FrameDecoder/#) 小节。
>
> 如下内容，因为排版，所以未使用引用语法。

该解码器是更通用的分隔符解码器，可支持多个分隔符，每个分隔符可为一个或多个字符。如果定义了多个分隔符，并且可解码出多个消息帧，则选择产生最小帧长的结果。例如，使用行分隔符`\r\n`和`\n`分隔：

```
+--------------+
| ABC\nDEF\r\n |
+--------------+

```

可有两种结果：

```
+-----+-----+              +----------+   
| ABC | DEF |  (√)   和    | ABC\nDEF |  (×)
+-----+-----+              +----------+

```

该编码器可配置的变量与`LineBasedFrameDecoder`类似，只是多了一个`ByteBuf[] delimiters`用于配置具体的分隔符。
Netty在`Delimiters`类中定义了两种默认的分隔符，分别是NULL分隔符和行分隔符：

```
public static ByteBuf[] nulDelimiter() {
    return new ByteBuf[] {
            Unpooled.wrappedBuffer(new byte[] { 0 }) };
}

public static ByteBuf[] lineDelimiter() {
    return new ByteBuf[] {
            Unpooled.wrappedBuffer(new byte[] { '\r', '\n' }),
            Unpooled.wrappedBuffer(new byte[] { '\n' }),
    };
}

```

# 666. 彩蛋

在 FixedLengthFrameDecoder 那里，卡了好长时间，Netty 在细节这块，扣的真给力啊！！！

本文参考如下文章：

- 简书闪电侠 [《netty源码分析之LengthFieldBasedFrameDecoder》](https://www.jianshu.com/p/a0a51fd79f62)
- Hypercube [《自顶向下深入分析Netty（八）–CodecHandler》](https://www.jianshu.com/p/7c439cc7b01c)

# Codec 之 MessageToByteEncoder



# 1. 概述

本文，我们来分享 MessageToByteEncoder 部分的内容。

MessageToByteEncoder 负责将消息**编码**成字节。核心类图如下：

![核心类图](http://static2.iocoder.cn/images/Netty/2018_12_18/01.png)

ByteToMessageDecoder 本身是个**抽象**类，其下有多个子类，笔者简单整理成两类，可能不全哈：

- 蓝框

  部分，将消息

  压缩

  ，主要涉及相关压缩算法，例如：GZip、BZip 等等。

  - 它要求消息类型是 ByteBuf ，将已经转化好的字节流，进一步压缩。

- 黄框

  部分，将消息使用

  指定序列化方式

  序列化成字节。例如：JSON、XML 等等。

  - 因为 Netty 没有内置的 JSON、XML 等相关的类库，所以不好提供类似 JSONEncoder 或 XMLEncoder ，所以图中笔者就使用 `netty-example` 提供的 NumberEncoder 。

在 [《精尽 Netty 源码解析 —— Codec 之 ByteToMessageDecoder（一）Cumulator》](http://svip.iocoder.cn/Netty/Codec-1-1-ByteToMessageDecoder-core-impl) 中，我们提到**粘包拆包**的现象，所以在实际使用 Netty 编码消息时，还需要有为了解决**粘包拆包**的 Encoder 实现类，例如：换行、定长等等方式。关于这块内容，胖友可以看看 [《netty使用MessageToByteEncoder 自定义协议》](https://www.codetd.com/article/1539061) 。

# 2. MessageToByteEncoder

`io.netty.handler.codec.MessageToByteEncoder` ，继承 ChannelOutboundHandlerAdapter 类，负责将消息**编码**成字节，支持**匹配指定类型**的消息。

## 2.1 构造方法

```
public abstract class MessageToByteEncoder<I> extends ChannelOutboundHandlerAdapter {

    /**
     * 类型匹配器
     */
    private final TypeParameterMatcher matcher;
    /**
     * 是否偏向使用 Direct 内存
     */
    private final boolean preferDirect;

    protected MessageToByteEncoder() {
        this(true);
    }

    protected MessageToByteEncoder(Class<? extends I> outboundMessageType) {
        this(outboundMessageType, true);
    }

    protected MessageToByteEncoder(boolean preferDirect) {
        // <1> 获得 matcher
        matcher = TypeParameterMatcher.find(this, MessageToByteEncoder.class, "I");
        this.preferDirect = preferDirect;
    }

    protected MessageToByteEncoder(Class<? extends I> outboundMessageType, boolean preferDirect) {
        // <2> 获得 matcher
        matcher = TypeParameterMatcher.get(outboundMessageType);
        this.preferDirect = preferDirect;
    }
    
    // ... 省略其他无关代码
}
```

- ```
  matcher
  ```

   

  属性，有

  两种

  方式赋值。

  - 【常用】`<1>` 处，使用类的 `I` 泛型对应的 TypeParameterMatcher 类型匹配器。
  - `<2>` 处，使用 `inboundMessageType` 参数对应的 TypeParameterMatcher 类型匹配器。
  - 在大多数情况下，我们不太需要特别详细的了解 `io.netty.util.internal.TypeParameterMatcher` 的代码实现，感兴趣的胖友可以自己看看 [《netty 简单Inbound通道处理器（SimpleChannelInboundHandler）》](http://donald-draper.iteye.com/blog/2387772) 的 [「TypeParameterMatcher」](http://svip.iocoder.cn/Netty/Codec-2-1-MessageToByteEncoder-core-impl/#)部分。

- `preferDirect` 属性，是否偏向使用 Direct 内存。默认为 `true` 。

## 2.2 acceptInboundMessage

`#acceptInboundMessage(Object msg)` 方法，判断消息是否匹配。代码如下：

```
/**
 * Returns {@code true} if the given message should be handled. If {@code false} it will be passed to the next
 * {@link ChannelInboundHandler} in the {@link ChannelPipeline}.
 */
public boolean acceptInboundMessage(Object msg) {
    return matcher.match(msg);
}
```

一般情况下，`matcher` 的类型是 ReflectiveMatcher( 它是 TypeParameterMatcher 的内部类 )。代码如下：

```
private static final class ReflectiveMatcher extends TypeParameterMatcher {
    
    /**
     * 类型
     */
    private final Class<?> type;
    
    ReflectiveMatcher(Class<?> type) {
        this.type = type;
    }
    
    @Override
    public boolean match(Object msg) {
        return type.isInstance(msg); // <1>
    }
    
}
```

- 匹配逻辑，看 `<1>` 处，使用 `Class#isInstance(Object obj)` 方法。对于这个方法，如果我们定义的 `I` 泛型是个父类，那可以匹配所有的子类。例如 `I` 设置为 Object 类，那么所有消息，都可以被匹配列。

## 2.3 write

`#write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)` 方法，匹配指定的消息类型，编码消息成 ByteBuf 对象，继续写到下一个节点。代码如下：

```
 1: @Override
 2: public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
 3:     ByteBuf buf = null;
 4:     try {
 5:         // 判断是否为匹配的消息
 6:         if (acceptOutboundMessage(msg)) {
 7:             @SuppressWarnings("unchecked")
 8:             I cast = (I) msg;
 9:             // 申请 buf
10:             buf = allocateBuffer(ctx, cast, preferDirect);
11:             // 编码
12:             try {
13:                 encode(ctx, cast, buf);
14:             } finally {
15:                 // 释放 msg
16:                 ReferenceCountUtil.release(cast);
17:             }
18: 
19:             // buf 可读，说明有编码到数据
20:             if (buf.isReadable()) {
21:                 // 写入 buf 到下一个节点
22:                 ctx.write(buf, promise);
23:             } else {
24:                 // 释放 buf
25:                 buf.release();
26:                 // 写入 EMPTY_BUFFER 到下一个节点，为了 promise 的回调
27:                 ctx.write(Unpooled.EMPTY_BUFFER, promise);
28:             }
29: 
30:             // 置空 buf
31:             buf = null;
32:         } else {
33:             // 提交 write 事件给下一个节点
34:             ctx.write(msg, promise);
35:         }
36:     } catch (EncoderException e) {
37:         throw e;
38:     } catch (Throwable e) {
39:         throw new EncoderException(e);
40:     } finally {
41:         // 释放 buf
42:         if (buf != null) {
43:             buf.release();
44:         }
45:     }
46: }
```

- 第 6 行：调用 `#acceptInboundMessage(Object msg)` 方法，判断是否为匹配的消息。

- ① 第 6 行：**匹配**。

  - 第 8 行：对象类型转化为 `I` 类型的消息。

  - 第 10 行：调用 `#allocateBuffer(ChannelHandlerContext ctx, I msg, boolean preferDirect)` 方法，申请 `buf` 。代码如下：

    ```
    /**
     * Allocate a {@link ByteBuf} which will be used as argument of {@link #encode(ChannelHandlerContext, I, ByteBuf)}.
     * Sub-classes may override this method to return {@link ByteBuf} with a perfect matching {@code initialCapacity}.
     */
    protected ByteBuf allocateBuffer(ChannelHandlerContext ctx, @SuppressWarnings("unused") I msg, boolean preferDirect) throws Exception {
        if (preferDirect) {
            return ctx.alloc().ioBuffer();
        } else {
            return ctx.alloc().heapBuffer();
        }
    }
    ```

    - x

  - 第 13 行：调用 `#encode(ChannelHandlerContext ctx, I msg, ByteBuf out)` 方法，编码。代码如下：

    ```
    /**
     * Encode a message into a {@link ByteBuf}. This method will be called for each written message that can be handled
     * by this encoder.
     *
     * @param ctx           the {@link ChannelHandlerContext} which this {@link MessageToByteEncoder} belongs to
     * @param msg           the message to encode
     * @param out           the {@link ByteBuf} into which the encoded message will be written
     * @throws Exception    is thrown if an error occurs
     */
    protected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception;
    ```

    - 子类可以实现该方法，实现自定义的编码功能。

  - 第 16 行：调用 `ReferenceCountUtil#release(Object msg)` 方法，释放 `msg` 。

  - 第 19 至 22 行：`buf` 可读，说明编码消息到 `buf` 中了，所以写入 `buf` 到下一个节点。😈 因为 `buf` 需要继续被下一个节点使用，所以不进行释放。

  - 第 23 至 28 行：`buf` 不可读，说明无法编码，所以释放 `buf` ，并写入 `EMPTY_BUFFER` 到下一个节点，为了 promise 的回调。

  - 第 31 行：置空 `buf` 为空。这里是为了防止【第 41 至 44 行】的代码，释放 `buf` 。

- ② 第 32 行：

  不匹配

  。

  - 提交 write 事件给下一个节点。

- 第 36 至 39 行：发生异常，抛出 EncoderException 异常。

- 第 40 至 45 行：如果中间发生异常，导致 `buf` 不为空，所以此处释放 `buf` 。

# 3. NumberEncoder

`io.netty.example.factorial.NumberEncoder` ，继承 MessageToByteEncoder 抽象类，Number 类型的消息的 Encoder 实现类。代码如下：

> NumberEncoder 是 `netty-example` 模块提供的示例类，实际使用时，需要做调整。

```
public class NumberEncoder extends MessageToByteEncoder<Number> {

    @Override
    protected void encode(ChannelHandlerContext ctx, Number msg, ByteBuf out) {
        // <1> 转化成 BigInteger 对象
        // Convert to a BigInteger first for easier implementation.
        BigInteger v;
        if (msg instanceof BigInteger) {
            v = (BigInteger) msg;
        } else {
            v = new BigInteger(String.valueOf(msg));
        }

        // <2> 转换为字节数组
        // Convert the number into a byte array.
        byte[] data = v.toByteArray();
        int dataLength = data.length;

        // <3> Write a message.
        out.writeByte((byte) 'F'); // magic number
        out.writeInt(dataLength);  // data length
        out.writeBytes(data);      // data
    }

}
```

- `<1>` 处，转化消息类型为 BigInteger 对象，方便统一处理。
- `<2>` 处，转化为字节数组。
- `<3>`处
  - 首位，写入 magic number ，方便区分**不同类型**的消息。例如说，后面如果有 Double 类型，可以使用 `D` ；String 类型，可以使用 `S` 。
  - 后两位，写入 data length + data 。如果没有 data length ，那么数组内容，是无法读取的。

实际一般不采用 NumberEncoder 的方式，因为 POJO 类型不好支持。关于这一块，可以参看下：

- Dubbo
- Motan
- Sofa-RPC

对 Encoder 和 Codec 真正实战。hoho

# 666. 彩蛋

MessageToByteEncoder 相比 ByteToMessageDecoder 来说，简单好多。

推荐阅读文章：

- Hypercube [《自顶向下深入分析Netty（八）–CodecHandler》](https://www.jianshu.com/p/7c439cc7b01c)

另外，可能很多胖友，看完 Encoder 和 Decoder ，还是一脸懵逼，不知道实际如何使用。可以在网络上，再 Google 一些资料，不要方，不要怕。

# Util 之 FastThreadLocal



笔者先把 Netty 主要的内容写完，所以关于 FastThreadLocal 的分享，先放在后续的计划里。

> 老艿艿：其实是因为，自己想去研究下 Service Mesh ，所以先简单收个小尾。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- 莫那一鲁道

   

  《Netty 高性能之道 FastThreadLocal 源码分析（快且安全）》

  - 😈 我的好基友，可以关注下他的简书。

- 暗夜君王 [《【源起Netty 外传】FastThreadLocal怎么Fast？》](https://segmentfault.com/a/1190000012926809)

为避免可能 [《Netty 高性能之道 FastThreadLocal 源码分析（快且安全）》](https://www.jianshu.com/p/3fc2fbac4bb7) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

## 前言

Netty 作为高性能框架，对 JDK 中的很多类都进行了封装了和优化，例如 Thread 类，Netty 使用了 FastThreadLocalRunnable 对所有 DefaultThreadFactory 创建出来的 Runnable 都进行了包装。包装的目的是 run 方法的不同，看代码：

```java
public void run() {
    try {
        runnable.run();
    } finally {
        FastThreadLocal.removeAll();
    }
}
```

可以看到，多了一行 FastThreadLocal.removeAll()，众所周知，JDK 中自带的 ThreadLocal 在线程池使用环境中，有内存泄漏的风险，很明显，Netty 为了避免这个 bug，重新进行了封装，而且这个封装线程的名字叫做 FastThreadLocalRunnable，语义很明显：快速的 ThreadLocal！意思说 JDK 自带的慢喽？那我们今天就来看看到底快在哪里？对 ThreadLocal 内存泄漏不清楚或者对 ThreadLoca 不清楚的可以移步 [并发编程之 ThreadLocal 源码剖析](https://www.jianshu.com/p/80284438bb97)。

## 1. 如何使用？

![img](https://upload-images.jianshu.io/upload_images/4236553-12c253f98742f4b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/648/format/jpeg)

测试用例

![img](https://upload-images.jianshu.io/upload_images/4236553-7ec7f64c3cbf86f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/454/format/jpeg)

运行结果

## 2. 构造方法解析

![img](https://upload-images.jianshu.io/upload_images/4236553-852af1ffc45a7a99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/563/format/jpeg)

构造方法

构造方法中定义了两个变量。 index 和 cleanerFlagIndex，这两个变量且都是 int final 的。且都是通过
InternalThreadLocalMap.nextVariableIndex() 方法而来。

![img](https://upload-images.jianshu.io/upload_images/4236553-266a99ac72429da7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/719/format/jpeg)

InternalThreadLocalMap.nextVariableIndex() 方法

![img](https://upload-images.jianshu.io/upload_images/4236553-5cdca30965ae3c19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/552/format/jpeg)

nextIndex 变量

该方法通过一个原子 int 变量自增得到。也就是说，cleanerFlagIndex 变量比 index 大1，这两个变量的作用稍后我们会看到他们如何使用。这里暂且不表。

## 3. set 方法解析

![img](https://upload-images.jianshu.io/upload_images/4236553-30ec041c29b4c55d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/698/format/jpeg)

set（） 方法

该方法步骤如下：

1. 判断设置的 value 值是否是缺省值，如果是，则调用 remove 方法。
2. 如果不是，则获取道当前线程的 InternalThreadLocalMap。然后将该 FastThreadLocal 对应的 index 下标的 value 替换成新的 value。老的 value 设置成缺省值。

**小小的一个 set 方法，内部可是非常的复杂，非战斗人员请尽快撤离！**

实际上，这里调用了4个方法：

1. InternalThreadLocalMap.get()；
2. setKnownNotUnset(threadLocalMap, value);
3. registerCleaner(threadLocalMap);
4. remove();

让我们慢慢说道说道。

#### 1. InternalThreadLocalMap.get()；

代码如下：

```java
public static InternalThreadLocalMap get() {
    Thread thread = Thread.currentThread();
    if (thread instanceof FastThreadLocalThread) {
        return fastGet((FastThreadLocalThread) thread);
    } else {
        return slowGet();
    }
}
```

首先是 InternalThreadLocalMap 的静态方法，方法逻辑很简单，主要是根据当前线程是否是 Netty 的 FastThreadLocalThread 来调用不同的方法，一个是 fast 的，一个 是 slow 的（不是 Netty 的线程就是 slow 的）。哈哈哈，Netty 的作者命名还真是犀利。那我们就看看 fastGet 方法是什么？

```java
private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) {
    InternalThreadLocalMap threadLocalMap = thread.threadLocalMap();
    if (threadLocalMap == null) {
        thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap());
    }
    return threadLocalMap;
}
```

逻辑很简单，获取当前线程的 InternalThreadLocalMap，如果没有，就创建一个。我们看看他的构造方法。

```java
public static final Object UNSET = new Object();

private InternalThreadLocalMap() {
    super(newIndexedVariableTable());
}

private static Object[] newIndexedVariableTable() {
    Object[] array = new Object[32];
    Arrays.fill(array, UNSET);
    return array;
}

UnpaddedInternalThreadLocalMap(Object[] indexedVariables) {
    this.indexedVariables = indexedVariables;
}
```

楼主将 3 个关联的方法都放在一起了，方便查看，首先，InternalThreadLocalMap 调用的父类 UnpaddedInternalThreadLocalMap 的构造方法，并传入了一个数组，而这个数组默认大小是 32，里面填充32 个空对象的引用。

那 slowGet 方法又是什么样子的呢？代码如下：

```java
static final ThreadLocal<InternalThreadLocalMap> slowThreadLocalMap = new ThreadLocal<InternalThreadLocalMap>();

private static InternalThreadLocalMap slowGet() {
    ThreadLocal<InternalThreadLocalMap> slowThreadLocalMap = UnpaddedInternalThreadLocalMap.slowThreadLocalMap;
    InternalThreadLocalMap ret = slowThreadLocalMap.get();
    if (ret == null) {
        ret = new InternalThreadLocalMap();
        slowThreadLocalMap.set(ret);
    }
    return ret;
}
```

代码还是很简单的，我们分析一下：首先使用 JDK 的 ThreadLocal 获取一个 Netty 的 InternalThreadLocalMap，如果没有就创建一个，并将这个 InternalThreadLocalMap 设置到 JDK 的 ThreadLocal 中，然后返回这个 InternalThreadLocalMap。从这里可以看出，为了提高性能，Netty 还是避免使用了JDK 的 threadLocalMap，他的方式是曲线救国：在JDK 的 threadLocal 中设置 Netty 的 InternalThreadLocalMap ，然后，这个 InternalThreadLocalMap 中设置 Netty 的 FastThreadLcoal。

好，到这里，我们的 InternalThreadLocalMap.get() 方法就看完了，主要是获取当前线程的 InternalThreadLocalMap，如果没有，就创建一个，这个 Map 内部维护的是一个数组，和 JDK 不同，JDK
维护的是一个使用线性探测法的 Map，可见，从底层数据结构上，JDK 就已经输了，他们的读取速度相差很大，特别是当数据量很大的时候，Netty 的数据结构速度依然不变，而 JDK 由于使用线性探测法，速度会相应的下降。

#### 2. setKnownNotUnset(threadLocalMap, value);

当 InternalThreadLocalMap.get() 返回了 一个 InternalThreadLocalMap，这个时候调用 setKnownNotUnset(threadLocalMap, value); 方法进行操作。代码如下：

```
private boolean setKnownNotUnset(InternalThreadLocalMap threadLocalMap, V value) {
    if (threadLocalMap.setIndexedVariable(index, value)) {
        addToVariablesToRemove(threadLocalMap, this);
        return true;
    }
    return false;
}
```

看方法名称，是设置一个值，但不是 unset，也就是那个空对象。通过 threadLocalMap.setIndexedVariable(index, value) 进行设置。如果返回 true，则调用 addToVariablesToRemove(threadLocalMap, this) 。这两个方法，我们一起看看。先看第一个：

setIndexedVariable 方法

```
public boolean setIndexedVariable(int index, Object value) {
    Object[] lookup = indexedVariables;
    if (index < lookup.length) {
        Object oldValue = lookup[index];
        lookup[index] = value;
        return oldValue == UNSET;
    } else {
        expandIndexedVariableTableAndSet(index, value);
        return true;
    }
}
```

首先，拿到那个 32 长度的数组，如果 FastThreadLocal 的 index 属性小于数组长度，则将值设定到指定槽位。将原来槽位的值设置为空对象。如果原来的对象也是空对象，则返回 true，否则返回 false。

如果不够呢？调用 expandIndexedVariableTableAndSet(index, value) 方法。进入该方法查看。看方法名称是扩大索引并设置值。

```
private void expandIndexedVariableTableAndSet(int index, Object value) {
    Object[] oldArray = indexedVariables;
    final int oldCapacity = oldArray.length;
    int newCapacity = index;
    newCapacity |= newCapacity >>>  1;
    newCapacity |= newCapacity >>>  2;
    newCapacity |= newCapacity >>>  4;
    newCapacity |= newCapacity >>>  8;
    newCapacity |= newCapacity >>> 16;
    newCapacity ++;

    Object[] newArray = Arrays.copyOf(oldArray, newCapacity);
    Arrays.fill(newArray, oldCapacity, newArray.length, UNSET);
    newArray[index] = value;
    indexedVariables = newArray;
}
```

这里代码很熟悉，HashMap 中也有这样的代码，我们去看看：

![img](https://upload-images.jianshu.io/upload_images/4236553-bb4c10b59073c4f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/647/format/jpeg)

HashMap 中的 tableSizeFor 方法

这段代码的作用就是按原来的容量扩容2倍。并且保证结果是2的幂次方。这里 Netty 的做法和 HashMap 一样，按照原来的容量扩容到最近的 2 的幂次方大小，比如原来32，就扩容到64，然后，将原来数组的内容填充到新数组中，剩余的填充`空对象`，然后将新数组赋值给成员变量 indexedVariables。完成了一次扩容。

回到 setKnownNotUnset 方法中，setIndexedVariable 方法什么情况下会返回 ture 呢？扩容了，或者没扩容，但插入的对象没有替换掉别的对象，也就是原槽位是空对象。换句话说，只有更新了对象才会返回 false。

也就是说，当新增了对象的时候，会调用 addToVariablesToRemove 方法，如同方法名，添加变量然后删除。我们看看 addToVariablesToRemove(threadLocalMap, this) 方法逻辑：

```
private static void addToVariablesToRemove(InternalThreadLocalMap threadLocalMap, FastThreadLocal<?> variable) {
    // 该变量是 static final 的，因此通常是 0
    Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex);
    Set<FastThreadLocal<?>> variablesToRemove;
    if (v == InternalThreadLocalMap.UNSET || v == null) {
        // 创建一个基于 IdentityHashMap 的 Set，泛型是 FastThreadLocal
        variablesToRemove = Collections.newSetFromMap(new IdentityHashMap<FastThreadLocal<?>, Boolean>());
        // 将这个 Set 放到这个 Map 数组的下标 0 处
        threadLocalMap.setIndexedVariable(variablesToRemoveIndex, variablesToRemove);
    } else {
        // 如果拿到的不是 UNSET ，说明这是第二次操作了，因此可以强转为 Set
        variablesToRemove = (Set<FastThreadLocal<?>>) v;
    }

    // 最后的目的就是将 FastThreadLocal 放置到 Set 中
    variablesToRemove.add(variable);
}
```

这个方法的目的是将 FastThreadLocal 对象保存到一个 Set 中，因为 Netty 的 Map 只是一个数组，没有键，所以保存到一个 Set 中，这样就可以判断是否 set 过这个 map，例如 Netty 的 isSet 方法就是根据这个判断的。

说完了 setKnownNotUnset 方法，我们再说说 registerCleaner 方法。

#### 3. registerCleaner(threadLocalMap);

这个方法可以说有点复杂了，请耐住性子，这里是 ftl（FastThreadLocal） 的精髓。

首先说下该方法的作用：将这个 ftl 注册到一个 `清理线程` 中，当 thread 对象被 gc 的时候，则会自动清理掉 ftl，防止 JDK 的内存泄漏问题。

让我们进入该方法查看：

```
private void registerCleaner(final InternalThreadLocalMap threadLocalMap) {
    Thread current = Thread.currentThread();
    if (FastThreadLocalThread.willCleanupFastThreadLocals(current) ||
        threadLocalMap.indexedVariable(cleanerFlagIndex) != InternalThreadLocalMap.UNSET) {
        return;
    }
    threadLocalMap.setIndexedVariable(cleanerFlagIndex, Boolean.TRUE);
    ObjectCleaner.register(current, new Runnable() {
        public void run() {
            remove(threadLocalMap);
        }
    });
}
```

楼主删除了源码中的注释，我们来好好说说这个方法：

1. 获取当前线程，如果当前线程是 FastThreadLocalThread 类型 且 cleanupFastThreadLocals 是 true，则返回 true，直接return。也就是说，Netty 线程池里面创建的线程都符合这条件，只有用户自定义的线程池不符合。
   当然还有一个条件：如果这个 ftl 的 index + 1 在 map 中的值不是空对象，则已经注册过了，也直接 return，不再重复注册。
2. 当不符合上面的条件的时候，将 Map 中对应的 ftl 的 index + 1 位置的值设置为 TRUE。根据上面的判断，防止重复注册。
3. 调用 ObjectCleaner 的 register 方法，注册一个任务，任务的内容就是调用 remove 方法，删除 ftl 在 map 中的对象和相应的内容。

问题来了，怎么注册的呢？为什么还带着一个 current 当前线程呢？

我们看看源码：

```
public static void register(Object object, Runnable cleanupTask) {
    AutomaticCleanerReference reference = new AutomaticCleanerReference(object,
            ObjectUtil.checkNotNull(cleanupTask, "cleanupTask"));
    LIVE_SET.add(reference);

    // Check if there is already a cleaner running.
    if (CLEANER_RUNNING.compareAndSet(false, true)) {
        final Thread cleanupThread = new FastThreadLocalThread(CLEANER_TASK);
        cleanupThread.setPriority(Thread.MIN_PRIORITY);
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                cleanupThread.setContextClassLoader(null);
                return null;
            }
        });
        cleanupThread.setName(CLEANER_THREAD_NAME);
        cleanupThread.setDaemon(true);
        cleanupThread.start();
    }
}
```

首先创建一个 AutomaticCleanerReference 自动清洁对象，继承了 WeakReference，先不看他的构造方法，先看下面，将这个构造好的实例放入到 LIVE_SET 中，实际上，这是一个 Netty 封装的 ConcurrentSet，然后判断清除线程是否在运行。如果没有，并且CAS改状态成功。就创建一个线程，任务是 定义好的 CLEANER_TASK，线程优先级是最低，上下位类加载器是null，名字是 objectCleanerThread，并且是后台线程。然后启动这个线程。运行 CLEANER_TASK。

一步一步来看看。

首先 AutomaticCleanerReference 的构造方法如下：

```java
private static final ReferenceQueue<Object> REFERENCE_QUEUE = new ReferenceQueue<Object>();

AutomaticCleanerReference(Object referent, Runnable cleanupTask) {
    super(referent, REFERENCE_QUEUE);
    this.cleanupTask = cleanupTask;
}   

void cleanup() {
   cleanupTask.run();
}
```

ReferenceQueue 的作用是，当对象被回收的时候，会将这个对象添加进这个队列，就可以跟踪这个对象。设置可以复活这个对象。也就是说，当这个 Thread 对象被回收的时候，会将这个对象放进这个引用队列，放进入干嘛呢？什么时候取出来呢？我们看看什么时候取出来：

代码如下：

```java
private static final Runnable CLEANER_TASK = new Runnable() {
    @Override
    public void run() {
        for (;;) {
            while (!LIVE_SET.isEmpty()) {
                final AutomaticCleanerReference reference = (AutomaticCleanerReference) REFERENCE_QUEUE.remove(REFERENCE_QUEUE_POLL_TIMEOUT_MS);
               
                if (reference != null) {
                    try {
                        reference.cleanup();
                    } catch (Throwable ignored) {
                    }
                    LIVE_SET.remove(reference);
                }
            }
            CLEANER_RUNNING.set(false);
            if (LIVE_SET.isEmpty() || !CLEANER_RUNNING.compareAndSet(false, true)) {
                break;
            }
        }
    }
};
```

巧了 ！！！！正是 CLEANER_TASK 在使用这个 ReferenceQueue！！！！别激动，我们还是慢慢看看这个任务到底是做什么的：

1. 死循环，如果 ConcurrentSet 不是空（还记得我们将 AutomaticCleanerReference 放进这里吗），尝试从 REFERENCE_QUEUE 中取出 AutomaticCleanerReference，也就是我们刚刚放进入的。这是标准的跟踪 GC 对象的做法。因为当一个对象被 GC 时，会将保证这个对象的 Reference 放进指定的引用队列，这是 JVM 做的。
2. 如果不是空，就调用应用的 cleanUp 方法，也就是我们传进去的任务，什么任务？就是那个调用 ftl 的 remove 方法的任务。随后从 Set 中删除这个引用。
3. 如果 Set 是空的话，将清理线程状态（原子变量） 设置成 fasle。
4. 继续判断，如果Set 还是空，或者 Set 不是空 且 设置 CAS 设置状态为true 失败（说明其他线程改了这个状态）则跳出循环，结束线程。

有点懵？那我们就好好总结这里为什么这么做：

> 当我们在一个非 Netty 线程池创建的线程中使用 ftl 的时候，Netty 会注册一个垃圾清理线程（因为 Netty 线程池创建的线程最终都会执行 removeAll 方法，不会出现内存泄漏） ，用于清理这个线程这个 ftl 变量，从上面的代码中，我们知道，非 Netty 线程如果使用 ftl，Netty 仍然会借助 JDK 的 ThreadLocal，只是只借用一个槽位，放置 Netty 的 Map， Map 中再放置 Netty 的 ftl 。所以，在使用线程池的情况下可能会出现内存泄漏。**Netty 为了解决这个问题，在每次使用新的 ftl 的时候，都将这个 ftl 注册到和线程对象绑定到一个 GC 引用上， 当这个线程对象被回收的时候，也会顺便清理掉他的 Map 中的 所有 ftl，解决了该问题，就像解决 JDK Nio bug 一样。**

好，到这里，Netty 的 FastThreadLocal 的精华我们基本就全部吸取了。ftl 不仅快，而且安全。快在使用数组代替线性探测法的 Map，安全在每次线程回收的时候都清理 ftl，不用担心内存泄漏。

剩下的方法都是很简单的。我们一起看完吧

#### 4. remove();

每次 Set 一个空对象的时候，就是调用remove 方法，我们看看该方法，源码如下：

```
public final void remove() {
     remove(InternalThreadLocalMap.getIfSet());
 }

 public static InternalThreadLocalMap getIfSet() {
     Thread thread = Thread.currentThread();
     if (thread instanceof FastThreadLocalThread) {
         return ((FastThreadLocalThread) thread).threadLocalMap();
     }
     return slowThreadLocalMap.get();

 }

 public final void remove(InternalThreadLocalMap threadLocalMap) {
     if (threadLocalMap == null) {
         return;
     }
     // 删除并返回 Map 数组中当前 ThreadLocal index 对应的 value
     Object v = threadLocalMap.removeIndexedVariable(index);
     // 从 Map 数组下标 0 的位置取出 Set ，并删除当前的 ThreadLocal
     removeFromVariablesToRemove(threadLocalMap, this);

     if (v != InternalThreadLocalMap.UNSET) {
         try {
             // 默认啥也不做，用户可以继承 FastThreadLocal 重定义这个方法。
             onRemoval((V) v);
         } catch (Exception e) {
             PlatformDependent.throwException(e);
         }
     }
 }
```

楼主将这3个方法都合并在一起了，首先获取当前线程的 threadLocalMap，然后就像注释中写的：删除 ftl 对应下标中 map 的 value，然后删除 map 下标0 处 Set 中的 ftl。防止 isSet 方法误判。最后，如果用户重写了 onRemoval 方法，就调用，默认是个空方法。用户可以重写 onRemoval 方法和 initialize 方法。

## 4. get 方法解析

get 方法就更简单了，代码如下：

```
public final V get() {
    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();
    Object v = threadLocalMap.indexedVariable(index);
    if (v != InternalThreadLocalMap.UNSET) {
        return (V) v;
    }

    V value = initialize(threadLocalMap);
    registerCleaner(threadLocalMap);
    return value;
}
```

首先获取当前线程的map，然后根据 ftl 的 index 获取 value，然后返回，如果是空对象，也就是没有设置，则通过 initialize 返回，initialize 方法会将返回值设置到 map 的槽位中，并放进 Set 中。最后，尝试注册一个清洁器。

## 5. remove All方法解析

这个方法在 Netty 的默认线程的 finally 块中调用。代码如下：

```java
public static void removeAll() {
    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.getIfSet();
    if (threadLocalMap == null) {
        return;
    }

    try {
        Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex);
        if (v != null && v != InternalThreadLocalMap.UNSET) {
            @SuppressWarnings("unchecked")
            Set<FastThreadLocal<?>> variablesToRemove = (Set<FastThreadLocal<?>>) v;
            FastThreadLocal<?>[] variablesToRemoveArray =
                    variablesToRemove.toArray(new FastThreadLocal[variablesToRemove.size()]);
            for (FastThreadLocal<?> tlv: variablesToRemoveArray) {
                tlv.remove(threadLocalMap);
            }
        }
    } finally {
        InternalThreadLocalMap.remove();
    }
}
```

非常简单，首先获取当前线程map，然后获取 Set，将 Set 转成数组，遍历数组，调用 ftl 的 remove 方法。最后，删除线程中 的 map 属性。

## 总结

现在我们来总结一下 FastThreadLocal 。

之所以称之为 Fast，因为没有使用 JDK 的使用线性探测法的 Map，如果你使用的是Netty 线程池工厂创建的线程，搭配 Netty 的 ftl，性能非常好，如果你使用自定义的线程，搭配 ftl，性能也会比 JDK 的好，注意： ftl 没有 JDK 的内存泄露的风险。

但做到这些不是没有代价的，由于每一个 ftl 都是一个唯一的下标，而这个下标是每次创建一个 ftl 对象都是递增 2，当你的下标很大，你的线程中的 Map 相应的也要增大，可以想象，如果创建了海量的 ftl 对象，这个数组的浪费是非常客观的。很明显，这是一种空间换时间的做法。

通常，ftl 都是静态对象，所以不会有我们假设的那么多。如果使用不当，确实会浪费大量内存。

但这个风险带来的好处是明显的，在楼主的机器上测试，ftl 的读取性能是 JDK 的 5 倍左右，写入的速度也要快 20% 左右。

FastThreadLocal 人如其名，快且安全！

今天就到这里，good luck！！！！

# Util 之 FastThreadLocal



笔者先把 Netty 主要的内容写完，所以关于 FastThreadLocal 的分享，先放在后续的计划里。

> 老艿艿：其实是因为，自己想去研究下 Service Mesh ，所以先简单收个小尾。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- 莫那一鲁道

   

  《Netty 高性能之道 FastThreadLocal 源码分析（快且安全）》

  - 😈 我的好基友，可以关注下他的简书。

- 暗夜君王 [《【源起Netty 外传】FastThreadLocal怎么Fast？》](https://segmentfault.com/a/1190000012926809)

为避免可能 [《Netty 高性能之道 FastThreadLocal 源码分析（快且安全）》](https://www.jianshu.com/p/3fc2fbac4bb7) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

## 前言

Netty 作为高性能框架，对 JDK 中的很多类都进行了封装了和优化，例如 Thread 类，Netty 使用了 FastThreadLocalRunnable 对所有 DefaultThreadFactory 创建出来的 Runnable 都进行了包装。包装的目的是 run 方法的不同，看代码：

```java
public void run() {
    try {
        runnable.run();
    } finally {
        FastThreadLocal.removeAll();
    }
}
```

可以看到，多了一行 FastThreadLocal.removeAll()，众所周知，JDK 中自带的 ThreadLocal 在线程池使用环境中，有内存泄漏的风险，很明显，Netty 为了避免这个 bug，重新进行了封装，而且这个封装线程的名字叫做 FastThreadLocalRunnable，语义很明显：快速的 ThreadLocal！意思说 JDK 自带的慢喽？那我们今天就来看看到底快在哪里？对 ThreadLocal 内存泄漏不清楚或者对 ThreadLoca 不清楚的可以移步 [并发编程之 ThreadLocal 源码剖析](https://www.jianshu.com/p/80284438bb97)。

## 1. 如何使用？

![img](https://upload-images.jianshu.io/upload_images/4236553-12c253f98742f4b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/648/format/jpeg)

测试用例

![img](https://upload-images.jianshu.io/upload_images/4236553-7ec7f64c3cbf86f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/454/format/jpeg)

运行结果

## 2. 构造方法解析

![img](https://upload-images.jianshu.io/upload_images/4236553-852af1ffc45a7a99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/563/format/jpeg)

构造方法

构造方法中定义了两个变量。 index 和 cleanerFlagIndex，这两个变量且都是 int final 的。且都是通过
InternalThreadLocalMap.nextVariableIndex() 方法而来。

![img](https://upload-images.jianshu.io/upload_images/4236553-266a99ac72429da7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/719/format/jpeg)

InternalThreadLocalMap.nextVariableIndex() 方法

![img](https://upload-images.jianshu.io/upload_images/4236553-5cdca30965ae3c19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/552/format/jpeg)

nextIndex 变量

该方法通过一个原子 int 变量自增得到。也就是说，cleanerFlagIndex 变量比 index 大1，这两个变量的作用稍后我们会看到他们如何使用。这里暂且不表。

## 3. set 方法解析

![img](https://upload-images.jianshu.io/upload_images/4236553-30ec041c29b4c55d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/698/format/jpeg)

set（） 方法

该方法步骤如下：

1. 判断设置的 value 值是否是缺省值，如果是，则调用 remove 方法。
2. 如果不是，则获取道当前线程的 InternalThreadLocalMap。然后将该 FastThreadLocal 对应的 index 下标的 value 替换成新的 value。老的 value 设置成缺省值。

**小小的一个 set 方法，内部可是非常的复杂，非战斗人员请尽快撤离！**

实际上，这里调用了4个方法：

1. InternalThreadLocalMap.get()；
2. setKnownNotUnset(threadLocalMap, value);
3. registerCleaner(threadLocalMap);
4. remove();

让我们慢慢说道说道。

#### 1. InternalThreadLocalMap.get()；

代码如下：

```java
public static InternalThreadLocalMap get() {
    Thread thread = Thread.currentThread();
    if (thread instanceof FastThreadLocalThread) {
        return fastGet((FastThreadLocalThread) thread);
    } else {
        return slowGet();
    }
}
```

首先是 InternalThreadLocalMap 的静态方法，方法逻辑很简单，主要是根据当前线程是否是 Netty 的 FastThreadLocalThread 来调用不同的方法，一个是 fast 的，一个 是 slow 的（不是 Netty 的线程就是 slow 的）。哈哈哈，Netty 的作者命名还真是犀利。那我们就看看 fastGet 方法是什么？

```java
private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) {
    InternalThreadLocalMap threadLocalMap = thread.threadLocalMap();
    if (threadLocalMap == null) {
        thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap());
    }
    return threadLocalMap;
}
```

逻辑很简单，获取当前线程的 InternalThreadLocalMap，如果没有，就创建一个。我们看看他的构造方法。

```java
public static final Object UNSET = new Object();

private InternalThreadLocalMap() {
    super(newIndexedVariableTable());
}

private static Object[] newIndexedVariableTable() {
    Object[] array = new Object[32];
    Arrays.fill(array, UNSET);
    return array;
}

UnpaddedInternalThreadLocalMap(Object[] indexedVariables) {
    this.indexedVariables = indexedVariables;
}
```

楼主将 3 个关联的方法都放在一起了，方便查看，首先，InternalThreadLocalMap 调用的父类 UnpaddedInternalThreadLocalMap 的构造方法，并传入了一个数组，而这个数组默认大小是 32，里面填充32 个空对象的引用。

那 slowGet 方法又是什么样子的呢？代码如下：

```java
static final ThreadLocal<InternalThreadLocalMap> slowThreadLocalMap = new ThreadLocal<InternalThreadLocalMap>();

private static InternalThreadLocalMap slowGet() {
    ThreadLocal<InternalThreadLocalMap> slowThreadLocalMap = UnpaddedInternalThreadLocalMap.slowThreadLocalMap;
    InternalThreadLocalMap ret = slowThreadLocalMap.get();
    if (ret == null) {
        ret = new InternalThreadLocalMap();
        slowThreadLocalMap.set(ret);
    }
    return ret;
}
```

代码还是很简单的，我们分析一下：首先使用 JDK 的 ThreadLocal 获取一个 Netty 的 InternalThreadLocalMap，如果没有就创建一个，并将这个 InternalThreadLocalMap 设置到 JDK 的 ThreadLocal 中，然后返回这个 InternalThreadLocalMap。从这里可以看出，为了提高性能，Netty 还是避免使用了JDK 的 threadLocalMap，他的方式是曲线救国：在JDK 的 threadLocal 中设置 Netty 的 InternalThreadLocalMap ，然后，这个 InternalThreadLocalMap 中设置 Netty 的 FastThreadLcoal。

好，到这里，我们的 InternalThreadLocalMap.get() 方法就看完了，主要是获取当前线程的 InternalThreadLocalMap，如果没有，就创建一个，这个 Map 内部维护的是一个数组，和 JDK 不同，JDK
维护的是一个使用线性探测法的 Map，可见，从底层数据结构上，JDK 就已经输了，他们的读取速度相差很大，特别是当数据量很大的时候，Netty 的数据结构速度依然不变，而 JDK 由于使用线性探测法，速度会相应的下降。

#### 2. setKnownNotUnset(threadLocalMap, value);

当 InternalThreadLocalMap.get() 返回了 一个 InternalThreadLocalMap，这个时候调用 setKnownNotUnset(threadLocalMap, value); 方法进行操作。代码如下：

```
private boolean setKnownNotUnset(InternalThreadLocalMap threadLocalMap, V value) {
    if (threadLocalMap.setIndexedVariable(index, value)) {
        addToVariablesToRemove(threadLocalMap, this);
        return true;
    }
    return false;
}
```

看方法名称，是设置一个值，但不是 unset，也就是那个空对象。通过 threadLocalMap.setIndexedVariable(index, value) 进行设置。如果返回 true，则调用 addToVariablesToRemove(threadLocalMap, this) 。这两个方法，我们一起看看。先看第一个：

setIndexedVariable 方法

```
public boolean setIndexedVariable(int index, Object value) {
    Object[] lookup = indexedVariables;
    if (index < lookup.length) {
        Object oldValue = lookup[index];
        lookup[index] = value;
        return oldValue == UNSET;
    } else {
        expandIndexedVariableTableAndSet(index, value);
        return true;
    }
}
```

首先，拿到那个 32 长度的数组，如果 FastThreadLocal 的 index 属性小于数组长度，则将值设定到指定槽位。将原来槽位的值设置为空对象。如果原来的对象也是空对象，则返回 true，否则返回 false。

如果不够呢？调用 expandIndexedVariableTableAndSet(index, value) 方法。进入该方法查看。看方法名称是扩大索引并设置值。

```
private void expandIndexedVariableTableAndSet(int index, Object value) {
    Object[] oldArray = indexedVariables;
    final int oldCapacity = oldArray.length;
    int newCapacity = index;
    newCapacity |= newCapacity >>>  1;
    newCapacity |= newCapacity >>>  2;
    newCapacity |= newCapacity >>>  4;
    newCapacity |= newCapacity >>>  8;
    newCapacity |= newCapacity >>> 16;
    newCapacity ++;

    Object[] newArray = Arrays.copyOf(oldArray, newCapacity);
    Arrays.fill(newArray, oldCapacity, newArray.length, UNSET);
    newArray[index] = value;
    indexedVariables = newArray;
}
```

这里代码很熟悉，HashMap 中也有这样的代码，我们去看看：

![img](https://upload-images.jianshu.io/upload_images/4236553-bb4c10b59073c4f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/647/format/jpeg)

HashMap 中的 tableSizeFor 方法

这段代码的作用就是按原来的容量扩容2倍。并且保证结果是2的幂次方。这里 Netty 的做法和 HashMap 一样，按照原来的容量扩容到最近的 2 的幂次方大小，比如原来32，就扩容到64，然后，将原来数组的内容填充到新数组中，剩余的填充`空对象`，然后将新数组赋值给成员变量 indexedVariables。完成了一次扩容。

回到 setKnownNotUnset 方法中，setIndexedVariable 方法什么情况下会返回 ture 呢？扩容了，或者没扩容，但插入的对象没有替换掉别的对象，也就是原槽位是空对象。换句话说，只有更新了对象才会返回 false。

也就是说，当新增了对象的时候，会调用 addToVariablesToRemove 方法，如同方法名，添加变量然后删除。我们看看 addToVariablesToRemove(threadLocalMap, this) 方法逻辑：

```
private static void addToVariablesToRemove(InternalThreadLocalMap threadLocalMap, FastThreadLocal<?> variable) {
    // 该变量是 static final 的，因此通常是 0
    Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex);
    Set<FastThreadLocal<?>> variablesToRemove;
    if (v == InternalThreadLocalMap.UNSET || v == null) {
        // 创建一个基于 IdentityHashMap 的 Set，泛型是 FastThreadLocal
        variablesToRemove = Collections.newSetFromMap(new IdentityHashMap<FastThreadLocal<?>, Boolean>());
        // 将这个 Set 放到这个 Map 数组的下标 0 处
        threadLocalMap.setIndexedVariable(variablesToRemoveIndex, variablesToRemove);
    } else {
        // 如果拿到的不是 UNSET ，说明这是第二次操作了，因此可以强转为 Set
        variablesToRemove = (Set<FastThreadLocal<?>>) v;
    }

    // 最后的目的就是将 FastThreadLocal 放置到 Set 中
    variablesToRemove.add(variable);
}
```

这个方法的目的是将 FastThreadLocal 对象保存到一个 Set 中，因为 Netty 的 Map 只是一个数组，没有键，所以保存到一个 Set 中，这样就可以判断是否 set 过这个 map，例如 Netty 的 isSet 方法就是根据这个判断的。

说完了 setKnownNotUnset 方法，我们再说说 registerCleaner 方法。

#### 3. registerCleaner(threadLocalMap);

这个方法可以说有点复杂了，请耐住性子，这里是 ftl（FastThreadLocal） 的精髓。

首先说下该方法的作用：将这个 ftl 注册到一个 `清理线程` 中，当 thread 对象被 gc 的时候，则会自动清理掉 ftl，防止 JDK 的内存泄漏问题。

让我们进入该方法查看：

```
private void registerCleaner(final InternalThreadLocalMap threadLocalMap) {
    Thread current = Thread.currentThread();
    if (FastThreadLocalThread.willCleanupFastThreadLocals(current) ||
        threadLocalMap.indexedVariable(cleanerFlagIndex) != InternalThreadLocalMap.UNSET) {
        return;
    }
    threadLocalMap.setIndexedVariable(cleanerFlagIndex, Boolean.TRUE);
    ObjectCleaner.register(current, new Runnable() {
        public void run() {
            remove(threadLocalMap);
        }
    });
}
```

楼主删除了源码中的注释，我们来好好说说这个方法：

1. 获取当前线程，如果当前线程是 FastThreadLocalThread 类型 且 cleanupFastThreadLocals 是 true，则返回 true，直接return。也就是说，Netty 线程池里面创建的线程都符合这条件，只有用户自定义的线程池不符合。
   当然还有一个条件：如果这个 ftl 的 index + 1 在 map 中的值不是空对象，则已经注册过了，也直接 return，不再重复注册。
2. 当不符合上面的条件的时候，将 Map 中对应的 ftl 的 index + 1 位置的值设置为 TRUE。根据上面的判断，防止重复注册。
3. 调用 ObjectCleaner 的 register 方法，注册一个任务，任务的内容就是调用 remove 方法，删除 ftl 在 map 中的对象和相应的内容。

问题来了，怎么注册的呢？为什么还带着一个 current 当前线程呢？

我们看看源码：

```
public static void register(Object object, Runnable cleanupTask) {
    AutomaticCleanerReference reference = new AutomaticCleanerReference(object,
            ObjectUtil.checkNotNull(cleanupTask, "cleanupTask"));
    LIVE_SET.add(reference);

    // Check if there is already a cleaner running.
    if (CLEANER_RUNNING.compareAndSet(false, true)) {
        final Thread cleanupThread = new FastThreadLocalThread(CLEANER_TASK);
        cleanupThread.setPriority(Thread.MIN_PRIORITY);
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                cleanupThread.setContextClassLoader(null);
                return null;
            }
        });
        cleanupThread.setName(CLEANER_THREAD_NAME);
        cleanupThread.setDaemon(true);
        cleanupThread.start();
    }
}
```

首先创建一个 AutomaticCleanerReference 自动清洁对象，继承了 WeakReference，先不看他的构造方法，先看下面，将这个构造好的实例放入到 LIVE_SET 中，实际上，这是一个 Netty 封装的 ConcurrentSet，然后判断清除线程是否在运行。如果没有，并且CAS改状态成功。就创建一个线程，任务是 定义好的 CLEANER_TASK，线程优先级是最低，上下位类加载器是null，名字是 objectCleanerThread，并且是后台线程。然后启动这个线程。运行 CLEANER_TASK。

一步一步来看看。

首先 AutomaticCleanerReference 的构造方法如下：

```java
private static final ReferenceQueue<Object> REFERENCE_QUEUE = new ReferenceQueue<Object>();

AutomaticCleanerReference(Object referent, Runnable cleanupTask) {
    super(referent, REFERENCE_QUEUE);
    this.cleanupTask = cleanupTask;
}   

void cleanup() {
   cleanupTask.run();
}
```

ReferenceQueue 的作用是，当对象被回收的时候，会将这个对象添加进这个队列，就可以跟踪这个对象。设置可以复活这个对象。也就是说，当这个 Thread 对象被回收的时候，会将这个对象放进这个引用队列，放进入干嘛呢？什么时候取出来呢？我们看看什么时候取出来：

代码如下：

```java
private static final Runnable CLEANER_TASK = new Runnable() {
    @Override
    public void run() {
        for (;;) {
            while (!LIVE_SET.isEmpty()) {
                final AutomaticCleanerReference reference = (AutomaticCleanerReference) REFERENCE_QUEUE.remove(REFERENCE_QUEUE_POLL_TIMEOUT_MS);
               
                if (reference != null) {
                    try {
                        reference.cleanup();
                    } catch (Throwable ignored) {
                    }
                    LIVE_SET.remove(reference);
                }
            }
            CLEANER_RUNNING.set(false);
            if (LIVE_SET.isEmpty() || !CLEANER_RUNNING.compareAndSet(false, true)) {
                break;
            }
        }
    }
};
```

巧了 ！！！！正是 CLEANER_TASK 在使用这个 ReferenceQueue！！！！别激动，我们还是慢慢看看这个任务到底是做什么的：

1. 死循环，如果 ConcurrentSet 不是空（还记得我们将 AutomaticCleanerReference 放进这里吗），尝试从 REFERENCE_QUEUE 中取出 AutomaticCleanerReference，也就是我们刚刚放进入的。这是标准的跟踪 GC 对象的做法。因为当一个对象被 GC 时，会将保证这个对象的 Reference 放进指定的引用队列，这是 JVM 做的。
2. 如果不是空，就调用应用的 cleanUp 方法，也就是我们传进去的任务，什么任务？就是那个调用 ftl 的 remove 方法的任务。随后从 Set 中删除这个引用。
3. 如果 Set 是空的话，将清理线程状态（原子变量） 设置成 fasle。
4. 继续判断，如果Set 还是空，或者 Set 不是空 且 设置 CAS 设置状态为true 失败（说明其他线程改了这个状态）则跳出循环，结束线程。

有点懵？那我们就好好总结这里为什么这么做：

> 当我们在一个非 Netty 线程池创建的线程中使用 ftl 的时候，Netty 会注册一个垃圾清理线程（因为 Netty 线程池创建的线程最终都会执行 removeAll 方法，不会出现内存泄漏） ，用于清理这个线程这个 ftl 变量，从上面的代码中，我们知道，非 Netty 线程如果使用 ftl，Netty 仍然会借助 JDK 的 ThreadLocal，只是只借用一个槽位，放置 Netty 的 Map， Map 中再放置 Netty 的 ftl 。所以，在使用线程池的情况下可能会出现内存泄漏。**Netty 为了解决这个问题，在每次使用新的 ftl 的时候，都将这个 ftl 注册到和线程对象绑定到一个 GC 引用上， 当这个线程对象被回收的时候，也会顺便清理掉他的 Map 中的 所有 ftl，解决了该问题，就像解决 JDK Nio bug 一样。**

好，到这里，Netty 的 FastThreadLocal 的精华我们基本就全部吸取了。ftl 不仅快，而且安全。快在使用数组代替线性探测法的 Map，安全在每次线程回收的时候都清理 ftl，不用担心内存泄漏。

剩下的方法都是很简单的。我们一起看完吧

#### 4. remove();

每次 Set 一个空对象的时候，就是调用remove 方法，我们看看该方法，源码如下：

```
public final void remove() {
     remove(InternalThreadLocalMap.getIfSet());
 }

 public static InternalThreadLocalMap getIfSet() {
     Thread thread = Thread.currentThread();
     if (thread instanceof FastThreadLocalThread) {
         return ((FastThreadLocalThread) thread).threadLocalMap();
     }
     return slowThreadLocalMap.get();

 }

 public final void remove(InternalThreadLocalMap threadLocalMap) {
     if (threadLocalMap == null) {
         return;
     }
     // 删除并返回 Map 数组中当前 ThreadLocal index 对应的 value
     Object v = threadLocalMap.removeIndexedVariable(index);
     // 从 Map 数组下标 0 的位置取出 Set ，并删除当前的 ThreadLocal
     removeFromVariablesToRemove(threadLocalMap, this);

     if (v != InternalThreadLocalMap.UNSET) {
         try {
             // 默认啥也不做，用户可以继承 FastThreadLocal 重定义这个方法。
             onRemoval((V) v);
         } catch (Exception e) {
             PlatformDependent.throwException(e);
         }
     }
 }
```

楼主将这3个方法都合并在一起了，首先获取当前线程的 threadLocalMap，然后就像注释中写的：删除 ftl 对应下标中 map 的 value，然后删除 map 下标0 处 Set 中的 ftl。防止 isSet 方法误判。最后，如果用户重写了 onRemoval 方法，就调用，默认是个空方法。用户可以重写 onRemoval 方法和 initialize 方法。

## 4. get 方法解析

get 方法就更简单了，代码如下：

```
public final V get() {
    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();
    Object v = threadLocalMap.indexedVariable(index);
    if (v != InternalThreadLocalMap.UNSET) {
        return (V) v;
    }

    V value = initialize(threadLocalMap);
    registerCleaner(threadLocalMap);
    return value;
}
```

首先获取当前线程的map，然后根据 ftl 的 index 获取 value，然后返回，如果是空对象，也就是没有设置，则通过 initialize 返回，initialize 方法会将返回值设置到 map 的槽位中，并放进 Set 中。最后，尝试注册一个清洁器。

## 5. remove All方法解析

这个方法在 Netty 的默认线程的 finally 块中调用。代码如下：

```java
public static void removeAll() {
    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.getIfSet();
    if (threadLocalMap == null) {
        return;
    }

    try {
        Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex);
        if (v != null && v != InternalThreadLocalMap.UNSET) {
            @SuppressWarnings("unchecked")
            Set<FastThreadLocal<?>> variablesToRemove = (Set<FastThreadLocal<?>>) v;
            FastThreadLocal<?>[] variablesToRemoveArray =
                    variablesToRemove.toArray(new FastThreadLocal[variablesToRemove.size()]);
            for (FastThreadLocal<?> tlv: variablesToRemoveArray) {
                tlv.remove(threadLocalMap);
            }
        }
    } finally {
        InternalThreadLocalMap.remove();
    }
}
```

非常简单，首先获取当前线程map，然后获取 Set，将 Set 转成数组，遍历数组，调用 ftl 的 remove 方法。最后，删除线程中 的 map 属性。

## 总结

现在我们来总结一下 FastThreadLocal 。

之所以称之为 Fast，因为没有使用 JDK 的使用线性探测法的 Map，如果你使用的是Netty 线程池工厂创建的线程，搭配 Netty 的 ftl，性能非常好，如果你使用自定义的线程，搭配 ftl，性能也会比 JDK 的好，注意： ftl 没有 JDK 的内存泄露的风险。

但做到这些不是没有代价的，由于每一个 ftl 都是一个唯一的下标，而这个下标是每次创建一个 ftl 对象都是递增 2，当你的下标很大，你的线程中的 Map 相应的也要增大，可以想象，如果创建了海量的 ftl 对象，这个数组的浪费是非常客观的。很明显，这是一种空间换时间的做法。

通常，ftl 都是静态对象，所以不会有我们假设的那么多。如果使用不当，确实会浪费大量内存。

但这个风险带来的好处是明显的，在楼主的机器上测试，ftl 的读取性能是 JDK 的 5 倍左右，写入的速度也要快 20% 左右。

FastThreadLocal 人如其名，快且安全！

今天就到这里，good luck！！！！

# Util 之 Recycler



笔者先把 Netty 主要的内容写完，所以关于 Recycler 的分享，先放在后续的计划里。

> 老艿艿：其实是因为，自己想去研究下 Service Mesh ，所以先简单收个小尾。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- 沧行 [《Netty之Recycler》](https://www.jianshu.com/p/4eab8450560c)

为避免可能 [《Netty之Recycler》](https://www.jianshu.com/p/4eab8450560c) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

Recycler用来实现对象池，其中对应堆内存和直接内存的池化实现分别是PooledHeapByteBuf和PooledDirectByteBuf。Recycler主要提供了3个方法：

- get():获取一个对象。
- recycle(T, Handle):回收一个对象，T为对象泛型。
- newObject(Handle):当没有可用对象时创建对象的实现方法。

Recycler的UML图如下：

![img](https://upload-images.jianshu.io/upload_images/3751588-916c6baab07fa863.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/jpeg)

Recycler.png

Recycler关联了4个核心类：

- DefaultHandle:对象的包装类，在Recycler中缓存的对象都会包装成DefaultHandle类。
- Stack:存储本线程回收的对象。对象的获取和回收对应Stack的pop和push，即获取对象时从Stack中pop出1个DefaultHandle，回收对象时将对象包装成DefaultHandle push到Stack中。Stack会与线程绑定，即每个用到Recycler的线程都会拥有1个Stack，在该线程中获取对象都是在该线程的Stack中pop出一个可用对象。
- WeakOrderQueue:存储其它线程回收到本线程stack的对象，当某个线程从Stack中获取不到对象时会从WeakOrderQueue中获取对象。每个线程的Stack拥有1个WeakOrderQueue链表，链表每个节点对应1个其它线程的WeakOrderQueue，其它线程回收到该Stack的对象就存储在这个WeakOrderQueue里。
- Link: WeakOrderQueue中包含1个Link链表，回收对象存储在链表某个Link节点里，当Link节点存储的回收对象满了时会新建1个Link放在Link链表尾。

整个Recycler回收对象存储结构如下图所示：

![img](https://upload-images.jianshu.io/upload_images/3751588-63236f0c4e59328d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/799/format/jpeg)

Recycler.png

下面分析下源码，首先看下Recycler.recycle(T, Handle)方法，用于回收1个对象：

```java
public final boolean recycle(T o, Handle handle) {
    if (handle == NOOP_HANDLE) {
        return false;
    }

    DefaultHandle h = (DefaultHandle) handle;
    if (h.stack.parent != this) {
        return false;
    }
    if (o != h.value) {
        throw new IllegalArgumentException("o does not belong to handle");
    }
    h.recycle();
    return true;
}
```

回收1个对象会调用该对象DefaultHandle.recycle()方法，如下：

```java
public void recycle() {
   stack.push(this);
}
```

回收1个对象（DefaultHandle）就是把该对象push到stack中。

```java
void push(DefaultHandle item) {
        Thread currentThread = Thread.currentThread();
        if (thread == currentThread) {
            // The current Thread is the thread that belongs to the Stack, we can try to push the object now.
            /**
             * 如果该stack就是本线程的stack，那么直接把DefaultHandle放到该stack的数组里
             */
            pushNow(item);
        } else {
            // The current Thread is not the one that belongs to the Stack, we need to signal that the push
            // happens later.
            /**
             * 如果该stack不是本线程的stack，那么把该DefaultHandle放到该stack的WeakOrderQueue中
             */
            pushLater(item, currentThread);
        }
    }
```

这里分为两种情况，当stack是当前线程对应的stack时，执行pushNow(item)方法，直接把对象放到该stack的DefaultHandle数组中，如下：

```java
/**
 * 直接把DefaultHandle放到stack的数组里，如果数组满了那么扩展该数组为当前2倍大小
 * @param item
 */
private void pushNow(DefaultHandle item) {
    if ((item.recycleId | item.lastRecycledId) != 0) {
        throw new IllegalStateException("recycled already");
    }
    item.recycleId = item.lastRecycledId = OWN_THREAD_ID;

    int size = this.size;
    if (size >= maxCapacity || dropHandle(item)) {
        // Hit the maximum capacity or should drop - drop the possibly youngest object.
        return;
    }
    if (size == elements.length) {
        elements = Arrays.copyOf(elements, min(size << 1, maxCapacity));
    }

    elements[size] = item;
    this.size = size + 1;
}
```

当stack是其它线程的stack时，执行pushLater(item, currentThread)方法，将对象放到WeakOrderQueue中，如下：

```java
private void pushLater(DefaultHandle item, Thread thread) {
       /** 
        * Recycler有1个stack->WeakOrderQueue映射，每个stack会映射到1个WeakOrderQueue，这个WeakOrderQueue是该stack关联的其它线程WeakOrderQueue链表的head WeakOrderQueue。
        * 当其它线程回收对象到该stack时会创建1个WeakOrderQueue中并加到stack的WeakOrderQueue链表中。 
        */
        Map<Stack<?>, WeakOrderQueue> delayedRecycled = DELAYED_RECYCLED.get();
        WeakOrderQueue queue = delayedRecycled.get(this);
        if (queue == null) {
            /**
             * 如果delayedRecycled满了那么将1个伪造的WeakOrderQueue（DUMMY）放到delayedRecycled中，并丢弃该对象（DefaultHandle）
             */
            if (delayedRecycled.size() >= maxDelayedQueues) {
                // Add a dummy queue so we know we should drop the object
                delayedRecycled.put(this, WeakOrderQueue.DUMMY);
                return;
            }
            // Check if we already reached the maximum number of delayed queues and if we can allocate at all.
            /**
             * 创建1个WeakOrderQueue
             */
            if ((queue = WeakOrderQueue.allocate(this, thread)) == null) {
                // drop object
                return;
            }
            delayedRecycled.put(this, queue);
        } else if (queue == WeakOrderQueue.DUMMY) {
            // drop object
            return;
        }

        /**
         * 将对象放入到该stack对应的WeakOrderQueue中
         */
        queue.add(item);
    }


static WeakOrderQueue allocate(Stack<?> stack, Thread thread) {
        // We allocated a Link so reserve the space
        /**
         * 如果该stack的可用共享空间还能再容下1个WeakOrderQueue，那么创建1个WeakOrderQueue，否则返回null
         */
        return reserveSpace(stack.availableSharedCapacity, LINK_CAPACITY)
                ? new WeakOrderQueue(stack, thread) : null;
    }
```

WeakOrderQueue的构造函数如下，WeakOrderQueue实现了多线程环境下回收对象的机制，当由其它线程回收对象到stack时会为该stack创建1个WeakOrderQueue，这些由其它线程创建的WeakOrderQueue会在该stack中按链表形式串联起来，每次创建1个WeakOrderQueue会把该WeakOrderQueue作为该stack的head WeakOrderQueue：

```java
private WeakOrderQueue(Stack<?> stack, Thread thread) {
        head = tail = new Link();
        owner = new WeakReference<Thread>(thread);
        /**
         * 每次创建WeakOrderQueue时会更新WeakOrderQueue所属的stack的head为当前WeakOrderQueue， 当前WeakOrderQueue的next为stack的之前head，
         * 这样把该stack的WeakOrderQueue通过链表串起来了，当下次stack中没有可用对象需要从WeakOrderQueue中转移对象时从WeakOrderQueue链表的head进行scavenge转移到stack的对DefaultHandle数组。
         */
        synchronized (stack) {
            next = stack.head;
            stack.head = this;
        }
        availableSharedCapacity = stack.availableSharedCapacity;
    }
```

下面再看Recycler.get()方法：

```java
public final T get() {
    if (maxCapacity == 0) {
        return newObject(NOOP_HANDLE);
    }
    Stack<T> stack = threadLocal.get();
    DefaultHandle handle = stack.pop();
    if (handle == null) {
        handle = stack.newHandle();
        handle.value = newObject(handle);
    }
    return (T) handle.value;
}
```

取出该线程对应的stack，从stack中pop出1个DefaultHandle，返回该DefaultHandle的真正对象。
下面看stack.pop()方法：

```java
DefaultHandle pop() {
        int size = this.size;
        if (size == 0) {
            if (!scavenge()) {
                return null;
            }
            size = this.size;
        }
        size --;
        DefaultHandle ret = elements[size];
        elements[size] = null;
        if (ret.lastRecycledId != ret.recycleId) {
            throw new IllegalStateException("recycled multiple times");
        }
        ret.recycleId = 0;
        ret.lastRecycledId = 0;
        this.size = size;
        return ret;
    }
```

如果该stack的DefaultHandle数组中还有对象可用，那么从该DefaultHandle数组中取出1个可用对象返回，如果该DefaultHandle数组没有可用的对象了，那么执行scavenge()方法，将head WeakOrderQueue中的head Link中的DefaultHandle数组转移到stack的DefaultHandle数组，scavenge方法如下：

```java
boolean scavenge() {
        // continue an existing scavenge, if any
        if (scavengeSome()) {
            return true;
        }

        // reset our scavenge cursor
        prev = null;
        cursor = head;
        return false;
    }
```

具体执行了scavengeSome()方法，清理WeakOrderQueue中部分DefaultHandle到stack，每次尽可能清理head WeakOrderQueue的head Link的全部DefaultHandle，如下：

```java
boolean scavengeSome() {
        WeakOrderQueue cursor = this.cursor;
        if (cursor == null) {
            cursor = head;
            if (cursor == null) {
                return false;
            }
        }

        boolean success = false;
        WeakOrderQueue prev = this.prev;
        do {
            /**
             * 将当前WeakOrderQueue的head Link的DefaultHandle数组转移到stack的DefaultHandle数组中
             */
            if (cursor.transfer(this)) {
                success = true;
                break;
            }

            WeakOrderQueue next = cursor.next;
            if (cursor.owner.get() == null) {
                if (cursor.hasFinalData()) {
                    for (;;) {
                        if (cursor.transfer(this)) {
                            success = true;
                        } else {
                            break;
                        }
                    }
                }
                if (prev != null) {
                    prev.next = next;
                }
            } else {
                prev = cursor;
            }

            cursor = next;

        } while (cursor != null && !success);

        this.prev = prev;
        this.cursor = cursor;
        return success;
    }
```

WeakOrderQueue.transfer()方法如下，将WeakOrderQueue的head Link中的DefaultHandle数组迁移到stack中：

```java
boolean transfer(Stack<?> dst) {
        Link head = this.head;
        if (head == null) {
            return false;
        }

        /**
         * 如果head Link的readIndex到达了Link的容量LINK_CAPACITY，说明该Link已经被scavengge完了。
         * 这时需要把下一个Link作为新的head Link。
         */
        if (head.readIndex == LINK_CAPACITY) {
            if (head.next == null) {
                return false;
            }
            this.head = head = head.next;
        }

        final int srcStart = head.readIndex;
        /**
         * head Link的回收对象数组的最大位置
         */
        int srcEnd = head.get();
        /**
         * head Link可以scavenge的DefaultHandle的数量
         */
        final int srcSize = srcEnd - srcStart;
        if (srcSize == 0) {
            return false;
        }

        final int dstSize = dst.size;

        /**
         * 每次会尽可能scavenge整个head Link，如果head Link的DefaultHandle数组能全部迁移到stack中，stack的DefaultHandle数组预期容量
         */
        final int expectedCapacity = dstSize + srcSize;
        /**
         * 如果预期容量大于stack的DefaultHandle数组最大长度，说明本次无法将head Link的DefaultHandle数组全部迁移到stack中
         */
        if (expectedCapacity > dst.elements.length) {
            final int actualCapacity = dst.increaseCapacity(expectedCapacity);
            srcEnd = min(srcStart + actualCapacity - dstSize, srcEnd);
        }

        if (srcStart != srcEnd) {
            /**
             * head Link的DefaultHandle数组
             */
            final DefaultHandle[] srcElems = head.elements;
            /**
             * stack的DefaultHandle数组
             */
            final DefaultHandle[] dstElems = dst.elements;
            int newDstSize = dstSize;
            /**
             * 迁移head Link的DefaultHandle数组到stack的DefaultHandle数组
             */
            for (int i = srcStart; i < srcEnd; i++) {
                DefaultHandle element = srcElems[i];
                if (element.recycleId == 0) {
                    element.recycleId = element.lastRecycledId;
                } else if (element.recycleId != element.lastRecycledId) {
                    throw new IllegalStateException("recycled already");
                }
                srcElems[i] = null;

                if (dst.dropHandle(element)) {
                    // Drop the object.
                    continue;
                }
                element.stack = dst;
                dstElems[newDstSize ++] = element;
            }

            /**
             * 当head节点的对象全都转移给stack后，取head下一个节点作为head，下次转移的时候再从新的head转移回收的对象
             */
            if (srcEnd == LINK_CAPACITY && head.next != null) {
                // Add capacity back as the Link is GCed.
                reclaimSpace(LINK_CAPACITY);

                this.head = head.next;
            }
            /**
             * 迁移完成后更新原始head Link的readIndex
             */
            head.readIndex = srcEnd;
            if (dst.size == newDstSize) {
                return false;
            }
            dst.size = newDstSize;
            return true;
        } else {
            // The destination stack is full already.
            return false;
        }
    }
```

# Util 之 HashedWheelTimer



笔者先把 Netty 主要的内容写完，所以关于 HashedWheelTimer 的分享，先放在后续的计划里。

> 老艿艿：其实是因为，自己想去研究下 Service Mesh ，所以先简单收个小尾。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- 德胜 [《Netty工具类HashedWheelTimer源码走读(一)》](https://my.oschina.net/haogrgr/blog/489320)
- 德胜 [《Netty工具类HashedWheelTimer源码走读(二)》](https://my.oschina.net/haogrgr/blog/490266)
- 德胜 [《Netty工具类HashedWheelTimer源码走读(三)》](https://my.oschina.net/haogrgr/blog/490348)
- Zacard [《netty源码解读之时间轮算法实现-HashedWheelTimer》](https://zacard.net/2016/12/02/netty-hashedwheeltimer/)

为避免可能 [《netty源码解读之时间轮算法实现-HashedWheelTimer》](https://zacard.net/2016/12/02/netty-hashedwheeltimer/) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

## 前因

由于netty动辄管理100w+的连接，每一个连接都会有很多超时任务。比如发送超时、心跳检测间隔等，如果每一个定时任务都启动一个`Timer`,不仅低效，而且会消耗大量的资源。

## 解决方案

根据George Varghese 和 Tony Lauck 1996 年的论文：[Hashed and Hierarchical Timing Wheels: data structures to efficiently implement a timer facility](http://static2.iocoder.cn/62dc58eaa06cbd6f431dc616c375b717)。提出了一种定时轮的方式来管理和维护大量的`Timer`调度.

## 原理

时间轮其实就是一种环形的数据结构，可以想象成时钟，分成很多格子，一个格子代码一段时间（这个时间越短，`Timer`的精度越高）。并用一个链表报错在该格子上的到期任务，同时一个指针随着时间一格一格转动，并执行相应格子中的到期任务。任务通过`取摸`决定放入那个格子。如下图所示：

[![img](http://static2.iocoder.cn/89a84b18103e57fc95e596a47daa49c5)](http://static2.iocoder.cn/89a84b18103e57fc95e596a47daa49c5)

以上图为例，假设一个格子是1秒，则整个wheel能表示的时间段为8s，假如当前指针指向2，此时需要调度一个3s后执行的任务，显然应该加入到(2+3=5)的方格中，指针再走3次就可以执行了；如果任务要在10s后执行，应该等指针走完一个round零2格再执行，因此应放入4，同时将round（1）保存到任务中。检查到期任务时应当只执行round为0的，格子上其他任务的round应减1。

是不是很像java中的`Hashmap`。其实就是`HashMap`的哈希拉链算法，只不过多了指针转动与一些定时处理的逻辑。所以其相关的操作和`HashMap`也一致：

- 添加任务：O(1)
- 删除/取消任务：O(1)
- 过期/执行任务：最差情况为O(n)->也就是当`HashMap`里面的元素全部hash冲突，退化为一条链表的情况。平均O(1)->显然，格子越多，每个格子上的链表就越短，这里需要权衡时间与空间。

### 多层时间轮

如果任务的时间跨度很大，数量很大，单层的时间轮会造成任务的`round`很大，单个格子的链表很长。这时候可以将时间轮分层，类似于时钟的时分秒3层。如下图所示：

[![img](http://static2.iocoder.cn/f3172a69ecb37b8c26871a2553bdeb2e)](http://static2.iocoder.cn/f3172a69ecb37b8c26871a2553bdeb2e)

但是个人认为，多层的时间轮造成的算法复杂度的进一步提升。单层时间轮只需增加每一轮的格子就能解决链表过长的问题。因此，更倾向使用单层的时间轮，netty4中时间轮的实现也是单层的。

## netty时间轮的实现-HashedWheelTimer

### 简单使用示例

1.引入netty依赖

```xml
<dependency>
    <groupId>io.netty</groupId>
    <artifactId>netty-all</artifactId>
    <version>4.1.4.Final</version>
</dependency>
```

2.示例代码

示例1：

```
@Test
public void test1() throws Exception {
    DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
    HashedWheelTimer hashedWheelTimer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS);

    System.out.println("start:" + LocalDateTime.now().format(formatter));

    hashedWheelTimer.newTimeout(timeout -> {
        System.out.println("task :" + LocalDateTime.now().format(formatter));
    }, 3, TimeUnit.SECONDS);
    Thread.sleep(5000);
}
```

输出为：

> start:2016-11-30 05:56:35
>
> task :2016-11-30 05:56:38

示例2：

```
@Test
public void test2() throws Exception {
    DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
    HashedWheelTimer hashedWheelTimer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS);

    System.out.println("start:" + LocalDateTime.now().format(formatter));

    hashedWheelTimer.newTimeout(timeout -> {
        Thread.sleep(3000);
        System.out.println("task1:" + LocalDateTime.now().format(formatter));
    }, 3, TimeUnit.SECONDS);

    hashedWheelTimer.newTimeout(timeout -> System.out.println("task2:" + LocalDateTime.now().format(
            formatter)), 4, TimeUnit.SECONDS);

    Thread.sleep(10000);
}
```

输出：

> start:2016-12-01 08:32:37
>
> task1:2016-12-01 08:32:43
>
> task2:2016-12-01 08:32:43

可以看到，当前一个任务执行时间过长的时候，会影响后续任务的到期执行时间的。也就是说其中的任务是串行执行的。所以，要求里面的任务都要短平快。

### HashedWheelTimer源码之构造函数

```
  public HashedWheelTimer(
          ThreadFactory threadFactory, // 用来创建worker线程
          long tickDuration, // tick的时长，也就是指针多久转一格
          TimeUnit unit, // tickDuration的时间单位
          int ticksPerWheel, // 一圈有几格
          boolean leakDetection // 是否开启内存泄露检测
          ) {

      // 一些参数校验
      if (threadFactory == null) {
          throw new NullPointerException("threadFactory");
      }
      if (unit == null) {
          throw new NullPointerException("unit");
      }
      if (tickDuration <= 0) {
          throw new IllegalArgumentException("tickDuration must be greater than 0: " + tickDuration);
      }
      if (ticksPerWheel <= 0) {
          throw new IllegalArgumentException("ticksPerWheel must be greater than 0: " + ticksPerWheel);
      }

      // 创建时间轮基本的数据结构，一个数组。长度为不小于ticksPerWheel的最小2的n次方
      wheel = createWheel(ticksPerWheel);
      // 这是一个标示符，用来快速计算任务应该呆的格子。
      // 我们知道，给定一个deadline的定时任务，其应该呆的格子=deadline%wheel.length.但是%操作是个相对耗时的操作，所以使用一种变通的位运算代替：
      // 因为一圈的长度为2的n次方，mask = 2^n-1后低位将全部是1，然后deadline&mast == deadline%wheel.length
      // java中的HashMap也是使用这种处理方法
      mask = wheel.length - 1;

      // 转换成纳秒处理
      this.tickDuration = unit.toNanos(tickDuration);

      // 校验是否存在溢出。即指针转动的时间间隔不能太长而导致tickDuration*wheel.length>Long.MAX_VALUE
      if (this.tickDuration >= Long.MAX_VALUE / wheel.length) {
          throw new IllegalArgumentException(String.format(
                  "tickDuration: %d (expected: 0 < tickDuration in nanos < %d",
                  tickDuration, Long.MAX_VALUE / wheel.length));
      }
      // 创建worker线程
      workerThread = threadFactory.newThread(worker);

// 这里默认是启动内存泄露检测：当HashedWheelTimer实例超过当前cpu可用核数*4的时候，将发出警告
      leak = leakDetection || !workerThread.isDaemon() ? leakDetector.open(this) : null;
  }
```

再来看下`createWheel`的代码：

```
  private static HashedWheelBucket[] createWheel(int ticksPerWheel) {
      // 一些参数校验
if (ticksPerWheel <= 0) {
          throw new IllegalArgumentException(
                  "ticksPerWheel must be greater than 0: " + ticksPerWheel);
      }
      if (ticksPerWheel > 1073741824) {
          throw new IllegalArgumentException(
                  "ticksPerWheel may not be greater than 2^30: " + ticksPerWheel);
      }

// 初始化ticksPerWheel的值为不小于ticksPerWheel的最小2的n次方
      ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel);
// 初始化wheel数组
      HashedWheelBucket[] wheel = new HashedWheelBucket[ticksPerWheel];
      for (int i = 0; i < wheel.length; i ++) {
          wheel[i] = new HashedWheelBucket();
      }
      return wheel;
  }
```

`normalizeTicksPerWheel()`的代码：

```
// 初始化ticksPerWheel的值为不小于ticksPerWheel的最小2的n次方
   private static int normalizeTicksPerWheel(int ticksPerWheel) {
       int normalizedTicksPerWheel = 1;
       while (normalizedTicksPerWheel < ticksPerWheel) {
           normalizedTicksPerWheel <<= 1;
       }
       return normalizedTicksPerWheel;
   }
```

这里其实不建议使用这种方式，因为当ticksPerWheel的值很大的时候，这个方法会循环很多次，方法执行时间不稳定，效率也不够。推荐使用java8 HashMap的做法：

```
private int normalizeTicksPerWheel(int ticksPerWheel) {
    // 这里参考java8 hashmap的算法，使推算的过程固定
    int n = ticksPerWheel - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    // 这里1073741824 = 2^30,防止溢出
    return (n < 0) ? 1 : (n >= 1073741824) ? 1073741824 : n + 1;
}
```

### HashedWheelTimer源码之启动、停止与添加任务

`start()`启动时间轮的方法：

```
// 启动时间轮。这个方法其实不需要显示的主动调用，因为在添加定时任务（newTimeout()方法）的时候会自动调用此方法。
// 这个是合理的设计，因为如果时间轮里根本没有定时任务，启动时间轮也是空耗资源
public void start() {
    // 判断当前时间轮的状态，如果是初始化，则启动worker线程，启动整个时间轮；如果已经启动则略过；如果是已经停止，则报错
    // 这里是一个Lock Free的设计。因为可能有多个线程调用启动方法，这里使用AtomicIntegerFieldUpdater原子的更新时间轮的状态
    switch (WORKER_STATE_UPDATER.get(this)) {
        case WORKER_STATE_INIT:
            if (WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_INIT, WORKER_STATE_STARTED)) {
                workerThread.start();
            }
            break;
        case WORKER_STATE_STARTED:
            break;
        case WORKER_STATE_SHUTDOWN:
            throw new IllegalStateException("cannot be started once stopped");
        default:
            throw new Error("Invalid WorkerState");
    }

    // 等待worker线程初始化时间轮的启动时间
    while (startTime == 0) {
        try {
            startTimeInitialized.await();
        } catch (InterruptedException ignore) {
            // Ignore - it will be ready very soon.
        }
    }
}
```

AtomicIntegerFieldUpdater是JUC里面的类，原理是利用反射进行原子操作。有比AtomicInteger更好的性能和更低得内存占用。跟踪这个类的github 提交记录，可以看到更详细的[原因](http://static2.iocoder.cn/894e662550de6d9f418324da5b2469d5)

`stop()`停止时间轮的方法：

```
public Set<Timeout> stop() {
    // worker线程不能停止时间轮，也就是加入的定时任务，不能调用这个方法。
    // 不然会有恶意的定时任务调用这个方法而造成大量定时任务失效
    if (Thread.currentThread() == workerThread) {
        throw new IllegalStateException(
                HashedWheelTimer.class.getSimpleName() +
                        ".stop() cannot be called from " +
                        TimerTask.class.getSimpleName());
    }
    // 尝试CAS替换当前状态为“停止：2”。如果失败，则当前时间轮的状态只能是“初始化：0”或者“停止：2”。直接将当前状态设置为“停止：2“
    if (!WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_STARTED, WORKER_STATE_SHUTDOWN)) {
        // workerState can be 0 or 2 at this moment - let it always be 2.
        WORKER_STATE_UPDATER.set(this, WORKER_STATE_SHUTDOWN);

        if (leak != null) {
            leak.close();
        }

        return Collections.emptySet();
    }

    // 终端worker线程
    boolean interrupted = false;
    while (workerThread.isAlive()) {
        workerThread.interrupt();
        try {
            workerThread.join(100);
        } catch (InterruptedException ignored) {
            interrupted = true;
        }
    }

    // 从中断中恢复
    if (interrupted) {
        Thread.currentThread().interrupt();
    }

    if (leak != null) {
        leak.close();
    }
    // 返回未处理的任务
    return worker.unprocessedTimeouts();
}
```

`newTimeout()`添加定时任务：

```
public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) {
    // 参数校验
    if (task == null) {
        throw new NullPointerException("task");
    }
    if (unit == null) {
        throw new NullPointerException("unit");
    }
    // 如果时间轮没有启动，则启动
    start();

    // Add the timeout to the timeout queue which will be processed on the next tick.
    // During processing all the queued HashedWheelTimeouts will be added to the correct HashedWheelBucket.
    // 计算任务的deadline
    long deadline = System.nanoTime() + unit.toNanos(delay) - startTime;
    // 这里定时任务不是直接加到对应的格子中，而是先加入到一个队列里，然后等到下一个tick的时候，会从队列里取出最多100000个任务加入到指定的格子中
    HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline);
    timeouts.add(timeout);
    return timeout;
}
```

这里使用的Queue不是普通java自带的Queue的实现，而是使用[JCTool](http://static2.iocoder.cn/752997222ee0591298f89db49439b894)–一个高性能的的并发Queue实现包。

### HashedWheelTimer源码之HashedWheelTimeout

`HashedWheelTimeout`是一个定时任务的内部包装类，双向链表结构。会保存定时任务到期执行的任务、deadline、round等信息。

```
private static final class HashedWheelTimeout implements Timeout {

    // 定义定时任务的3个状态：初始化、取消、过期
    private static final int ST_INIT = 0;
    private static final int ST_CANCELLED = 1;
    private static final int ST_EXPIRED = 2;
    // 用来CAS方式更新定时任务状态
    private static final AtomicIntegerFieldUpdater<HashedWheelTimeout> STATE_UPDATER;

    static {
        AtomicIntegerFieldUpdater<HashedWheelTimeout> updater =
                PlatformDependent.newAtomicIntegerFieldUpdater(HashedWheelTimeout.class, "state");
        if (updater == null) {
            updater = AtomicIntegerFieldUpdater.newUpdater(HashedWheelTimeout.class, "state");
        }
        STATE_UPDATER = updater;
    }

    // 时间轮引用
    private final HashedWheelTimer timer;
    // 具体到期需要执行的任务
    private final TimerTask task;
    private final long deadline;

    @SuppressWarnings({"unused", "FieldMayBeFinal", "RedundantFieldInitialization" })
    private volatile int state = ST_INIT;

    // 离任务执行的轮数，当将次任务加入到格子中是计算该值，每过一轮，该值减一。
    long remainingRounds;

    // 双向链表结构，由于只有worker线程会访问，这里不需要synchronization / volatile
    HashedWheelTimeout next;
    HashedWheelTimeout prev;

    // 定时任务所在的格子
    HashedWheelBucket bucket;

    HashedWheelTimeout(HashedWheelTimer timer, TimerTask task, long deadline) {
        this.timer = timer;
        this.task = task;
        this.deadline = deadline;
    }

    @Override
    public Timer timer() {
        return timer;
    }

    @Override
    public TimerTask task() {
        return task;
    }

    @Override
    public boolean cancel() {
        // 这里只是修改状态为ST_CANCELLED，会在下次tick时，在格子中移除
        if (!compareAndSetState(ST_INIT, ST_CANCELLED)) {
            return false;
        }
        // 加入到时间轮的待取消队列，并在每次tick的时候，从相应格子中移除。
        timer.cancelledTimeouts.add(this);
        return true;
    }

    // 从格子中移除自身
    void remove() {
        HashedWheelBucket bucket = this.bucket;
        if (bucket != null) {
            bucket.remove(this);
        }
    }

    public boolean compareAndSetState(int expected, int state) {
        return STATE_UPDATER.compareAndSet(this, expected, state);
    }

    public int state() {
        return state;
    }

    @Override
    public boolean isCancelled() {
        return state() == ST_CANCELLED;
    }

    @Override
    public boolean isExpired() {
        return state() == ST_EXPIRED;
    }

    // 过期并执行任务
    public void expire() {
        if (!compareAndSetState(ST_INIT, ST_EXPIRED)) {
            return;
        }

        try {
            task.run(this);
        } catch (Throwable t) {
            if (logger.isWarnEnabled()) {
                logger.warn("An exception was thrown by " + TimerTask.class.getSimpleName() + '.', t);
            }
        }
    }

    // 略过toString()
}
```

### HashedWheelTimer源码之HashedWheelBucket

`HashedWheelBucket`用来存放HashedWheelTimeout，结构类似于LinkedList。提供了`expireTimeouts(long deadline)`方法来过期并执行格子中的定时任务

```
private static final class HashedWheelBucket {
    // 指向格子中任务的首尾
    private HashedWheelTimeout head;
    private HashedWheelTimeout tail;

    // 基础的链表添加操作
    public void addTimeout(HashedWheelTimeout timeout) {
        assert timeout.bucket == null;
        timeout.bucket = this;
        if (head == null) {
            head = tail = timeout;
        } else {
            tail.next = timeout;
            timeout.prev = tail;
            tail = timeout;
        }
    }

    // 过期并执行格子中的到期任务，tick到该格子的时候，worker线程会调用这个方法，根据deadline和remainingRounds判断任务是否过期
    public void expireTimeouts(long deadline) {
        HashedWheelTimeout timeout = head;

        // 遍历格子中的所有定时任务
        while (timeout != null) {
            boolean remove = false;
            if (timeout.remainingRounds <= 0) { // 定时任务到期
                if (timeout.deadline <= deadline) {
                    timeout.expire();
                } else {
                    // 如果round数已经为0，deadline却>当前格子的deadline，说放错格子了，这种情况应该不会出现
                    throw new IllegalStateException(String.format(
                            "timeout.deadline (%d) > deadline (%d)", timeout.deadline, deadline));
                }
                remove = true;
            } else if (timeout.isCancelled()) {
                remove = true;
            } else { //没有到期，轮数-1
                timeout.remainingRounds --;
            }
            // 先保存next，因为移除后next将被设置为null
            HashedWheelTimeout next = timeout.next;
            if (remove) {
                remove(timeout);
            }
            timeout = next;
        }
    }

    // 基础的链表移除node操作
    public void remove(HashedWheelTimeout timeout) {
        HashedWheelTimeout next = timeout.next;
        // remove timeout that was either processed or cancelled by updating the linked-list
        if (timeout.prev != null) {
            timeout.prev.next = next;
        }
        if (timeout.next != null) {
            timeout.next.prev = timeout.prev;
        }

        if (timeout == head) {
            // if timeout is also the tail we need to adjust the entry too
            if (timeout == tail) {
                tail = null;
                head = null;
            } else {
                head = next;
            }
        } else if (timeout == tail) {
            // if the timeout is the tail modify the tail to be the prev node.
            tail = timeout.prev;
        }
        // null out prev, next and bucket to allow for GC.
        timeout.prev = null;
        timeout.next = null;
        timeout.bucket = null;
    }

    /**
     * Clear this bucket and return all not expired / cancelled {@link Timeout}s.
     */
    public void clearTimeouts(Set<Timeout> set) {
        for (;;) {
            HashedWheelTimeout timeout = pollTimeout();
            if (timeout == null) {
                return;
            }
            if (timeout.isExpired() || timeout.isCancelled()) {
                continue;
            }
            set.add(timeout);
        }
    }

    // 链表的poll操作
    private HashedWheelTimeout pollTimeout() {
        HashedWheelTimeout head = this.head;
        if (head == null) {
            return null;
        }
        HashedWheelTimeout next = head.next;
        if (next == null) {
            tail = this.head =  null;
        } else {
            this.head = next;
            next.prev = null;
        }

        // null out prev and next to allow for GC.
        head.next = null;
        head.prev = null;
        head.bucket = null;
        return head;
    }
}
```

### HashedWheelTimer源码之Worker

`Worker`是时间轮的核心线程类。tick的转动，过期任务的处理都是在这个线程中处理的。

```
private final class Worker implements Runnable {
    private final Set<Timeout> unprocessedTimeouts = new HashSet<Timeout>();

    private long tick;

    @Override
    public void run() {
        // 初始化startTime.只有所有任务的的deadline都是想对于这个时间点
        startTime = System.nanoTime();
        // 由于System.nanoTime()可能返回0，甚至负数。并且0是一个标示符，用来判断startTime是否被初始化，所以当startTime=0的时候，重新赋值为1
        if (startTime == 0) {
            startTime = 1;
        }

        // 唤醒阻塞在start()的线程
        startTimeInitialized.countDown();

        // 只要时间轮的状态为WORKER_STATE_STARTED，就循环的“转动”tick，循环判断响应格子中的到期任务
        do {
            // waitForNextTick方法主要是计算下次tick的时间, 然后sleep到下次tick
            // 返回值就是System.nanoTime() - startTime, 也就是Timer启动后到这次tick, 所过去的时间
            final long deadline = waitForNextTick();
            if (deadline > 0) { // 可能溢出或者被中断的时候会返回负数, 所以小于等于0不管
                // 获取tick对应的格子索引
                int idx = (int) (tick & mask);
                // 移除被取消的任务
                processCancelledTasks();
                HashedWheelBucket bucket =
                        wheel[idx];
                // 从任务队列中取出任务加入到对应的格子中
                transferTimeoutsToBuckets();
                // 过期执行格子中的任务
                bucket.expireTimeouts(deadline);
                tick++;
            }
        } while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED);

        // 这里应该是时间轮停止了，清除所有格子中的任务，并加入到未处理任务列表，以供stop()方法返回
        for (HashedWheelBucket bucket: wheel) {
            bucket.clearTimeouts(unprocessedTimeouts);
        }
        // 将还没有加入到格子中的待处理定时任务队列中的任务取出，如果是未取消的任务，则加入到未处理任务队列中，以供stop()方法返回
        for (;;) {
            HashedWheelTimeout timeout = timeouts.poll();
            if (timeout == null) {
                break;
            }
            if (!timeout.isCancelled()) {
                unprocessedTimeouts.add(timeout);
            }
        }
        // 处理取消的任务
        processCancelledTasks();
    }

    // 将newTimeout()方法中加入到待处理定时任务队列中的任务加入到指定的格子中
    private void transferTimeoutsToBuckets() {
        // 每次tick只处理10w个任务，以免阻塞worker线程
        for (int i = 0; i < 100000; i++) {
            HashedWheelTimeout timeout = timeouts.poll();
            // 如果没有任务了，直接跳出循环
            if (timeout == null) {
                break;
            }
            // 还没有放入到格子中就取消了，直接略过
            if (timeout.state() == HashedWheelTimeout.ST_CANCELLED) {
                continue;
            }

            // 计算任务需要经过多少个tick
            long calculated = timeout.deadline / tickDuration;
            // 计算任务的轮数
            timeout.remainingRounds = (calculated - tick) / wheel.length;

            //如果任务在timeouts队列里面放久了, 以至于已经过了执行时间, 这个时候就使用当前tick, 也就是放到当前bucket, 此方法调用完后就会被执行.
            final long ticks = Math.max(calculated, tick); // Ensure we don't schedule for past.
            int stopIndex = (int) (ticks & mask);

            // 将任务加入到响应的格子中
            HashedWheelBucket bucket = wheel[stopIndex];
            bucket.addTimeout(timeout);
        }
    }

    // 将取消的任务取出，并从格子中移除
    private void processCancelledTasks() {
        for (;;) {
            HashedWheelTimeout timeout = cancelledTimeouts.poll();
            if (timeout == null) {
                // all processed
                break;
            }
            try {
                timeout.remove();
            } catch (Throwable t) {
                if (logger.isWarnEnabled()) {
                    logger.warn("An exception was thrown while process a cancellation task", t);
                }
            }
        }
    }

    /**
     * calculate goal nanoTime from startTime and current tick number,
     * then wait until that goal has been reached.
     * @return Long.MIN_VALUE if received a shutdown request,
     * current time otherwise (with Long.MIN_VALUE changed by +1)
     */
    //sleep, 直到下次tick到来, 然后返回该次tick和启动时间之间的时长
    private long waitForNextTick() {
        //下次tick的时间点, 用于计算需要sleep的时间
        long deadline = tickDuration * (tick + 1);

        for (;;) {
            // 计算需要sleep的时间, 之所以加999999后再除10000000, 是为了保证足够的sleep时间
            // 例如：当deadline - currentTime=2000002的时候，如果不加999999，则只睡了2ms，
            // 而2ms其实是未到达deadline这个时间点的，所有为了使上述情况能sleep足够的时间，加上999999后，会多睡1ms
            final long currentTime = System.nanoTime() - startTime;
            long sleepTimeMs = (deadline - currentTime + 999999) / 1000000;

            if (sleepTimeMs <= 0) {
	// 以下为个人理解：（如有错误，欢迎大家指正）
                // 这里的意思应该是从时间轮启动到现在经过太长的时间(跨度大于292年...)，以至于让long装不下，都溢出了...对于netty的严谨，我服！
                if (currentTime == Long.MIN_VALUE) {
                    return -Long.MAX_VALUE;
                } else {
                    return currentTime;
                }
            }

            // Check if we run on windows, as if thats the case we will need
            // to round the sleepTime as workaround for a bug that only affect
            // the JVM if it runs on windows.
            //
            // See https://github.com/netty/netty/issues/356
            if (PlatformDependent.isWindows()) { // 这里是因为windows平台的定时调度最小单位为10ms，如果不是10ms的倍数，可能会引起sleep时间不准确
                sleepTimeMs = sleepTimeMs / 10 * 10;
            }

            try {
                Thread.sleep(sleepTimeMs);
            } catch (InterruptedException ignored) {
	// 调用HashedWheelTimer.stop()时优雅退出
                if (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_SHUTDOWN) {
                    return Long.MIN_VALUE;
                }
            }
        }
    }

    public Set<Timeout> unprocessedTimeouts() {
        return Collections.unmodifiableSet(unprocessedTimeouts);
    }
}
```

## 总结

通过阅读源码，学到了很多之前不知道的知识点和注意事项。比如：

1. 操作数字型要考虑溢出问题
2. System.nanoTime(）返回值
3. Atomic*FieldUpdater类的运用
4. 一些代码设计方式
5. 不断优化性能，Lock Less代替Lock；Lock Free代替Lock Less
6. JCTool高性能队列的使用

# Util 之 MpscUnboundedArrayQueue



笔者先把 Netty 主要的内容写完，所以关于 MpscUnboundedArrayQueue 的分享，先放在后续的计划里。

> 老艿艿：其实是因为，自己想去研究下 Service Mesh ，所以先简单收个小尾。

当然，良心如我，还是为对这块感兴趣的胖友，先准备好了一篇不错的文章：

- HMILYYLIMH [《原理剖析（第 012 篇）Netty之无锁队列MpscUnboundedArrayQueue原理分析》](https://www.jianshu.com/p/119a03332619)

为避免可能 [《原理剖析（第 012 篇）Netty之无锁队列MpscUnboundedArrayQueue原理分析》](https://www.jianshu.com/p/119a03332619) 被作者删除，笔者这里先复制一份作为备份。

# 666. 备份

## 一、大致介绍

```
1、了解过netty原理的童鞋，其实应该知道工作线程组的每个子线程都维护了一个任务队列；
2、细心的童鞋会发现netty的队列是重写了队列的实现方法，覆盖了父类中的LinkedBlockingQueue队列，但是如今却换成了JCTools的一些并发队列，因为JCTools是一款对jdk并发数据结构进行增强的并发工具；
3、那么问题就来了，现在的netty要用新的队列呢？难道是新的队列确实很高效么？
4、那么本章节就来和大家分享分析一下Netty新采用的队列之一MpscUnboundedArrayQueue，分析Netty的源码版本为：netty-netty-4.1.22.Final；
```

## 二、回顾预习

### 2.1 构造队列

```
1、源码：
    // NioEventLoop.java
    @Override
    protected Queue<Runnable> newTaskQueue(int maxPendingTasks) {
        // This event loop never calls takeTask()
        // 由于默认是没有配置io.netty.eventLoop.maxPendingTasks属性值的，所以maxPendingTasks默认值为Integer.MAX_VALUE；
        // 那么最后配备的任务队列的大小也就自然使用无参构造队列方法
        return maxPendingTasks == Integer.MAX_VALUE ? PlatformDependent.<Runnable>newMpscQueue()
                                                    : PlatformDependent.<Runnable>newMpscQueue(maxPendingTasks);
    }

    // PlatformDependent.java
    /**
     * Create a new {@link Queue} which is safe to use for multiple producers (different threads) and a single
     * consumer (one thread!).
     * @return A MPSC queue which may be unbounded.
     */
    public static <T> Queue<T> newMpscQueue() {
        return Mpsc.newMpscQueue();
    }

    // Mpsc.java
    static <T> Queue<T> newMpscQueue() {
        return USE_MPSC_CHUNKED_ARRAY_QUEUE ? new MpscUnboundedArrayQueue<T>(MPSC_CHUNK_SIZE)
                                            : new MpscUnboundedAtomicArrayQueue<T>(MPSC_CHUNK_SIZE);
    }

2、通过源码回顾，想必大家已经隐约回忆起之前分析过这段代码，我们在构建工作线程管理组的时候，还需要实例化子线程数组children[]，所以自然就会碰到这段代码；

3、这段代码其实就是为了实现一个无锁方式的线程安全队列，总之一句话，效率相当相当的高；
```

### 2.2 何为JCTools？

```
1、JCTools是服务虚拟机并发开发的工具，提供一些JDK没有的并发数据结构辅助开发。

2、是一个聚合四种 SPSC/MPSC/SPMC/MPMC 数据变量的并发队列：
    • SPSC：单个生产者对单个消费者（无等待、有界和无界都有实现）
    • MPSC：多个生产者对单个消费者（无锁、有界和无界都有实现）
    • SPMC：单生产者对多个消费者（无锁 有界）
    • MPMC：多生产者对多个消费者（无锁、有界）

3、SPSC/MPSC 提供了一个在性能，分配和分配规则之间的平衡的关联数组队列；
```

### 2.3 常用重要的成员属性及方法

```
1、private volatile long producerLimit;
   // 数据链表所分配或者扩展后的容量值

2、protected long producerIndex;
   // 生产者指针，每添加一个数据，指针加2

3、protected long consumerIndex;
   // 消费者指针，每移除一个数据，指针加2

4、private static final int RETRY = 1; // 重新尝试，有可能是因为并发原因，CAS操作指针失败，所以需要重新尝试添加动作
   private static final int QUEUE_FULL = 2; // 队列已满，直接返回false操作
   private static final int QUEUE_RESIZE = 3; // 需要扩容处理，扩容的后的容量值producerLimit一般都是mask的N倍
   // 添加数据时，根据offerSlowPath返回的状态值来做各种处理

5、protected E[] producerBuffer;
   // 数据缓冲区，需要添加的数据放在此

6、protected long producerMask;
   // 生产者扩充容量值，一般producerMask与consumerMask是一致的，而且需要扩容的数值一般和此值一样

7、public boolean offer(final E e)
   // 添加元素

8、public E poll()
   // 移除元素
```

### 2.4 数据结构

```
1、如果chunkSize初始化大小为4，则最后显示的数据结构如下：
   E1，E2，。。。，EN：表示具体的元素；
   NBP：表示下一个缓冲区的指针，我采用的是英文的缩写( Next Buffer Pointer)；

   而且你看着我是拆分开写的，其实每一个NBP指向的就是下面一组缓冲区；
   Buffer1中的NBP其实就是Buffer2的指针引用；
   Buffer2中的NBP其实就是Buffer3的指针引用；
   以此类推。。。
+------+------+------+------+------+
|      |      |      |      |      |
|  E1  |  E2  |  E3  | JUMP |  NBP |    Buffer1
|      |      |      |      |      |
+------+------+------+------+------+

+------+------+------+------+------+
|      |      |      |      |      |
|  E5  |  E6  | JUMP |  E4  |  NBP |    Buffer2
|      |      |      |      |      |
+------+------+------+------+------+

+------+------+------+------+------+
|      |      |      |      |      |
|  E9  | JUMP |  E7  |  E8  |  NBP |    Buffer3
|      |      |      |      |      |
+------+------+------+------+------+

+------+------+------+------+------+
|      |      |      |      |      |
| JUMP |  E10 |  E11 |  E12 |  NBP |    Buffer4
|      |      |      |      |      |
+------+------+------+------+------+

+------+------+------+------+------+
|      |      |      |      |      |
|  E13 |  E14 |  E15 | JUMP |  NBP |    Buffer5
|      |      |      |      |      |
+------+------+------+------+------+

2、这个数据结构和我们通常所认知的链表是不是有点异样，其实大体还是雷同的，这种数据结构其实也是指针的单项指引罢了；
```

## 三、源码分析MpscUnboundedArrayQueue

### 3.1、MpscUnboundedArrayQueue(int)

```
1、源码：
    // MpscUnboundedArrayQueue.java
    public MpscUnboundedArrayQueue(int chunkSize)
    {
        super(chunkSize); // 调用父类的含参构造方法
    }

    // BaseMpscLinkedArrayQueue.java
    /**
     * @param initialCapacity the queue initial capacity. If chunk size is fixed this will be the chunk size.
     *                        Must be 2 or more.
     */
    public BaseMpscLinkedArrayQueue(final int initialCapacity)
    {
        // 校验队列容量值，大小必须不小于2
        RangeUtil.checkGreaterThanOrEqual(initialCapacity, 2, "initialCapacity");

        // 通过传入的参数通过Pow2算法获取大于initialCapacity最近的一个2的n次方的值
        int p2capacity = Pow2.roundToPowerOfTwo(initialCapacity);
        // leave lower bit of mask clear
        long mask = (p2capacity - 1) << 1; // 通过p2capacity计算获得mask值，该值后续将用作扩容的值
        // need extra element to point at next array
        E[] buffer = allocate(p2capacity + 1); // 默认分配一个 p2capacity + 1 大小的数据缓冲区
        producerBuffer = buffer;
        producerMask = mask;
        consumerBuffer = buffer;
        consumerMask = mask;
        // 同时用mask作为初始化队列的Limit值，当生产者指针producerIndex超过该Limit值时就需要做扩容处理
        soProducerLimit(mask); // we know it's all empty to start with
    }

    // RangeUtil.java
    public static int checkGreaterThanOrEqual(int n, int expected, String name)
    {
        // 要求队列的容量值必须不小于 expected 值，这个 expected 值由上层决定，但是对 MpscUnboundedArrayQueue 而言，expected 为 2；
        // 那么就是说 MpscUnboundedArrayQueue 的值必须不小于 2；
        if (n < expected)
        {
            throw new IllegalArgumentException(name + ": " + n + " (expected: >= " + expected + ')');
        }

        return n;
    }

2、通过调用父类的构造方法，分配了一个数据缓冲区，初始化容量大小，并且容量值不小于2，差不多就这样队列的实例化操作已经完成了；
```

### 3.2、offer(E)

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    @Override
    public boolean offer(final E e)
    {
        if (null == e) // 待添加的元素e不允许为空，否则抛空指针异常
        {
            throw new NullPointerException();
        }

        long mask;
        E[] buffer;
        long pIndex;

        while (true)
        {
            long producerLimit = lvProducerLimit(); // 获取当前数据Limit的阈值
            pIndex = lvProducerIndex(); // 获取当前生产者指针位置
            // lower bit is indicative of resize, if we see it we spin until it's cleared
            if ((pIndex & 1) == 1)
            {
                continue;
            }
            // pIndex is even (lower bit is 0) -> actual index is (pIndex >> 1)

            // mask/buffer may get changed by resizing -> only use for array access after successful CAS.
            mask = this.producerMask;
            buffer = this.producerBuffer;
            // a successful CAS ties the ordering, lv(pIndex) - [mask/buffer] -> cas(pIndex)

            // assumption behind this optimization is that queue is almost always empty or near empty
            if (producerLimit <= pIndex) // 当阈值小于等于生产者指针位置时，则需要扩容，否则直接通过CAS操作对pIndex做加2处理
            {
                // 通过offerSlowPath返回状态值，来查看怎么来处理这个待添加的元素
                int result = offerSlowPath(mask, pIndex, producerLimit);
                switch (result)
                {
                    case CONTINUE_TO_P_INDEX_CAS:
                        break;
                    case RETRY: // 可能由于并发原因导致CAS失败，那么则再次重新尝试添加元素
                        continue;
                    case QUEUE_FULL: // 队列已满，直接返回false操作
                        return false;
                    case QUEUE_RESIZE: // 队列需要扩容操作
                        resize(mask, buffer, pIndex, e); // 对队列进行直接扩容操作
                        return true;
                }
            }

            // 能走到这里，则说明当前的生产者指针位置还没有超过阈值，因此直接通过CAS操作做加2处理
            if (casProducerIndex(pIndex, pIndex + 2))
            {
                break;
            }
        }
        // INDEX visible before ELEMENT
        // 获取计算需要添加元素的位置
        final long offset = modifiedCalcElementOffset(pIndex, mask);
        // 在buffer的offset位置添加e元素
        soElement(buffer, offset, e); // release element e
        return true;
    }

    // BaseMpscLinkedArrayQueueProducerFields.java
    @Override
    public final long lvProducerIndex()
    {
        // 通过Unsafe对象调用native方法，获取生产者指针位置
        return UNSAFE.getLongVolatile(this, P_INDEX_OFFSET);
    }

    // UnsafeRefArrayAccess.java
    /**
     * An ordered store(store + StoreStore barrier) of an element to a given offset
     *
     * @param buffer this.buffer
     * @param offset computed via {@link UnsafeRefArrayAccess#calcElementOffset}
     * @param e      an orderly kitty
     */
    public static <E> void soElement(E[] buffer, long offset, E e)
    {
        // 通过Unsafe对象调用native方法，将元素e设置到buffer缓冲区的offset位置
        UNSAFE.putOrderedObject(buffer, offset, e);
    }

2、此方法为添加新的元素对象，当pIndex指针超过阈值producerLimit时则扩容处理，否则直接通过CAS操作添加记录pIndex位置；
```

### 3.3、offerSlowPath(long, long, long)

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    /**
     * We do not inline resize into this method because we do not resize on fill.
     */
    private int offerSlowPath(long mask, long pIndex, long producerLimit)
    {
        // 获取消费者指针
        final long cIndex = lvConsumerIndex();
        // 获取当前缓冲区的容量值，getCurrentBufferCapacity方法由子类MpscUnboundedArrayQueue实现，默认返回mask值
        long bufferCapacity = getCurrentBufferCapacity(mask);

        // 如果消费指针加上容量值如果超过了生产指针，那么则会尝试进行扩容处理
        if (cIndex + bufferCapacity > pIndex)
        {
            if (!casProducerLimit(producerLimit, cIndex + bufferCapacity))
            {
                // retry from top
                return RETRY;
            }
            else
            {
                // continue to pIndex CAS
                return CONTINUE_TO_P_INDEX_CAS;
            }
        }
        // full and cannot grow 子类MpscUnboundedArrayQueue默认返回Integer.MAX_VALUE值，所以不会进入此分支
        else if (availableInQueue(pIndex, cIndex) <= 0)
        {
            // offer should return false;
            return QUEUE_FULL;
        }
        // grab index for resize -> set lower bit 尝试扩容队列
        else if (casProducerIndex(pIndex, pIndex + 1))
        {
            // trigger a resize
            return QUEUE_RESIZE;
        }
        else
        {
            // failed resize attempt, retry from top
            return RETRY;
        }
    }

    // MpscUnboundedArrayQueue.java
    @Override
    protected long getCurrentBufferCapacity(long mask)
    {
        // 获取当前缓冲区的容量值
        return mask;
    }

    // BaseMpscLinkedArrayQueue.java
    final boolean casProducerLimit(long expect, long newValue)
    {
        // 通过CAS尝试对阈值进行修改扩容处理
        return UNSAFE.compareAndSwapLong(this, P_LIMIT_OFFSET, expect, newValue);
    }

    // MpscUnboundedArrayQueue.java
    @Override
    protected long availableInQueue(long pIndex, long cIndex)
    {
        // 获取可用容量值
        return Integer.MAX_VALUE;
    }

    // BaseMpscLinkedArrayQueueProducerFields.java
    final boolean casProducerIndex(long expect, long newValue)
    {
        // 通过CAS操作更新生产者指针
        return UNSAFE.compareAndSwapLong(this, P_INDEX_OFFSET, expect, newValue);
    }

2、该方法主要通过一系列的if...else判断，并结合子类MpscUnboundedArrayQueue的一些重写方法来判断针对该新添加的元素要做何种状态处理；
```

### 3.4、resize(long, E[], long, E)

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    private void resize(long oldMask, E[] oldBuffer, long pIndex, E e)
    {
        // 获取oldBuffer的长度值
        int newBufferLength = getNextBufferSize(oldBuffer);
        // 重新创建新的缓冲区
        final E[] newBuffer = allocate(newBufferLength);

        producerBuffer = newBuffer; // 将新创建的缓冲区赋值到生产者缓冲区对象上
        final int newMask = (newBufferLength - 2) << 1;
        producerMask = newMask;

        // 根据oldMask获取偏移位置值
        final long offsetInOld = modifiedCalcElementOffset(pIndex, oldMask);
        // 根据newMask获取偏移位置值
        final long offsetInNew = modifiedCalcElementOffset(pIndex, newMask);

        // 将元素e设置到新的缓冲区newBuffer的offsetInNew位置处
        soElement(newBuffer, offsetInNew, e);// element in new array

        // 通过nextArrayOffset(oldMask)计算新的缓冲区将要放置旧的缓冲区的哪个位置
        // 将新的缓冲区newBuffer设置到旧的缓冲区oldBuffer的nextArrayOffset(oldMask)位置处
        // 主要是将oldBuffer中最后一个元素的位置指向新的缓冲区newBuffer
        // 这样就构成了一个单向链表指向的关系
        soElement(oldBuffer, nextArrayOffset(oldMask), newBuffer);// buffer linked

        // ASSERT code
        final long cIndex = lvConsumerIndex();
        final long availableInQueue = availableInQueue(pIndex, cIndex);
        RangeUtil.checkPositive(availableInQueue, "availableInQueue");

        // Invalidate racing CASs
        // We never set the limit beyond the bounds of a buffer
        // 重新扩容阈值，因为availableInQueue反正都是Integer.MAX_VALUE值，所以自然就取mask值啦
        // 因此针对MpscUnboundedArrayQueue来说，扩容的值其实就是mask的值的大小
        soProducerLimit(pIndex + Math.min(newMask, availableInQueue));

        // make resize visible to the other producers
        // 设置生产者指针加2处理
        soProducerIndex(pIndex + 2);

        // INDEX visible before ELEMENT, consistent with consumer expectation

        // make resize visible to consumer
        // 用一个空对象来衔接新老缓冲区，凡是在缓冲区中碰到JUMP对象的话，那么就得琢磨着准备着获取下一个缓冲区的数据元素了
        soElement(oldBuffer, offsetInOld, JUMP);
    }

    // MpscUnboundedArrayQueue.java
    @Override
    protected int getNextBufferSize(E[] buffer)
    {
        // 获取buffer缓冲区的长度
        return length(buffer);
    }

    // LinkedArrayQueueUtil.java
    static int length(Object[] buf)
    {
        // 直接通过length属性来获取数组的长度
        return buf.length;
    }

    // CircularArrayOffsetCalculator.java
    @SuppressWarnings("unchecked")
    public static <E> E[] allocate(int capacity)
    {
        // 根据容量值创建数组
        return (E[]) new Object[capacity];
    }

2、该方法主要完成新的元素的放置，同时也完成了扩容操作，采用单向链表指针关系，将原缓冲区和新创建的缓冲区衔接起来；
```

### 3.5、poll()

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    /**
     * {@inheritDoc}
     * <p>
     * This implementation is correct for single consumer thread use only.
     */
    @SuppressWarnings("unchecked")
    @Override
    public E poll()
    {
        final E[] buffer = consumerBuffer; // 获取缓冲区的数据
        final long index = consumerIndex;
        final long mask = consumerMask;

        // 根据消费指针与mask来获取当前需要从哪个位置开始来移除元素
        final long offset = modifiedCalcElementOffset(index, mask);
        // 从buffer缓冲区的offset位置获取元素内容
        Object e = lvElement(buffer, offset);// LoadLoad
        if (e == null) // 如果元素为null的话
        {
            // 则再探讨看看消费指针是不是和生产指针是不是相同
            if (index != lvProducerIndex())
            {
                // poll() == null iff queue is empty, null element is not strong enough indicator, so we must
                // check the producer index. If the queue is indeed not empty we spin until element is
                // visible.
                // 若不相同的话，则先尝试从buffer缓冲区的offset位置获取元素先，若获取元素为null则结束while处理
                do
                {
                    e = lvElement(buffer, offset);
                }
                while (e == null);
            }
            // 说明消费指针是不是和生产指针是相等的，那么则缓冲区的数据已经被消费完了，直接返回null即可
            else
            {
                return null;
            }
        }

        // 如果元素为JUMP空对象的话，那么意味着我们就得获取下一缓冲区进行读取数据了
        if (e == JUMP)
        {
            //
            final E[] nextBuffer = getNextBuffer(buffer, mask);
            //
            return newBufferPoll(nextBuffer, index);
        }

        // 能执行到这里，说明需要移除的元素既不是空的，也不是JUMP空对象，那么则就按照正常处理置空即可
        // 移除元素时，则将buffer缓冲区的offset位置的元素置为空即可
        soElement(buffer, offset, null); // release element null
        // 同时也通过CAS操作增加消费指针的关系，加2操作
        soConsumerIndex(index + 2); // release cIndex
        return (E) e;
    }

    // BaseMpscLinkedArrayQueueProducerFields.java
    @Override
    public final long lvProducerIndex()
    {
        // 通过Unsafe对象调用native方法，获取当前生产者指针值
        return UNSAFE.getLongVolatile(this, P_INDEX_OFFSET);
    }

    // UnsafeRefArrayAccess.java
    /**
     * A volatile load (load + LoadLoad barrier) of an element from a given offset.
     *
     * @param buffer this.buffer
     * @param offset computed via {@link UnsafeRefArrayAccess#calcElementOffset(long)}
     * @return the element at the offset
     */
    @SuppressWarnings("unchecked")
    public static <E> E lvElement(E[] buffer, long offset)
    {
        // 通过Unsafe对象调用native方法，获取buffer缓冲区offset位置的元素
        return (E) UNSAFE.getObjectVolatile(buffer, offset);
    }

    // BaseMpscLinkedArrayQueue.java
    @SuppressWarnings("unchecked")
    private E[] getNextBuffer(final E[] buffer, final long mask)
    {
        // 获取下一个缓冲区的偏移位置值
        final long offset = nextArrayOffset(mask);
        // 从buffer缓冲区的offset位置获取下一个缓冲区数组
        final E[] nextBuffer = (E[]) lvElement(buffer, offset);
        // 获取出来后，同时将buffer缓冲区的offset位置置为空，代表指针已经被取出，原来位置没用了，清空即可
        soElement(buffer, offset, null);
        return nextBuffer;
    }

    // BaseMpscLinkedArrayQueue.java
    private E newBufferPoll(E[] nextBuffer, long index)
    {
        // 从下一个新的缓冲区中找到需要移除数据的指针位置
        final long offset = newBufferAndOffset(nextBuffer, index);
        // 从newBuffer新的缓冲区中offset位置取出元素
        final E n = lvElement(nextBuffer, offset);// LoadLoad
        if (n == null) // 若取出的元素为空，则直接抛出异常
        {
            throw new IllegalStateException("new buffer must have at least one element");
        }
        // 如果取出的元素不为空，那么先将这个元素原先的位置内容先清空掉
        soElement(nextBuffer, offset, null);// StoreStore
        // 然后通过Unsafe对象调用native方法，修改消费指针的数值偏移加2处理
        soConsumerIndex(index + 2);
        return n;
    }

2、该方法主要阐述了该队列是如何的移除数据的；取出的数据如果为JUMP空对象的话，那么则准备从下一个缓冲区获取数据元素，否则还是从当前的缓冲区对象中移除元素，并且更新消费指针；
```

### 3.6、size()

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    @Override
    public final int size()
    {
        // NOTE: because indices are on even numbers we cannot use the size util.

        /*
         * It is possible for a thread to be interrupted or reschedule between the read of the producer and
         * consumer indices, therefore protection is required to ensure size is within valid range. In the
         * event of concurrent polls/offers to this method the size is OVER estimated as we read consumer
         * index BEFORE the producer index.
         */
        long after = lvConsumerIndex(); // 获取消费指针
        long size;
        while (true) // 为了防止在获取大小的时候指针发生变化，那么则死循环自旋方式获取大小数值
        {
            final long before = after;
            final long currentProducerIndex = lvProducerIndex(); // 获取生产者指针
            after = lvConsumerIndex(); // 获取消费指针

            // 如果后获取的消费指针after和之前获取的消费指针before相等的话，那么说明此刻还没有指针变化
            if (before == after)
            {
                // 那么则直接通过生产指针直接减去消费指针，然后向偏移一位，即除以2，得出最后size大小
                size = ((currentProducerIndex - after) >> 1);

                // 计算完了之后则直接break中断处理
                break;
            }

            // 若消费指针前后不一致，那么可以说是由于并发原因导致了指针发生了变化；
            // 那么则进行下一次循环继续获取最新的指针值再次进行判断
        }
        // Long overflow is impossible, so size is always positive. Integer overflow is possible for the unbounded
        // indexed queues.
        if (size > Integer.MAX_VALUE)
        {
            return Integer.MAX_VALUE;
        }
        else
        {
            return (int) size;
        }
    }

2、获取缓冲区数据大小其实很简单，就是拿着生产指针减去消费指针，但是为了防止并发操作计算错，才用了死循环的方式计算zise值；
```

### 3.7、isEmpty()

```
1、源码：
    // BaseMpscLinkedArrayQueue.java
    @Override
    public final boolean isEmpty()
    {
        // Order matters!
        // Loading consumer before producer allows for producer increments after consumer index is read.
        // This ensures this method is conservative in it's estimate. Note that as this is an MPMC there is
        // nothing we can do to make this an exact method.
        // 这个就简单了，直接判断消费指针和生产指针是不是相等就知道了
        return (this.lvConsumerIndex() == this.lvProducerIndex());
    }

2、通过前面我们已经知道了，添加数据的话生产指针在不停的累加操作，而做移除数据的时候消费指针也在不停的累加操作；

3、那么这种指针总会有一天会碰面的吧，碰面的那个时候则是数据已经空空如也的时刻；
```

## 四、性能测试

```
1、测试Demo：
/**
 * 比较队列的消耗情况。
 *
 * @author hmilyylimh
 * ^_^
 * @version 0.0.1
 * ^_^
 * @date 2018/3/30
 */
public class CompareQueueCosts {

    /** 生产者数量 */
    private static int COUNT_OF_PRODUCER = 2;

    /** 消费者数量 */
    private static final int COUNT_OF_CONSUMER = 1;

    /** 准备添加的任务数量值 */
    private static final int COUNT_OF_TASK = 1 << 20;

    /** 线程池对象 */
    private static ExecutorService executorService;

    public static void main(String[] args) throws Exception {

        for (int j = 1; j < 7; j++) {
            COUNT_OF_PRODUCER = (int) Math.pow(2, j);
            executorService = Executors.newFixedThreadPool(COUNT_OF_PRODUCER * 2);

            int basePow = 8;
            int capacity = 0;
            for (int i = 1; i <= 3; i++) {
                capacity = 1 << (basePow + i);
                System.out.print("Producers: " + COUNT_OF_PRODUCER + "\t\t");
                System.out.print("Consumers: " + COUNT_OF_CONSUMER + "\t\t");
                System.out.print("Capacity: " + capacity + "\t\t");
                System.out.print("LinkedBlockingQueue: " + testQueue(new LinkedBlockingQueue<Integer>(capacity), COUNT_OF_TASK) + "s" + "\t\t");
                // System.out.print("ArrayList: " + testQueue(new ArrayList<Integer>(capacity), COUNT_OF_TASK) + "s" + "\t\t");
                // System.out.print("LinkedList: " + testQueue(new LinkedList<Integer>(), COUNT_OF_TASK) + "s" + "\t\t");
                System.out.print("MpscUnboundedArrayQueue: " + testQueue(new MpscUnboundedArrayQueue<Integer>(capacity), COUNT_OF_TASK) + "s" + "\t\t");
                System.out.print("MpscChunkedArrayQueue: " + testQueue(new MpscChunkedArrayQueue<Integer>(capacity), COUNT_OF_TASK) + "s" + "\t\t");
                System.out.println();
            }
            System.out.println();

            executorService.shutdown();
        }
    }

    private static Double testQueue(final Collection<Integer> queue, final int taskCount) throws Exception {
        CompletionService<Long> completionService = new ExecutorCompletionService<Long>(executorService);

        long start = System.currentTimeMillis();
        for (int i = 0; i < COUNT_OF_PRODUCER; i++) {
            executorService.submit(new Producer(queue, taskCount / COUNT_OF_PRODUCER));
        }
        for (int i = 0; i < COUNT_OF_CONSUMER; i++) {
            completionService.submit((new Consumer(queue, taskCount / COUNT_OF_CONSUMER)));
        }

        for (int i = 0; i < COUNT_OF_CONSUMER; i++) {
            completionService.take().get();
        }

        long end = System.currentTimeMillis();
        return Double.parseDouble("" + (end - start)) / 1000;
    }

    private static class Producer implements Runnable {
        private Collection<Integer> queue;
        private int taskCount;

        public Producer(Collection<Integer> queue, int taskCount) {
            this.queue = queue;
            this.taskCount = taskCount;
        }

        @Override
        public void run() {
            // Queue队列
            if (this.queue instanceof Queue) {
                Queue<Integer> tempQueue = (Queue<Integer>) this.queue;
                while (this.taskCount > 0) {
                    if (tempQueue.offer(this.taskCount)) {
                        this.taskCount--;
                    } else {
                        // System.out.println("Producer offer failed.");
                    }
                }
            }
            // List列表
            else if (this.queue instanceof List) {
                List<Integer> tempList = (List<Integer>) this.queue;
                while (this.taskCount > 0) {
                    if (tempList.add(this.taskCount)) {
                        this.taskCount--;
                    } else {
                        // System.out.println("Producer offer failed.");
                    }
                }
            }
        }
    }

    private static class Consumer implements Callable<Long> {
        private Collection<Integer> queue;
        private int taskCount;

        public Consumer(Collection<Integer> queue, int taskCount) {
            this.queue = queue;
            this.taskCount = taskCount;
        }

        @Override
        public Long call() {
            // Queue队列
            if (this.queue instanceof Queue) {
                Queue<Integer> tempQueue = (Queue<Integer>) this.queue;
                while (this.taskCount > 0) {
                    if ((tempQueue.poll()) != null) {
                        this.taskCount--;
                    }
                }
            }
            // List列表
            else if (this.queue instanceof List) {
                List<Integer> tempList = (List<Integer>) this.queue;
                while (this.taskCount > 0) {
                    if (!tempList.isEmpty() && (tempList.remove(0)) != null) {
                        this.taskCount--;
                    }
                }
            }
            return 0L;
        }
    }
}

2、指标结果：
Producers: 2        Consumers: 1        Capacity: 512       LinkedBlockingQueue: 1.399s     MpscUnboundedArrayQueue: 0.109s     MpscChunkedArrayQueue: 0.09s
Producers: 2        Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 1.462s     MpscUnboundedArrayQueue: 0.041s     MpscChunkedArrayQueue: 0.048s
Producers: 2        Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 0.281s     MpscUnboundedArrayQueue: 0.037s     MpscChunkedArrayQueue: 0.082s

Producers: 4        Consumers: 1        Capacity: 512       LinkedBlockingQueue: 0.681s     MpscUnboundedArrayQueue: 0.085s     MpscChunkedArrayQueue: 0.133s
Producers: 4        Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 0.405s     MpscUnboundedArrayQueue: 0.094s     MpscChunkedArrayQueue: 0.172s
Producers: 4        Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 0.248s     MpscUnboundedArrayQueue: 0.107s     MpscChunkedArrayQueue: 0.153s

Producers: 8        Consumers: 1        Capacity: 512       LinkedBlockingQueue: 1.523s     MpscUnboundedArrayQueue: 0.093s     MpscChunkedArrayQueue: 0.172s
Producers: 8        Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 0.668s     MpscUnboundedArrayQueue: 0.094s     MpscChunkedArrayQueue: 0.281s
Producers: 8        Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 0.555s     MpscUnboundedArrayQueue: 0.078s     MpscChunkedArrayQueue: 0.455s

Producers: 16       Consumers: 1        Capacity: 512       LinkedBlockingQueue: 2.676s     MpscUnboundedArrayQueue: 0.093s     MpscChunkedArrayQueue: 0.753s
Producers: 16       Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 2.135s     MpscUnboundedArrayQueue: 0.093s     MpscChunkedArrayQueue: 0.792s
Producers: 16       Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 0.944s     MpscUnboundedArrayQueue: 0.098s     MpscChunkedArrayQueue: 0.64s

Producers: 32       Consumers: 1        Capacity: 512       LinkedBlockingQueue: 6.647s     MpscUnboundedArrayQueue: 0.078s     MpscChunkedArrayQueue: 2.109s
Producers: 32       Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 3.893s     MpscUnboundedArrayQueue: 0.095s     MpscChunkedArrayQueue: 1.797s
Producers: 32       Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 2.019s     MpscUnboundedArrayQueue: 0.109s     MpscChunkedArrayQueue: 2.427s

Producers: 64       Consumers: 1        Capacity: 512       LinkedBlockingQueue: 26.59s     MpscUnboundedArrayQueue: 0.078s     MpscChunkedArrayQueue: 3.627s
Producers: 64       Consumers: 1        Capacity: 1024      LinkedBlockingQueue: 22.566s    MpscUnboundedArrayQueue: 0.093s     MpscChunkedArrayQueue: 3.047s
Producers: 64       Consumers: 1        Capacity: 2048      LinkedBlockingQueue: 1.719s     MpscUnboundedArrayQueue: 0.093s     MpscChunkedArrayQueue: 2.549s

3、结果分析(一)：
通过结果打印耗时可以明显看到MpscUnboundedArrayQueue耗时几乎大多数都是不超过0.1s的，这添加、删除的操作效率不是一般的高，这也难怪人家netty要舍弃自己写的队列框架了；

4、结果分析(二)：
CompareQueueCosts代码里面我将ArrayList、LinkedList注释掉了，那是因为队列数量太大，List的操作太慢，效率低下，所以在大量并发的场景下，大家还是能避免则尽量避免，否则就遭殃了；
```

## 五、总结

```
1、通过底层无锁的Unsafe操作方式实现了多生产者同时访问队列的线程安全模型；

2、由于使用锁会造成的线程切换，特别消耗资源，因此使用无锁而是采用CAS的操作方式，虽然会在一定程度上造成CPU使用率过高，但是整体上将效率还是听可观的；

3、队列的数据结构是一种单向链表式的结构，通过生产、消费指针来标识添加、移除元素的指针位置，缓冲区与缓冲区之间通过指针指向，避免的数组的复制，较少了大量内存的占用情况；
```